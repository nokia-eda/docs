{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"apps/app-store/","title":"EDA Store","text":""},{"location":"apps/app-store/#overview","title":"Overview","text":"<p>Almost everything in EDA is considered an Application (App), including all the Apps that were installed during the Getting Started - Install step. Apps extend the functionality of EDA by exposing custom resources to the EDA API and MicroPython code that will be executed by EDA whenever such a custom resource is manipulated either by a user or another App.</p> <p>The EDA Store is used to manage the Applications inside EDA. It can be accessed through the UI which provides 3 different views:</p> All Packages List The initial page when opening the EDA Store in the UI will show all the packages known to the EDA Store. Clicking the \"All Packages\" dropdown at the top allows the selection of \"My Packages\". Clicking an App from the list will open the App specific page. My Packages List This view shows all the installed Apps in the current EDA deployment. Clicking on an App from the list will open the App specific page. App Page After clicking on an App in either of the list views, a page will open with specific details from the App. It will show a set of details of the App, and if it has not been installed yet, it will show an install button. If the App has an update available (a new version), an update button will appear. In the future, more details about Apps will become available as the Overview, Documentation and License pages are added to Apps."},{"location":"apps/app-store/#resources","title":"Resources","text":"<p>The EDA Store relies on two different resources in the EDA environment:</p> <code>Catalog</code> A catalog is a git repository that contains the manifests of Apps. A manifest contains all the details of an App and will be discussed further in the Development section. Using the manifests of all the <code>Catalogs</code> registered in EDA, the EDA Store can build a list of all available Apps. <code>Registry</code> While a manifest of an App contains all the details of an App, the actual code and resources of an App are stored in an OCI compliant image. This image needs to be stored in a container registry. This registry must be known to the EDA deployment so the EDA Store can pull the image and use the data in the image to deploy the App. This information is given to EDA in the form of a <code>Registry</code> custom resource."},{"location":"apps/app-store/#installing-an-app","title":"Installing an App","text":"<p>To install an App, you can use the EDA Store UI, select the App from the list and click the \"Install\" button. In the background, this will create a <code>Workflow</code> custom resource in the EDA environment. The EDA Store backend takes this resource and takes the appropriate actions to read the information of the App from its manifest, and make sure the appropriate data is available to EDA, which can include the code of the App, custom resource definitions and more.</p> <p>You can also install an App using <code>kubectl</code> and giving it the correct <code>Workflow</code> custom resource. Here's an example to install the Cloud Connect App:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: connect-nokia\n  namespace: eda-system\nspec:\n  operation: install\n  autoProcessRequirements:\n    - strict\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v3.0.0\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: connect-nokia\n  namespace: eda-system\nspec:\n  operation: install\n  autoProcessRequirements:\n    - strict\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v3.0.0\n\nEOF\n</code></pre> <p>The status of the Workflow shows the progress of the installation. This <code>Workflow</code> resource initiates an app installer job. Once installed, a <code>Manifest</code> resource will be created and the Workflow is done (and the object may be deleted). To see the installed apps using <code>kubectl</code>, you can check their manifests:</p> <pre><code>kubectl get manifests -n eda-system\n</code></pre>"},{"location":"apps/app-store/#uninstalling-an-app","title":"Uninstalling an App","text":"<p>To uninstall an App, you can use the UI. Open the App page, and it will say the currently installed version and to the right, under the general information block, there is a link to \"Uninstall package\". This will remove the App.</p> <p>Alternatively, you can use <code>kubectl</code> commands to delete an app. Creating a new Workflow with a <code>delete</code> operation, will start uninstalling an application. Here's an example to delete the previously created Cloud Connect App.</p> Known Limitations <p>There is no validation yet when uninstalling apps, so make sure all your config is removed before uninstalling.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: delete-connect-nokia\n  namespace: eda-system\nspec:\n  operation: delete\n  autoProcessRequirements:\n    - strict\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v3.0.0\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: delete-connect-nokia\n  namespace: eda-system\nspec:\n  operation: delete\n  autoProcessRequirements:\n    - strict\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v3.0.0\n\nEOF\n</code></pre> <p>Note the difference between installing and uninstalling by the <code>operation</code> field. Changing an already existing Workflow by updating its operation field from <code>install</code> to <code>delete</code> will not trigger a new (un)install job. A new Workflow needs to be created instead.</p> Uninstalling apps with dependencies <p>Trying to delete an app that is required by another app will not be permitted to prevent the second app from malfunctioning. In this case, the EDA store might return an error message saying that the to-be-deleted app is not present. This is a known bug and a more meaningful error message is planned for an upcoming release.</p>"},{"location":"apps/app-store/#app-requirements","title":"App Requirements","text":"<p>App requirement (or app dependency) management plays an important part to make sure that the whole system after (un)installing apps still functions properly. In EDA, apps may expect some resources to exist that are provided by other applications. These need to be installed before (or at the same time as) the dependent app. Deletion of apps may also be blocked if it breaks the requirement of another app. The requirement of an app is defined in its manifest specification, which contains the app and a version constraint (e.g. <code>v3.0.*</code>, <code>&gt;=v3.0.0</code>). The EDA Store makes sure that all the app requirements stay valid at all times to prevent invalid app version configurations.</p> <p>When trying to install an app through the UI, the EDA Store will check if other apps needs to be installed or updated alongside it. You will then be prompted to approve that the EDA store needs to install or upgrade these additional applications.</p> Requirements show the full graph in a flat list <p>The requirements tab in the UI currently shows the full dependency graph in a flat list. So the list does not only include the apps that are required to install app <code>A</code>, but also the apps that require <code>A</code> themselves.</p> Requirement modes using CLI <p>Through the CLI, there is currently only one requirement mode that is the default on what the EDA store is allowed to do:</p> <p><code>strict</code>: The app installer only verifies that the resulting installed apps will be satisfied w.r.t. their requirements. If invalid, the installation will be aborted with an error message denoting what requirement is missing.</p> <p>Other modes are planned in future releases.</p> <p>To specify a mode, pass the <code>autoProcessRequirements</code> field to the workflow spec. See the app installation example for how this is filled in.</p>"},{"location":"apps/fabric/","title":"Fabric","text":"<p>The Fabric application streamlines the construction and deployment of data center fabrics, suitable for environments ranging from small, single-node edge configurations to large, complex multi-tier and multi-pod networks. It automates crucial network configurations such as IP address assignments, VLAN setups, and both underlay and overlay network protocols.</p> <p>Upon deployment, the Fabric application initiates several supporting applications including ISLs (Inter-Switch Links), DefaultRouters, DefaultInterfaces, and DefaultBGPPeers, among others. These applications, in turn, generate node configurations. The operational state of the Fabric is determined by the collective status of these underlying applications.</p>"},{"location":"apps/fabric/#deployment-models","title":"Deployment Models","text":"<p>The Fabric application supports highly flexible deployment models, enabling you to tailor the configuration of your data center fabric to suit different architectural needs. You can deploy a single instance of a Fabric resource to manage the entire data center, incorporating all network nodes, or you can opt to divide your data center into multiple, smaller Fabric instances.</p> <p>For example, you might deploy one Fabric instance to manage the superspine and borderleaf layers while deploying separate Fabric instances for each pod within the data center. This modular approach allows for more granular control.  This can be taken to the extreme where each layer of a datacenter fabric could be its own instance of a Fabric.  The choice is yours!</p> <p>The Fabric application facilitates interconnecting these Fabric instances through the fabricSelector property. This property enables different Fabric instances to work together seamlessly, ensuring that the network functions as a cohesive whole even when managed by multiple instances of the Fabric resource.</p> <p>The fabricSelector is a label selector that selects adjacent Fabrics based on their assigned labels and the criteria specified in the selector. The fabricSelector operates in a unidirectional manner, meaning only the upper layer of the fabric needs to select the downstream fabrics. For example, the instance of the Fabric representing the superspine layer would use a label selector to select the pod Fabrics; the pod Fabrics do not need nor should they to select the superspine layer.  Example found below.</p>"},{"location":"apps/fabric/#selecting-toponodes-topolinks-and-fabrics","title":"Selecting TopoNodes, TopoLinks and Fabrics","text":"<p>The Fabric application configures network nodes, their interswitch links, and the interconnections between different Fabric instances using a mechanism based on label selectors. These selectors identify specific TopoNodes, TopoLinks, and adjacent Fabric instances that correspond to node roles within a typical Clos network architecture\u2014such as Leaf, Spine, Super-spine, and Border-leaf. The role of a node and the interconnections between Fabric instances significantly influence the configuration parameters applied to them, which are determined by additional inputs from the Fabric application such as the selected underlay or overlay network protocols.</p>"},{"location":"apps/fabric/#how-label-selectors-work","title":"How Label Selectors Work","text":"<p>Label selectors are used to filter and select the key-value pairs assigned to TopoNodes, TopoLinks, and other Fabric instances based on specific criteria such as their role within the network. Once these elements are labeled, the Fabric application can automatically apply the necessary configurations.</p>"},{"location":"apps/fabric/#configuring-nodes-links-and-fabrics","title":"Configuring Nodes, Links, and Fabrics","text":"<ol> <li> <p>Initial Labeling:  If TopoNodes, TopoLinks, and adjacent Fabric instances are labeled before the creation of the Fabric instance, the application will automatically generate all necessary configurations for these components during the transaction associated with the addition of the Fabric instance.</p> </li> <li> <p>Post-Deployment Labeling: If new labels that match the Fabric's selection criteria are added to TopoNodes, TopoLinks, or adjacent Fabric instances after the Fabric instance has been deployed, these components will automatically be configured by the Fabric application during the transaction that handles the addition of the labels. This ensures that changes in network topology, roles, or Fabric interconnections are dynamically incorporated into the Fabric's configuration.</p> </li> </ol>"},{"location":"apps/fabric/#example-label-selectors","title":"Example Label Selectors","text":"<ul> <li>Leaf Node Selector: <code>eda.nokia.com/role=leaf</code></li> <li>Spine Node Selector: <code>eda.nokia.com/role=spine</code></li> <li>Fabric Selector: <code>eda.nokia.com/pod=pod1</code></li> </ul>"},{"location":"apps/fabric/#assigning-ip-addresses","title":"Assigning IP Addresses","text":"<p>IP addresses play a critical role in network configuration within the Fabric application. Here's how IP addressing is managed:</p>"},{"location":"apps/fabric/#systemloopback-interfaces","title":"System/Loopback Interfaces","text":"<ul> <li>IPv4 Assignment: IPv4 addresses must be assigned to the primary loopback interface (System or Lo0) of each node.</li> <li>IPv6 Assignment: Optionally, IPv6 addresses can also be configured on these interfaces.</li> </ul>"},{"location":"apps/fabric/#topolink-interfaces","title":"TopoLink Interfaces","text":"<ul> <li>The Fabric application requires the configuration of either IPv4, IPv6 addresses or the use of IPV6 unnumbered on the interfaces selected by the TopoLink label selector under the <code>InterSwitchLinks</code> property . This ensures that all connections within the network are appropriately addressed.</li> </ul>"},{"location":"apps/fabric/#ip-address-allocation-pools","title":"IP Address Allocation Pools","text":"<ul> <li>IP addresses can be automatically assigned from specified IP Address allocation pools. Separate pools are typically used for System interfaces and ISL (Inter-Switch Link) interfaces.</li> <li>Important: The allocation pool referenced for either set of interfaces must exist prior to the deployment of the Fabric application instance to ensure successful IP configuration.</li> </ul> <p>The <code>systemPoolIPV4</code> property must be provided.</p>"},{"location":"apps/fabric/#optional-ip-pools-and-autonomous-systems-per-role","title":"Optional IP Pools and Autonomous Systems per Role","text":"<p>The Fabric application allows for the optional specification of system IP pools and autonomous systems for different roles within the network fabric. These optional configurations can override the global settings.</p> <p>For each role (Leaf, Spine, Superspine, Borderleaf) the following properties may be configured:</p> <ul> <li>Autonomous System: The <code>asnPool</code> property allows for a specific ASN pool to be used for eBGP sessions, override the pools specified under the underlay protocol section.</li> <li>IP Pools: The <code>systemPoolIPV4</code> and <code>systemPoolIPV6</code> properties can be specified to dynamically allocate IP addresses for the System/ lo0 interfaces.</li> </ul>"},{"location":"apps/fabric/#selecting-an-underlay-protocol","title":"Selecting an Underlay Protocol","text":"<p>The Fabric application currently supports a single underlay protocol: eBGP. This section details how eBGP is implemented within the network fabric.</p>"},{"location":"apps/fabric/#ebgp-configuration","title":"eBGP Configuration","text":"<ul> <li>ISL Application: The Fabric app will emit instances of the ISL application to configure both the IP addressing and the BGP peering between nodes on each of the TopoLinks.</li> <li>Autonomous Systems: Like IP addresses, the autonomous systems used by the eBGP sessions are automatically allocated from the specified ASN pool (<code>asnPool</code>).</li> </ul>"},{"location":"apps/fabric/#routing-policies","title":"Routing Policies","text":"<ul> <li>Automatic Generation: If not explicitly specified, the Fabric will automatically generate the required <code>RoutingPolicies</code>. These policies are used in the eBGP peering sessions to ensure IP reachability across the fabric.  However, if RoutingPolicies are defined independently of the Fabric they can be used by specifying the <code>importPolicy</code> and <code>exportPolicy</code> properties.</li> </ul>"},{"location":"apps/fabric/#selecting-an-overlay-protocol","title":"Selecting an Overlay Protocol","text":"<p>The application supports the use of either eBGP or iBGP for transporting the EVPN AFI/SAFI, which are used for overlay services.</p>"},{"location":"apps/fabric/#ebgp-configuration_1","title":"eBGP Configuration","text":"<p>When eBGP is selected as the overlay protocol, it leverages existing eBGP sessions established by the underlay protocol. These sessions are extended to advertise the EVPN address family, in addition to the existing ipv4-unicast and ipv6-unicast families.  It should be noted that the import and export policies specified in the Underlay configuration will be used, any import or export policies specified in the overlay protocol will be ignored.</p>"},{"location":"apps/fabric/#ibgp-configuration","title":"iBGP Configuration","text":"<p>If iBGP is the preferred method for exchanging EVPN routes, additional properties must be configured within the Fabric application:</p> <ul> <li> <p>Autonomous System (<code>autonomousSystem</code>): Specifies the AS used for the establishment of the iBGP session.</p> </li> <li> <p>Route Reflector (RR) Configuration:</p> </li> <li>RR Client Node Selector (<code>rrClientNodeSelector</code>): This label selector identifies TopoNodes to be configured as iBGP RR clients. It also drives the configuration of the selected iBGP RR neighbors if being configured by the Fabric.  Typically, this would select leaf and border leaf nodes.<ul> <li>Example: <code>eda.nokia.com/role=leaf</code></li> </ul> </li> <li>RR IP Addresses (<code>rrIPAddresses</code>): If the Route Reflectors are not configured by the Fabric application, these IP addresses are used to configure the iBGP neighbors on the selected RR clients.</li> <li>RR Node Selector (<code>rrNodeSelector</code>): This label selector identifies TopoNodes to be configured as iBGP Route Reflectors. It also drives the configuration of the selected iBGP RR client neighbors, typically involving spines or border leafs.<ul> <li>Example: <code>eda.nokia.com/role=borderleaf</code></li> </ul> </li> </ul>"},{"location":"apps/fabric/#example-fabric-k8s-crs","title":"Example fabric K8S CRs","text":""},{"location":"apps/fabric/#simple-leaf-spine-fabric","title":"Simple Leaf / Spine Fabric","text":"<code>kubectl</code>YAML <pre><code>cat &lt;&lt; 'EOF' | tee my-fabric.yaml | kubectl apply -f -\napiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: myfabric-1\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n\nEOF\n</code></pre> <pre><code>apiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: myfabric-1\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n</code></pre>"},{"location":"apps/fabric/#verify-the-fabric","title":"Verify the Fabric","text":"<p>Verify the fabric operational state:</p> <pre><code>kubectl get fabrics\n\nNAME           LAST CHANGE   OPERATIONAL STATE\nsunnyvale-dc1   104m          up\n</code></pre>"},{"location":"apps/interfaces/","title":"Interfaces","text":"Description The interfaces application enables the configuration and management of network interfaces across your infrastructure, supporting various interface types including single interfaces, LAGs, and loopback interfaces. Supported OS SR Linux, SR OS Catalog nokia-eda/catalog Source Code coming soon <p>The Interfaces application provides two resources - Interface and Breakout.</p>"},{"location":"apps/interfaces/#interface","title":"Interface","text":"<p> TOPOLOGY \u2192 IInterface</p> <p>The Interface resource declaratively defines abstracted network interfaces for the range of supported network operating systems and supports three primary interface types:</p> <ul> <li>Standard Interface: Individual physical interfaces</li> <li>LAG (Link Aggregation Group): Bundled interfaces operating as a single logical link</li> <li>Loopback: Virtual interfaces for management and routing purposes</li> </ul>"},{"location":"apps/interfaces/#basic-configuration-fields","title":"Basic Configuration Fields","text":"<p>In the basic scenario of configuring a simple interface the following basic configuration fields are typically set:</p> <ul> <li>Type: An interface type - <code>standard</code>, <code>lag</code> or <code>loopback</code>.</li> <li>Members: A list of objects where each object is a reference to a node name and its associated physical interface name.     The interface name is provided in the normalized way, non alphanumerical characters are replaced with <code>-</code> (dash). For example, original interface name <code>ethernet-1/13</code> becomes <code>ethernet-1-13</code>.</li> <li>Enabled State: Interfaces are enabled by default but can be explicitly disabled</li> <li>Description: Optional text description of the interface</li> <li>MTU: Maximum Transmission Unit (range: 1450-9500)</li> </ul> <p>Add the metadata blob that includes the Interface resource Name, Namespace and Labels, and you get a valid EDA resource that you can apply, for example to your Try EDA cluster.</p> <p>When applied, the resource presented below will create a simple physical network interface configuration on the supported network OS with the user-provided values and the resource defaults.</p> YAML<code>kubectl</code> basic Interface resource definition<pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-ethernet-1-13\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: interface\n  description: \"Customer facing interface\"\n  enabled: true\n  mtu: 9000\n  members:\n    - node: leaf1\n      interface: ethernet-1-13\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-ethernet-1-13\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: interface\n  description: \"Customer facing interface\"\n  enabled: true\n  mtu: 9000\n  members:\n    - node: leaf1\n      interface: ethernet-1-13\n\nEOF\n</code></pre>"},{"location":"apps/interfaces/#interface-naming-and-normalization","title":"Interface Naming and Normalization","text":"<p>The Interface application employs a standardized, or normalized, format for interface names within its configurations. This approach ensures consistency when defining interfaces across diverse network operating systems (NOS). The system subsequently translates these normalized names into the specific format required by each target OS.</p> <p>A key aspect of EDA's interface modeling is the use of normalized interface names. Typically, an OS-native interface name like <code>ethernet-1/13</code> is represented as <code>ethernet-1-13</code> in EDA configurations by replacing non-alphanumeric characters (like <code>/</code>) with a dash (<code>-</code>). This normalized name is then used by the system to derive the OS-specific interface identifier.</p> <p>The following subsections detail how these normalized EDA interface names are translated for various supported operating systems, based on the underlying logic.</p>"},{"location":"apps/interfaces/#sr-linux","title":"SR Linux","text":"<ul> <li>Native interface name <code>ethernet-1/1</code> is normalized as <code>ethernet-1-1</code>.</li> <li>Breakout interfaces like <code>ethernet-1/1/1</code> become <code>ethernet-1-1-1</code>.</li> <li>Loopback interfaces such as <code>lo0</code> translate to <code>loopback-0</code>.</li> <li>LAG interfaces like <code>lag10</code> translate to <code>lag-10</code>.</li> </ul>"},{"location":"apps/interfaces/#sr-os","title":"SR OS","text":"<ul> <li>Native port identifier <code>1/1/1</code> translates to <code>ethernet-1-a-1</code> name, where \"a\" is the first MDA on a 1<sup>st</sup> line card.</li> <li>The system supports more complex mappings for different hardware configurations:<ul> <li>Port <code>2/2/1</code> translates to <code>ethernet-2-b-1</code> (representing linecard 2, MDA \"b\"<sup>2</sup>, port 1).</li> <li>Breakout (implicit MDA 1): <code>1/1/c1/1</code> translates to <code>ethernet-1-1-1</code>.</li> <li>Breakout (explicit \"a\" for MDA 1): <code>1/1/c2/1</code> translates to <code>ethernet-1-a-2-1</code> (where MDA \"a\" maps to 1, and \"2-1\" defines the port as <code>c2/1</code>).</li> <li>XIOM MDA: <code>1/x1/1/1</code> translates to <code>ethernet-1-1-a-1</code>.</li> </ul> </li> <li>Loopback interfaces like <code>lo0</code> become <code>loopback-0</code>.</li> <li>LAG interfaces retain names like <code>lag-10</code>.</li> </ul>"},{"location":"apps/interfaces/#ethernet-configuration","title":"Ethernet Configuration","text":"<p>The Interface application provides extensive Ethernet-specific configurations through the <code>ethernet</code> property, including:</p> <ul> <li>Speed: Interface speed (100G, 40G, 25G, 10G, 1G, etc.)</li> <li>Forward Error Correction (FEC): Various FEC modes (disabled, rs528, rs544, baser, rs108)</li> <li>Timers: Hold-up, hold-down, and reload delay timers</li> <li>Storm Control: Traffic rate limiting for broadcast, multicast, and unknown unicast</li> <li>L2CP Protocol Transparency: Configuration for tunneling various L2CP protocols</li> </ul>"},{"location":"apps/interfaces/#storm-control-configuration","title":"Storm Control Configuration","text":"<p>Storm control helps protect the network from traffic storms by setting rate limits:</p> YAML<code>kubectl</code> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: example-interface\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: interface\n  description: \"Customer facing interface with storm control enabled\"\n  enabled: true\n  mtu: 9000\n  ethernet:\n    stormControl:\n      enabled: true\n      units: kbps\n      broadcastRate: 1000000\n      multicastRate: 1000000\n      unknownUnicastRate: 1000000\n  members:\n    - node: leaf-1\n      interface: ethernet-1-1\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: example-interface\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: interface\n  description: \"Customer facing interface with storm control enabled\"\n  enabled: true\n  mtu: 9000\n  ethernet:\n    stormControl:\n      enabled: true\n      units: kbps\n      broadcastRate: 1000000\n      multicastRate: 1000000\n      unknownUnicastRate: 1000000\n  members:\n    - node: leaf-1\n      interface: ethernet-1-1\nEOF\n</code></pre>"},{"location":"apps/interfaces/#lag-configuration","title":"LAG Configuration","text":"<p>Link Aggregation Groups (LAGs) provide link redundancy and increased bandwidth. The Interface application supports both regular/local LAGs (with static and LACP-based configurations) as well as ESI-based<sup>1</sup> multihoming LAGs.</p> <p>The following set of Interface objects is relevant for the LAG interface configuration:</p> <ul> <li>Minimum Links: Minimum required number of active links in a LAG to be operational</li> <li>LACP Settings: Mode, interval, system priority, and admin key</li> <li>Multi-homing: ESI configuration for multi-chassis operation</li> </ul>"},{"location":"apps/interfaces/#example-lag-configuration","title":"Example LAG Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-simple-lag\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: lag\n  description: \"Customer facing lag\"\n  enabled: true\n  mtu: 9000\n  lag:\n    type: lacp\n    minLinks: 2\n    lacp:\n      mode: active\n      interval: fast\n      systemPriority: 32768\n  members:\n    - node: leaf1\n      interface: ethernet-1-14\n    - node: leaf1\n      interface: ethernet-1-15\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-simple-lag\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: lag\n  description: \"Customer facing lag\"\n  enabled: true\n  mtu: 9000\n  lag:\n    type: lacp\n    minLinks: 2\n    lacp:\n      mode: active\n      interval: fast\n      systemPriority: 32768\n  members:\n    - node: leaf1\n      interface: ethernet-1-14\n    - node: leaf1\n      interface: ethernet-1-15\n\nEOF\n</code></pre>"},{"location":"apps/interfaces/#multi-homing-support","title":"Multi-homing Support","text":"<p>The Interface application supports sophisticated multi-homing configurations for LAGs based on EVPN standard, enabling high availability and load balancing:</p> <ul> <li>Modes: all-active, single-active, or port-active</li> <li>ESI: Ethernet Segment Identifier configuration</li> <li>Active Node Preference: Preferred node selection for single-active scenarios</li> <li>Revertive Behavior: Controls failback behavior</li> </ul>"},{"location":"apps/interfaces/#multi-homing-configuration-example","title":"Multi-homing Configuration Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-leaf2-simple-mh-lag\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: lag\n  description: \"Customer facing multihoming lag\"\n  enabled: true\n  mtu: 9000\n  lag:\n    type: lacp\n    minLinks: 2\n    multihoming:\n      mode: all-active\n      preferredActiveNode: leaf1\n      revertive: true\n    lacp:\n      mode: active\n      interval: fast\n      systemPriority: 32768\n  members:\n    - node: leaf1\n      interface: ethernet-1-20\n    - node: leaf2\n      interface: ethernet-1-20\n</code></pre> <pre><code>cat &lt;&lt; 'EOF'  | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-leaf2-simple-mh-lag\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: lag\n  description: \"Customer facing multihoming lag\"\n  enabled: true\n  mtu: 9000\n  lag:\n    type: lacp\n    minLinks: 2\n    multihoming:\n      mode: all-active\n      preferredActiveNode: leaf1\n      revertive: true\n    lacp:\n      mode: active\n      interval: fast\n      systemPriority: 32768\n  members:\n    - node: leaf1\n      interface: ethernet-1-20\n    - node: leaf2\n      interface: ethernet-1-20\n\nEOF\n</code></pre>"},{"location":"apps/interfaces/#operational-state","title":"Operational State","text":"<p>The Interface application maintains detailed operational state information, including:</p> <ul> <li>Administrative and operational status</li> <li>Interface speed</li> <li>Last state change timestamp</li> <li>Member status and neighbor discovery</li> <li>LAG-specific operational details</li> </ul> <p>You can verify the interface operational state using:</p> <pre><code>kubectl -A get interfaces\n</code></pre> <pre><code>NAME               ENABLED   OPERATIONAL STATE   SPEED   LAST CHANGE   AGE\ncustomer-facing    true      up                 100G    2m            10m\n</code></pre>"},{"location":"apps/interfaces/#breakout","title":"Breakout","text":"<p> TOPOLOGY \u2192 BBreakout</p> <p>The Breakout resource allows for the configuration of interface breakouts on specified Nodes. This resource specifies the Nodes, parent Interfaces, the number of breakout channels, and the speed of each channel.</p>"},{"location":"apps/interfaces/#configuration-fields","title":"Configuration Fields","text":"<ul> <li><code>node</code>: A list of references to TopoNodes where the parent interfaces are to be broken out.</li> <li><code>interface</code>: A list of normalized parent interface/port names to be broken out.</li> <li><code>channels</code>: (Required) The number of breakout channels to create (integer, min: 1, max: 8).</li> <li><code>speed</code>: (Required) The speed of each breakout channel. Supported speeds are: 800G, 400G, 200G, 100G, 50G, 40G, 25G, 10G.</li> <li><code>nodeSelector</code>: An alternative way to specify the TopoNode(s) where the parent interfaces are to be broken out.</li> </ul>"},{"location":"apps/interfaces/#example-breakout-configuration","title":"Example Breakout Configuration","text":"<p>This example demonstrates how to configure a breakout port.</p> YAML<code>kubectl</code> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Breakout\nmetadata:\n  name: breakout-example\n  namespace: default\nspec:\n  node:\n    - node-1 # Name of the TopoNode\n  interface:\n    - ethernet-1-1 # Name of the parent interface on node-1\n  channels: 4\n  speed: 100G\n</code></pre> <pre><code>cat &lt;&lt; 'EOF'  | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Breakout\nmetadata:\n  name: breakout-example\n  namespace: default\nspec:\n  node:\n    - node-1 # Name of the TopoNode\n  interface:\n    - ethernet-1-1 # Name of the parent interface on node-1\n  channels: 4\n  speed: 100G\nEOF\n</code></pre> <ol> <li> <p>A standards-based alternative to proprietary Multi-chassis LAGs.\u00a0\u21a9</p> </li> <li> <p>Letter \"b\" means 2<sup>nd</sup> MDA.\u00a0\u21a9</p> </li> </ol>"},{"location":"apps/kafka-exporter/","title":"Kafka Exporter","text":"Description Kafka Exporter publishes network data to a Kafka broker. Author Nokia Supported OS SR Linux, SR OS Catalog nokia-eda/catalog Language Go Source Code coming soon"},{"location":"apps/kafka-exporter/#installation","title":"Installation","text":"<p>The Kafka Exporter app can be installed using EDA Store or by running the <code>app-install</code> workflow with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: kafka-exporter-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: kafka.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: kafka-exporter-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: kafka.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n\nEOF\n</code></pre>"},{"location":"apps/kafka-exporter/#configuration","title":"Configuration","text":"<p>After installation, you can configure the Kafka Exporter using a <code>Producer</code> or a <code>ClusterProducer</code> Custom Resources (CR).</p> <p>The CR specifies the data to be exported, the Kafka broker settings and the messages delivery behavior.</p> <p>The <code>Producer</code> CR is namespace specific and is used to export data only from its own namespace. While the <code>ClusterProducer</code> CR is created in the EDA base namespace (<code>eda-system</code>) and allows to export data from any user namespace.</p>"},{"location":"apps/kafka-exporter/#what-to-export","title":"What to export","text":"<p>Define the data to be exported.</p> <ul> <li> <p>Export Paths: <code>.spec.exports[].path</code></p> <p>Specifies the paths in the state DB to export, e.g., <code>.namespace.node.srl.interface</code>.</p> <p>For a <code>Producer</code> CR the <code>.namespace</code> prefix can be omitted.</p> </li> <li> <p>Fields: <code>.spec.exports[].fields</code></p> <p>Lists the fields to include in the exported data. If not specified, all fields under the path are included.</p> </li> <li> <p>Where Query: <code>.spec.exports[].where</code></p> <p>A filter for the data, e.g., <code>oper-state = down</code>. Only matching data will be exported.</p> </li> </ul>"},{"location":"apps/kafka-exporter/#where-are-we-exporting-it","title":"Where are we exporting it","text":"<p>Specify the destination and security settings for the export</p> <ul> <li> <p>Broker Addresses: <code>.spec.brokers</code></p> <p>Comma-separated list of Kafka broker addresses to connect to, e.g., <code>broker1:9092,broker2:9092</code>.</p> </li> <li> <p>Security Settings:</p> <ul> <li> <p>SASL: <code>.spec.sasl</code></p> <ul> <li><code>user</code>: Kafka username.</li> <li><code>password</code>: Kafka password.</li> <li><code>mechanism</code>: Authentication mechanisms such as <code>plain</code>, <code>scram-sha-256</code>,<code>scram-sha-512</code> or <code>oauthbearer</code>.</li> <li><code>token-url</code>: The token URL when <code>mechanism</code> is <code>oauthbearer</code>.</li> </ul> </li> <li> <p>TLS: <code>.spec.tls</code></p> <p>Certificate-based authentication for secure communication. Includes:</p> <ul> <li><code>cert-file</code>: Path to the client certificate file.</li> <li><code>key-file</code>: Path to the client private key file.</li> <li><code>ca-file</code>: Path to the certificate authority file.</li> <li><code>skip-verify</code>: whether the producer should verify the broker's certificate</li> </ul> </li> </ul> </li> </ul>"},{"location":"apps/kafka-exporter/#how-are-we-doing-all-that","title":"How are we doing all that?","text":"<p>Set how often or when data is exported and what kind of acknowledgment is required.</p> <ul> <li> <p>Message Delivery Mode:</p> <ul> <li><code>.spec.sync-producer</code>: Use synchronous messaging (<code>true</code>) or asynchronous messaging (<code>false</code>).</li> <li><code>.spec.flush-frequency</code>: Defines how long messages can sit in the producer's buffer before being batch sent to the broker.</li> </ul> </li> <li> <p>Acknowledgment Level: <code>.spec.required-acks</code></p> <ul> <li><code>no-response</code>: No acknowledgment required.</li> <li><code>wait-for-local</code>: Acknowledged by the leader broker only.</li> <li><code>wait-for-all</code>: Acknowledged by all in-sync replicas.</li> </ul> </li> <li> <p>Compression Codec: <code>.spec.compression-codec</code></p> <ul> <li>Options: <code>none</code>, <code>gzip</code>, <code>snappy</code>, <code>zstd</code>, <code>lz4</code>.</li> </ul> </li> <li> <p>Retry and Timeout:</p> <ul> <li><code>.spec.max-retry</code>: Number of retries for failed message delivery (default: 3).</li> <li><code>.spec.timeout</code>: Timeout duration for producer operations (default: 10 seconds).</li> </ul> </li> <li> <p>Export Frequency: <code>.spec.exports[].period</code></p> <ul> <li>Interval for periodic exports (minimum: 10 seconds).</li> </ul> </li> <li> <p>Export Triggers: <code>.spec.exports[].mode</code></p> <ul> <li><code>on-change</code>: Export data when it changes.</li> <li><code>periodic</code>: Export data at regular intervals.</li> <li><code>periodic-on-change</code>: Combine both periodic and change-based exports.</li> </ul> </li> </ul>"},{"location":"apps/kafka-exporter/#usage-examples","title":"Usage Examples","text":""},{"location":"apps/kafka-exporter/#producer","title":"Producer","text":"YAML<code>kubectl</code> <pre><code>apiVersion: kafka.eda.nokia.com/v1alpha1\nkind: Producer\nmetadata:\n  name: kafka-producer\n  namespace: eda\nspec:\n  brokers: \"broker1:9092,broker2:9092\"\n  required-acks: wait-for-local\n  max-retry: 3\n  timeout: \"10s\"\n  compression-codec: gzip\n  exports:\n    - topic: \"interface-state\"\n      path: \".node.srl.interface\"\n      fields:\n        - admin-state\n        - oper-state\n      where: 'admin-state = \"enable\"'\n      period: \"60s\"\n      mode: periodic-on-change\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: kafka.eda.nokia.com/v1alpha1\nkind: Producer\nmetadata:\n  name: kafka-producer\n  namespace: eda\nspec:\n  brokers: \"broker1:9092,broker2:9092\"\n  required-acks: wait-for-local\n  max-retry: 3\n  timeout: \"10s\"\n  compression-codec: gzip\n  exports:\n    - topic: \"interface-state\"\n      path: \".node.srl.interface\"\n      fields:\n        - admin-state\n        - oper-state\n      where: 'admin-state = \"enable\"'\n      period: \"60s\"\n      mode: periodic-on-change\n\nEOF\n</code></pre>"},{"location":"apps/kafka-exporter/#clusterproducer","title":"ClusterProducer","text":"YAML<code>kubectl</code> <pre><code>apiVersion: kafka.eda.nokia.com/v1alpha1\nkind: ClusterProducer\nmetadata:\n  name: kafka-cluster-producer\n  namespace: eda-system\nspec:\n  brokers: \"broker1:9092,broker2:9092\"\n  required-acks: wait-for-local\n  max-retry: 3\n  timeout: \"10s\"\n  compression-codec: gzip\n  exports:\n    - topic: \"interface-state\"\n      path: \".namespace.node.srl.interface\"\n      fields:\n        - admin-state\n        - oper-state\n      where: 'admin-state = \"enable\"'\n      period: \"60s\"\n      mode: periodic-on-change\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: kafka.eda.nokia.com/v1alpha1\nkind: ClusterProducer\nmetadata:\n  name: kafka-cluster-producer\n  namespace: eda-system\nspec:\n  brokers: \"broker1:9092,broker2:9092\"\n  required-acks: wait-for-local\n  max-retry: 3\n  timeout: \"10s\"\n  compression-codec: gzip\n  exports:\n    - topic: \"interface-state\"\n      path: \".namespace.node.srl.interface\"\n      fields:\n        - admin-state\n        - oper-state\n      where: 'admin-state = \"enable\"'\n      period: \"60s\"\n      mode: periodic-on-change\n\nEOF\n</code></pre> <p>Also check out EDA Telemetry demo lab for Kafka exporter usage examples.</p>"},{"location":"apps/netbox/","title":"NetBox","text":"Description The EDA NetBox app integrates with NetBox to synchronize EDA resources with NetBox Supported OS N/A Catalog EDA built in apps Source Code coming soon"},{"location":"apps/netbox/#overview","title":"Overview","text":"<p>The NetBox app enables users to integrate/synchronize various resources between NetBox and EDA by providing the following resource types:</p> <ul> <li>Instance: Defines the target NetBox instance to interact with.</li> <li>Allocation: Specifies the type of EDA allocation to create based on the NetBox's <code>Prefixes</code>.</li> </ul> <p>Corresponding Instance and Allocation resources must be created in the same (non-<code>eda-system</code>) namespace.</p> <p>EDA continues to use its own allocation pools for IP addresses, indices and subnets, but the NetBox app will dynamically create the allocation pools based on the NetBox's <code>IPAM &gt; Prefixes</code> objects and post the allocated objects back to NetBox.</p> <p>This mode of operation allows the users to leverage NetBox's IPAM features and dynamically create the allocation pools in EDA. Check out the end-to-end example for more details.</p>"},{"location":"apps/netbox/#supported-objects","title":"Supported objects","text":"<p>In the current version of the NetBox app EDA's allocation pools are created based on the NetBox Prefix objects. Depending on the Prefix's Status mode, the allocation pools of certain type can be created.</p> Prefix Status Suitable EDA Allocation Pools Example usage in EDA Active IP Address (<code>IPAllocationPool</code>),IP Address + Mask (<code>IPInSubnetAllocationPool</code>) System IPManagement IP Container Subnet (<code>SubnetAllocationPool</code>) ISL subnet <p>More objects will be supported in the future.</p>"},{"location":"apps/netbox/#netbox-configuration","title":"NetBox Configuration","text":""},{"location":"apps/netbox/#create-a-webhook","title":"Create a Webhook","text":"<p>The Webhook in NetBox is triggered by the NetBox's Event Rule and allows NetBox to send updates to the EDA app.</p> <ul> <li>Name: Any meaningful identifier</li> <li> <p>URL: <code>https://${EDA_ADDR}:${EDA_PORT}/core/httpproxy/v1/netbox/webhook/${INSTANCE_NAMESPACE}/${INSTANCE_NAME}</code>       Replace the <code>${INSTANCE_NAMESPACE}</code> with the EDA namespace name you will use to create the NetBox Instance custom resource later. The <code>${INSTANCE_NAME}</code> should be the name of the NetBox Instance custom resource you will create in the Instance Customer Resource section.</p> <p>For example, if you want to create EDA-NetBox integration for the EDA Allocation pools in the <code>eda</code> namespace, and you will name your NetBox Instance CR simply <code>netbox</code>, then the URL will be:</p> <pre><code>https://youredaaddress.com:9443/core/httpproxy/v1/netbox/webhook/eda/netbox\n</code></pre> </li> <li> <p>Method: <code>POST</code></p> </li> <li>Secret: Choose a signature secret (plaintext string) that will be used to validate the webhook request. The matching Kubernetes secret with the same string will be created later in the Kubernetes Secrets section.</li> <li>SSL verification: Based on your setup either leave SSL verification enabled or disable it.</li> <li>Leave all other settings as default.</li> </ul>"},{"location":"apps/netbox/#create-an-event-rule","title":"Create an Event Rule","text":"<p>An event rule is used to trigger webhook based on the events happening in NetBox. You will find the Event Rules menu item under the Integrations section in NetBox.</p> <ul> <li>Name: Choose a relevant name</li> <li>Objects: Include IPAM\u00a0IPAddresses and IPAM\u00a0Prefixes</li> <li>Enabled: Yes</li> <li> <p>Event Types:</p> <ul> <li>Object created</li> <li>Object updated</li> <li>Object deleted</li> </ul> </li> <li> <p>Action:</p> <ul> <li>Type: Webhook</li> <li>Webhook: Select the one created above</li> </ul> </li> </ul>"},{"location":"apps/netbox/#generate-an-api-token","title":"Generate an API Token","text":"<p>Using the Admin \u2192 Authentication \u2192 API Tokens menu create a NetBox API token for the NetBox user that EDA app will use. Enable write permission for the API token.</p>"},{"location":"apps/netbox/#configure-user-permissions","title":"Configure User Permissions","text":"<p>In the Admin \u2192 Authentication \u2192 Permissions menu, grant the user you created the API token for the permissions to <code>create</code>, <code>update</code>, and <code>delete</code> for the following objects:</p> <ul> <li><code>IPAM &gt; IPAddress</code></li> <li><code>IPAM &gt; Prefix</code></li> <li><code>Extras &gt; Tag</code> (a.k.a <code>Customizations.Tags</code> in earlier versions)</li> <li><code>Extras &gt; Custom Field</code> (a.k.a <code>Customizations.CustomFields</code> in earlier versions)</li> </ul>"},{"location":"apps/netbox/#configure-global-vrf-setting","title":"Configure Global VRF Setting","text":"<p>Starting with NetBox 4.2.6, the <code>ENFORCE_GLOBAL_UNIQUE</code> setting has been flipped to <code>true</code>, this may have negative effect on EDA installations that use multiple topologies using the same IP addressing.</p> <p>As per the NetBox documentation, to relax this enforcement change the configuration setting of the global VRF via environment variable or in the <code>configuration.py</code> file.</p> <pre><code>ENFORCE_GLOBAL_UNIQUE=false\n</code></pre>"},{"location":"apps/netbox/#tags","title":"Tags","text":"<p>In case you plan to have more than one \"NetBox Prefix\" \u2192 \"EDA allocation pool\" mapping, you will need to create a tag in NetBox for each distinct allocation pool and assign it to the Prefix object in NetBox.</p> <p>In the EDA Allocation resource you then reference the tag name in the <code>tags</code> field and the allocation pool will be created based on the prefixes with that tag.</p>"},{"location":"apps/netbox/#kubernetes-secrets","title":"Kubernetes Secrets","text":"<p>The NetBox API Token and the Webhook secret must be created as Kubernetes Secrets in the same namespace where the EDA NetBox app will run (example: <code>eda</code>). The data for these secrets must be provided as base64 encoded strings.</p> <p>Secret for the webhook:</p> YAML<code>kubectl</code> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-webhook-signature\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded signature key that NetBox will use\n  signatureKey: ${NETBOX_WEBHOOK_SIGNATURE_KEY}\n</code></pre> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-webhook-signature\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded signature key that NetBox will use\n  signatureKey: ${NETBOX_WEBHOOK_SIGNATURE_KEY}\nEOF\n</code></pre> <p>Secret for the API Token:</p> YAML<code>kubectl</code> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-api-token\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded NetBox API token with IPAM permissions\n  apiToken: ${NETBOX_API_TOKEN}\n</code></pre> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-api-token\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded NetBox API token with IPAM permissions\n  apiToken: ${NETBOX_API_TOKEN}\nEOF\n</code></pre>"},{"location":"apps/netbox/#eda-configuration","title":"EDA Configuration","text":""},{"location":"apps/netbox/#installation","title":"Installation","text":"<p>Install the NetBox app from the EDA Store or with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: netbox-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: netbox.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v2.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: netbox-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: netbox.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v2.0.0\n\nEOF\n</code></pre>"},{"location":"apps/netbox/#instance-resource","title":"Instance Resource","text":"<p>Defines connection details to the NetBox instance from the EDA NetBox app:</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Instance\nmetadata:\n  name: netbox1\n  namespace: eda\nspec:\n  url: http://${NETBOX_ADDR}:${NETBOX_PORT}\n  # Name of a secret containing the base64-encoded API token\n  # under the `apiToken` key\n  apiToken: netbox-api-token\n  # Name of a secret containing the base64-encoded signature key\n  # under the `signatureKey` key\n  signatureKey: netbox-webhook-signature\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Instance\nmetadata:\n  name: netbox1\n  namespace: eda\nspec:\n  url: http://${NETBOX_ADDR}:${NETBOX_PORT}\n  # Name of a secret containing the base64-encoded API token\n  # under the `apiToken` key\n  apiToken: netbox-api-token\n  # Name of a secret containing the base64-encoded signature key\n  # under the `signatureKey` key\n  signatureKey: netbox-webhook-signature\nEOF\n</code></pre> <p>The NetBox Instance resource requires a user to provide names of the two Kubernetes secrets created in the same namespace where the Instance is deployed:</p> <ol> <li>The <code>apiToken</code> field references the secret containing the NetBox API Token.</li> <li>The <code>webhookSignatureSecret</code> field references the secret containing the Webhook signature secret.</li> </ol> <p>After creation, check the status of the Instance resource to verify successful connection.</p>"},{"location":"apps/netbox/#allocation-resource","title":"Allocation Resource","text":"<p>With Allocation resource a user specifies which NetBox Prefixes should create which EDA allocation pools.</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: netbox-isl-pool\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox  # &lt;-- Reference to the Instance resource\n  tags:\n    - eda-isl-pool  # &lt;-- Must match tags on NetBox prefixes\n  type: subnet      # &lt;-- One of: ip-address, subnet, ip-in-subnet\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: netbox-isl-pool\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox  # &lt;-- Reference to the Instance resource\n  tags:\n    - eda-isl-pool  # &lt;-- Must match tags on NetBox prefixes\n  type: subnet      # &lt;-- One of: ip-address, subnet, ip-in-subnet\nEOF\n</code></pre> <p>The name of the Allocation resource will drive the name of the EDA allocation pool.</p> <p>With tags a user selects which tagged Prefixes from NetBox would be \"mapped\" to this Allocation resource. Since NetBox prefixes don't have a unique name, the tags are used to identify the Prefixes.</p> <p>A single NetBox prefix object can be mapped to three different allocation pools in EDA depending on the type specified in the Allocation resource.</p> Type Resource Created Typical\u00a0Use <code>ip-address</code> <code>ipallocationpools.core.eda.nokia.com</code> IP Addresses\u00a0\u2192 System IPs <code>ip-in-subnet</code> <code>ipinsubnetallocationpools.core.eda.nokia.com</code> IP Addresses\u00a0+\u00a0Masks\u00a0\u2192 Management IP <code>subnet</code> <code>subnetallocationpools.core.eda.nokia.com</code> Subnets\u00a0\u2192 ISL\u00a0links <p>Consult with the Supported Objects section to see what status a NetBox prefix must have to be compatible with the desired allocation pool type.</p> <p>The status field of the Allocation resource is used to track the matching allocations. For example, consider the following status block in the Allocation resource:</p> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-systemip-v4\n  namespace: eda\n  labels: {}\n  annotations: {}\nspec:\n  enabled: true\n  instance: netbox\n  tags:\n    - eda-systemip-v4\n  type: ip-address\n  description: ''\n  subnetLength: null\nstatus:\n  matchedPrefixes:\n    - id: 3\n      prefix: 192.168.10.0/24\n      tags:\n        - eda-systemip-v4\n  lastEvent: ''\n  lastEventStatus: ''\n  lastEventTime: null\n</code></pre> <p>It indicates that the incoming via Webhook NetBox prefix <code>192.168.10.0/24</code> tagged with the <code>eda-systemip-v4</code> tag was recorded with the ID <code>3</code> for this Allocation resource.</p>"},{"location":"apps/netbox/#example","title":"Example","text":"<p>In this example, we will demonstrate how EDA/NetBox integration works by creating two Prefix objects in NetBox for System IPs and inter-switch link subnets that will be synchronized to EDA and result in two Allocation pools in EDA. The two pools will then be used to instantiate a Fabric in EDA and through that we will</p> <p>We will install a demo NetBox instance<sup>1</sup> in the same cluster that runs EDA using helm and the netbox chart v6.0.33:</p> <pre><code>helm install netbox-server oci://ghcr.io/netbox-community/netbox-chart/netbox \\\n    --create-namespace \\\n    --namespace=netbox \\\n    --set superuser.password=netbox \\\n    --set enforceGlobalUnique=false \\ #(1)!\n    --version 6.0.33 #(2)!\n</code></pre> <ol> <li><code>enforceGlobalUnique=false</code> allows configures the global VRF of NetBox to allow duplicate IP addresses. The duplicated IP addresses may be created by EDA when distinct topologies use the same IP addressing.</li> <li>We fix the chart version to ensure the reproducibility of the example, but there is no hard dependency on the chart version.</li> </ol> <p>The NetBox instance will take a few minutes to start, you can monitor the pods in the <code>netbox</code> namespace<sup>2</sup> and once all pods are up and running, expose the NetBox instance:</p> <pre><code>kubectl -n netbox port-forward svc/netbox-server 45123:80\n</code></pre> <p>You should now be able to login to the NetBox UI via <code>http://localhost:45123</code> using <code>admin:netbox</code> credentials.</p> <p>Then install the NetBox EDA app using one of the documented methods.</p> NetBox configuration Webhook <p>Go to Operations \u2192 Integrations \u2192 Webhook in NetBox UI and create a webhook with the following values:</p> <ul> <li>Name: <code>eda</code></li> <li> <p>URL: <code>https://${EDA_ADDR}:${EDA_PORT}/core/httpproxy/v1/netbox/webhook/eda/netbox</code>     Replace <code>${EDA_ADDR}</code> and <code>${EDA_PORT}</code> with the address and port of the EDA instance you use.</p> </li> <li> <p>Secret: <code>eda</code></p> </li> <li>SSL verification: disabled</li> </ul> Event Rule <p>Go to Operations \u2192 Integrations \u2192 Event Rules in NetBox UI and create an Event Rule that will trigger the Webhook with the following fields set:</p> <ul> <li>Name: <code>eda</code></li> <li>Object types:<ul> <li><code>IPAM &gt; IP Address</code></li> <li><code>IPAM &gt; Prefix</code></li> </ul> </li> <li>Enabled: checked</li> <li>Event types: <code>Object created</code> <code>Object deleted</code> <code>Object updated</code></li> <li>Action type: <code>Webhook</code></li> <li>Webhook: <code>eda</code> (the name of the webhook we created above)</li> </ul> API Token and Permissions <p>Normally you would generate a new API token for the user you want to use for API access, but since the demo instance of NetBox that we installed with the Helm chart already contains an API token for the <code>admin</code> user, we will just use it, instead of generating a new one.</p> Create secrets <p>Now we need to create the Kubernetes secrets for the generated API Token and the Webhook signature secret.</p> <p>The inputs to the secrets should be in base64 format, therefore the snippets below run the raw inputs through <code>base64</code> command to convert them to base64 format.</p> <p>We install the secrets in the <code>eda</code> namespace - the default namespace your EDA installation comes with. If you use another namespace, adjust the namespace name accordingly.</p> Token secretWebhook signature secretToken secret (regular installation) <p>The NetBox Helm chart used in this example creates a Kubernetes secret <code>netbox/netbox-server-superuser</code> which contains the API token for the <code>admin</code> user. We will use the existing token value as is:</p> <pre><code>NETBOX_API_TOKEN=$(kubectl -n netbox get secret netbox-server-superuser -o jsonpath='{.data.api_token}')\ncat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-api-token\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded NetBox API token with IPAM permissions\n  apiToken: ${NETBOX_API_TOKEN}\nEOF\n</code></pre> <pre><code>NETBOX_WEBHOOK_SIGNATURE_KEY=$(echo -n \"eda\" | base64)\ncat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-webhook-signature\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded signature key that NetBox will use\n  signatureKey: ${NETBOX_WEBHOOK_SIGNATURE_KEY}\nEOF\n</code></pre> <p>In case you are repeating this exercise without using NetBox Helm chart, or if you run a non-admin user, you will need to generate the API Token manually.</p> <pre><code>NETBOX_API_TOKEN=$(base64 &lt;&lt;&lt; \"yourTokenHere\")\ncat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-api-token\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded NetBox API token with IPAM permissions\n  apiToken: ${NETBOX_API_TOKEN}\nEOF\n</code></pre> Prefixes and Tags <p>As per the task of this example we need to create two prefixes in NetBox, one for the System IPs and one for the subnets used by our Fabric app to assign addresses on the point-to-point interswitch links.</p> <p>We will also create a tag for each of the prefixes, such that we can use the tags to identify each prefix in EDA's Allocation resource.</p> <p>Starting with the System IPs prefix, we first create a Tag using the Customization \u2192 Tags NetBox menu, we will name the tag simply <code>eda-systemip-v4</code>. Then create a prefix in IPAM \u2192 Prefixes NetBox menu and specify the <code>192.168.10.0/24</code> prefix with the Status=Active and assign the <code>eda-systemip-v4</code> tag to it.</p> <p>Next, we need to create a Prefix for our interswitch links. In EDA, the Fabric app uses the allocation pool of type \"subnet\" to then assign point-to-point addresses to each end of the interswitch link. This means, that the Prefix in NetBox would need to be created with the <code>Container</code> status, as this would indicate that the Prefix is a container for sub-prefixes. Exactly what we need.</p> <p>We create the <code>eda-isl-v6</code> tag first and then the Prefix <code>2005::/64</code> with the Status=Container and this tag assigned.</p> EDA configuration <p>Switching to EDA. Install the NetBox app if you haven't done already and proceed with creation of the NetBox Instance resource as per the documentation.</p> <p>We are using the names of the Kubernetes secrets we created a moment ago for the API Token and the Webhook signature key. And since we deployed the NetBox inside the same cluster, we know the DNS name of the service it uses.</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Instance\nmetadata:\n  name: netbox\n  namespace: eda\nspec:\n  url: http://netbox-server.netbox.svc.cluster.local\n  apiToken: netbox-api-token\n  signatureKey: netbox-webhook-signature\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Instance\nmetadata:\n  name: netbox\n  namespace: eda\nspec:\n  url: http://netbox-server.netbox.svc.cluster.local\n  apiToken: netbox-api-token\n  signatureKey: netbox-webhook-signature\nEOF\n</code></pre> <p>Shortly after submitting the instance resource, you should see EDA reporting the instance as reachable in the status field of the instance resource. Verify with:</p> <pre><code>kubectl get instance netbox -n eda \\\n-o custom-columns=\"URL:.spec.url,STATUS:.status.reachable\"\n</code></pre> <pre><code>URL                                             STATUS\nhttp://netbox-server.netbox.svc.cluster.local   true\n</code></pre> Allocations <p>Once the Instance resource is configured and the NetBox is reachable, you can proceed with creating the Allocation resources.</p> <p>As per our task, we need two Allocation Pools in EDA:</p> <ol> <li><code>IPAllocationPool</code> for the IPv4 addresses used as System IPs for our leaf and spines</li> <li><code>SubnetAllocationPool</code> for the subnets used for the interswitch links in our fabric.</li> </ol> <p>Instead of creating these pools manually, we will create two Allocation resources from the EDA NetBox app and let it create these pools for us based on the NetBox prefixes.</p> <p>Starting with the Allocation resource for the System IPs:</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-systemip-v4\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox\n  tags:\n    - eda-systemip-v4\n  type: ip-address\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-systemip-v4\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox\n  tags:\n    - eda-systemip-v4\n  type: ip-address\nEOF\n</code></pre> <p>The name of the Allocation resource (<code>nb-systemip-v4</code>) will drive the name of the EDA Allocation Pool name once NetBox app will get to create the pool based on the received webhook from the NetBox server.</p> <p>In the specification block of the Allocation resource we provide</p> <ul> <li>the name of the NetBox instance resource we just created</li> <li>the tags to match the received prefixes from the NetBox server and associate with this Allocation. Recall, that we created this tag in NetBox and added it to the Prefix we intend to use for the System IPs.</li> <li>the type of the allocation, which will drive the type of the EDA Allocation Pool. Since System IPs are plain IPv4 addresses, we choose <code>ip-address</code> type.</li> </ul> <p>Following the same approach, create the Allocation resource for the subnets used for the interswitch links:</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-isl-v6\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox\n  subnetLength: 127\n  tags:\n    - eda-isl-v6\n  type: subnet\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-isl-v6\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox\n  subnetLength: 127\n  tags:\n    - eda-isl-v6\n  type: subnet\nEOF\n</code></pre> <p>The difference between the two Allocation resources is the type of the allocation. Since subnets are CIDR blocks, we choose the <code>subnet</code> type and we also specify the <code>subnetLength</code> property to define the length of the subnet to allocate from the received prefix.</p> <p>Once you have the Allocation resources created, you should see the pools with the matching names created in EDA:</p> IP PoolSubnet Pool <pre><code>kubectl -n eda get ipallocationpool nb-systemip-v4\n</code></pre> <pre><code>NAME             AGE\nnb-systemip-v4   13h\n</code></pre> <pre><code>kubectl -n eda get subnetallocationpool nb-isl-v6\n</code></pre> <pre><code>NAME        AGE\nnb-isl-v6   13h\n</code></pre> Fabric <p>Next we create a fabric resource using the EDA Playground topology setup in this example. We reference the allocation pools our NetBox app created when it synced the prefixes:</p> YAML<code>kubectl</code> <pre><code>apiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: my-nb-ebgp-fabric\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    poolIPV6: nb-isl-v6\n  systemPoolIPV4: nb-systemip-v4\n  underlayProtocol:\n    bgp:\n      asnPool: asn-pool\n    protocol:\n      - EBGP\n  overlayProtocol:\n    protocol: EBGP\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: my-nb-ebgp-fabric\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    poolIPV6: nb-isl-v6\n  systemPoolIPV4: nb-systemip-v4\n  underlayProtocol:\n    bgp:\n      asnPool: asn-pool\n    protocol:\n      - EBGP\n  overlayProtocol:\n    protocol: EBGP\nEOF\n</code></pre> <p>The Fabric app will use the referenced pools and will try to allocated the pool resources in order to instantiate a fabric. In our example the System IP (v4) and Subnets (v6) will be allocated from the pools and the allocated resources will be populated back to the NetBox server to keep track of the allocated resources.</p> <p>From the Prefix we created for System IPs you will see the three allocated IPs populated back in NetBox server, one per each spine and leaf in our topology:</p> <p>In the same way, you will see interswitch subnets carved out from the <code>2005::/64</code> prefix, one per each link between leafs and spines:</p> Custom Fields <p>The NetBox app also creates some custom fields in NetBox model to backtrack the allocation of the resources. For example, if you select an allocated sub-prefix from the <code>2005::/64</code> prefix, you will see EDA custom fields that show the Allocation resource that created this allocation and the owner object that requested the allocation.</p> <p>The objects allocated by EDA will also have the <code>EDAManaged</code> tag assigned to them.</p> <ol> <li> <p>Based on NetBox Community v4.3.2-Docker-3.3.0 version and Helm chart v6.0.33.\u00a0\u21a9</p> </li> <li> <p>Or run a wait with:  </p> <p><pre><code>kubectl -n netbox wait --for=condition=available --timeout=300s \\\ndeployment/netbox-server\n</code></pre> \u21a9</p> </li> </ol>"},{"location":"apps/notifier/","title":"Notifier","text":"Description The Notifier app creates and delivers creates and delivers custom notifications from a variety of sources to multiple destinations. Author Nokia Supported OS SR Linux, SR OS Catalog nokia-eda/catalog Language Go Source Code coming soon"},{"location":"apps/notifier/#installation","title":"Installation","text":"<p>Notifier app can be installed using EDA Store or by running the app-installer workflow with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: notifier-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: notifier.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: notifier-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: notifier.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n\nEOF\n</code></pre>"},{"location":"apps/notifier/#configuration","title":"Configuration","text":"<p>After installing the app, you can configure your notification sources and destinations. You have the option to choose between two sources - Alarm or Query - and can send notifications to multiple destinations.</p> <p>Sources are defined using the Notifier or ClusterNotifier Custom Resources (CRs), while destinations<sup>1</sup> (referred to as Providers) are set up using the Provider or ClusterProvider CRs. You can mix and match sources, as well as send notifications to multiple destinations.</p> <p>The ClusterNotifier and ClusterProvider CRs are deployed in the eda-system namespace and provide system-wide notification capabilities across all EDA namespaces. In contrast, the regular Notifier and Provider CRs are namespace-scoped and can only generate notifications from alarms or queries within their own namespace.</p>"},{"location":"apps/notifier/#notification-source","title":"Notification source","text":""},{"location":"apps/notifier/#alarm","title":"Alarm","text":"<p>To configure the source of the notifications, you need to create a Notifier or ClusterNotifier CR. </p> <p>The example below shows a ClusterNotifier CR that genrates notifications based on any alarm across all namespaces and sends them to the referenced <code>discord</code> provider.</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterNotifier\nmetadata:\n  name: alarms-to-discord\n  namespace: eda-system\nspec:\n  description: \"Notifier for all alarms to Discord\"\n  enabled: true\n  sources:\n    alarms:\n      include:\n        - \"*\"\n  providers:\n    - discord\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterNotifier\nmetadata:\n  name: alarms-to-discord\n  namespace: eda-system\nspec:\n  description: \"Notifier for all alarms to Discord\"\n  enabled: true\n  sources:\n    alarms:\n      include:\n        - \"*\"\n  providers:\n    - discord\n\nEOF\n</code></pre> <p>You can filter which alarms trigger notifications by specifying their <code>type</code> in the include/exclude lists (for example, <code>InterfaceDown</code>, <code>TopoLinkDown</code>). For ClusterNotifier CRs, you can further refine the scope by specifying which namespaces to monitor.</p>"},{"location":"apps/notifier/#query","title":"Query","text":"<p>EQL queries can be used as a source for notifications. Users can specify the table, select relevant fields, and define conditions to trigger a notification. When the condition is met, a notification is generated and sent using the referenced providers.</p> <p>The notification format can be customized using two fields; <code>title</code> and <code>template</code>; both use Go templates.. These templates render based on a map that includes all selected fields and the keys returned by the table. The key names match the raw column names shown in the EDA UI query tool.</p> <p>For example, querying the table <code>.namespace.node.srl.interface</code> returns the keys:</p> <ul> <li><code>namespace.name</code></li> <li><code>namespace.node.name</code></li> <li><code>name</code> (this is the interface name)</li> <li>and any field that was explicitly requested under <code>fields</code>.</li> </ul> <p>The example below shows a ClusterNotifier CR that generates notifications whenever an interface operational state changes to <code>down</code> while its administrative state is <code>enable</code>.</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterNotifier\nmetadata:\n  name: interface-down-notifier\n  namespace: eda-system\nspec:\n  enabled: true\n  sources:\n    query:\n      table: .namespace.node.srl.interface\n      fields:\n        - admin-state\n        - oper-state\n        - .namespace.node.name\n      where: admin-state = \"enable\" and oper-state = \"down\"\n      title: Interface Down Alert\n      template: |\n        Namespace: {{ index . \"namespace.name\" }}.\n        Interface {{ index . \"name\"}} is DOWN on node {{ index . \"namespace.node.name\"}}.\n        (State admin/oper: {{ index . \"oper-state\" }}/{{ index . \"admin-state\"}})    \n  providers:\n    - discord\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterNotifier\nmetadata:\n  name: interface-down-notifier\n  namespace: eda-system\nspec:\n  enabled: true\n  sources:\n    query:\n      table: .namespace.node.srl.interface\n      fields:\n        - admin-state\n        - oper-state\n        - .namespace.node.name\n      where: admin-state = \"enable\" and oper-state = \"down\"\n      title: Interface Down Alert\n      template: |\n        Namespace: {{ index . \"namespace.name\" }}.\n        Interface {{ index . \"name\"}} is DOWN on node {{ index . \"namespace.node.name\"}}.\n        (State admin/oper: {{ index . \"oper-state\" }}/{{ index . \"admin-state\"}})    \n  providers:\n    - discord\n\nEOF\n</code></pre>"},{"location":"apps/notifier/#provider-reference","title":"Provider reference","text":"<p>The Notifier/ClusterNotifier CR references the notification destination(s) by name. In the examples above, the <code>discord</code> provider referenced in the ClusterNotifier CR is the name of the ClusterProvider CR that should exist in the <code>eda-system</code> namespace. When using namespace-scoped notifiers, both the Notifier and Provider CRs must be in the same namespace, for example <code>namespace: eda</code>.</p>"},{"location":"apps/notifier/#notification-destination","title":"Notification destination","text":"<p>Notifier supports multiple notification destinations (aka providers), and leverages the shoutrrr package to send notifications to the supported providers with a few provider using custom integrations. The full list of supported providers is available at the shouterrr docs.</p> <p>Notifier app knows which provider to use based on the <code>uri</code> field in the Provider or ClusterProvider CR.</p>"},{"location":"apps/notifier/#discord","title":"Discord","text":"<p>To send notifications to Discord a user needs to create a Discord webhook<sup>2</sup>. The webhook URL should look like this:</p> <pre><code>https://discord.com/api/webhooks/webhookid/token\n</code></pre> <p>Replace the <code>https://</code> scheme with <code>discord://</code></p> <pre><code>discord://discord.com/api/webhooks/webhookid/token\n</code></pre> <p>Now everything is ready for the ClusterProvider CR creation with the following configuration:</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: discord\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: discord://discord.com/api/webhooks/webhookid/token\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: discord\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: discord://discord.com/api/webhooks/webhookid/token\n\nEOF\n</code></pre> <p>The Discord username posting the notification can be customized using a query parameter <code>username</code> overwriting the default webhook bot name. For example : <code>discord://discord.com/api/webhooks/123456789/XXXXXXXXXXXXX?username=EDA</code></p> <p>The following example of a Discord notification shows two different TopoLink alarm states: a critical alarm when all members are down (red), and a major alarm when the link is in degraded state (green). Each notification includes detailed information about the resource, its state, and timing.</p> <p> </p> Discord alarm notifications"},{"location":"apps/notifier/#teams","title":"Teams","text":"<p>The <code>teams</code> provider allows users to send MS Teams notifications when events occur in the network or within EDA. The integration is done using Teams <code>Incoming Webhook Connector</code>, a guide can be found here<sup>3</sup>.</p> <p>Copy the generated webhook address and replace the <code>https://</code> scheme with <code>teams://</code> to configure the teams provider.</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: teams\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: teams://&lt;company&gt;.webhook.office.com/webhookb2/XXXXX\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: teams\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: teams://&lt;company&gt;.webhook.office.com/webhookb2/XXXXX\n\nEOF\n</code></pre> <p>The following example shows notifications from the EDA Notifier app to Teams that shows two consecutive messages: a TopoLinkDown alarm (critical severity, not cleared) indicating all members are down, followed by a TopoLinkDegraded alarm that has been cleared (major severity, cleared=true). Each notification provides structured information including namespace, resource details, severity level, and timestamp.</p> <p> </p> Teams alarm notifications"},{"location":"apps/notifier/#slack","title":"Slack","text":"<p>The <code>slack</code> provider allows users to send Slack notifications when events occur in the network or within EDA. The integration is done using Slack webhooks, you can find the guide here<sup>4</sup>.</p> <p>Copy the generated webhook address and replace the <code>https://</code> scheme with <code>slack://</code> to configure the slack provider.</p> <p>The Slack channel where the notification must be posted as well as the username posting it can optionally be customized using a query parameters <code>channel</code> and <code>username</code> overwriting the default webhook name and destination channel. For example : <code>slack://hooks.slack.com/services/XXXXX/YYYYYY/ZZZZZZ?username=EDA&amp;channel=alerts</code></p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: slack\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: slack://hooks.slack.com/services/ABC/DEF/GHI\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: slack\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: slack://hooks.slack.com/services/ABC/DEF/GHI\n\nEOF\n</code></pre> <p>The following example of a Slack notification shows two consecutive messages: a TopoLinkDown alarm (critical severity, red icon) indicating all members are down, followed by a TopoLinkDegraded alarm that has been cleared (major severity with green checkmark, cleared=true). Both messages provide detailed information including namespace, resource name, group, severity, and timestamp.</p> <p> </p> Slack alarm notifications"},{"location":"apps/notifier/#email","title":"Email","text":"<p>The <code>email</code> provider allows users to send notifications as emails when events occur in the network or within EDA. Notifier sends an email given an SMTP address and some additional parameters:</p> <p>The SMTP address must start with <code>smtp://</code>. If a username and password are required, they must be part of the URI authority field <code>smtp://$user:$password@host</code> Additional query parameters can be added to the URI:</p> <ul> <li><code>from</code>     : The sender email address</li> <li><code>to</code>       : The recipient email address</li> <li><code>startTLS</code> : <code>yes | no</code>, if set to <code>yes</code> the connection to the SMTP server must use TLS.</li> <li><code>useHTML</code>  : <code>yes | no</code>, if set to <code>yes</code> the email content type will be set to \"text/html; charset=UTF-8\" otherwise \"text/plain; charset=UTF-8\"</li> </ul> <p>Example <code>email</code> ClusterProvider CR:</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: email\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: smtp://$user:$password@smtp.example.com?from=eda@nokia.com&amp;to=noc@customer.com&amp;startTLS=yes\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: email\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: smtp://$user:$password@smtp.example.com?from=eda@nokia.com&amp;to=noc@customer.com&amp;startTLS=yes\n\nEOF\n</code></pre> <ol> <li> <p>The full list of supported destinations/providers is available here.\u00a0\u21a9</p> </li> <li> <p>Refer to the Discord docs for more information on how to create a Discord webhook.\u00a0\u21a9</p> </li> <li> <p>Teams incoming webhook integration.\u00a0\u21a9</p> </li> <li> <p>Slack webhooks guide \u21a9</p> </li> </ol>"},{"location":"apps/prometheus-exporter/","title":"Prometheus Exporter","text":"Description Prometheus Exporter exposes EDA and network metrics to be scraped by a Prometheus server. Author Nokia Supported OS SR Linux, SR OS Catalog nokia-eda/catalog Language Go Source Code coming soon"},{"location":"apps/prometheus-exporter/#installation","title":"Installation","text":"<p>The Prometheus exporter app can be installed using EDA Store or by running the <code>app-install</code> workflow with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: prom-exporter-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: prom.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: prom-exporter-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: prom.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n\nEOF\n</code></pre>"},{"location":"apps/prometheus-exporter/#configuration","title":"Configuration","text":"<p>After installing the app you can configure the metrics you wish to be exported by defining an EDB path (also referred to as <code>jsPath</code>) and, optionally, a <code>fields</code> list and a <code>where</code> EQL statement. You can check what is returned by the path using the EDA Query UI or <code>edactl</code>.</p> <p>At every scrape request the app will retrieve the configured paths and fields and automatically generate the metric name, its labels and its value based on the path, fields and values received back from EDA.</p> <p>If your use case requires additional customizations, the app supports:</p> <ul> <li>Renaming metric names using regex and replacement patterns.</li> <li>Adding static or dynamic labels to metrics.</li> <li>Mapping non-numeric values to Prometheus-compatible numeric values.</li> </ul> <p>Scrape requests from Prometheus must be directed to the URL <code>https://EDA_API_ADDRESS/core/httpproxy/v1/prometheus-exporter/metrics</code>.</p>"},{"location":"apps/prometheus-exporter/#export-custom-resource","title":"Export Custom Resource","text":"<p>The app is configured using an <code>Export</code> Custom Resource (CR) from the <code>prom.eda.nokia.com</code> API group that groups a list of <code>exports</code> together.</p> <p>Each <code>export</code> definition includes:</p> <ul> <li>Path<sup>Required</sup>: The EDB path to export, e.g., <code>.namespace.node.srl.interface.statistics</code>.</li> <li>Fields: A list of fields to expose as part of the metric. If not defined all fields under the configured <code>path</code> are exposed.</li> <li>Where: A filter clause for querying, e.g., <code>oper-state = down</code> or <code>.interface.name != \"mgmt0\"</code>.</li> <li>Prefix: A prefix to prepend to all metrics exposed by this definition.</li> <li>Metric Name: Customization of metric names using regex and replacements.</li> <li>Labels: Static or dynamic labels to add to metrics.</li> <li>Mappings: Rules to map non-numeric values to numeric equivalents.</li> </ul> <p>Here is an example of a Prometheus exporter custom resource:</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: replaced-metrics\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      metricName:\n        regex: namespace_node_srl_(\\w+)_statistics_(\\w+)\n        replacement: \"${1}_${2}\"\n</code></pre>"},{"location":"apps/prometheus-exporter/#metric-customization","title":"Metric customization","text":"<p>The resulting Prometheus metrics are autogenerated based on the returned paths, fields and values. A metric is composed of the following parts:</p> <ul> <li>Name</li> <li>Labels</li> <li>Value</li> </ul>"},{"location":"apps/prometheus-exporter/#name","title":"Name","text":"<p>Metric names are derived from the provided jsPath and fields. For example:</p> <ul> <li>jsPath: <code>.namespace.node.srl.interface.statistics</code></li> <li>Field: <code>out-octets</code></li> </ul> <p>The resulting metric name will be generated by following this process:</p> <ol> <li> <p>Strip the leading <code>.</code> (period) from the jsPath.</p> </li> <li> <p>Remove all keys from the jsPath.</p> </li> <li> <p>Replace all <code>.</code> (period) with an <code>_</code> (underscore) in the jsPath</p> </li> <li> <p>Replace every <code>-</code> (hyphen) with <code>_</code> (underscore) in the jsPath and field name</p> </li> <li> <p>Join the resulting jsPath and field name with and <code>_</code> (underscore)</p> </li> </ol> <p>Example</p> <p>Given the path <code>.namespace.node.srl.interface.statistics</code> and field <code>out-octets</code>, the resulting metric name is: <code>namespace_node_srl_interface_statistics_out_octets</code>.</p>"},{"location":"apps/prometheus-exporter/#customization","title":"Customization","text":"<p>Metric names can be customized to suit user needs in a simple or advanced way.</p>"},{"location":"apps/prometheus-exporter/#simple","title":"Simple","text":"<p>Use the <code>prefix</code> field in the CR to add a prefix to all metric names.</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: prefixed-metrics\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      prefix: eda\n</code></pre> <p>The above configuration produces metrics starting with <code>eda_</code> prefix. For example, the metric <code>namespace_node_srl_interface_statistics_out_octets</code> becomes: <code>eda_namespace_node_srl_interface_statistics_out_octets</code>.</p>"},{"location":"apps/prometheus-exporter/#advanced","title":"Advanced","text":"<p>Use the <code>metricName</code> field to apply regex-based transformations which has two components:</p> <ul> <li>Regex: Defines the pattern to match in the metric name.</li> <li>Replacement: Defines how the matched pattern should be replaced.</li> </ul> <p>For example, if the metric name <code>namespace_node_srl_interface_statistics_out_octets</code> is too long, you can shorten it to <code>interface_out_octets</code>:</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: replaced-metrics\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      metricName:\n        regex: namespace_node_srl_(\\w+)_statistics_(\\w+)\n        replacement: \"${1}_${2}\"\n</code></pre>"},{"location":"apps/prometheus-exporter/#labels","title":"Labels","text":"<p>Labels add context and categorization to metrics. They are generated automatically from the jsPath keys and their values. For each key in the jsPath, a label name is a created using the path element name and the key name joined using an <code>_</code>.</p> <p>Example</p> <p>Given the jsPath: <code>.namespace{.name==\"eda\"}.node.srl{.name==\"dut1\"}.interface{.name==\"ethernet-1/1\"}.statistics</code></p> <p>The resulting labels would be: <code>namespace_name=\"eda\", node_name=\"dut1\", interface_name=\"ethernet-1/1\"</code></p> <p>In addition to <code>jsPath</code>-based labels, two types of additional labels can be defined:</p>"},{"location":"apps/prometheus-exporter/#static-labels","title":"Static Labels","text":"<p>Predefined name-value pairs that are the same for all metrics in an export. The CR in the example below will result in metrics with 2 additional labels <code>env=prod</code> and <code>region=us-west-1</code> added:</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: static-labels-metric\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      labels:\n        static:\n          - name: env\n            value: prod\n          - name: region\n            value: us-west-1\n</code></pre>"},{"location":"apps/prometheus-exporter/#dynamic-labels","title":"Dynamic Labels","text":"<p>Labels generated based on data from a specific <code>path</code> (EDB path/jsPath) and <code>field</code>, with optional regex transformations. Example:</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: dynamic-labels-metric\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      labels:\n        dynamic:\n          - path: .namespace.node.srl.interface\n            field: description\n          - path: .namespace.node.srl.platform.chassis\n            field: type\n</code></pre> <p>The above example generates metrics based on the given path and adds 2 labels:</p> <ol> <li>the interface description for which the metric is exposed</li> <li>node's chassis type</li> </ol>"},{"location":"apps/prometheus-exporter/#values","title":"Values","text":"<p>Metric values are derived directly from the data at the specified <code>path</code> and <code>field</code>. If the raw value is not a numeric type that Prometheus can ingest, mappings are required to convert the value.</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: mapped-values-metric\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface\n      fields:\n        - admin-state\n        - oper-state\n      mappings:\n        - source: \"up\"\n          destination: \"2\"\n        - source: \"down\"\n          destination: \"1\"\n        - source: \"enable\"\n          destination: \"2\"\n        - source: \"disable\"\n          destination: \"1\"\n</code></pre> <p>The above Export maps non-numeric values from the fields into numeric values that can be ingested by Prometheus. The mapping rules are:</p> <ul> <li>up \u2192 2</li> <li>down \u2192 1</li> <li>enable \u2192 2</li> <li>disable \u2192 1</li> </ul>"},{"location":"apps/prometheus-exporter/#metrics-grouping","title":"Metrics grouping","text":"<p>Metrics grouping in the Prometheus exporter allows for efficient organization and selective scraping of metrics by Prometheus. Here's how it works:</p> <p>By default, Prometheus scrapes all exported metrics from the endpoint: <code>https://EDA_API_ADDRESS/core/httpproxy/v1/prometheus-exporter/metrics</code> This endpoint aggregates metrics from all <code>Export</code> CRs defined in the system.</p>"},{"location":"apps/prometheus-exporter/#group-specific-metrics-scraping","title":"Group-Specific Metrics Scraping","text":"<p>To provide more control over which metrics are scraped, you can assign CRs to specific groups. When a <code>group</code> is specified in the CR, Prometheus can scrape only the metrics belonging to that group using a targeted endpoint: <code>https://EDA_API_ADDRESS/core/httpproxy/v1/prometheus-exporter/metrics/{group}</code></p> <p>Where <code>{group}</code> is the name of the group specified in the CR.</p> <p>Groups are defined in the <code>spec.group</code> field of an <code>Export</code> CR. For example:</p> YAML<code>kubectl</code> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: metrics-grouping\n  namespace: eda-system\nspec:\n  group: group1\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: metrics-grouping\n  namespace: eda-system\nspec:\n  group: group1\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n\nEOF\n</code></pre>"},{"location":"apps/prometheus-exporter/#use-cases-for-grouping","title":"Use Cases for Grouping","text":"<ol> <li> <p>Selective Scraping: If you want Prometheus to scrape only specific metrics (e.g., metrics related to networking or storage), you can group the relevant CRs and use the group-specific endpoint.</p> </li> <li> <p>Performance Optimization: By grouping metrics, you can reduce the load on the Prometheus server and the exporter by scraping only the necessary data.</p> </li> <li> <p>Access Control: Different teams or systems can be assigned specific groups, ensuring each team accesses its relevant metrics.</p> </li> </ol>"},{"location":"apps/prometheus-exporter/#usage-examples","title":"Usage Examples","text":"<p>Check out EDA Telemetry demo lab for Prometheus exporter usage examples.</p>"},{"location":"apps/protocols/","title":"Protocols","text":"Description The Protocols application manages BGP, static, and aggregate route resources to automatically generate routing configurations for network nodes in both default and custom VRFs. Supported OS SR Linux, SR OS Catalog nokia-eda/catalog / manifest Source Code coming soon <p>The Protocols application enables users to create and manage various routing protocols in EDA and contains resources that are split between Overlay and Default routing categories. These two categories define the deployment model for the resource.</p> <p>Resources from the Default Routing category will be used in the network element's default VRF, whereas resources listed under the Overlay Routing category designed to be associated with a custom, non-default VRF.</p> <p>The application provides the following components:</p> Resource TypesDashboards <p> DEFAULT ROUTING</p> <ul> <li>Default BGP Groups</li> <li>Default BGP Peers</li> <li>Default Static Routes</li> <li>Default Aggregate Routes</li> <li>Default Route Reflectors</li> <li>Default Route Reflector Clients</li> </ul> <p> OVERLAY ROUTING</p> <ul> <li>BGP Groups</li> <li>BGP Peers</li> <li>Static Routes</li> <li>Aggregate Routes</li> <li>Route Reflectors</li> <li>Route Reflector Clients</li> </ul> <p>Summary dashboards for the following resource types:</p> <ul> <li>Default BGP Peers</li> <li>Default BGP Groups</li> <li>Default Route Reflectors</li> <li>Default Route Reflector Clients</li> </ul>"},{"location":"apps/protocols/#border-gateway-protocol-bgp","title":"Border Gateway Protocol (BGP)","text":"<p>BGP configuration in the Protocols application supports both default VRF and custom VRF deployments, with comprehensive features for peer management, route reflection, and policy control.</p>"},{"location":"apps/protocols/#configuration-types","title":"Configuration Types","text":"<p>The application supports two primary BGP deployment models:</p> <ul> <li>Default BGP: Configuration in the default VRF using <code>DefaultBGPPeer</code> and <code>DefaultBGPGroup</code> custom resources (CRs).</li> <li>Custom VRF BGP: Configuration in custom IP-VRFs using <code>BGPPeer</code> and <code>BGPGroup</code> CRs.</li> </ul>"},{"location":"apps/protocols/#bgp-groups","title":"BGP Groups","text":"<p>BGP Groups enable centralized management of peer configurations, ensuring consistent policy application across multiple peers.</p> <p>Because a BGP group in the default VRF and custom VRF usually have different configuration options and represent different groups, two BGP groups resource types are offered - <code>DefaultBGPGroup</code> and <code>BGPGroup</code>.</p>"},{"location":"apps/protocols/#default-bgp-group-configuration","title":"Default BGP Group Configuration","text":"<p> DEFAULT ROUTING  \u2192 DGDefault BGP Group</p> YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultBGPGroup\nmetadata:\n  name: example-default-group\n  namespace: eda\nspec:\n  description: \"Default VRF BGP group\"\n  localAS:\n    autonomousSystem: 65001\n  timers:\n    holdTime: 90\n    keepAlive: 30\n  ipv4Unicast:\n    enabled: true\n    maxReceivedRoutes: 1000\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultBGPGroup\nmetadata:\n  name: example-default-group\n  namespace: eda\nspec:\n  description: \"Default VRF BGP group\"\n  localAS:\n    autonomousSystem: 65001\n  timers:\n    holdTime: 90\n    keepAlive: 30\n  ipv4Unicast:\n    enabled: true\n    maxReceivedRoutes: 1000\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-bgp-group-configuration","title":"Custom VRF BGP Group Configuration","text":"<p> OVERLAY ROUTING \u2192 BGBGP Group</p> YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: BGPGroup\nmetadata:\n  name: example-custom-group\n  namespace: eda\nspec:\n  description: \"Custom VRF BGP group\"\n  localAS:\n    autonomousSystem: 65002\n  timers:\n    holdTime: 90\n    keepAlive: 30\n  ipv4Unicast:\n    enabled: true\n    maxReceivedRoutes: 1000\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: BGPGroup\nmetadata:\n  name: example-custom-group\n  namespace: eda\nspec:\n  description: \"Custom VRF BGP group\"\n  localAS:\n    autonomousSystem: 65002\n  timers:\n    holdTime: 90\n    keepAlive: 30\n  ipv4Unicast:\n    enabled: true\n    maxReceivedRoutes: 1000\nEOF\n</code></pre>"},{"location":"apps/protocols/#bgp-peers","title":"BGP Peers","text":"<p>BGP peers represent individual BGP sessions and can inherit configurations from BGP groups. The Protocols application supports both explicit peer configuration and dynamic neighbor discovery.  Selecting an interface will bind the session to the Toponode on which the Interface is deployed.  The interface can be a DefaultInterface (interface in the default VRF) or a SystemInterface (primary loopback in the default VRF).</p>"},{"location":"apps/protocols/#default-bgp-peer-configuration","title":"Default BGP Peer Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultBGPPeer\nmetadata:\n  name: example-default-peer\n  namespace: eda\nspec:\n  description: \"Default VRF BGP peer\"\n  group: \"example-default-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  peerAS:\n    autonomousSystem: 65100\n  peerIP: \"192.168.1.1\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultBGPPeer\nmetadata:\n  name: example-default-peer\n  namespace: eda\nspec:\n  description: \"Default VRF BGP peer\"\n  group: \"example-default-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  peerAS:\n    autonomousSystem: 65100\n  peerIP: \"192.168.1.1\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-bgp-peer-configuration","title":"Custom VRF BGP Peer Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: BGPPeer\nmetadata:\n  name: example-custom-peer\n  namespace: eda\nspec:\n  description: \"Custom VRF BGP peer\"\n  group: \"example-custom-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  peerAS:\n    autonomousSystem: 65200\n  peerIP: \"192.168.2.1\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: BGPPeer\nmetadata:\n  name: example-custom-peer\n  namespace: eda\nspec:\n  description: \"Custom VRF BGP peer\"\n  group: \"example-custom-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  peerAS:\n    autonomousSystem: 65200\n  peerIP: \"192.168.2.1\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#address-family-support","title":"Address Family Support","text":"<p>The Protocols application provides comprehensive support for multiple BGP address families including, but not limited to:</p>"},{"location":"apps/protocols/#ipv4-unicast","title":"IPv4 Unicast","text":"<ul> <li>Enable/disable IPv4 unicast routing</li> <li>Support for IPv6 next-hops (RFC 5549)</li> <li>Configurable maximum route limits</li> <li>Next-hop self options</li> <li>Independent policy control</li> </ul>"},{"location":"apps/protocols/#ipv6-unicast","title":"IPv6 Unicast","text":"<ul> <li>Enable/disable IPv6 unicast routing</li> <li>Configurable maximum route limits</li> <li>Independent policy control</li> </ul>"},{"location":"apps/protocols/#l2vpn-evpn","title":"L2VPN EVPN","text":"<ul> <li>Enable/disable EVPN</li> <li>Support for IPv6 next-hops</li> <li>Configurable maximum route limits</li> <li>Integration with overlay services</li> </ul>"},{"location":"apps/protocols/#route-reflection","title":"Route Reflection","text":"<p>Route reflection enables scalable iBGP deployments by eliminating the need for a full mesh of iBGP sessions. The Protocols application supports route reflection in both default and custom VRFs.</p> <p>The router reflector resources can select the clients to connect to using a label selector. The label selector will select RouteReflectorClient or DefaultRouteReflectorClient resources; if the clients are not EDA resources, you may specify a list of client IPs to which the the route reflector will attempt to establish a session.</p>"},{"location":"apps/protocols/#configuration-types_1","title":"Configuration Types","text":"<ul> <li>Default VRF: Using <code>DefaultRouteReflector</code> and <code>DefaultRouteReflectorClient</code>.</li> <li>Custom VRF: Using <code>RouteReflector</code> and <code>RouteReflectorClient</code>.</li> </ul>"},{"location":"apps/protocols/#route-reflector-configuration","title":"Route Reflector Configuration","text":""},{"location":"apps/protocols/#default-vrf-example","title":"Default VRF Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultRouteReflector\nmetadata:\n  name: example-default-rr\n  namespace: eda\nspec:\n  description: \"Default VRF Route Reflector\"\n  clusterID: \"1.1.1.1\"\n  defaultBGPRRGroup: \"rr-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  clientSelector:\n    - \"role=leaf\"\n  clientIPs:\n    - \"192.168.1.1\"\n    - \"192.168.1.2\"\n  ipv4Unicast:\n    enabled: true\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultRouteReflector\nmetadata:\n  name: example-default-rr\n  namespace: eda\nspec:\n  description: \"Default VRF Route Reflector\"\n  clusterID: \"1.1.1.1\"\n  defaultBGPRRGroup: \"rr-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  clientSelector:\n    - \"role=leaf\"\n  clientIPs:\n    - \"192.168.1.1\"\n    - \"192.168.1.2\"\n  ipv4Unicast:\n    enabled: true\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-route-reflector-example","title":"Custom VRF Route Reflector Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: RouteReflector\nmetadata:\n  name: example-custom-rr\n  namespace: eda\nspec:\n  clusterID: \"2.2.2.2\"\n  bgpGroup: \"custom-rr-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  ipv4ClientSelector:\n    - \"role=customer-edge\"\n  ipv6ClientSelector:\n    - \"role=customer-edge\"\n  clientIPs:\n    - \"172.16.1.1\"\n    - \"172.16.1.2\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: RouteReflector\nmetadata:\n  name: example-custom-rr\n  namespace: eda\nspec:\n  clusterID: \"2.2.2.2\"\n  bgpGroup: \"custom-rr-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  ipv4ClientSelector:\n    - \"role=customer-edge\"\n  ipv6ClientSelector:\n    - \"role=customer-edge\"\n  clientIPs:\n    - \"172.16.1.1\"\n    - \"172.16.1.2\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#route-reflector-client-configuration","title":"Route Reflector Client Configuration","text":"<p>Route reflector clients establish sessions with route reflectors based on selectors or explicit IP addresses.  The label selector will select DefaultRouteReflector or RouteReflector resources, or a list of IP addresses can be provided which the router relctor client will try to establish a session to.</p>"},{"location":"apps/protocols/#default-vrf-client-example","title":"Default VRF Client Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultRouteReflectorClient\nmetadata:\n  name: example-default-rr-client\n  namespace: eda\nspec:\n  defaultBgpClientGroup: \"client-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  routeReflectorSelector:\n    - \"role=spine\"\n  routeReflectorIPs:\n    - \"192.168.0.1\"\n    - \"192.168.0.2\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultRouteReflectorClient\nmetadata:\n  name: example-default-rr-client\n  namespace: eda\nspec:\n  defaultBgpClientGroup: \"client-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  routeReflectorSelector:\n    - \"role=spine\"\n  routeReflectorIPs:\n    - \"192.168.0.1\"\n    - \"192.168.0.2\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-client-example","title":"Custom VRF Client Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: RouteReflectorClient\nmetadata:\n  name: example-custom-rr-client\n  namespace: eda\nspec:\n  bgpGroup: \"custom-client-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  ipv4RouteReflectorSelector:\n    - \"role=provider-edge\"\n  ipv6RouteReflectorSelector:\n    - \"role=provider-edge\"\n  routeReflectorIPs:\n    - \"172.16.0.1\"\n    - \"172.16.0.2\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: RouteReflectorClient\nmetadata:\n  name: example-custom-rr-client\n  namespace: eda\nspec:\n  bgpGroup: \"custom-client-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  ipv4RouteReflectorSelector:\n    - \"role=provider-edge\"\n  ipv6RouteReflectorSelector:\n    - \"role=provider-edge\"\n  routeReflectorIPs:\n    - \"172.16.0.1\"\n    - \"172.16.0.2\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#static-routes","title":"Static Routes","text":"<p>Static routes provide explicit path control for network traffic.</p>"},{"location":"apps/protocols/#configuration-types_2","title":"Configuration Types","text":"<p>The application supports two types of static route deployments:</p> <ul> <li>Default Static Routes: Configuration in the default VRF using a <code>DefaultStaticRoute</code> resource.</li> <li>Custom VRF Static Routes: Configuration in custom VRFs using a <code>StaticRoute</code> resource.</li> </ul>"},{"location":"apps/protocols/#default-vrf-static-route-configuration","title":"Default VRF Static Route Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultStaticRoute\nmetadata:\n  name: example-default-static\n  namespace: eda\nspec:\n  defaultRouter: \"default-router\"\n  prefixes:\n    - \"192.168.0.0/24\"\n    - \"172.16.0.0/24\"\n  preference: 5\n  nexthopGroup:\n    nexthops:\n      - ipPrefix: \"10.0.0.1\"\n      - ipPrefix: \"10.0.0.2\"\n    resolve: true\n    bfd:\n      enabled: true\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultStaticRoute\nmetadata:\n  name: example-default-static\n  namespace: eda\nspec:\n  defaultRouter: \"default-router\"\n  prefixes:\n    - \"192.168.0.0/24\"\n    - \"172.16.0.0/24\"\n  preference: 5\n  nexthopGroup:\n    nexthops:\n      - ipPrefix: \"10.0.0.1\"\n      - ipPrefix: \"10.0.0.2\"\n    resolve: true\n    bfd:\n      enabled: true\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-static-route-configuration","title":"Custom VRF Static Route Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: StaticRoute\nmetadata:\n  name: example-custom-static\n  namespace: eda\nspec:\n  router: \"customer-router\"\n  prefixes:\n    - \"192.168.1.0/24\"\n    - \"192.168.2.0/24\"\n  preference: 10\n  nodes:\n    - \"node1\"\n    - \"node2\"\n  nexthopGroup:\n    nexthops:\n      - ipPrefix: \"10.1.0.1\"\n        bfd:\n          enabled: true\n      - ipPrefix: \"10.1.0.2\"\n    resolve: true\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: StaticRoute\nmetadata:\n  name: example-custom-static\n  namespace: eda\nspec:\n  router: \"customer-router\"\n  prefixes:\n    - \"192.168.1.0/24\"\n    - \"192.168.2.0/24\"\n  preference: 10\n  nodes:\n    - \"node1\"\n    - \"node2\"\n  nexthopGroup:\n    nexthops:\n      - ipPrefix: \"10.1.0.1\"\n        bfd:\n          enabled: true\n      - ipPrefix: \"10.1.0.2\"\n    resolve: true\nEOF\n</code></pre>"},{"location":"apps/protocols/#route-aggregation","title":"Route Aggregation","text":"<p>Route aggregation enables efficient route summarization and management.</p>"},{"location":"apps/protocols/#configuration-types_3","title":"Configuration Types","text":"<p>The application supports two types of route aggregation:</p> <ul> <li>Default Aggregate Routes: Configuration in the default VRF using a <code>DefaultAggregateRoute</code> resource.</li> <li>Custom VRF Aggregate Routes: Configuration in custom VRFs using an <code>AggregateRoute</code> resource.</li> </ul>"},{"location":"apps/protocols/#default-vrf-aggregate-route-configuration","title":"Default VRF Aggregate Route Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultAggregateRoute\nmetadata:\n  name: example-default-aggregate\n  namespace: eda\nspec:\n  defaultRouter: \"default-router\"\n  prefixes:\n    - \"192.168.0.0/16\"\n    - \"172.16.0.0/12\"\n  aggregatorIP: \"10.0.0.1\"\n  aggregatorASN: 65001\n  summaryOnly: true\n  generateICMP: false\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultAggregateRoute\nmetadata:\n  name: example-default-aggregate\n  namespace: eda\nspec:\n  defaultRouter: \"default-router\"\n  prefixes:\n    - \"192.168.0.0/16\"\n    - \"172.16.0.0/12\"\n  aggregatorIP: \"10.0.0.1\"\n  aggregatorASN: 65001\n  summaryOnly: true\n  generateICMP: false\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-aggregate-route-configuration","title":"Custom VRF Aggregate Route Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: AggregateRoute\nmetadata:\n  name: example-custom-aggregate\n  namespace: eda\nspec:\n  router: \"customer-router\"\n  prefixes:\n    - \"192.168.1.0/24\"\n    - \"192.168.2.0/24\"\n  aggregatorIP: \"10.0.0.2\"\n  aggregatorASN: 65002\n  nodes:\n    - \"node1\"\n    - \"node2\"\n  summaryOnly: true\n  generateICMP: false\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: AggregateRoute\nmetadata:\n  name: example-custom-aggregate\n  namespace: eda\nspec:\n  router: \"customer-router\"\n  prefixes:\n    - \"192.168.1.0/24\"\n    - \"192.168.2.0/24\"\n  aggregatorIP: \"10.0.0.2\"\n  aggregatorASN: 65002\n  nodes:\n    - \"node1\"\n    - \"node2\"\n  summaryOnly: true\n  generateICMP: false\nEOF\n</code></pre>"},{"location":"apps/protocols/#operational-state-and-verification","title":"Operational State and Verification","text":""},{"location":"apps/protocols/#bgp-status","title":"BGP Status","text":"<pre><code># Check BGP peer status\nkubectl get bgppeers\nNAME         SESSION STATE   LAST CHANGE   ENABLED   OPERATIONAL STATE   PEER AS\nexample-peer Established    10m           true      up                  65100\n\n# Check BGP group status\nkubectl get bgpgroups\nNAME          LAST CHANGE   OPERATIONAL STATE\nexample-group 10m          up\n\n# Check route reflector status\nkubectl get routereflectors\nNAME    LAST CHANGE   OPERATIONAL STATE   NUM RR BGP PEERS   NUM RR BGP PEERS DOWN\nrr-1    10m          up                  4                  0\n</code></pre>"},{"location":"apps/protocols/#static-route-status","title":"Static Route Status","text":"<pre><code># Check static route status\nkubectl get staticroutes\nNAME          LAST CHANGE   OPERATIONAL STATE   HEALTH\ncustom-route  10m          up                  100\n</code></pre>"},{"location":"apps/protocols/#aggregate-route-status","title":"Aggregate Route Status","text":"<pre><code># Check aggregate route status\nkubectl get aggregateroutes\nNAME             LAST CHANGE   OPERATIONAL STATE   HEALTH\ncustomer-summary 10m          up                  100\n</code></pre>"},{"location":"apps/remote-write/","title":"Remote Write","text":"Description The Remote Write app exports metrics to servers adhering to Prometheus Remote-Write Specifications Author Nokia Supported OS N/A Catalog nokia-eda/catalog Source Code coming soon"},{"location":"apps/remote-write/#overview","title":"Overview","text":"<p>The Remote Write app enables exporting network and EDA metrics to remote Prometheus-compatible servers using the Remote-Write specification v1.0. The app provides resources to define the metrics to export and the destinations to send them to.</p> <p>Application components:</p> Resources <p> REMOTEWRITE</p> <ul> <li>Cluster Destinations</li> <li>Cluster Exporters</li> <li>Destinations</li> <li>Exporters</li> </ul>"},{"location":"apps/remote-write/#installation","title":"Installation","text":"<p>Notifier app can be installed using EDA Store or by running the app-installer workflow with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: remote-write-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: remotewrite.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v2.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: remote-write-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: remotewrite.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v2.0.0\n\nEOF\n</code></pre>"},{"location":"apps/remote-write/#getting-started","title":"Getting Started","text":"<p>After installing the app, you can configure:</p> <ul> <li>Export and ClusterExport: Define metrics to collect (with filtering, mapping, renaming, labels, etc.).</li> <li>Destination and ClusterDestination: Define remote write endpoints (with TLS, authentication, and buffering).</li> </ul>"},{"location":"apps/remote-write/#example-resources","title":"Example Resources","text":""},{"location":"apps/remote-write/#destination","title":"Destination","text":"<p>Defines a remote server to which metrics are written. Supports optional TLS, authentication, custom headers, retries, and timeouts.</p> YAML<code>kubectl</code> <pre><code>apiVersion: remotewrite.eda.nokia.com/v1alpha1\nkind: Destination\nmetadata:\n  name: dest1\n  namespace: eda\nspec:\n  url: 'http://prw.example.com:9090/api/v1/write'\n  writeOptions:\n    bufferSize: 100           # Number of metrics before sending\n    flushInterval: 60s        # Time interval for sending buffered data\n    maxRetries: 3             # Retry attempts on failure\n    timeout: 10s              # Client write timeout\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: remotewrite.eda.nokia.com/v1alpha1\nkind: Destination\nmetadata:\n  name: dest1\n  namespace: eda\nspec:\n  url: 'http://prw.example.com:9090/api/v1/write'\n  writeOptions:\n    bufferSize: 100           # Number of metrics before sending\n    flushInterval: 60s        # Time interval for sending buffered data\n    maxRetries: 3             # Retry attempts on failure\n    timeout: 10s              # Client write timeout\nEOF\n</code></pre>"},{"location":"apps/remote-write/#export-interfaces-statistics","title":"Export: Interfaces Statistics","text":"<p>Defines what metrics to export and to which destinations. Metrics are retrieved from the state DB at the given <code>path</code> and can include optional filtering, labeling, and transformation.</p> YAML<code>kubectl</code> <pre><code>apiVersion: remotewrite.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: interface-stats\n  namespace: eda\nspec:\n  exports:\n    - prefix: interfaces\n      path: .namespace.node.srl.interface.statistics # EQL path\n      interval: 30s                                  # Optional polling interval\n      mode: periodic                                 # periodic | on-change | periodic-on-change\n      fields: [\"in-octets\", \"out-octets\"]            # Optional subset of fields\n      labels:\n        static:\n          - name: region\n            value: us-west\n  destinations:\n    - name: dest1\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: remotewrite.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: interface-stats\n  namespace: eda\nspec:\n  exports:\n    - prefix: interfaces\n      path: .namespace.node.srl.interface.statistics # EQL path\n      interval: 30s                                  # Optional polling interval\n      mode: periodic                                 # periodic | on-change | periodic-on-change\n      fields: [\"in-octets\", \"out-octets\"]            # Optional subset of fields\n      labels:\n        static:\n          - name: region\n            value: us-west\n  destinations:\n    - name: dest1\n\nEOF\n</code></pre>"},{"location":"apps/remote-write/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"apps/remote-write/#destination-resource-options","title":"Destination Resource Options","text":"<ul> <li>authentication: <code>username</code>/<code>password</code> for basic auth.</li> <li>authorization: <code>type</code> (for example, Bearer) and token-based credentials.</li> <li>tls: Provide CA/cert/key file paths and <code>skipVerify</code> flag.</li> <li>writeOptions: Tune buffer size, flush interval, custom HTTP headers, retries, and timeouts.</li> <li> <p>metadata:</p> <ul> <li><code>include</code>: Whether to send metadata.</li> <li><code>interval</code>: Frequency of metadata updates.</li> <li><code>maxEntriesPerWrite</code>: Limit per request.</li> </ul> </li> </ul>"},{"location":"apps/remote-write/#export-resource-options","title":"Export Resource Options","text":"<ul> <li>path (required): State DB path to collect from.</li> <li>mode: <code>periodic</code>, <code>on-change</code>, or <code>periodic-on-change</code>.</li> <li>interval: Polling interval for metric collection.</li> <li>fields: Optional subset of fields to export.</li> <li>labels: Static and dynamic labels.</li> <li>mappings: Transform field values using regex and numeric replacements.</li> <li>metricName: Rename metrics using regex.</li> <li>resource: Use a CR as source; metric value is <code>1</code>, and CR labels are used as metric labels.</li> <li>where: Filtering condition (e.g., <code>admin-state = enable</code>).</li> </ul>"},{"location":"apps/virtualnetwork/","title":"Virtual Network (VNET)","text":"<p>The Virtual Network (<code>VNET</code>) application is a resource designed to group and manage network services together, typically deployed as overlay services. The VNET simplifies management by serving as a single input for a set of resources that support a common set of applications.</p>"},{"location":"apps/virtualnetwork/#core-components-of-vnet","title":"Core Components of VNET","text":"<p>The primary components that make up the VNET include:</p> <ul> <li> <p>BridgeDomain: Represents a Layer 2 broadcast domain. It is used in conjunction with VLAN and BridgeInterface resources, which attach sub-interfaces to this L2 broadcast domain.</p> </li> <li> <p>VLAN: Groups sub-interfaces together under a common VLAN ID. VLAN IDs can be automatically assigned from a pool or manually set by the user.  The VLAN uses a label selector to select the interfaces on which to provisioning the sub-interfaces.</p> </li> <li> <p>BridgeInterface: Allows operators to manually attach a sub-interface to a specific BridgeDomain.</p> </li> <li> <p>Router: Acts as a Layer 3 domain manager. It can connect multiple BridgeDomains through an <code>IRBInterface</code> or link directly to <code>RoutedInterfaces</code>.</p> </li> <li> <p>IRBInterface (Integrated Routing and Bridging Interface): Connects a BridgeDomain to a Router, facilitating communication between Layer 2 and Layer 3 networks.</p> </li> <li> <p>RoutedInterface: Represents a directly connected Layer 3 interface on a device that is attached to a Router.</p> </li> <li> <p>DHCPRelay: Enables DHCP relay functionality on sub-interfaces within the VNET, facilitating dynamic IP address allocation.</p> </li> </ul>"},{"location":"apps/virtualnetwork/#additional-capabilities","title":"Additional Capabilities","text":"<ul> <li>PE-CE BGP: The VNET also supports Provider Edge to Customer Edge (PE-CE) BGP.</li> <li>IP Filters: IPv4, IPv6 and MAC filters can also be used within the <code>VirtualNetwork</code>.</li> <li>DSCP and Dot1p classifiers: Attachment of DSCP and Dot1p classifiers are also supported.</li> </ul>"},{"location":"apps/virtualnetwork/#example-vnets","title":"Example VNETs","text":""},{"location":"apps/virtualnetwork/#layer-2-vnet","title":"Layer 2 VNET","text":"<code>kubectl</code>YAML <pre><code>cat &lt;&lt; 'EOF' | tee l2-vnet.yaml | kubectl apply -f -\napiVersion: services.eda.nokia.com/v1alpha1\nkind: VirtualNetwork\nmetadata:\n  name: vnet1\n  namespace: eda\nspec:\n  bridgeDomains:\n    - name: bd1\n      spec:\n        eviPool: evi-pool\n        l2proxyARPND:\n          dynamicLearning:\n            ageTime: 2000\n            enabled: true\n            sendRefresh: 2000\n          ipDuplication:\n            enabled: true\n            holdDownTime: 10\n            monitoringWindow: 10\n            numMoves: 4\n          proxyARP: true\n          proxyND: false\n          tableSize: 250\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  vlans:\n    - name: storage\n      spec:\n        bridgeDomain: bd1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=storage\n        vlanID: pool\n        vlanPool: vlan-pool\n    - name: compute\n      spec:\n        bridgeDomain: bd1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=compute\n        vlanID: pool\n        vlanPool: vlan-pool\n\nEOF\n</code></pre> <pre><code>apiVersion: services.eda.nokia.com/v1alpha1\nkind: VirtualNetwork\nmetadata:\n  name: vnet1\n  namespace: eda\nspec:\n  bridgeDomains:\n    - name: bd1\n      spec:\n        eviPool: evi-pool\n        l2proxyARPND:\n          dynamicLearning:\n            ageTime: 2000\n            enabled: true\n            sendRefresh: 2000\n          ipDuplication:\n            enabled: true\n            holdDownTime: 10\n            monitoringWindow: 10\n            numMoves: 4\n          proxyARP: true\n          proxyND: false\n          tableSize: 250\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  vlans:\n    - name: storage\n      spec:\n        bridgeDomain: bd1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=storage\n        vlanID: pool\n        vlanPool: vlan-pool\n    - name: compute\n      spec:\n        bridgeDomain: bd1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=compute\n        vlanID: pool\n        vlanPool: vlan-pool\n</code></pre>"},{"location":"apps/virtualnetwork/#layer-3-vnet","title":"Layer 3 VNET","text":"<code>kubectl</code>YAML <pre><code>cat &lt;&lt; 'EOF' | tee l3-vnet.yaml | kubectl apply -f -\n---\napiVersion: services.eda.nokia.com/v1alpha1\nkind: VirtualNetwork\nmetadata:\n  name: vnet2\n  namespace: eda\nspec:\n  bridgeDomains:\n    - name: app1\n      spec:\n        eviPool: evi-pool\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n    - name: app2\n      spec:\n        eviPool: evi-pool\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  irbInterfaces:\n    - name: irb1\n      spec:\n        arpTimeout: 14400\n        bfd:\n          desiredMinTransmitInt: 150002\n          detectionMultiplier: 4\n          enabled: true\n          minEchoReceiveInterval: 1000000\n          requiredMinReceive: 150000\n        bridgeDomain: app1\n        evpnRouteAdvertisementType:\n          arpDynamic: true\n          arpStatic: true\n          ndDynamic: false\n          ndStatic: false\n        hostRoutePopulate:\n          dynamic: true\n          evpn: true\n          static: false\n        ipAddresses:\n          - ipv4Address:\n              ipPrefix: 13.3.3.1/24\n              primary: true\n            ipv6Address:\n              ipPrefix: fc00:31::1/120\n              primary: true\n          - ipv4Address:\n              ipPrefix: 14.4.4.1/24\n              primary: false\n            ipv6Address:\n              ipPrefix: fc00:41::1/120\n              primary: false\n        ipMTU: 1500\n        l3ProxyARPND:\n          proxyARP: false\n          proxyND: false\n        learnUnsolicited: NONE\n        router: routetable1\n    - name: irb2\n      spec:\n        arpTimeout: 14400\n        bfd:\n          desiredMinTransmitInt: 150002\n          detectionMultiplier: 4\n          enabled: true\n          minEchoReceiveInterval: 1000000\n          requiredMinReceive: 150000\n        bridgeDomain: app2\n        evpnRouteAdvertisementType:\n          arpDynamic: true\n          arpStatic: true\n          ndDynamic: false\n          ndStatic: false\n        hostRoutePopulate:\n          dynamic: true\n          evpn: true\n          static: false\n        ipAddresses:\n          - ipv4Address:\n              ipPrefix: 15.3.3.1/24\n              primary: true\n            ipv6Address:\n              ipPrefix: fc00:51::1/120\n              primary: true\n          - ipv4Address:\n              ipPrefix: 16.4.4.1/24\n              primary: false\n            ipv6Address:\n              ipPrefix: fc00:61::1/120\n              primary: false\n        ipMTU: 1500\n        l3ProxyARPND:\n          proxyARP: false\n          proxyND: false\n        learnUnsolicited: NONE\n        router: routetable1\n  routers:\n    - name: routetable1\n      spec:\n        eviPool: evi-pool\n        routerID: 5.4.3.2\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  vlans:\n    - name: vlan1\n      spec:\n        bridgeDomain: app1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=storage\n        vlanID: pool\n        vlanPool: vlan-pool\n    - name: vlan2\n      spec:\n        bridgeDomain: app2\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=compute\n        vlanID: pool\n        vlanPool: vlan-pool\n\nEOF\n</code></pre> <pre><code>---\napiVersion: services.eda.nokia.com/v1alpha1\nkind: VirtualNetwork\nmetadata:\n  name: vnet2\n  namespace: eda\nspec:\n  bridgeDomains:\n    - name: app1\n      spec:\n        eviPool: evi-pool\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n    - name: app2\n      spec:\n        eviPool: evi-pool\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  irbInterfaces:\n    - name: irb1\n      spec:\n        arpTimeout: 14400\n        bfd:\n          desiredMinTransmitInt: 150002\n          detectionMultiplier: 4\n          enabled: true\n          minEchoReceiveInterval: 1000000\n          requiredMinReceive: 150000\n        bridgeDomain: app1\n        evpnRouteAdvertisementType:\n          arpDynamic: true\n          arpStatic: true\n          ndDynamic: false\n          ndStatic: false\n        hostRoutePopulate:\n          dynamic: true\n          evpn: true\n          static: false\n        ipAddresses:\n          - ipv4Address:\n              ipPrefix: 13.3.3.1/24\n              primary: true\n            ipv6Address:\n              ipPrefix: fc00:31::1/120\n              primary: true\n          - ipv4Address:\n              ipPrefix: 14.4.4.1/24\n              primary: false\n            ipv6Address:\n              ipPrefix: fc00:41::1/120\n              primary: false\n        ipMTU: 1500\n        l3ProxyARPND:\n          proxyARP: false\n          proxyND: false\n        learnUnsolicited: NONE\n        router: routetable1\n    - name: irb2\n      spec:\n        arpTimeout: 14400\n        bfd:\n          desiredMinTransmitInt: 150002\n          detectionMultiplier: 4\n          enabled: true\n          minEchoReceiveInterval: 1000000\n          requiredMinReceive: 150000\n        bridgeDomain: app2\n        evpnRouteAdvertisementType:\n          arpDynamic: true\n          arpStatic: true\n          ndDynamic: false\n          ndStatic: false\n        hostRoutePopulate:\n          dynamic: true\n          evpn: true\n          static: false\n        ipAddresses:\n          - ipv4Address:\n              ipPrefix: 15.3.3.1/24\n              primary: true\n            ipv6Address:\n              ipPrefix: fc00:51::1/120\n              primary: true\n          - ipv4Address:\n              ipPrefix: 16.4.4.1/24\n              primary: false\n            ipv6Address:\n              ipPrefix: fc00:61::1/120\n              primary: false\n        ipMTU: 1500\n        l3ProxyARPND:\n          proxyARP: false\n          proxyND: false\n        learnUnsolicited: NONE\n        router: routetable1\n  routers:\n    - name: routetable1\n      spec:\n        eviPool: evi-pool\n        routerID: 5.4.3.2\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  vlans:\n    - name: vlan1\n      spec:\n        bridgeDomain: app1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=storage\n        vlanID: pool\n        vlanPool: vlan-pool\n    - name: vlan2\n      spec:\n        bridgeDomain: app2\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=compute\n        vlanID: pool\n        vlanPool: vlan-pool\n</code></pre>"},{"location":"apps/virtualnetwork/#verify-the-status-of-the-virtualnetwork","title":"Verify the status of the <code>VirtualNetwork</code>","text":"<p>Verify the fabric operational state:</p> <pre><code>kubectl -n eda get virtualnetwork\n\nNAME    OPERATIONALSTATE   LASTCHANGE\nvnet1   down               2024-04-30T21:26:36.000Z\nvnet2   degraded           2024-04-30T22:47:38.000Z\n</code></pre>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/subscribe/","title":"Subscribe To This Blog","text":"<p>If you want to get notified when a new post is published on this blog - consider subscribing via one of the following channels.</p>"},{"location":"blog/subscribe/#rss","title":"RSS","text":"<p>This blog publishes two RSS feeds:</p> <ul> <li><code>https://docs.eda.dev/feed_rss_created.xml</code> - feed is updated whenever a new post is created.</li> <li><code>https://docs.eda.dev/feed_rss_updated.xml</code> - feed is updated whenever a new post is created or updated.</li> </ul> <p>Depending on how thoroughly you want to monitor the blog choose between those two feeds.</p>"},{"location":"blog/subscribe/#email","title":"Email","text":"<p>You can get notifications in your mailbox by channeling the RSS feed using one of the RSS-to-Email services.</p> <p>A popular option is a free blogtrottr service, but if it doesn't suit you, there are alternatives like feedrabbit and IFTT.</p> <p>In blogtrottr, all you need to do is to enter <code>https://docs.eda.dev</code> in the site input field, type in your email and select the \"Realtime\" delivery option. Then select which feed you want to receive.</p>"},{"location":"blog/tags/","title":"Tags","text":""},{"location":"blog/tags/#tag:installation","title":"installation","text":"<ul> <li>            Try EDA Like a Pro          </li> </ul>"},{"location":"blog/tags/#tag:media","title":"media","text":"<ul> <li>            The beginning of an era EDA          </li> </ul>"},{"location":"blog/tags/#tag:nfd","title":"nfd","text":"<ul> <li>            The beginning of an era EDA          </li> </ul>"},{"location":"blog/tags/#tag:release","title":"release","text":"<ul> <li>            EDA 25.4          </li> </ul>"},{"location":"blog/the-beginning-of-an-era-eda/","title":"The beginning of an era EDA","text":"<p>Today marks a huge milestone. You may have heard us talking about \"EDA\" at several public events - now you get to experience it for yourself.</p> <p>It was a mere 24 months ago that we started the initial design for a next generation controller, which eventually adopted the codename EDA - Event Driven Automation.</p> <p>Our goals were lofty; intents without inflexibility, simplified consumption of streaming telemetry, multi vendor, multi domain, CI/CD, pipelines, all encompassing revision control, all built for the modern tooling era.</p> <p>Did we succeed? You get to be the judge!</p> <p></p>","tags":["media","nfd"]},{"location":"blog/the-beginning-of-an-era-eda/#eda","title":"EDA?","text":"<p>If you've never heard of EDA before there is no better place to start than checking out the NFD special dedicated to this next generation automation controller.</p> <p>Before diving into the technical details, we wanted to share a bit about our motivations. What problems we saw unsolved and how we saw EDA as a solution, and the world of declarative abstractions.</p> <p>What you will notice when reading through this engineering documentation portal is that we always try to put a demo behind the concepts we are describing. Our NFD appearance was not an exception - after explaining the design goals, drawing out the problem space and telling you how we think EDA is fit to solve them, we did a live demo of EDA in action.</p> <p>How to deploy the whole fabric config in a network-wide transaction over a fleet of devices using declarative abstractions? How declarative abstractions can be nested and composed? How leveraging modeled network management interfaces can guarantee safety and reliability when used in conjunction with a transaction model? This is all waiting for you in the next video:</p> <p>After covering the configuration aspects of EDA we switch to state. What exactly do we mean by saying that abstractions should not only be for configuration, but also for state? How having state and configuration together can help operations? What would it look like to have a query language for your whole network, both for config and state? And lastly, if you came for AI bits - this video is for you!</p>","tags":["media","nfd"]},{"location":"blog/the-beginning-of-an-era-eda/#try-eda","title":"Try EDA","text":"<p>The NFD videos are a great introduction to the concepts behind EDA, and it is highly likely we target the same problems you face with existing automation software. In that case, you would presumably willing to book an EDA demo... While booking a demo is absolutely possible, we are confident that you'll be able to recognize the value of EDA by running it in your own environment and on your own terms.</p> <p>And with that said. the team<sup>1</sup> is immensely proud to share EDA's first public release tagged with <code>24.12.1</code> version. This release is available for everyone to enjoy without a license and is available for download from the public GitHub container registry. No, really - no pay walls or registration walls.</p> <p> Try EDA </p> <p>We're excited to see the yet-unimagined ways you'll use the framework to solve interesting automation problems.</p>","tags":["media","nfd"]},{"location":"blog/the-beginning-of-an-era-eda/#community","title":"Community","text":"<p>EDA is a framework that allows users to create their own automation journey by creating custom abstractions, CI/CD workflows, composable UI dashboards, and applications that can be shared with the community. We wholeheartedly believe that the automation flourishes when it is open, collaborative, and accessible to everyone.</p> <p>As with SR Linux, we host our community Discord server and invite everyone to join us as we push the boundaries of what is possible with automation.</p> <p>  Join EDA Discord </p> <ol> <li> <p>From the EDA development, test, and product management teams.\u00a0\u21a9</p> </li> </ol>","tags":["media","nfd"]},{"location":"blog/try-eda-like-a-pro/","title":"Try EDA Like a Pro","text":"<p>Our tiny but mighty <code>make try-eda</code> command carries out the entire EDA Playground installation. It installs a Kubernetes cluster, deploys the EDA core apps, and creates the necessary playground components along with a simulated network topology. Automation greatness, one click away. Just like we love it.</p> <p>But as you build up your EDA experience, you may find yourself eager to step off the beaten path and start customizing your installation experience to your needs. In this blog post we share some new additions made to the Playground installation to make your Try EDA experience more enjoyable.</p>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#preferences-file","title":"Preferences file","text":"<p>Most likely you started your EDA journey by following our quickstart guide and deployed your playground environment like this:</p> <pre><code>make try-eda\n</code></pre> <p>Yes, this is all you need to get the ball rolling, but providing the variable values inline is not always convenient. Often you want to store the values in a configuration file.</p> <p>EDA's Playground config is powered by the make's preferences file and we ship the instance of it - <code>prefs.mk</code> - within the playground repo itself.</p> <p>The preferences file contains a selected set of the \"most wanted\" variables that you would want to tune for your playground installation. Things like the address you use to access the UI, the proxy settings, and kind cluster name.</p> <p>You can of course edit the provided <code>prefs.mk</code> file, but what I like to do is to create a new file within the <code>./private</code> directory where I can store my values without changing the original file. There are a few reasons for this:</p> <ol> <li>Keep the git repo clean, as the files in the <code>private</code> directory are not tracked by git.</li> <li>Doing <code>git pull</code> won't overwrite the changes I made to a copy of the <code>prefs.mk</code> file.</li> <li>I can create multiple preferences files for different installation scenarios.</li> </ol> <p>If you opt in using a custom preferences file you would need to set the <code>PLAYGROUND_PREFS_FILE</code> environment variable to point to the file you want to use.</p> Using a custom preferences file<pre><code>export PLAYGROUND_PREFS_FILE=\"private/kind-prefs.mk\" #(1)!\nmake try-eda\n</code></pre> <ol> <li>Both absolute and relative paths are supported.</li> </ol> Spice it up with direnv <p>A neat trick is to use direnv tool and create an <code>.envrc</code> file in your working directory that would set the <code>PLAYGROUND_PREFS_FILE</code> variable to point to the file you want to use.</p> <code>.envrc</code><pre><code>export PLAYGROUND_PREFS_FILE=\"private/kind-prefs.mk\"\n</code></pre>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#kpt-setters-file","title":"KPT Setters File","text":"<p>Alright, you noticed that the make preferences file contain only a handful of variables. But what if you want to customize the installation further?</p> <p>EDA uses the kpt to deploy and manage the configuration of its components. When browsing the nokia-eda/kpt repository you may notice the <code>kpt-set</code> comments in various kubernetes manifests:</p> snippet from <code>eda-kpt-base/engine-config/engineconfig.yaml</code><pre><code>apiVersion: core.eda.nokia.com/v1\nkind: EngineConfig\nmetadata:\n  name: engine-config # kpt-set: ${CLUSTER_MEMBER_NAME}\nspec:\n  # ...\n  llm:\n    apiKey: \"\" # kpt-set: ${LLM_API_KEY}\n    model: gpt-4o # kpt-set: ${LLM_MODEL}\n  simulate: true # kpt-set: ${SIMULATE}\n</code></pre> <p>These <code>kpt-set</code> comments are markers for the kpt tool that these values can set by Kpt using the <code>${VARIABLE_NAME}</code> syntax. How would you set the values of these variables you ask? Using the Kpt setters file.</p> <p>Kpt Setters Reference</p> <p>We maintain the reference of all available setters in our docs.</p> <p>The setters file allow you to specify the values for the setters that will be used when you install EDA Playground. For example, to set the PV claim volume size for the Git server deployment, you would create a yaml file like this:</p> <code>my-setters.yml</code><pre><code>apiVersion: v1\nkind: ConfigMap #(1)!\nmetadata:\n  name: my-setters\ndata:\n  GOGS_REPLICA_PV_CLAIM_SIZE: 10Gi #(2)!\n  # your other setters here\n</code></pre> <ol> <li>As you can see, the setters file is a ConfigMap resource, but it is not applied to your cluster, it is only used by the kpt tool to read the values from it.</li> <li>The setter's key must match the name of the setter variable in the manifest file.</li> </ol> <p>Now that you have your setters file with the necessary values, you should set the path to it in the preferences file:</p> <pre><code>KPT_SETTERS_FILE := private/my-setters.yml\n</code></pre> <p>And that's it! The kpt will read the values from the setters file and apply them to the manifests when you run the <code>make try-eda</code> command.</p>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#kind-config","title":"Kind Config","text":"<p>The default EDA Playground installation deploys the platform on a KinD cluster. And by default we deploy a default KinD cluster using a barebones cluster configuration.</p> <p>This works great for the most installation scenarios, but sometimes you need to customize the kind cluster configuration. For example, you may need to add extra bits of configuration to play with Ingress resources and expose additional ports for your cluster.</p> <p>We allow you to use your own kind configuration file by setting the <code>KIND_CONFIG_FILE</code> variable in the preferences file pointing to the desired config file. Here is an example of a custom kind config file that I use to setup ingress nginx with kind:</p> kind configpreferences file <code>private/kind-ingress-config.yml</code><pre><code>---\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnetworking:\n  ipFamily: dual\n  apiServerAddress: \"127.0.0.1\"\nnodes:\n  - role: control-plane\n    kubeadmConfigPatches:\n      - |\n        kind: InitConfiguration\n        nodeRegistration:\n          kubeletExtraArgs:\n            node-labels: \"ingress-ready=true\"\n    extraPortMappings:\n      - containerPort: 80\n        hostPort: 80\n        protocol: TCP\n      - containerPort: 443\n        hostPort: 443\n        protocol: TCP\n</code></pre> <pre><code>KIND_CONFIG_FILE := private/kind-ingress-config.yml\n</code></pre>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#llm-api-key","title":"LLM API Key","text":"<p>The Natural Language Query feature requires an OpenAI API key to be set in the EDA's Engine Config resource. You can provide the key directly in the preferences file using the <code>LLM_API_KEY</code> variable, but providing a \"secret\" in a file body is not the most secure way to do it.</p> <p>Instead, you can set the environment variable under the same key <code>LLM_API_KEY</code> in your <code>.profile</code>, <code>.zshenv</code>, <code>.bashrc</code>, <code>.zshrc</code>, or any other file that your shell reads on startup. Make tool will read the env variable under this key by default, so you may leave the variable unset in the preferences file.</p>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#kind-api-server-address","title":"Kind API Server Address","text":"<p>When we deploy a Kind cluster for EDA Playground, the k8s API server address is kept at its default value of <code>127.0.0.1</code>. The localhost nature of the address results in the k8s API server being inaccessible from outside the machine you run the cluster on.</p> <p>We noticed that many users would like to spin up playground on a remote servers and access the k8s API server via a network. To support this use case, we added the <code>KIND_API_SERVER_ADDRESS</code> variable to the preferences file which allows you to set the non localhost IP address for the k8s API server. This effectively allows you to access the k8s API server from outside the machine you run the cluster on.</p>","tags":["installation"]},{"location":"blog/eda-254/","title":"EDA 25.4","text":"<p>It is that time again  The EDA product team are pleased to announce the release of EDA 25.4.1 </p> <p>The team have been hard at work; introducing our first non-SR Linux OS, a boatload of QoL UI improvements (bulk edits!), and a number of app extensions to cover additional use cases.</p> <p>To some numbers! In this release we delivered 152 GA features, 14 alpha features, and 90 beta features (I'll come back to this later).</p> <p>Our big themes for this release were DX (or Developer Experience) and productizing SR OS as a first class citizen.</p> <p>To look at DX first, with EDA 25.4 we are providing:</p> <ul> <li> <p>Extensions to <code>edactl</code> to support intent debuggability (under edactl intent debug).     This includes the ability to trigger instances of intents to run, with DEBUG toggled to allow more logging verbosity.</p> <p>It includes the ability to monitor execution of instances (including the immediate monitor + trigger). This massively improves intent debuggability, dumping any logs, subscriptions, inputs, and outputs your application received/emitted.</p> <p>For performance debugging, stats are provided for all execution of all intents, including number of executions and cumulative execution time.</p> </li> <li> <p>The new <code>edabuilder</code> tool.</p> <p>Purposefully built for developing applications on EDA (intent-based or otherwise). The initial focus of the tool is primarily to assist with the scaffolding/packaging/testing/publishing of an application, including its resources and intents. A new section of documentation dedicated to the above.</p> </li> </ul> <p>Now for Nokia SR OS - our first litmus test on our claims of supporting multiple operating systems. We are releasing this as beta in EDA 25.4.1, with the expectation that this graduates to GA in 25.8.1. The large number of beta features mentioned above relate to this.</p> <p>You are free to try EDA with SR OS in a lab environment, with most apps already providing support.</p> <p>There are minor gaps in app coverage for SR OS (upgrades are not supported for example), but you should find coverage for the common use cases we support SR Linux for, including:</p> <ul> <li>ZTP (including component configuration)</li> <li>Underlay via the Fabric resource and its dependencies.</li> <li>Overlay via the VirtualNetwork resource and its dependencies.</li> <li>The surrounding set of policies/profiles in filters, QoS, routing policies, and almost everything else.</li> <li>Queries with EQL, including natural language.     Use <code>sros:</code> as a prefix to force a query to only SR OS devices.</li> <li>Normalization of all state data, including overlays (CPU, memory, disk).</li> <li>Lots, lots more.</li> </ul> <p>This covers SR OS both as a DC GW (using option A), and as any of the roles used by SR Linux today - leaf, spine, superspine.</p> <p>Supported SR OS releases</p> <p>You must use SR OS 24.10R4 or above, or 25.3R2 or above.</p> <p>For now you must run SR OS nodes in containerlab, or interact with real hardware in your physical lab.</p> <p>Beyond these themes you'll find new overlays, extensions to our integrations with Prometheus, ServiceNow, PagerDuty, and NetBox, and enhancements in our integration with OpenStack.</p> <p>You'll also (if you're paying attention) notice huge speed improvements in transactions and general scale improvements at scale. We were already blazing fast here (deploying scaled fabrics in seconds) but we have managed to squeeze a measly 10x improvement in some intent apps, with most seeing somewhere in the 5-8x range.</p> <p>With that said, onwards!</p> <p>If you aren't there yet, join the EDA Discord server: https://eda.dev/discord.</p> <p>with  from the EDA product team</p>","tags":["release"]},{"location":"blog/150-minutes-of-eda/","title":"150 minutes of EDA","text":"<p>A week ago we gathered for the 20<sup>th</sup> time with our partners and customers to share our vision for the future of networking. The sunny Tarragona hosted our SReXperts EMEA 2025 and it was a blast. Many after-event social media postings<sup>1</sup><sup>2</sup><sup>3</sup> can give you a taste of the event.</p> <p>It was also the first time we hosted the EDA hackathon for the lucky hundred participants who were there with us on the first day to learn about the product and later solve some challenges we carefully outlined on the https://hack.srexperts.net website.</p> <p>It was great to see so many people getting engaged and excited about the possibilities EDA brings to the industry and getting the most out of the practical exercises.</p> <p>Yet, we understand that not everyone could make it to the event, and that's why we've decided to share the theoretical part of the hackathon with the community, as we believe in the power of knowledge sharing and collaboration.</p> <p>When introducing EDA to the community, we wanted to cut it close to the wire and mix the slides with real demos. In fact, we had eight demos flawlessly executed from the stage as we were introducing the concepts to the audience.</p> <p>Once I landed from Tarragona, I started to slice the single stream into topics, and this resulted in seven parts, each with a clear message and scope. We hope you enjoy the content and find it useful, as we had a lot of fun preparing it.</p> <p>Don't forget to join our Discord if you want to connect with us and learn more.</p>"},{"location":"blog/150-minutes-of-eda/#building-on-k8s-and-try-eda","title":"Building on K8s and \"Try EDA\"","text":"<p>Nokia EDA uses Kubernetes not only as a universal deployment platform that enables high availability and horizontal scaling, but also brings the Kubernetes Resource Model concepts to networking to ensure declarative configuration of resources.</p> <p>In Part 1 we explore the benefits of using Kubernetes as a platform for infrastructure and network automation and explain how to make use of the \"Try EDA\" installation that brings the full-fledged EDA setup with a Digital Twin and a small DC pod on the side.</p>"},{"location":"blog/150-minutes-of-eda/#declarative-abstractions-labels-and-allocation-pools","title":"Declarative Abstractions, Labels, and Allocation Pools","text":"<p>The networking industry has pretty much converged on the benefits that abstractions bring to the table. Instead of exposing dozens of nerd knobs, we tend to create business-critical and user-friendly abstractions. Couple the abstracted input with declarative principles and you get a modern and simple network management solution. But simple is hard.</p> <p>In Part 2 we present the core concepts of EDA, starting with Declarative Abstractions. All EDA resources (Interface, BGP Peer, Static Route, etc.) are declarative and abstract. This concept underpins the simplicity and multivendor design principles we strive to offer to users.</p> <p>Next, we introduce the two ways a user can select and reference resources in EDA - by name or labels. The label-based selection plays a key role in automation at scale, where the mapping is done implicitly by dereferencing objects with a given label set.</p> <p>At the end of this part we talk about Allocation Pools, a concept that allows users to reliably manage resources such as indices, IP addresses, ASNs and so on.</p>"},{"location":"blog/150-minutes-of-eda/#building-an-evpn-vxlan-fabric","title":"Building an EVPN VXLAN Fabric","text":"<p>The concepts introduced in Part 2 https://youtu.be/a7j_xKz7XhI enable EDA users to declaratively build and manage complex networks by offering simple and abstracted input.</p> <p>Take an EVPN VXLAN fabric, for instance. To build an EVPN VXLAN fabric one needs to sort out things like underlay addressing, BGP peer configuration, ASN assignments, ACL policy creation, overlay protocol setup and many other adjacent tasks.</p> <p>A perfect task for an abstracted intent, don't you think? This is exactly our plan for this part where we build a fabric across our topology by providing the bare minimum configuration input, and the system takes care of the rest.</p>"},{"location":"blog/150-minutes-of-eda/#network-wide-transactions-and-deviations","title":"Network-wide Transactions and Deviations","text":"<p>With great power comes great responsibility. Performing automation at scale without having reliability built-in is a recipe for a massive outage. With Nokia EDA you get best-in-class network-wide transaction support where a configuration change undergoes a set of checks:</p> <ul> <li>syntax check</li> <li>schema validation</li> <li>dependency check</li> <li>node-based check</li> </ul> <p>And if any of the checks fail, the whole transaction reverts to ensure that you don't have partially rolled out configuration. Worry-free configuration push on Friday is closer than you might think.</p>"},{"location":"blog/150-minutes-of-eda/#network-state-and-query-language","title":"Network State and Query Language","text":"<p>In the DIY world of network automation we have a peculiar split - we perform configuration management with one set of tools (terraform, ansible, scrapli, napalm) and we deal with the network state using a completely different set of tools (zabbix, grafana, librenms).</p> <p>This severance does not do justice for operations, though, asking the NOC teams to correlate raw state metrics with the deployed services. How do you know if your service for a particular tenant is running?</p> <p>Things are different in the EDA realm where any given resource submitted to EDA has a corresponding state reported for it. If you configured the Fabric in part 3, you know that even this composite abstraction has a state associated with it. Knowing the health score of your Fabric gives you clear visibility into its performance and reduces the complexity in day 2+ operations.</p> <p>Besides having the state of the resources, we bring you the real-time, distributed and network-wide query language that runs across all your network with blazing fast performance. Do you want to find that rogue MAC in your DC fabric? You can, even with natural language support.</p> <p>Operations are often neglected in DIY solutions, and we are set to change that.</p>"},{"location":"blog/150-minutes-of-eda/#building-virtual-networks","title":"Building Virtual Networks","text":"<p>As we start with datacenter automation, one of the prime-time automation activities is creating overlay networks on top of the EVPN VXLAN fabric.</p> <p>Again, building on top of declarative abstraction principles, we offer you a range of resources to help achieve your goal. Do you need a layer 2 network? Take the Bridge Domain resource. Want to create a layer 3 network? Use the Router resource. Combine the two with the IRB Interface resource and you get a distributed L\u2154 network.</p> <p>On top of that you can create Routed Interfaces and set up BGP Peers on them to break out from your datacenter and achieve external connectivity.</p> <p>The reusability of abstracted components in EDA makes it easy to mix and match and build tailored network designs without compromising the declarative principles.</p>"},{"location":"blog/150-minutes-of-eda/#automation-and-extensibility","title":"Automation and Extensibility","text":"<p>Not API-first, but API-only. EDA lives and breathes APIs and we hope you will appreciate our strong focus on automation. Everything you can do via EDA UI is possible to achieve with any REST API client, as EDA UI is just a client of the API.</p> <p>But API alone is not enough to ensure you get the best out of the platform. EDA, like Kubernetes, is a platform to build upon, and we can't wait to see what you will build on it. To support you in this endeavor we offer developer experience tools like EDABuilder to help you build and package EDA apps.</p> <p>Oh yes, apps - everything in EDA is an app and you can fork, edit an existing one or build your own app. Abstracting the provided abstractions? Possible.</p> <p>To ensure your applications can be discovered and managed we implemented the EDA Store - a component that discovers applications from catalogs. You can publish your apps to your own catalog and make EDA watch it and discover apps from it. Lots of options to offer you full flexibility in how you create, host and distribute EDA apps.</p> <ol> <li> <p>https://www.linkedin.com/feed/update/urn:li:activity:7337432794446393344/ \u21a9</p> </li> <li> <p>https://www.linkedin.com/posts/vach-kompella-75846_nokia-srexperts-evpn-activity-7241886104923037696-T8IJ \u21a9</p> </li> <li> <p>https://www.linkedin.com/posts/rdodin_autocon3-srexperts2025-containerlab-activity-7336793194862411778-QhtC \u21a9</p> </li> </ol>"},{"location":"connect/audit/","title":"Audit","text":""},{"location":"connect/audit/#overview","title":"Overview","text":"<p>The EDA Cloud Connect plugins are listening to or directly interacting with the cloud platforms they manage. Sometimes this connection can be broken temporarily or be out of sync. To automatically fix these out of sync events, you can run an audit on the plugin.</p> <p>An audit can be launched through the UI by navigating to System Administration-&gt;Connect-&gt;Audit. </p> <p>As an alternative, you can also create an <code>Audit</code> resource in the Kubernetes cluster of EDA with the following content:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectAudit\nmetadata:\n  name: test-audit\n  namespace: eda\nspec:\n  connectPluginName: &lt;name of the plugin&gt;\n  scope: PLUGIN\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectAudit\nmetadata:\n  name: test-audit\n  namespace: eda\nspec:\n  connectPluginName: &lt;name of the plugin&gt;\n  scope: PLUGIN\n\nEOF\n</code></pre>"},{"location":"connect/audit/#audit-result","title":"Audit Result","text":"<p>An audit runs out-of-band inside the plugin (that is, VMWare or OpenShift plugin). You can follow this process using the .status.state field, which will progress from Scheduled to InProgress to Finished. Once the audit is finished, the spec.finished field will be true.</p> <p>An example output is given below: <pre><code>status:\n  endTime: \"2024-12-16T13:37:56Z\"\n  enqueueTime: \"2024-12-16T13:37:56Z\"\n  outcome: Success\n  results:\n  - auditType: ConnectPluginAudit\n    foundDiscrepancies:\n    - connectResourceKind: BridgeDomain\n      connectResourceName: 4030b313-60c5-4256-8135-57833913ce67\n      outcome: Success\n      pluginResourceKind: vlan on Distributed Virtual Portgroup\n      type: Missing\n    - connectResourceKind: Vlan\n      connectResourceName: 33b01228-b522-434c-b099-26ff69ec57c4\n      outcome: Success\n      pluginResourceKind: vlan on Distributed Virtual Portgroup\n      type: Dangling\n    - connectResourceKind: Vlan\n      connectResourceName: 0c7f00d6-5d0a-469f-85a7-6733e457df8c\n      outcome: Success\n      pluginResourceKind: vlan on Distributed Virtual Portgroup\n      type: Missing\n    outcome: Success\n    state: Finished\n  state: Finished\n  totalNumberOfDiscrepancies: 3\n  totalNumberOfSuccessfulDiscrepancies: 3\n</code></pre></p> <p>The status of an audit consists of one or more results, each one referencing a different part of the audit. In case of a PLUGIN audit, the only stage is the plugin auditing against EDA, so typically there will be only one result. The result has an AuditType field to indicate the stage of the audit, as well as an outcome field. The outcome is Success if the audit was able to correct any discrepancies found.</p> <p>If there are any discrepancies found, they are listed in the foundDiscrepancies list, detailing what resources where involved and what the taken action is. Dangling resources are resources left in EDA that are not available in the plugin environment, while missing resources are the opposite. Misconfigured resources are available in both environments, but have one or more misconfigured fields.</p> <p>Finally, a count is provided of the totalNumberOfDiscrepancies as well as successfully and failed fixes.</p>"},{"location":"connect/cloud-connect/","title":"Cloud Connect","text":""},{"location":"connect/cloud-connect/#overview","title":"Overview","text":"<p>The EDA Cloud Connect solution (or \"Connect\") acts as a bridge between EDA and different cloud environments like Red Hat OpenShift, VMware vSphere and others.</p> <p>Connect is aware of the different processes and workloads running on the servers that make up the cloud environment, while at the same time being aware of the fabric as configured on EDA itself.</p> <p>This dual awareness enables Connect to configure the fabric dynamically based on workloads coming and going on the cloud platform. It does this by inspecting the cloud itself and learning the compute server, network interface and VLAN on which a specific workload is scheduled. By also learning the topology based on the LLDP information arriving in the fabric switches, it connects those two information sources.</p>"},{"location":"connect/cloud-connect/#components","title":"Components","text":"<p>The Connect solution is built around a central service, called the Cloud Connect Core, and plugins for each supported cloud environment.</p> <p>The Connect Core is responsible for managing the plugins and the relationship between Connect interfaces (compute interfaces) and EDA interfaces (fabric interfaces or edge-links). It keeps track of the LLDP information of EDA interfaces and correlates that back to the Connect interfaces created by plugins to identify the different physical interfaces of the computes of a cloud environment.</p> <p>Connect plugins are responsible for tracking the state of compute nodes, their physical interfaces, the virtual networks created in the cloud environment and their correlation to the physical network interfaces. As applications create networks and virtual machines or containers, the plugins will inform Connect Core of the changes needed to the fabric. Plugins will also create or manage EDA BridgeDomains to make sure the correct sub-interfaces are created for the application connectivity.</p>"},{"location":"connect/cloud-connect/#plugins-overview","title":"Plugins Overview","text":"<p>Connect plugins are specifically made to inspect one type of cloud environment. While these plugins can be developed specifically targeting a custom cloud environment, Connect comes with three Nokia supported plugins:</p> <ul> <li>Connect OpenShift plugin</li> <li>Connect VMware plugin</li> </ul>"},{"location":"connect/cloud-connect/#feature-overview","title":"Feature Overview","text":"<p>Connect supports the following features:</p> <ul> <li>Creating Layer 2 EVPN overlay services on EDA.</li> <li>Automatically discovering the cloud compute resources and connectivity to the fabric using LLDP.</li> <li>Automatically resolving inconsistent states between Connect and the fabric by performing an audit between Connect and EDA.</li> <li>Using pre-existing LAGs in the fabric.</li> <li>Using the cloud management's standard network management tools to manage the fabric transparently.</li> <li>Using EVPN services that are managed by EDA. This is the case in which an operator provisions a service in EDA before making them available in the   compute environment for use. This allows for more advanced use cases than the compute environment might support natively.</li> </ul>"},{"location":"connect/cloud-connect/#installation-of-cloud-connect-core","title":"Installation of Cloud Connect Core","text":"<p>Cloud Connect is an application in the EDA app ecosystem. It can be easily installed using the EDA Store UI.</p>"},{"location":"connect/cloud-connect/#installation-using-kubernetes-api","title":"Installation using Kubernetes API","text":"<p>If you prefer installing the Connect Core using the Kubernetes API, you can do so by creating the following Workflow resource:</p> Connect Core dependencies <p>When installing through the UI, dependencies are automatically resolved; this is not the case through the API. Make sure all dependencies of the Connect Core app are installed before executing the below kubectl command.</p> <p>When the dependencies are not satisfied, an error like the following will be added to the status of the AppInstaller object:</p> <p><code>app requirements validation failed: connect.nokia requires interfaces.nokia, but interfaces.nokia is not present</code></p> YAML Resource<code>kubectl apply</code> command\" <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: connect-nokia\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v4.0.0\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: connect-nokia\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v4.0.0\n\nEOF\n</code></pre>"},{"location":"connect/cloud-connect/#plugin-configuration-options","title":"Plugin Configuration Options","text":"<p>When installing Cloud Connect via the EDA UI, users are prompted to configure the application using the following options. These settings control resource limits and behavior of the Connect controllers:</p> Configuration Option Description Default Value Interface Controller GraceTimer (<code>interfaceControllerGraceTimer</code>) The grace period (in seconds) used by the Interface Controller before acting on missing LLDP data. <code>10</code> Interface Controller Pod CPU Limit (<code>interfaceControllerCpuLimit</code>) CPU limit for the connect-interface-controller pod. <code>1</code> Interface Controller Pod Memory Limit (<code>interfaceControllerMemoryLimit</code>) Memory limit for the connect-interface-controller pod. <code>2Gi</code> Plugin Controller Pod CPU Limit (<code>pluginControllerCpuLimit</code>) CPU limit for the connect-plugin-controller pod. <code>500m</code> Plugin Controller Pod Memory Limit (<code>pluginControllerMemoryLimit</code>) Memory limit for the connect-plugin-controller pod. <code>128Mi</code> <p>These options can be adjusted during installation to meet specific performance or resource requirements.</p> Settings are an advanced use case <p>type: warning</p> <p>These settings are intended for advanced users. Misconfiguration can lead to system instability or failure. Proceed with caution and ensure changes are validated in a test environment before applying them to production.</p>"},{"location":"connect/cloud-connect/#resources","title":"Resources","text":"<p>Connect uses a pluggable architecture. The Cloud Connect core installation is a collection of controllers responsible for bridging the hypervisor world with the fabric world. It is the plugin that is responsible for introspecting the cloud environment.</p> <p>The following Custom Resources are involved:</p> ConnectPlugin The logical representation of the plugin, created for each plugin automatically when the plugin starts with valid credentials. ConnectPluginActionable An actionable is an action to be taken by the <code>ConnectPlugin</code>. It is used by the Core to tell the plugin to do something (for example: initiate an audit). ConnectPluginHeartbeat The <code>ConnectPlugin</code> will continuously send heartbeats to the Cloud Connect service to report its status and alarms. ConnectInterface The logical representation of a hypervisor NIC and/or LAG. The labels on the <code>ConnectInterface</code> are used to label the EDA interface (leaf interface) correctly so that the correct subinterfaces are created."},{"location":"connect/cloud-connect/#plugins","title":"Plugins","text":"<p>Plugins are a core component of the Event Driven Automation (EDA) Connect environment. In the Connect environment, a plugin represents the component that communicates with the external cloud services. The following plugins are supported by EDA, and are further documented in their respective sections:</p> <ul> <li>OpenShift Connect plugin</li> <li>VMware vSphere plugin</li> <li>VMware NSX plugin</li> </ul> <p>Plugins are automatically registered within the Connect service when they are deployed. Each is stored in the database with the following main properties:</p> Name A unique name based on the plugin type and compute environment it is connected to. Plugin Type The type of plugin, for example, VMware or OpenShift. Heartbeat Interval The interval, in seconds, between heartbeats that the plugin intends to use. Supported Actions The different actions a plugin can support. These are actions the Core can request the plugin to do. For example, to trigger an audit."},{"location":"connect/cloud-connect/#heartbeats","title":"Heartbeats","text":"<p>When plugins register with the Connect core service, they can indicate that they support heartbeats. When a plugin supports heartbeats, the plugin is expected to send a heartbeat to the Connect core service at an interval of the configured value (or more frequently). If the Connect core does not receive a heartbeat from the plugin after two intervals, it raises an alarm in EDA to indicate that there could be an issue with the plugin.</p>"},{"location":"connect/cloud-connect/#connect-interfaces","title":"Connect Interfaces","text":"<p>Connect interfaces are managed by the plugins and represent the network interfaces of a compute node. When a plugin notices a new compute or new network interface on a compute node, it will create a Connect interface in EDA for Connect Core to monitor.</p> <p>Connect Core uses the information from the Connect interface to determine the matching EDA interface. This is the interface on a leaf managed by EDA to which the interface on the compute is connected, or potentially multiple interfaces, in case of a LAG or bond.</p> <p>The plugin will label these Connect interfaces to indicate that Connect Core needs to make sure the matching leaf interfaces have a subinterface created in the corresponding overlay service (BridgeDomain).</p> <p>This way, only those subinterfaces that are truly necessary are configured in the fabric. This limits configuration bloat and possible security risks.</p>"},{"location":"connect/cloud-connect/#namespace-support","title":"Namespace Support","text":"<p>The EDA Connect service supports multiple namespaces. Each plugin is namespaced and can only access resources within its namespace.</p> <p>This also means that a compute cluster can only belong to a single namespace, and cannot span multiple namespaces. This is to be expected, as compute clusters belong to a single fabric, and a fabric is part of a single namespace.</p>"},{"location":"connect/cloud-connect/#connect-ui","title":"Connect UI","text":"<p>The Connect UI can be found as part of the System Administrator section of the EDA UI, and allows for inspection of the different resources owned and managed by Connect. This Connect UI follows the same design as the regular EDA UI, where the left menu for Connect opens and displays the different resources available.</p> Do not create new resources manually, as this could interfere with the behavior of the plugins. <p>type: warning</p> <p>If you have made changes manually, an audit will revert them. Changes should be made through the Cloud orchestration platform.</p>"},{"location":"connect/cloud-connect/#connect-integration-modes","title":"Connect Integration Modes","text":"<p>Integration modes define how plugins create resources in EDA for use by the applications in the compute environments.</p> <p>Connect supports two integration modes:</p> CMS-managed mode Networking concepts of the CMS (Cloud Management System) are used to create new services in EDA. EDA-managed mode Network services are created in EDA and the networking concepts in the CMS are linked or associated with these pre-existing services. <p>Each of these modes can be used by the plugins. For the plugins provided by Nokia, both modes are supported, and you can combine them and switch between them as needed. For instance, you can use one integration mode for one application, while using the other for another application.</p>"},{"location":"connect/cloud-connect/#cms-managed-integration-mode","title":"CMS-Managed Integration Mode","text":"<p>In the Cloud Management mode, Connect creates an EDA BridgeDomain resource for each subnet that is created in the Cloud Management system. In this mode, the changes in the Cloud Management system are transparently reflected into EDA. The administrator of the Cloud Management system does not require any knowledge about how to use EDA.</p>"},{"location":"connect/cloud-connect/#eda-managed-integration-mode","title":"EDA-Managed Integration Mode","text":"<p>For more advanced use cases, a more complex EVPN service (or set of services) may be needed. This can include features of these services that are supported by EDA, but not natively by the CMS. Examples are configuring complex routing or QoS policies, or using BGP PE/CE for route advertisement from the application into the network service.</p> <p>In such cases, Nokia recommends using the EDA-managed integration mode, which instructs Connect to associate the subnets in the CMS with existing BridgeDomains in EDA, instead of creating new resources in EDA based on the cloud management networking.</p> <p>In this mode, an administrator (or orchestration engine) with knowledge of EDA first creates the necessary resources in EDA directly. You can create more complex configurations than the cloud management system itself would be able to do. When creating the networking constructs in the Cloud Management system, you provide a set of unique identifiers referring to those pre-created networking constructs. This way, the Connect plugin and Connect service know not to create their own resources, but to use the pre-created items.</p>"},{"location":"connect/cloud-connect/#lldp","title":"LLDP","text":"<p>To bridge EDA with the cloud environment, Cloud Connect uses LLDP extensively. The LLDP information is collected at the fabric level and streamed to EDA. There is also support for reversing that LLDP relationship, by having the computes collect the LLDP information.</p> <ul> <li>OpenShift Plugin: LLDP collected at hypervisor level</li> <li>VMware plugin: LLDP collected at fabric level</li> </ul> <p>When LLDP is collected at the fabric level, it is advised to disable in-hardware LLDP to prevent those LLDP messages from interfering with the ones that the host operating system is sending out.<sup>1</sup><sup>2</sup></p>"},{"location":"connect/cloud-connect/#lldp-gracetimer","title":"LLDP gracetimer","text":"<p>To prevent unnecessary fabric reconfiguration due to temporary LLDP data loss, a grace period is applied when LLDP information is collected at the fabric level. During this grace period, Connect Core will not reconfigure the fabric, allowing time for LLDP data to recover. The grace period is not applicable when LLDP data is collected at the hypervisor level. The gracetimer can be configured when installing Connect using the <code>interfaceControllerGraceTimer</code> setting; the default is 10 seconds.</p>"},{"location":"connect/cloud-connect/#support-matrix","title":"Support Matrix","text":"<p>In the table below you can find the qualified matrix for the Cloud Connect service.</p>"},{"location":"connect/cloud-connect/#258","title":"25.8","text":"Component Release Supported Versions (Cloud Type) EDA Core Version OpenShift 4.0.x OpenShift 4.16, 4.18 v3.0.0 (EDA release 25.8.x) VMware vCenter v4.0.x VMware vCenter 7.X, 8.X v3.0.0 (EDA release 25.8.x) VMware NSX v0.0.x (Beta) VMware NSX 4.2.X v3.0.0 (EDA release 25.8.x) <ol> <li> <p>Instructions on how to disable in-hardware LLDP for Mellanox cards can be found here: https://forums.developer.nvidia.com/t/need-help-disabling-hardware-lldp-c5x-ex/294083 \u21a9</p> </li> <li> <p>Instructions on how to disable in-hardware LLDP in VMware ESXI environments: https://knowledge.broadcom.com/external/article/344761/enabling-and-disabling-native-drivers-in.html \u21a9</p> </li> </ol>"},{"location":"connect/openshift-plugin/","title":"OpenShift Plugin","text":""},{"location":"connect/openshift-plugin/#overview","title":"Overview","text":"<p>EDA Cloud Connect integrates with OpenShift to provide fabric-level application networks for OpenShift pods and services. The Connect integration leverages the OpenShift Multus CNI solution to support managing the fabric directly from OpenShift and make the fabric dynamically respond to the networking needs of the application.</p> <p>It provides the following advantages and capabilities:</p> <ul> <li>Direct integration into the network management workflow of OpenShift</li> <li>Use of the common CNIs used by Enterprise applications and CNFs like IPVLAN and SR-IOV</li> <li>Automatic provisioning of the fabric based on where the application pods need the connectivity</li> <li>Support for advanced workflows</li> </ul>"},{"location":"connect/openshift-plugin/#supported-versions","title":"Supported Versions","text":"<ul> <li>Red Hat OpenShift 4.16</li> <li>Red Hat OpenShift 4.18</li> </ul>"},{"location":"connect/openshift-plugin/#prerequisites","title":"Prerequisites","text":"<p>Before using the Connect OpenShift plugin, make sure the following prerequisites are met:</p> <ul> <li>Ensure that the Openshift cluster is up and running.</li> <li>Ensure NMState-Operator and Multus are installed on the OpenShift cluster.</li> <li>Ensure that all the nodes which are connected to SRL leaf nodes have LLDP enabled on each node.</li> <li>Ensure that the EDA cluster is up and running.</li> <li>Ensure that the EDA Cloud Connect App is installed.</li> <li>Ensure you have access to the controller container image named <code>ghcr.io/nokia-eda/eda-connect-k8s-controller:4.0.0</code>.</li> <li> <p>NMState Operator is configured to listen for LLDP TLVs. Create the following resource in your OpenShift cluster and make sure to include all interfaces in the list that are connected to leaf switches managed by EDA:</p> <pre><code>apiVersion: nmstate.io/v1\nkind: NodeNetworkConfigurationPolicy\nmetadata:\nname: enable-receive-lldp\nspec:\ndesiredState:\n    interfaces:\n    - name: &lt;interface-name&gt;\n    lldp:\n        enabled: true\n</code></pre> </li> </ul>"},{"location":"connect/openshift-plugin/#architecture","title":"Architecture","text":"<p>The OpenShift plugin consists of a controller which will monitor the following resources in OpenShift:</p> <ul> <li>The physical NIC configuration and correlation to <code>NetworkAttachmentDefinitions</code> through the NMState Operator.</li> <li><code>NetworkAttachmentDefinitions</code> and their master interfaces.</li> <li><code>ConnectNetworkDefinitions</code> for the configuration of Layer 2 and Layer 3 services configuration.</li> </ul>"},{"location":"connect/openshift-plugin/#operational-modes","title":"Operational Modes","text":"<p>The OpenShift Plugin supports three ways of associating <code>NetworkAttachmentDefinitions</code> to EDA <code>BridgeDomains</code>, called operational modes:</p> Transparent association This association does not require any information from EDA in OpenShift. For every unique master interface defined in <code>NADs</code> in the OpenShift cluster, the plugin will create a unique <code>BridgeDomain</code> resource. This association only supports OpenShift-managed mode. Annotation based association In this association, annotations are added to the <code>NAD</code> that reference an existing EDA <code>BridgeDomain</code>. This association only supports EDA-managed mode. <code>ConnectNetworkDefinition</code> association The <code>ConnectNetworkDefinition</code> is a Custom Resource Definition that gets added to the OpenShift Cluster and is used to describe the relationship between the different services and <code>NetworkAttachmentDefinitions</code>, and how the services relate to each other. This association supports both OpenShift-managed and EDA-managed modes."},{"location":"connect/openshift-plugin/#supported-features","title":"Supported Features","text":"<p>The following are some of the supported OpenShift features:</p> <ul> <li>CMS-managed integration mode</li> <li>EDA-managed integration mode</li> <li>Network Attachment Definition Transparent operational mode (CMS-managed only)</li> <li>Connect Network Definition operational mode (CMS-managed and EDA-managed)</li> <li>Network Attachment Definition Annotation operational mode (EDA-managed only)</li> <li>Optimally configure subinterfaces to minimize configuration and security footprint of network services</li> <li>LAG/LACP interfaces</li> <li>VLAN Trunking</li> <li>Audits</li> </ul> <p>The following are supported CNIs:</p> <ul> <li>MACVLAN</li> <li>IPVLAN</li> <li>SRIOV</li> <li>Dynamic SRIOV</li> </ul>"},{"location":"connect/openshift-plugin/#eda-connect-openshift-plugin-deployment","title":"EDA Connect OpenShift Plugin Deployment","text":""},{"location":"connect/openshift-plugin/#eda-kubernetes-preparation","title":"EDA Kubernetes Preparation","text":""},{"location":"connect/openshift-plugin/#create-a-service-account","title":"Create a Service Account","text":"<p>The EDA Connect OpenShift plugin uses a <code>ServiceAccount</code> in the EDA Kubernetes cluster to create the necessary resources in the EDA cluster for the integration to work properly.</p> <p>To create a service account in the EDA Kubernetes cluster, the following resource can be used.</p> Service Account and Cluster Role Binding manifest <p>This service account must be created in the <code>eda-system</code> namespace.</p> YAML Resource<code>kubectl apply</code> command <pre><code>---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: k8s-controller-plugin\n  namespace: eda-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: k8s-controller-plugin\nsubjects:\n- kind: ServiceAccount\n  name: k8s-controller-plugin\n  namespace: eda-system\nroleRef:\n  kind: ClusterRole\n  # This cluster role is assumed to be already installed by connect app.\n  name: eda-connect-plugin-cluster-role\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: k8s-controller-plugin\n  namespace: eda-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: k8s-controller-plugin\nsubjects:\n- kind: ServiceAccount\n  name: k8s-controller-plugin\n  namespace: eda-system\nroleRef:\n  kind: ClusterRole\n  # This cluster role is assumed to be already installed by connect app.\n  name: eda-connect-plugin-cluster-role\n  apiGroup: rbac.authorization.k8s.io\n\nEOF\n</code></pre>"},{"location":"connect/openshift-plugin/#create-a-service-account-token","title":"Create a Service Account Token","text":"<p>From the above Service Account, you need to create a Service Account Token that can be used by the plugin to connect to the EDA Kubernetes cluster. This can be done with the below manifest, which should be applied on the EDA Kubernetes cluster.</p> Service Account Token Manifest YAML Resource<code>kubectl apply</code> command <pre><code>---\napiVersion: v1\nkind: Secret\ntype: kubernetes.io/service-account-token\nmetadata:\n  name: k8s-controller-plugin\n  namespace: eda-system\n  annotations:\n    kubernetes.io/service-account.name: k8s-controller-plugin\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\n---\napiVersion: v1\nkind: Secret\ntype: kubernetes.io/service-account-token\nmetadata:\n  name: k8s-controller-plugin\n  namespace: eda-system\n  annotations:\n    kubernetes.io/service-account.name: k8s-controller-plugin\n\nEOF\n</code></pre> <p>After creating the Service Account Token, you can retrieve the actual token itself using the following command from <code>eda-system</code> namespace as defined in the service account created above. This token is what will need to be provided to the plugin during deployment.</p> <pre><code>kubectl get secrets/k8s-controller-plugin -n eda-system --template={{.data.token}} | base64 --decode\n</code></pre>"},{"location":"connect/openshift-plugin/#fetching-the-eda-connect-openshift-plugin-helm-charts","title":"Fetching the EDA Connect OpenShift plugin Helm charts","text":"<p>There are two ways to get the Helm charts to deploy the EDA Connect OpenShift plugin:</p> <ol> <li> <p>Using the EDA Playground, which you used to install EDA, you can clone the github repository:</p> <pre><code>make download-connect-k8s-helm-charts\n</code></pre> </li> <li> <p>Downloading the release tarball and unpacking it:</p> <pre><code>curl -sLO https://github.com/nokia-eda/connect-k8s-helm-charts/archive/refs/tags/4.0.0.tar.gz\ntar zxf 4.0.0.tar.gz \n</code></pre> </li> </ol>"},{"location":"connect/openshift-plugin/#deploying-the-plugin-in-openshift","title":"Deploying the Plugin in OpenShift","text":""},{"location":"connect/openshift-plugin/#create-a-namespace-for-the-openshift-plugin","title":"Create a Namespace for the OpenShift Plugin","text":"<p>The OpenShift Plugin uses its own namespace to separate it from other resources in the OpenShift cluster. You can create the correct namespace using the following command:</p> <pre><code>kubectl create namespace eda-connect-k8s-controller\n</code></pre>"},{"location":"connect/openshift-plugin/#configuring-a-pull-secret-for-the-controller-image","title":"Configuring a Pull Secret for the Controller Image","text":"<p>If the EDA Connect OpenShift Plugin Controller image is hosted in a registry that requires authentication, a Kubernetes secret needs to be created for OpenShift to be able to pull the image.</p> <p>The following command does so for the officially hosted image with a secure read-only token to the registry.</p> <pre><code>export PULL_TOKEN=&lt;PULL_TOKEN&gt;\nkubectl create secret docker-registry eda-k8s-image-secret \\\n  --docker-server=ghcr.io/nokia-eda/eda-connect-k8s-controller \\\n  --docker-username=nokia-eda-bot \\\n  --docker-password=${PULL_TOKEN} \\\n  -n eda-connect-k8s-controller\n</code></pre> Getting the pull token <p>The easiest way to get the token/password for the pull secret is to look at your EDA deployment and look for the <code>appstore-eda-apps-registry-image-pull</code> secret. By grabbing the content of that secret and using <code>base64</code> to decode the <code>dockerconfigjson</code>, you can find the password in the resulting JSON file.</p> <p>The following command (entered in one line) shows how to get the token/password (make sure to have the KUBECONFIG for the EDA cluster loaded, not the OpenShift config):</p> <pre><code>kubectl get secret appstore-eda-apps-registry-image-pull -n eda-system -o json | jq -r '.data.\".dockerconfigjson\"' | base64 -d | jq -r '.auths.\"ghcr.io\".password'\n</code></pre>"},{"location":"connect/openshift-plugin/#setting-up-the-local-helm-values","title":"Setting up the local Helm values","text":"<p>Create a <code>helm-values.yaml</code> file with the following content and update the fields as appropriate:</p> <pre><code>controllerEnvConfig:\n  connectpluginname: eda-openshift-controller-plugin\n  heartbeat: \"10\"\n  namespace: &lt;eda-fabric-namespace&gt; # The namespace in EDA containing the fabric and resources, this will different from the eda-system namespace.\n  skiptlsverify: False\n  loglevel: info\n  tlscertificatedata: &lt;EDA K8s certificate data can be extracted from kubeconfig from cluster `certificate-authority-data`&gt;\n  tlsenabled: True\ncontrollerEnvSecret:\n  connectHost: https://&lt;EDA-k8s-cluster-ip or hostname&gt;:&lt;port&gt; # (Caution - Do not use EDA API values, use EDA k8s API values)\n  connectPassword: &lt;Secret long-lived token of the service account created before&gt;\n  connectUsername: &lt;Name of the service account based on which secret token was created&gt;\n</code></pre>"},{"location":"connect/openshift-plugin/#helm-values","title":"Helm Values","text":"<p>The possible Helm Values are:</p> <code>connectpluginname</code> A name for the plugin. Make sure this is a unique name within your EDA environment. <code>heartbeat</code> The interval in seconds at which the plugin should send heartbeats. 10-30 are good values, lower can cause extra unnecessary load on the system. <code>namespace</code> A name of a namespace. This will be a namespace in EDA containing the fabric and resources, this will different from the eda-system namespace. <code>skiptlsverify</code> Can be enabled to disable server TLS certificate verification when connecting to the EDA Kubernetes cluster <code>tlscertificatedata</code> When certificate validation is enabled, this property can contain the certificate information of the EDA Kubernetes cluster, similar to what a kubeconfig would contain. This is only needed if certificate validation is enabled and if the EDA Kubernetes certificate has not been signed by a trusted authority. <code>tlsenabled</code> Should always be true to make sure TLS is used to secure the communication with the EDA Kubernetes cluster. <code>connectHost</code> The URL to reach the EDA Kubernetes cluster API. <code>connectPassword</code> The long lived token created in the Create a Service Account Token section. <code>connectUsername</code> The service account name for the account created in the Create a Service Account section."},{"location":"connect/openshift-plugin/#deploying-the-plugin","title":"Deploying the Plugin","text":"<p>You can now deploy the EDA Connect OpenShift Plugin using its Helm charts with the following command:</p> <pre><code>helm install eda-k8s connect-k8s-helm-charts/ \\\n  -n eda-connect-k8s-controller \\\n  -f helm-values.yaml \\\n  --set controller.imagePullSecretName=eda-k8s-image-secret\n</code></pre>"},{"location":"connect/openshift-plugin/#deployment-verification","title":"Deployment Verification","text":"<p>You can verify if the plugin was deployed by checking if the controller is running in the OpenShift Cluster.</p> <pre><code>$ kubectl get pods -n connect-k8s-controller\nNAME                                            READY   STATUS  RESTARTS AGE\nconnect-k8s-controller-manager-c8d4875bc-bpzrx  2/2     Running 0        66m\n</code></pre> <p>On the EDA Kubernetes environment you can verify the plugin has been registered on EDA in the namespace referred in <code>openshift-helm-values.yaml</code>. The following command assumes that namespace value set to be <code>eda</code></p> <pre><code>$ kubectl get connectplugins -n eda\nNAME                                   PROVIDED NAME           PLUGIN TYPE   AGE\n470e9af1-b85b-439b-b81a-ab71a7166bb0   k8s-controller-plugin   KUBERNETES    2h\n</code></pre>"},{"location":"connect/openshift-plugin/#using-operational-modes","title":"Using Operational Modes","text":"<p>The OpenShift Connect plugin operates in the following operational modes:</p> <ul> <li>Transparent operational mode</li> <li>Connect Network Definition operational mode</li> <li>NAD annotation operational mode</li> </ul>"},{"location":"connect/openshift-plugin/#using-the-transparent-operational-mode","title":"Using the Transparent Operational Mode","text":"<p>To use the Transparent operational mode, create network attachment definitions (NADs) in OpenShift without any EDA Connect annotations or any reference to the NAD in a Connect Network Definition (CND).</p> <p>By doing so, the plugin creates a new EDA <code>BridgeDomain</code> for each NAD with a unique master (+VLAN) interface. If a NAD is created for which a NAD with the same master interface and VLAN already exists, it is associated with the existing <code>BridgeDomain</code>.</p> <p>When you remove the NAD, the EDA bridge domain is also removed.</p>"},{"location":"connect/openshift-plugin/#using-the-connect-network-definition-operational-mode","title":"Using the Connect Network Definition Operational Mode","text":"<p>Connect Network Definition (CND) is a custom resource definition (CRD) that is added to the OpenShift cluster on deployment of the plugin.</p> <p>A CND contains a design of all the network services and configuration an application may need. It can be used to define EDA Routers and EDA BridgeDomain resources. For each BridgeDomain, it is possible to associate one or more NADs with it. By doing so, the plugin knows how to connect applications into different network services.</p> <p>In some deployment use cases, <code>preProvisionHostGroupSelector</code> can be used to pre-provision connect interface for a NAD interface on a set of selected hosts, regardless of whether they are consumed by any pod.</p> Limitations of <code>preProvisionHostGroupSelector</code> <p>Please note that this attribute is only applicable to <code>IPVLAN</code> and <code>MACVLAN</code> type of <code>NetworkAttachmentDefinitions</code></p> <p>You can use the CMS-managed integration mode, the EDA-managed integration mode, or a combination of both.</p> <p>Multiple CNDs can exist, for instance one per application.</p>"},{"location":"connect/openshift-plugin/#example-1-multiple-nads-in-one-bridgedomain","title":"Example 1: Multiple <code>NADs</code> in One <code>BridgeDomain</code>","text":"<p>The following is a sample configuration of the CND usage to be able to have multiple <code>NetworkAttachmentDefinitions</code> be residing in a single subnet, when they belong to different master interface. This is an example of OpenShift Managed Mode.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd1\nspec:\n  subnets:\n    - name: \"subnet1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: ipvlan-ns1/ipvlan-nad2\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd1\nspec:\n  subnets:\n    - name: \"subnet1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: ipvlan-ns1/ipvlan-nad2\nEOF\n</code></pre>"},{"location":"connect/openshift-plugin/#example-2-multiple-nads-in-one-bridgedomain-with-vlan-trunking","title":"Example 2: Multiple <code>NADs</code> in One <code>BridgeDomain</code> with VLAN Trunking","text":"<p>The following is a sample configuration of the CND usage to be able to have multiple <code>NetworkAttachmentDefinitions</code> be residing in a single subnet, and have them use trunk VLAN's:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd2\nspec:\n  subnets:\n    - name: \"trunked-subnet1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1-untagged\n          trunkVlans:\n            - 10\n        - name: sriov-ns1/sriov-nad1-untagged\n          trunkVlans:\n            - 20\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd2\nspec:\n  subnets:\n    - name: \"trunked-subnet1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1-untagged\n          trunkVlans:\n            - 10\n        - name: sriov-ns1/sriov-nad1-untagged\n          trunkVlans:\n            - 20\nEOF\n</code></pre>"},{"location":"connect/openshift-plugin/#example-3-using-eda-managed-mode","title":"Example 3: Using EDA-managed mode","text":"<p>The following is a sample configuration of the CND usage to be able to have multiple <code>NetworkAttachmentDefinitions</code> be part of a single <code>BridgeDomain</code> that was pre-created in EDA:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd3\nspec:\n  subnets:\n    - name: \"eda-managed-subnet1\"\n      linkedBridgeDomain: eda_bridgedomain_1\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: sriov-ns1/sriov-nad1\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd3\nspec:\n  subnets:\n    - name: \"eda-managed-subnet1\"\n      linkedBridgeDomain: eda_bridgedomain_1\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: sriov-ns1/sriov-nad1\nEOF\n</code></pre>"},{"location":"connect/openshift-plugin/#example-4-using-preprovisionhostgroupselector-to-pre-provision-connect-interface-with-the-label-selector","title":"Example 4: Using preProvisionHostGroupSelector to pre-provision connect interface with the label selector","text":"<p>To be able to consume this attribute in CND, ensure that the openshift/k8s nodes are labelled correctly and the same value is used in the CND.</p> <p>Example of the labelling a node is as following:</p> <pre><code>kubectl label nodes node-1 connect.eda.nokia.com/hostGroup=net-group-1\nkubectl label nodes node-2 connect.eda.nokia.com/hostGroup=net-group-2\n</code></pre> <p>The following is a sample configuration of the CND usage to be able to pre-configure connect interface</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd4\nspec:\n  subnets:\n    - name: \"subnet-1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n          preProvisionHostGroupSelector: 'net-group-1'\n        - name: macvlan-ns1/macvlan-nad1\n          preProvisionHostGroupSelector: 'net-group-2'\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd4\nspec:\n  subnets:\n    - name: \"subnet-1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n          preProvisionHostGroupSelector: 'net-group-1'\n        - name: macvlan-ns1/macvlan-nad1\n          preProvisionHostGroupSelector: 'net-group-2'\n\nEOF\n</code></pre>"},{"location":"connect/openshift-plugin/#example-5-multiple-nads-in-one-bridgedomain-associated-to-a-router","title":"Example 5: Multiple <code>NADs</code> in One <code>BridgeDomain</code> associated to a <code>Router</code>","text":"<p>The following is a sample configuration of the CND usage to be able to have multiple <code>NetworkAttachmentDefinitions</code> be residing in a single subnet, associated with a router:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd-router\nspec:\n  routers:\n    - name: router-1\n  subnets:\n    - name: \"subnet1\"\n      router: router-1\n      ipv4Addresses:\n        - ipPrefix: 192.168.6.0/24\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: ipvlan-ns1/ipvlan-nad2\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd-router\nspec:\n  routers:\n    - name: router-1\n  subnets:\n    - name: \"subnet1\"\n      router: router-1\n      ipv4Addresses:\n        - ipPrefix: 192.168.6.0/24\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: ipvlan-ns1/ipvlan-nad2\n\nEOF\n</code></pre>"},{"location":"connect/openshift-plugin/#using-the-nad-annotation-operational-mode","title":"Using the NAD Annotation Operational Mode","text":"<p>The NAD Annotation operational mode only works for the EDA-managed integration mode because it relies on an annotation on the NAD that identifies the pre-existing EDA BridgeDomain resource to which the NAD needs to be associated with.</p> <p>To use this operational mode, when creating or updating a NAD, add the following annotation to it:</p> <pre><code>connect.eda.nokia.com/bridgedomain: &lt;eda-bridge-domain-name&gt; \n</code></pre> <p>In case of VLAN trunking, a more complex annotation can be used, for example:</p> <pre><code>connect.eda.nokia.com/bridgedomain: &lt;eda-bridge-domain-name&gt;:&lt;vlan-id&gt;, &lt;eda-bridge-domain-name-2&gt;:&lt;vlan-id&gt; \n</code></pre>"},{"location":"connect/openshift-plugin/#troubleshooting","title":"Troubleshooting","text":""},{"location":"connect/openshift-plugin/#the-controller-plugin-is-not-running","title":"The controller plugin is not running","text":"<p>Verify the following items:</p> <ul> <li>Incorrect Service Account Token configuration.</li> <li>Check connectivity between controller pod in Openshift and EDA cluster.</li> <li>Ensure the heartbeat interval is a non-negative integer.</li> <li>Plugin name must comply with this regex check <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code>. It may only contain alphanumerical characters and '.', '_', '-' (dot, underscore, and, dash) and must start and end with an alphanumerical character.</li> </ul>"},{"location":"connect/openshift-plugin/#nothing-is-created-in-eda","title":"Nothing is created in EDA","text":"<p>Verify the following items:</p> <ul> <li>Check if the plugin controller is able to access the <code>NMstate</code> API and <code>NetworkAttachmentDefinition</code> API on the OpenShift cluster.</li> <li>Check the plugin can reach EDA cluster correctly.</li> </ul>"},{"location":"connect/openshift-plugin/#the-plugin-is-not-configuring-the-correct-state","title":"The plugin is not configuring the correct state","text":"<ul> <li>Inspect the EDA resources, like <code>VLAN</code>, <code>BridgeDomain</code> and <code>ConnectInterface</code>.</li> <li>Check the logs of the plugin pod.</li> </ul>"},{"location":"connect/troubleshooting/","title":"Troubleshooting Cloud Connect","text":""},{"location":"connect/troubleshooting/#cloud-connect-custom-resources","title":"Cloud Connect Custom Resources","text":"<p>Connect will introduce and expose four new CRDs in EDA and the EDA Kubernetes environment:</p> <ul> <li><code>ConnectPlugin</code> - The logical representation of a plugin, created and managed by a running plugin.</li> <li><code>ConnectPluginActionable</code> - An actionable is an action that a plugin must take. This can be created by the Connect Core itself or by a user who wants to trigger the action.</li> <li><code>ConnectPluginHeartbeat</code> - A plugin sends heartbeats at a well-defined interval, and by doing so, updates this resources linked to its <code>ConnectPlugin</code>. When a plugin does not send heartbeats for a while (three times the expected interval), an alarm will be raised by the Core.</li> <li><code>ConnectInterface</code> - The logical representation of a physical interface of a bare metal compute. The labels on the <code>ConnectInterface</code> are used to label the matching EDA <code>Interface</code>, so that they can be used as sub-interface label selectors for EDA <code>BridgeDomains</code>.</li> </ul>"},{"location":"connect/troubleshooting/#problem-missing-connectplugin-for-deployed-plugin","title":"Problem: Missing <code>ConnectPlugin</code> for deployed plugin","text":"<p>This indicates a connection problem from the plugin towards the EDA Kubernetes cluster. Verify the following information:</p> <ul> <li>Check the plugin logs for error messages.</li> <li>Verify the plugin's configuration, especially the Kubernetes information (location/URL, certificates, user certificates, and so forth).</li> </ul>"},{"location":"connect/troubleshooting/#problem-application-connectivity","title":"Problem: Application connectivity","text":"<p>An application missing connectivity can have multiple causes; here are some of the most common:</p> <ul> <li>Check whether there are any alarms reported in EDA.</li> <li>Check whether there are any transaction results in FAILED state.</li> <li>Check whether the bridge domain and VLAN are up, and the VLAN is showing the expected number of UP subinterfaces</li> <li>Check the Connect interface corresponding to the hypervisor NIC where you expect to see traffic.<ul> <li>If no Connect interface can be found, check the plugin. It is responsible for creating the Connect interface.</li> <li>If a Connect interface can be found, check the status.<ul> <li>If it is '', the connect-interface-controller is not online.</li> <li>If it is 'Disconnected', it cannot find an interface to label.</li> </ul> </li> </ul> </li> <li>Check the interface corresponding to the NIC on the SRL that is connected to the relevant hypervisor.<ul> <li>If it is not found: the operator has to create the \"downlink\" interfaces</li> <li>If it is found: check the status<ul> <li>If no members with the LLDP information are found, check the LLDP process on the hypervisor and on the SRL node</li> </ul> </li> </ul> </li> </ul>"},{"location":"connect/vmware-nsx/","title":"VMware NSX Plugin","text":"<p>Technical Preview</p> <p>The VMware NSX Plugin is currently only available as alpha version for technical preview purposes. It can be used for demo, POC or lab purposes.</p> <p>The following features are not included in the technical preview:</p> <ul> <li>Connect Audit</li> <li>EDA-managed</li> <li>Alarms</li> <li>Lag support</li> <li>NSX certificate support: As a workaround set nsxTlsVerify to false in the NsxPluginInstance</li> </ul>"},{"location":"connect/vmware-nsx/#overview","title":"Overview","text":"<p>The NSX plugin enables automated fabric configuration for VMware NSX environments, supporting both Overlay and VLAN segments. It integrates with EDA Connect to dynamically manage bridge domains and VLANs based on NSX segment definitions.</p> <p>NSX provides advanced networking capabilities such as:</p> <ul> <li>L2/L3 overlays using VXLAN or Geneve</li> <li>VLAN-based connectivity</li> <li>Tier-0 routers for overlay-to-underlay breakout</li> <li>Micro-segmentation, load balancing, and VPN services</li> </ul> <p>This plugin focuses on automating fabric configuration for overlay and VLAN segments:</p> <ul> <li>Automatic provisioning of the fabric based on the configured NSX VLAN segments.</li> <li>Automatic provisioning of the fabric based on NSX Transport Node and Host Switch Profile. The plugin will facilitate the communication between the hypervisors on these overlay segments. EDA will not be involved in the actual overlay traffic in this case.</li> </ul>"},{"location":"connect/vmware-nsx/#supported-versions","title":"Supported Versions","text":"<ul> <li>VMware NSX 4.2</li> </ul>"},{"location":"connect/vmware-nsx/#architecture","title":"Architecture","text":"<p>The VMware NSX plugin consists of two components:</p> VMware NSX Plugin App This app runs in EDA and manages the lifecycle of the VMware NSX plugins. It does so in the standard app model where a custom resource is used to manage the VMware NSX plugins. VMware NSX Plugin The plugin itself, which is responsible for connecting and monitoring the VMware NSX environment for changes."},{"location":"connect/vmware-nsx/#supported-features","title":"Supported Features","text":"<p>The following are some of the supported VMware NSX plugin features:</p> <ul> <li>CMS-managed integration mode</li> <li>EDA-managed integration mode (not in 25.8)</li> <li>VLAN segment fabric management</li> <li>Overlay segment fabric management</li> </ul>"},{"location":"connect/vmware-nsx/#overlay-segments","title":"Overlay Segments","text":"<p>Overlay segments in NSX are L2 networks encapsulated in L3 using VXLAN or Geneve. The encapsulated traffic is VLAN-tagged and transported via uplinks defined in NSX configurations.</p> <p>The NSX plugin will create a <code>BridgeDomain</code> and a <code>VLAN</code> resource based on the Transport VLAN defined on the Transport Node in NSX.</p>"},{"location":"connect/vmware-nsx/#vlan-segments","title":"VLAN Segments","text":"<p>In NSX, it is also still possible to create VLAN segments; the NSX plugin will create the appropriate <code>BridgeDomain</code> and <code>VLAN</code> resources in EDA.</p>"},{"location":"connect/vmware-nsx/#deployment","title":"Deployment","text":"Similarity with VMware vSphere Plugin <p>Those familiar with the VMware vSphere plugin will recognize the steps defined here.</p> <p>To deploy the VMware NSX plugin, complete the following tasks:</p> <ul> <li>Deploy the plugin app.</li> <li>Deploy the plugin.</li> </ul>"},{"location":"connect/vmware-nsx/#connect-vmware-nsx-plugin-app-deployment","title":"Connect VMware NSX Plugin App Deployment","text":"<p>The VMware NSX plugin app is an application in the EDA app ecosystem. It can be easily installed using the EDA Store UI.</p>"},{"location":"connect/vmware-nsx/#installation-using-kubernetes-api","title":"Installation using Kubernetes API","text":"<p>If you prefer installing the plugin using the Kubernetes API, you can do so by creating the following Workflow resource:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: nsx-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: nsx.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v1alpha1\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: nsx-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: nsx.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v1alpha1\n\nEOF\n</code></pre>"},{"location":"connect/vmware-nsx/#connect-vmware-nsx-plugin-deployment","title":"Connect VMware NSX Plugin Deployment","text":"<p>A prerequisite for creating a <code>NsxPluginInstance</code> resource is a <code>Secret</code> resource with username and password fields that contain the account information for an account that can connect to the VMware NSX environment and has read-only access to the cluster so that it can monitor the necessary resources.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-vmware-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata: \n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-vmware-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata: \n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n\nEOF\n</code></pre> Base64 encoding <p>Use the following command to base64 encode your username and password:</p> <pre><code>echo -n myUsernameOrPassword | base64\n</code></pre> <p>As the VMware NSX plugins are managed through the operator, you can use the EDA UI to create a new <code>NsxPluginInstance</code> resource under the * System Administration &gt; Connect &gt; NSX Plugins* menu item.</p> <p>As an alternative, you can also create the same <code>NsxPluginInstance</code> using the following custom resource example. Make sure to replace the specified values with their relevant content.</p> <p>A VMware NSX instance can manage multiple VMware vCenter servers, this is reflected by referencing the vCenters and the corresponding Connect VMware Vcenter plugins in the <code>NsxPluginInstance</code>.</p> vCenterFQDN <p>The vCenterFQDN field has to correspond to the \"FQDN or IP Address\" field when creating the compute manager. </p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: vmware.eda.nokia.com/v1\nkind: NsxPluginInstance\nmetadata:\n  name: my-nsx-plugin-instance # A unique name for the plugin resource (can be the same as the spec.name, or different)\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  externalId: example-external-id # A unique Identifier for the plugin (can be same as the name)\n  heartbeatInterval: 30\n  name: example-NSX # A unique name for the plugin\n  nsxManagementIP: exampleHost # The IP address of the NSX Server\n  nsxPollInterval: 2 # The plugin will poll NSX for changes every x seconds\n  nsxTlsVerify: false # To verify TLS of the NSX server\n  nsxCertificate: \"\" # If the NSX certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-nsx-creds # Credentials are hosted in a separate Secret\n  vCenters:\n    - vCenterFQDN: x.y.z # FQDN or IP of the Vcenter as defined in NSX\n      vmwarePluginID: example-VMWARE # Name of the Vcenter Plugin\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: vmware.eda.nokia.com/v1\nkind: NsxPluginInstance\nmetadata:\n  name: my-nsx-plugin-instance # A unique name for the plugin resource (can be the same as the spec.name, or different)\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  externalId: example-external-id # A unique Identifier for the plugin (can be same as the name)\n  heartbeatInterval: 30\n  name: example-NSX # A unique name for the plugin\n  nsxManagementIP: exampleHost # The IP address of the NSX Server\n  nsxPollInterval: 2 # The plugin will poll NSX for changes every x seconds\n  nsxTlsVerify: false # To verify TLS of the NSX server\n  nsxCertificate: \"\" # If the NSX certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-nsx-creds # Credentials are hosted in a separate Secret\n  vCenters:\n    - vCenterFQDN: x.y.z # FQDN or IP of the Vcenter as defined in NSX\n      vmwarePluginID: example-VMWARE # Name of the Vcenter Plugin\n\nEOF\n</code></pre> <p>The plugin name and external ID must comply with the regex check of <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code> and can only contain alphanumerical characters and <code>.</code>, <code>_</code> and <code>-</code>. It must start with an alphanumerical character.</p>"},{"location":"connect/vmware-nsx/#functionality","title":"Functionality","text":""},{"location":"connect/vmware-nsx/#startup","title":"Startup","text":"<p>When the plugin is started, the following actions are taken by the plugin:</p> <ul> <li>The plugin registers itself with Connect, based on the provided <code>externalID</code>. If a matching <code>ConnectPlugin</code> pre-exists, it is reused.</li> <li>The plugin performs an audit: Any Connect-related state that was programmed in NSX while the plugin was not running is synchronized with   Connect.</li> </ul>"},{"location":"connect/vmware-nsx/#polling-loop","title":"Polling Loop","text":"<p>The plugin will connect to a VMware NSX environment and poll for changes. The plugin will configure Connect and EDA based on the configuration in NSX.</p>"},{"location":"connect/vmware-nsx/#vcenter-plugin-dependency","title":"vCenter Plugin Dependency","text":"<p>While NSX is used for defining overlay networking, vCenter is still used to configure the compute hosts and VMs. The NSX plugin has a dependency on one or more VMware vCenter plugins for the creation of the ConnectInterface objects in EDA.</p>"},{"location":"connect/vmware-nsx/#operational-modes","title":"Operational Modes","text":"<p>The technical preview of the NSX plugin only supports NSX-managed mode.</p> NSX Managed Mode Also referred to as Connect Managed. When using this mode, the plugin will create a unique <code>BridgeDomain</code> for each VLAN segment and to facilitate overlay segment communication between the hypervisors."},{"location":"connect/vmware-nsx/#troubleshooting","title":"Troubleshooting","text":"Technical preview <p>The technical preview in 25.8 will not support alarms. Please consult the logs of the NSX plugin pod for troubleshooting.</p>"},{"location":"connect/vmware-nsx/#the-plugin-is-not-running","title":"The plugin is not running","text":"<p>If an incorrect NSX hostname or IP is configured in the <code>NsxPluginInstance</code> resource, the plugin will try to connect for 3 minutes and log an error if it fails to connect. To retry, the plugin can be restarted. In case the credentials are incorrect, the plugin will crash and restart immediately.</p> <ul> <li>Check the connectivity from the EDA cluster to NSX.</li> <li>Verify the credentials for NSX.</li> <li>Check the logs of the plugin pod.</li> </ul>"},{"location":"connect/vmware-nsx/#the-plugin-is-not-creating-any-resources-in-eda","title":"The plugin is not creating any resources in EDA","text":"<ul> <li>Check the connectivity from the EDA cluster to NSX.</li> <li>Check the logs of the plugin pod.</li> <li>Check the plugin staleness state field and verify that heartbeats are being updated.</li> <li>Check the <code>NSXPluginInstance</code> resource and verify that it has valid values.</li> </ul>"},{"location":"connect/vmware-plugin/","title":"VMware vSphere Plugin","text":""},{"location":"connect/vmware-plugin/#overview","title":"Overview","text":"<p>The VMware vSphere plugin leverages the VMware vSphere distributed vSwitch architecture to support managing the fabric directly from VMware vCenter and make the fabric respond to the networking needs of the environment.</p> <p>It provides the following advantages and capabilities:</p> <ul> <li>Direct integration into the network management workflow of VMware vCenter.</li> <li>The use of the common distributed vSwitches and port groups for both regular virtual machine NICs as well as SR-IOV use cases.</li> <li>VMware plugin supports the following VLAN types for port groups.<ul> <li>None: Vlan 0</li> <li>VLAN:  (1-4094) <li>Automatic provisioning of the fabric based on where the virtual machines need the connectivity.</li> <li>Support advanced workflows through the Fabric Service System Managed solution, including for VNF use cases with features like QoS, ACLs, and BGP   PE-CE.</li> <li>Interconnectivity between different cloud environments, allowing for flexible network configurations.</li>"},{"location":"connect/vmware-plugin/#supported-versions","title":"Supported Versions","text":"<ul> <li>VMware vSphere 7</li> <li>VMware vSphere 8</li> </ul>"},{"location":"connect/vmware-plugin/#prerequisites","title":"Prerequisites","text":"<p>Before installing or deploying the VMware vSphere plugin components, make sure that the Cloud Connect Core application is properly installed in the cluster.</p>"},{"location":"connect/vmware-plugin/#architecture","title":"Architecture","text":"<p>The VMware vSphere plugin consists of two components:</p> VMware vSphere Plugin App This app runs in EDA and manages the lifecycle of the VMware vSphere plugins. It does so in the standard app model where a custom resource is used to manage the VMware vSphere plugins. VMware vSphere Plugin <p>The plugin itself, which is responsible for connecting and monitoring the VMware vCenter environment for changes. The plugin will listen to the events of the following objects:</p> <ul> <li>Distributed vSwitch (dvS)</li> <li>Distributed Port Groups (dvPG)</li> <li>Host to dvS associations</li> <li>Custom attributes</li> </ul>"},{"location":"connect/vmware-plugin/#supported-features","title":"Supported Features","text":"<p>The following are some of the supported VMware vSphere features:</p> <ul> <li>CMS-managed integration mode</li> <li>EDA-managed integration mode</li> <li>Optimally configure subinterfaces to minimize configuration and security footprint of network services</li> <li>LAG/LACP interfaces</li> <li>SRIOV interfaces</li> <li>Audits</li> </ul>"},{"location":"connect/vmware-plugin/#deployment","title":"Deployment","text":"<p>To deploy the VMware vSphere plugin, complete the following tasks:</p> <ul> <li>Deploy the plugin app.</li> <li>Deploy the plugin.</li> </ul>"},{"location":"connect/vmware-plugin/#connect-vmware-vsphere-plugin-app-deployment","title":"Connect VMware vSphere Plugin App Deployment","text":"<p>The VMware vSphere plugin app is an application in the EDA app ecosystem. It can be easily installed using the EDA Store UI.</p>"},{"location":"connect/vmware-plugin/#installation-using-kubernetes-api","title":"Installation using Kubernetes API","text":"<p>If you prefer installing the plugin using the Kubernetes API, you can do so by creating the following Workflow resource:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: vmware-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: vmware.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v4.0.0\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: vmware-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: vmware.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v4.0.0\n\nEOF\n</code></pre>"},{"location":"connect/vmware-plugin/#connect-vmware-vsphere-plugin-deployment","title":"Connect VMware vSphere Plugin Deployment","text":"<p>A prerequisite for creating a <code>vmwarePluginInstance</code> resource is a <code>Secret</code> resource with username and password fields that contain the account information for an account that can connect to the VMware vCenter environment and has read-only access to the cluster so that it can monitor the necessary resources.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-vmware-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata: \n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-vmware-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata: \n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n\nEOF\n</code></pre> Base64 encoding <p>Use the following command to base64 encode your username and password:</p> <pre><code>echo -n myUsernameOrPassword | base64\n</code></pre> <p>As the VMware vSphere plugins are managed through the operator, you can use the EDA UI to create a new <code>VmwarePluginInstance</code> resource under the * System Administration &gt; Connect &gt; VMware Plugins* menu item.</p> <p>As an alternative, you can also create the same <code>VmwarePluginInstance</code> using the following custom resource example. Make sure to replace the specified values with their relevant content.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: vmware.eda.nokia.com/v1\nkind: VmwarePluginInstance\nmetadata:\n  name: my-vmware-plugin-instance # A unique name for the plugin resource (can be the same as the spec.name, or different)\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  externalId: example-external-id # A unique Identifier for the plugin (can be same as the name)\n  heartbeatInterval: 30\n  name: example-vSphere # A unique name for the plugin\n  vcsaHost: example-host # The IP address of the vCenter Server\n  vcsaTlsVerify: true # To verify TLS of the VCSA\n  vcsaCertificate: \"\" # If the VCSA certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-vmware-creds # Credentials are hosted in a separate Secret\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: vmware.eda.nokia.com/v1\nkind: VmwarePluginInstance\nmetadata:\n  name: my-vmware-plugin-instance # A unique name for the plugin resource (can be the same as the spec.name, or different)\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  externalId: example-external-id # A unique Identifier for the plugin (can be same as the name)\n  heartbeatInterval: 30\n  name: example-vSphere # A unique name for the plugin\n  vcsaHost: example-host # The IP address of the vCenter Server\n  vcsaTlsVerify: true # To verify TLS of the VCSA\n  vcsaCertificate: \"\" # If the VCSA certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-vmware-creds # Credentials are hosted in a separate Secret\n\nEOF\n</code></pre> <p>The plugin name and external ID must comply with the regex check of <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code> and can only contain alphanumerical characters and <code>.</code>, <code>_</code> and <code>-</code>. It must start with an alpha-numerical character.</p>"},{"location":"connect/vmware-plugin/#functionality","title":"Functionality","text":"<p>This section describes VMware vSphere plugin operations including startup, event monitoring, and the plugin's operational modes.</p>"},{"location":"connect/vmware-plugin/#startup","title":"Startup","text":"<p>When the plugin is started, the following actions are taken by the plugin:</p> <ul> <li>The plugin registers itself with Connect, based on the provided <code>externalID</code>. If a matching <code>ConnectPlugin</code> pre-exists, it is reused.</li> <li>The plugin performs an audit: Any Connect-related state that was programmed in vCenter while the plugin was not running is synchronized with   Connect.</li> </ul>"},{"location":"connect/vmware-plugin/#event-monitoring","title":"Event Monitoring","text":"<p>A plugin will connect to a VMware vCenter environment and subscribe to VMware events. The plugin will configure Connect and EDA based on the events it receives:</p> Event Trigger Custom Resource Purpose VLAN-tagged distributed PortGroup events <code>BridgeDomain</code> In VMware-managed mode, each dvPG will result in its own unique <code>BridgeDomain</code>. VLAN-tagged distributed PortGroup events <code>VLAN</code> Each dvPG with a specific VLAN tag will have an EDA <code>VLAN</code> resource so it can be attached to the <code>BridgeDomain</code>. Host NIC distributed Switch Uplink events <code>ConnectInterface</code> Each host NIC that gets added as an uplink to a dvS will trigger the creation of a <code>ConnectInterface</code>, which is mapped by Connect Core to an EDA <code>Interface</code>. <p>Naming limitations</p> <p>The uplink names must comply with the regex check of <code>^[a-zA-Z0-9][a-zA-Z0-9._-]*[a-zA-Z0-9]$</code>. It can only contain alpha-numerical characters and <code></code>(space), <code>.</code>, <code>_</code>, and <code>-</code>. It must also have a length of 30 characters or fewer.</p>"},{"location":"connect/vmware-plugin/#lldp","title":"LLDP","text":"<p>Cloud Connect uses LLDP to discover which VMware hypervisors are running on which switches in EDA. Make sure you enable both send and receive LLDP in the Discovery protocol settings of the distributed vSwitch.</p>"},{"location":"connect/vmware-plugin/#operational-modes","title":"Operational Modes","text":"<p>The plugin supports the following operational modes; these modes can be used simultaneously:</p> VMware-Managed Mode Also referred to as Connect Managed. When using this mode, the plugin will create a unique <code>BridgeDomain</code> resource for each VLAN tagged dvPG in the VMware vCenter environment. EDA-Managed Mode In EDA-managed mode, a dvPG is given a special custom attribute that refers to an existing EDA <code>BridgeDomain</code> resource. When the plugin detects this custom attribute, and it refers to an existing <code>BridgeDomain</code> resource in EDA, it will not create a new <code>BridgeDomain</code> but instead will associate the dvPG with the existing one. This allows for more advanced configuration of the application networks."},{"location":"connect/vmware-plugin/#using-eda-managed-mode","title":"Using EDA-Managed Mode","text":"<p>To use the EDA-managed mode follow these steps:</p> <ol> <li>Create a <code>BridgeDomain</code> in EDA with the desired settings</li> <li>When creating a distributed Port Group in vCenter, configure a Custom Attribute called <code>ConnectBridgeDomain</code> and set its value to the key of the EDA    <code>BridgeDomain</code>.</li> </ol> <p>Note</p> <p>Both the key of the Custom Attribute and the value are case-sensitive</p> Global vs Distributed Port Group type of Custom Attribute <p>Make sure to create a Custom Attribute of type Distributed Port Group on the Port Group. </p> <p>You can configure multiple dvPGs with the same <code>BridgeDomain</code>.</p> <p>You can switch between EDA-managed and VMware-managed mode at any time. You can switch back to VMware-managed mode by setting the <code>ConnectBridgeDomain</code> Custom Attribute to <code>none</code>, or by deleting the Custom Attribute entirely.</p>"},{"location":"connect/vmware-plugin/#troubleshooting","title":"Troubleshooting","text":""},{"location":"connect/vmware-plugin/#the-plugin-is-not-running","title":"The plugin is not running","text":"<p>If an incorrect vCenter hostname or IP is configured in the <code>VmwarePluginInstance</code> resource, the plugin will try to connect for 3 minutes and crash and restart if it fails to connect. In case the credentials are incorrect, the plugin will crash and restart immediately.</p> <ul> <li>Check the raised plugin alarms.</li> <li>Check the connectivity from the EDA cluster to vCenter.</li> <li>Verify the credentials for vCenter.</li> <li>Check the logs of the plugin pod.</li> </ul>"},{"location":"connect/vmware-plugin/#the-plugin-is-not-creating-any-resources-in-eda","title":"The plugin is not creating any resources in EDA","text":"<ul> <li>Check the raised plugin alarms.</li> <li>Check the connectivity from the EDA cluster to vCenter.</li> <li>Check the logs of the plugin pod.</li> <li>Check the Plugin staleness state field and verify heartbeats are being updated.</li> </ul>"},{"location":"connect/vmware-plugin/#the-plugin-is-not-configuring-the-correct-state","title":"The plugin is not configuring the correct state","text":"<ul> <li>Check the raised plugin alarms.</li> <li>Verify the Uplinks for the dvPG in vCenter are configured as active or standby. If there are no active or standby Uplinks configured, the plugin   will not associate any <code>ConnectInterface</code> with the <code>VLAN</code>.</li> <li>Uplink names can only contain alpha-numerical characters and <code>.</code>, <code>_</code>, <code>-</code> and must have a length of 30 characters or less.</li> <li>VLAN ranges are not supported on dvPGs.</li> <li>Inspect the EDA resources, like <code>VLAN</code>, <code>BridgeDomain</code> and <code>ConnectInterface</code>.</li> <li>Check the logs of the plugin pod.</li> </ul>"},{"location":"development/custom-catalog/","title":"Add a Custom EDA Store Catalog","text":""},{"location":"development/custom-catalog/#overview","title":"Overview","text":"<p>An App Catalog is a structured git repository that contains all the necessary information EDA Store needs to install an app. The <code>Manifest</code>  is the most important one. But the app can also contain other app metadata information for the UI, like a README, or a license (see the manifest <code>appInfo</code>  specification field). The catalog of built-in apps that is delivered along with EDA can be found here.</p>"},{"location":"development/custom-catalog/#catalog-structure","title":"Catalog Structure","text":"<p>The structure of a catalog is as follows:</p> <pre><code>vendors/\n    &lt;vendor-1-name&gt;\n        apps/\n            &lt;app-1-name&gt;/\n                manifest.yaml\n                README.md\n                LICENSE\n                ... # Other useful files, which can be referenced in the manifest and used in the UI.\n            &lt;app-2-name&gt;/\n                ...\n    &lt;vendor-2-name&gt;/\n        apps/\n            ...\n    ...\n</code></pre> <p>The manifest of an App must be called <code>manifest.yaml</code> and be placed in <code>vendors/&lt;vendor-name&gt;/apps/&lt;app-name&gt;/manifest.yaml</code> in the git repository.</p>"},{"location":"development/custom-catalog/#app-versioning","title":"App Versioning","text":"<p>Apps will have multiple versions. To version the Apps in the Catalog, git tags are used. A structured git tag will be seen as an installable App (with a certain version) for the EDA Store, which can then be installed from the UI.</p> <p>Any tag in the form of <code>vendors/&lt;vendor-name&gt;/apps/&lt;app-name&gt;/&lt;version&gt;</code> will be registered as an installable App by the EDA Store.</p> <p>The version field should conform to Semantic Versioning 2.0, prefixed with a \"v\". For example: v0.1, v0.1.0-alpha.</p>"},{"location":"development/custom-catalog/#adding-a-catalog-to-the-eda-store","title":"Adding a Catalog to the EDA Store","text":""},{"location":"development/custom-catalog/#creating-a-credentials-secret","title":"Creating a Credentials Secret","text":"<p>If the Catalog-hosting Git repository requires authentication, you must create a Kubernetes secret that contains the credentials to connect to the Catalog git repository over HTTPS. This can be done using the following resource where you replace the data with the correct <code>base64</code> encoded values.</p> <p>mandatory label</p> <p>The secrets used by the app catalog or app registry must have the <code>eda.nokia.com/backup: \"true\"</code> label for the EDA Store to pick them up.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: your-creds # A unique secret name\n  labels:\n    eda.nokia.com/backup: \"true\"\ndata:\n  username: &lt;base64(username)&gt; # Base64 encoded username\n  password: &lt;base64(password or token)&gt; # Base64 encoded password/token\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: your-creds # A unique secret name\n  labels:\n    eda.nokia.com/backup: \"true\"\ndata:\n  username: &lt;base64(username)&gt; # Base64 encoded username\n  password: &lt;base64(password or token)&gt; # Base64 encoded password/token\n\nEOF\n</code></pre>"},{"location":"development/custom-catalog/#creating-the-catalog","title":"Creating the Catalog","text":"<p>You can create your own Catalog using the following resource. This uses the above created secret as <code>authSecretRef</code>.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: your-catalog # name of your catalog\nspec:\n  title: Your Awesome Catalog # UI name of your catalog, optional\n  remoteURL: https://&lt;your-catalog&gt;.git # link to your git repository.\n  authSecretRef: your-creds # reference to valid credentials for the git repository\n  skipTLSVerify: {true|false}\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: your-catalog # name of your catalog\nspec:\n  title: Your Awesome Catalog # UI name of your catalog, optional\n  remoteURL: https://&lt;your-catalog&gt;.git # link to your git repository.\n  authSecretRef: your-creds # reference to valid credentials for the git repository\n  skipTLSVerify: {true|false}\nEOF\n</code></pre>"},{"location":"development/custom-registry/","title":"Add a Custom EDA Store Registry","text":""},{"location":"development/custom-registry/#overview","title":"Overview","text":"<p>An EDA Store Registry is a container registry that contains OCI compliant images of an App. It is where you will upload your full App content and code as a single OCI image.</p> <p>The <code>manifest.spec.image</code> field will point to the specific App image with a specific tag for each version.</p>"},{"location":"development/custom-registry/#adding-a-registry-to-the-eda-store","title":"Adding a Registry to the EDA Store","text":""},{"location":"development/custom-registry/#creating-a-credentials-secret","title":"Creating a Credentials Secret","text":"<p>If the registry hosting your App OCI image requires authentication, you must create a Kubernetes secret that contains the credentials to connect to the Registry git repository over HTTPS. This can be done using the following resource where you replace the data with the correct <code>base64</code> encoded values.</p> <p>mandatory label</p> <p>The secrets used by the app catalog or app registry must have the <code>eda.nokia.com/backup: \"true\"</code> label for the EDA Store to pick them up.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: your-creds # A unique secret name\n  labels:\n    eda.nokia.com/backup: \"true\"\ndata:\n  username: &lt;base64(username)&gt; # Base64 encoded username\n  password: &lt;base64(password or token)&gt; # Base64 encoded password/token\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: your-creds # A unique secret name\n  labels:\n    eda.nokia.com/backup: \"true\"\ndata:\n  username: &lt;base64(username)&gt; # Base64 encoded username\n  password: &lt;base64(password or token)&gt; # Base64 encoded password/token\n\nEOF\n</code></pre> <p>Make sure to give the secret a different name than the Catalog Credentials secret</p>"},{"location":"development/custom-registry/#creating-the-registry","title":"Creating the Registry","text":"<p>You can create your own Registry using the following resource. This uses the above created secret as <code>authSecretRef</code>.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: Registry\nmetadata:\n  name: your-registry # name of your registry\nspec:\n  remoteURL: &lt;url-to-your-registry.com&gt; # link to your registry\n  authSecretRef: your-registry-creds # reference to valid credentials for your registry\n  skipTLSVerify: {true|false}\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: Registry\nmetadata:\n  name: your-registry # name of your registry\nspec:\n  remoteURL: &lt;url-to-your-registry.com&gt; # link to your registry\n  authSecretRef: your-registry-creds # reference to valid credentials for your registry\n  skipTLSVerify: {true|false}\nEOF\n</code></pre>"},{"location":"development/custom-registry/#mirroring-a-registry-to-the-eda-store","title":"Mirroring a Registry to the EDA Store","text":"<p>If it is not possible to use a registry that is referenced in the manifests of a certain catalog, you can mirror that registry to a local registry and then update the Registry resource in the EDA Kubernetes cluster and update the <code>mirrorUrl</code> to point to the mirror hostname.</p> <p>Only the hostname/FQDN will be replaced, image repositories and tags are assumed to be the same when using a mirror.</p>"},{"location":"development/custom-registry/#limitations","title":"Limitations","text":""},{"location":"development/custom-registry/#using-artifactory-container-registry-with-apps-using-embedded-container-images","title":"Using Artifactory container registry with Apps using embedded container images","text":"<p>Artifactory currently doesn't support OCI compliant images with embedded container images. If you are creating an advanced App that uses its own container image, you can not use Artifactory as a registry. An alternative could be to host your own Harbor registry.</p> <p>Regular MicroPython Apps do not have this limitation, for these Artifactory will work fine.</p>"},{"location":"development/ansible/","title":"Ansible Collections for Nokia EDA","text":"<p> https://ansible.eda.dev \u00b7  Nokia EDA Collection in Galaxy \u00b7 Beta release</p> <p>Ansible is an open-source automation platform that allows you to automate tasks across a wide range of IT environments. It uses a simple, human-readable language to describe automation tasks, making it accessible to both developers and operations teams. In order to extend the platform and meet specific needs and target environments, Ansible allows users to create custom modules and plugins that are packaged as Ansible collections and hosted at Ansible Galaxy.</p> <p>Nokia provides a set of Ansible collections specifically designed for the Event Driven Automation (EDA) platform that allow users to automate interactions with the EDA platform and manage the resources under its management.</p> <p>Go to https://ansible.eda.dev for a complete reference and examples.</p>"},{"location":"development/api/","title":"API","text":""},{"location":"development/api/#overview","title":"Overview","text":"<p>EDA includes an HTTP REST API to support software integration. By using the REST API, you can write your own software that can configure any feature of the EDA.</p>"},{"location":"development/api/#general-concepts","title":"General Concepts","text":"<p>The EDA API is following a very similar model as the Kubernetes Resource Model. Every custom resource that gets added through the installation of an App, will be available through the EDA API in a similar way as custom resources in Kubernetes are available through the Kubernetes API.</p> <p>There are two major components to the EDA API, and a few internal components:</p> Core API The Core API is used to manage a few core concepts of EDA, like getting and posting <code>Transactions</code>, executing EQL <code>Queries</code> and getting <code>NodeConfigs</code> for specific nodes. Apps API <p>The Apps API is where every App installed into EDA, exposes its custom resources. That includes all the default installed Apps.</p> <p>EDA API vs Kubernetes API &amp; <code>kubectl</code></p> <p>In the current EDA model, both the EDA API and Kubernetes API (or <code>kubectl</code>) can be used to manage certain resources. However, be aware that anything that has been internally generated within EDA might not be fully visible to the Kubernetes environment and only available over the EDA API.</p> OpenAPI API This API provides access to OpenAPIv3 Specifications for the Core and Apps API. HTTPProxy API The EDA API server acts as a transparent passthrough proxy for certain services, like Keycloak for authentication and other internal services. This is handled by the HTTPProxy API. <p>Do not change or manipulate any of the HTTPProxy API settings as this can break your EDA deployment.</p>"},{"location":"development/api/#synchronous-vs-asynchronous","title":"Synchronous vs Asynchronous","text":"<p>All the API requests are handled as synchronous API requests. To make asynchronous API requests use the <code>Transaction</code> API.</p>"},{"location":"development/api/#authentication","title":"Authentication","text":"<p>For authentication and authorization, EDA uses Keycloak as its backend. Keycloak is a proven and secure solution for Identity and Access management. EDA uses Keycloak through the OpenID Connect protocol where the authentication flow to obtain the OAuth 2.0 token is different for browser-based and non-browser-based clients:</p> <ol> <li>For browser-based clients, the user is redirected to Keycloak for authentication and then send back with the necessary tokens for the API to authenticate and verify the user as a legitimate user. This is referred to as the Standard Flow (Authorization Code Grant in the OAuth2 specifications RFC 6749 4.1).</li> <li>For non-browser API clients, such as CLI applications, scripts, etc., the Direct Access Grant flow (Resource Owner Password Credentials Grant in the OAuth2 specifications RFC 6749 4.5) is used to obtain the authentication token. In this case the API client directly authenticates with Keycloak using client_secret and provides the Authorization Server with Resource Owner credentials (EDA username credentials). The Authorization Server (Keycloak) provides the client with the token that is used for further API calls to the EDA API. The API client is also responsible for refreshing or renewing their token.</li> </ol> <p>The non-browser API clients authenticate against the Kecloak authorization server by providing the following parameters in the request:</p> <ul> <li><code>client_id</code>: Must be set to <code>eda</code></li> <li><code>grant_type</code>: Must be set to <code>password</code></li> <li><code>scope</code>: Must be set to <code>openid</code></li> <li><code>username</code>: The username for the user that needs to authenticate</li> <li><code>password</code>: The password for the user that needs to authenticate</li> <li><code>client_secret</code>: The Keycloak client secret for client ID <code>eda</code></li> </ul> <p>Some of the hardcoded settings might change in the future</p>"},{"location":"development/api/#getting-the-client_secret","title":"Getting the <code>client_secret</code>","text":"<p>Every EDA deployment gets a unique client secret token generated during installtion. An EDA system administrator is responsible for retrieving the client secret and providing it to the application/scripts/clients that intent to interact with the EDA API server. The secret can be retrieved using Keycloak UI and Keycloak API. Below you will find different methods to obtain the client secret:</p> UIShell scriptAnsible module <ul> <li>Navigate to <code>https://{EDA_URL}/core/httpproxy/v1/keycloak</code> in your browser.</li> <li>Log in with the Keycloak administrator username and password (default is <code>admin:admin</code> and can be changed<sup>1</sup>).</li> <li>From the Keycloak drop-down list on the upper left, select Event Driven Automation (eda).</li> <li>Select Clients from the menu on the left.</li> <li>Select eda in the client table.</li> <li>Select Credentials in the tab bar on the top.</li> <li>Copy the Client Secret.</li> </ul> <p>The above steps are shown in the video:</p> <p>During the development cycle a user might want to fetch the client secret in the automated way, without resorting to the UI. The shell script below fetches the client secret using the variables defined at the top of the file:</p> <p>Note, the script requires <code>curl</code> and <code>jq</code> to be installed in your environment.</p> Shell Script <pre><code>#!/bin/bash\n\nexport EDA_API_URL=\"${EDA_API_URL:-https://myinstance.eda.rocks:9443}\"\nexport KC_KEYCLOAK_URL=\"${EDA_API_URL}/core/httpproxy/v1/keycloak/\"\nexport KC_REALM=\"master\"\nexport KC_CLIENT_ID=\"admin-cli\"\nexport KC_USERNAME=\"${KC_USERNAME:-admin}\"\nexport KC_PASSWORD=\"${KC_PASSWORD:-admin}\"\nexport EDA_REALM=\"eda\"\nexport API_CLIENT_ID=\"eda\"\n\n# Get access token\nKC_ADMIN_ACCESS_TOKEN=$(curl -sk \\\n  -X POST \"$KC_KEYCLOAK_URL/realms/$KC_REALM/protocol/openid-connect/token\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"grant_type=password\" \\\n  -d \"client_id=$KC_CLIENT_ID\" \\\n  -d \"username=$KC_USERNAME\" \\\n  -d \"password=$KC_PASSWORD\" \\\n  | jq -r '.access_token')\n\nif [ -z \"$KC_ADMIN_ACCESS_TOKEN\" ]; then\n  echo \"Failed to obtain keycloak admin token\"\n  exit 1\nfi\n\n\n# Fetch all clients in the 'eda-realm'\nKC_CLIENTS=$(curl -sk \\\n  -X GET \"$KC_KEYCLOAK_URL/admin/realms/$EDA_REALM/clients\" \\\n  -H \"Authorization: Bearer $KC_ADMIN_ACCESS_TOKEN\" \\\n  -H \"Content-Type: application/json\")\n\n# Get the `eda` client's ID\nEDA_CLIENT_ID=$(echo \"$KC_CLIENTS\" | jq -r \".[] | select(.clientId==\\\"${API_CLIENT_ID}\\\") | .id\")\n\nif [ -z \"$EDA_CLIENT_ID\" ]; then\n  echo \"Client 'eda' not found in realm 'eda-realm'\"\n  exit 1\nfi\n\n# Fetch the client secret\nEDA_CLIENT_SECRET=$(curl -sk \\\n  -X GET \"$KC_KEYCLOAK_URL/admin/realms/$EDA_REALM/clients/$EDA_CLIENT_ID/client-secret\" \\\n  -H \"Authorization: Bearer $KC_ADMIN_ACCESS_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  | jq -r '.value')\n\nif [ -z \"$EDA_CLIENT_SECRET\" ]; then\n  echo \"Failed to fetch client secret\"\n  exit 1\nfi\n\necho \"$EDA_CLIENT_SECRET\"\n</code></pre> <p>If you have this script saved as a file, you can call it like this:</p> <pre><code>EDA_API_URL=https://eda.netdevops.me:9443 /tmp/clientsecret.sh\nk9NeZZK4LT6hHypzgy3djteFITEkUUaR\n</code></pre> <p>With overriding the top level parameters using the env variables.</p> <p>In case you're using Ansible collections for Nokia EDA, you can fetch the client secret using the Utils collection and the <code>get_client_secret</code> module.</p>"},{"location":"development/api/#getting-the-access-token","title":"Getting the Access Token","text":"<p>With the client secret obtained from the previous step, an API client can now request an access token from Keycloak. Below you will find different ways of getting the token:</p> curlAnsible <p>An example of using <code>curl</code> to authenticate and get an access token for the EDA API. Make sure to use your own EDA URL and Keycloak client secret.</p> <pre><code>curl -s https://${EDA_API_URL}/core/httpproxy/v1/keycloak/realms/eda/protocol/openid-connect/token \\\n  -H 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'client_id=eda' \\\n  --data-urlencode 'grant_type=password' \\\n  --data-urlencode 'scope=openid' \\\n  --data-urlencode 'username=${EDA_USERNAME}' \\\n  --data-urlencode 'password=${EDA_PASSWORD}' \\\n  --data-urlencode 'client_secret=${EDA_CLIENT_SECRET}'\n</code></pre> Example output parsed using <code>jq</code> <pre><code>curl -s https://${EDA_API_URL}/core/httpproxy/v1/keycloak/realms/eda/protocol/openid-connect/token \\\n  -H 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'client_id=eda' \\\n  --data-urlencode 'grant_type=password' \\\n  --data-urlencode 'scope=openid' \\\n  --data-urlencode 'username=admin' \\\n  --data-urlencode 'password=admin' \\\n  --data-urlencode 'client_secret=9eGhwdAaox8bQ5DnfuUHuQTbOxhJxUwg' | jq -S\n{\n  \"access_token\": \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJBTHBheFhxanhaYmY5Vy1Pb3JpVnoxSUNTUV9SLUNrc05jZzVGRGFadUI0In0.eyJleHAiOjE3MzM5OTMyNDcsImlhdCI6MTczMzk5Mjk0NywianRpIjoiZjExZTdmM2UtMzFkNi00NTQ0LWE3MDUtMjA2Mzg0ZTYyYmNiIiwiaXNzIjoiaHR0cHM6Ly9wbG0tc2Itazgubm92YWxvY2FsOjk0NDMvY29yZS9odHRwcHJveHkvdjEva2V5Y2xvYWsvcmVhbG1zL2VkYSIsInN1YiI6ImYyYTc1MDM1LTU2YTUtNGJhMC1iZTliLTUzZTEzNTEyNTliZSIsInR5cCI6IkJlYXJlciIsImF6cCI6ImVkYSIsInNpZCI6ImYyZTU1YjQ2LWRiN2YtNGIwMi05ZTIwLTc2YTc2YWE0MDYwMSIsImFjciI6IjEiLCJhbGxvd2VkLW9yaWdpbnMiOlsiLyoiXSwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbImVkYXJvbGVfc3lzdGVtLWFkbWluaXN0cmF0b3IiLCJhZG1pbiJdfSwic2NvcGUiOiJvcGVuaWQgcHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwibmFtZSI6IkVEQSBhZG1pbiB1c2VyIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4iLCJnaXZlbl9uYW1lIjoiRURBIiwiZmFtaWx5X25hbWUiOiJhZG1pbiB1c2VyIn0.ZH2vO1sbxm4tke2bE1fUdUbkCtHYo3bFUZpr0J46GL0lGpyIf0LkxOnosatjpLCQl7-CpExhZCv11SmUM6W6c4DoX6d90PKeC-t-GoSKshAxGIh7njtFt1_dYAf1NgF4EGOQMPINj-_n4igjU22Ef7aU8c05m-QkbIPykYFJ0BefqG_H8A1QzNvntADrEfrpHAudGFxB1Ei5FpBxIRfqX40B7_9brzWMlrRRXeWA9i-JVe-6JXQxTTqRKAF9sWGllTA-vbcl-MZ1WsGcC8yS-KQ9nyTrqkwT4Sh06Z7s8IpqBNPEcVJ8p_X65bblGoRKrXMSD0zEXM2zTsJRGd6JVA\",\n  \"expires_in\": 300,\n  \"id_token\": \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJBTHBheFhxanhaYmY5Vy1Pb3JpVnoxSUNTUV9SLUNrc05jZzVGRGFadUI0In0.eyJleHAiOjE3MzM5OTMyNDcsImlhdCI6MTczMzk5Mjk0NywianRpIjoiODM0MGVlMWQtOThkNC00ZmQ5LThhOTQtNTIwNTQ5YWJlMjE3IiwiaXNzIjoiaHR0cHM6Ly9wbG0tc2Itazgubm92YWxvY2FsOjk0NDMvY29yZS9odHRwcHJveHkvdjEva2V5Y2xvYWsvcmVhbG1zL2VkYSIsImF1ZCI6ImVkYSIsInN1YiI6ImYyYTc1MDM1LTU2YTUtNGJhMC1iZTliLTUzZTEzNTEyNTliZSIsInR5cCI6IklEIiwiYXpwIjoiZWRhIiwic2lkIjoiZjJlNTViNDYtZGI3Zi00YjAyLTllMjAtNzZhNzZhYTQwNjAxIiwiYXRfaGFzaCI6IlNJRUREbWdpb2xneXpPT2lqQ3ZHRWciLCJhY3IiOiIxIiwiZW1haWxfdmVyaWZpZWQiOmZhbHNlLCJuYW1lIjoiRURBIGFkbWluIHVzZXIiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJhZG1pbiIsImdpdmVuX25hbWUiOiJFREEiLCJmYW1pbHlfbmFtZSI6ImFkbWluIHVzZXIifQ.a9946wNL4_UCfi9LmysRz6wiZG3Zgt84Vz6pa5HfxRcQj5tvFsoBVNCSWd07OzxAS_QuPsMESl9WM4WalUW4Ib6XyNEPENvJsQE8mRWSm-x1R0d1lqrGSaiOJzKX5XUNgZ1u7PRbG-jtlcY-Iaq3Ei7sfOWVmXz8mKOyGteRCa9MSrbD4oFe52DTPNV4EwHIbkI8hUuO9dvgu3MdX6OdLSU9FApDAQjrMo7dqF9_E5SfGvnIPWcAiPD2QyuTP6ZF2SBDEX0OIqn7LNiyyeg4t6RylCakgi31zi_cTY3SfeMhmc9_X4SOj0XbmqZYM7o_mCFxbXTjeSVLcJv4zvuMHg\",\n  \"not-before-policy\": 0,\n  \"refresh_expires_in\": 1800,\n  \"refresh_token\": \"eyJhbGciOiJIUzUxMiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI1NDRjYThkOC0yN2JkLTRlYTAtOGY2Ny1jOTkzYjExMDAwZDYifQ.eyJleHAiOjE3MzM5OTQ3NDcsImlhdCI6MTczMzk5Mjk0NywianRpIjoiZmE2OGQwYWEtNTcyOS00ZjhiLWE5OWUtNDQyNmY3ZWEwNzg5IiwiaXNzIjoiaHR0cHM6Ly9wbG0tc2Itazgubm92YWxvY2FsOjk0NDMvY29yZS9odHRwcHJveHkvdjEva2V5Y2xvYWsvcmVhbG1zL2VkYSIsImF1ZCI6Imh0dHBzOi8vcGxtLXNiLWs4Lm5vdmFsb2NhbDo5NDQzL2NvcmUvaHR0cHByb3h5L3YxL2tleWNsb2FrL3JlYWxtcy9lZGEiLCJzdWIiOiJmMmE3NTAzNS01NmE1LTRiYTAtYmU5Yi01M2UxMzUxMjU5YmUiLCJ0eXAiOiJSZWZyZXNoIiwiYXpwIjoiZWRhIiwic2lkIjoiZjJlNTViNDYtZGI3Zi00YjAyLTllMjAtNzZhNzZhYTQwNjAxIiwic2NvcGUiOiJvcGVuaWQgcm9sZXMgd2ViLW9yaWdpbnMgYWNyIGJhc2ljIHByb2ZpbGUgZW1haWwifQ.SQeRoXLXA61l8AozNH2iaOYR0lJVMYWTtbAEYKY4lREYYesAAMNRVk5wcLR1oKJrFzCFRnhMmIEZysQ7D_DDcw\",\n  \"scope\": \"openid profile email\",\n  \"session_state\": \"f2e55b46-db7f-4b02-9e20-76a76aa40601\",\n  \"token_type\": \"Bearer\"\n}\n</code></pre> <p>In case you're using Ansible collections for Nokia EDA, you can fetch the client secret using the Utils collection and the <code>get_token</code> module.</p>"},{"location":"development/api/#openapi-specifications","title":"OpenAPI Specifications","text":"<p>Detailed information about all of the individual API endpoints and their parameters is available in the OpenAPI (v3) format. You can download OpenAPIv3 JSON files either from your EDA installation or from the community-supported eda-labs/openapi repository.</p>"},{"location":"development/api/#api-documentation-in-the-eda-ui","title":"API documentation in the EDA UI","text":"<p>If you have EDA already installed<sup>2</sup> you can find OpenAPI documentation and download specifications for both EDA Core as well as for every application you have installed in your cluster. To access the API Documentation, use the  icon in the top right corner and select API Documentation menu item:</p> <p>The API Documentation UI can be used to explore the API specification as well as to download the OpenAPI Specification JSON files. To download the specification file for a selected application, use the  icon in the top right corner.</p> <p>You can then use these files within your own tools that can work with the standard OpenAPI specifications.</p> <p>The API documentation web view does not only provide a reference to the available APIs and endpoints, but also allows you to run the requests for all available endpoints. For example, the video below shows how to run a <code>GET</code> request to list configured users in the EDA platform by using the Core API.</p> <p>The request runner in the API documentation web view takes care of the authentication flow on your behalf. You can start running API requests right away.</p>"},{"location":"development/api/#eda-openapi-repository","title":"EDA OpenAPI Repository","text":"<p>If you don't have EDA installed, but still want to browse the OpenAPI specification for the EDA core and its default apps, you can use the community-supported eda-labs/openapi repository.</p> <p>This repo uses tags to indicate which EDA software release these OpenAPI spec files were extracted from.</p>"},{"location":"development/api/#listing-openapi-specifications","title":"Listing OpenAPI Specifications","text":"<p>For EDA Core and each installed EDA App the API server maintains the API Specification file that can be listed and fetched via the <code>openapi</code> endpoint.</p> <p>To list the available API Specifications and their relevant URLs, first authenticate the client and then you can execute the following <code>curl</code> command to get the list of APIs and OpenAPI Specification URLs per API.</p> <pre><code>curl -s https://${EDA_URL}/openapi/v3 \\\n  -H 'Authorization: Bearer ${TOKEN}' \\\n  -H 'Content-Type: application/json'\n</code></pre> Example output parsed using <code>jq</code> <pre><code>$ curl -s https://${EDA_URL}/openapi/v3 \\\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJuNnV4VXVyODdyaHNYUEt6dHNlT1Qxc1lERVI5MVVlMXBzWnhhaEdQX19rIn0.eyJleHAiOjE3MTQ2MDMwNjAsImlhdCI6MTcxNDYwMjc2MCwianRpIjoiYzdiZjU3NGUtY2ZkNi00Nzk3LTk2NzItMWI5Y2E5YTg2NzQ2IiwiaXNzIjoiaHR0cDovL2hlbGl4Lm5va2lhLmRlbGxhZXJ0LmRldjo5MjAwL2NvcmUvaHR0cHByb3h5L3YxL2tleWNsb2FrL3JlYWxtcy9lZGEiLCJzdWIiOiJmMmE3NTAzNS01NmE1LTRiYTAtYmU5Yi01M2UxMzUxMjU5YmUiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJlZGEiLCJzZXNzaW9uX3N0YXRlIjoiMTFkZjU2OWEtNTZhYi00NmMyLWJkOTItNTJkYTg1YzM4NzA4IiwiYWNyIjoiMSIsImFsbG93ZWQtb3JpZ2lucyI6WyIvKiJdLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsiYWRtaW4iXX0sInNjb3BlIjoib3BlbmlkIHByb2ZpbGUgZW1haWwiLCJzaWQiOiIxMWRmNTY5YS01NmFiLTQ2YzItYmQ5Mi01MmRhODVjMzg3MDgiLCJlbWFpbF92ZXJpZmllZCI6ZmFsc2UsInByZWZlcnJlZF91c2VybmFtZSI6ImFkbWluIiwiZ2l2ZW5fbmFtZSI6IiIsImZhbWlseV9uYW1lIjoiIn0.bfTVRxe8KaVAqxjjDKIOJI6UGtJtpKc4W58ouvM1ILAVTiUtaWONT9xGIWDsUaEOzWQTlg-fjYWD3SmAMwPMo11wXafQkL7hTItj6Gs0DalwvmarXGetaVc7rVQhG5p3kvTQ0rNYqjE2bU763ml173kPXNKWUl7VXArCVK6uZ0azBDDX5uzlFBd5QEBtn1pH_-rATheCpvnkjC3s2WfJhDULfkix63N5MQWwhOajAKRe5mXTWLv9W9d_nwDsrHipPBtvAvG65I7s6tqjFH_M--PQPXifsl73v0hTnIHzC9ujpcGxkxctK9DvpwADF7TmuKVjbFHZqxp3FT7HxaK6Zg' \\\n  -H 'Content-Type: application/json' | jq -S\n{\n    \"paths\": {\n        \"/apps/aaa.eda.nokia.com/v1alpha1\": {\n            \"x-eda-nokia-com\": {\n                \"serverRelativeURL\": \"/openapi/v3/apps/aaa.eda.nokia.com/v1alpha1\",\n                \"title\": \"AAA Application APIs\"\n            },\n            \"serverRelativeURL\": \"/openapi/v3/apps/aaa.eda.nokia.com/v1alpha1\",\n            \"title\": \"AAA Application APIs\"\n        },\n        \"/apps/aifabrics.eda.nokia.com/v1alpha1\": {\n            \"x-eda-nokia-com\": {\n                \"serverRelativeURL\": \"/openapi/v3/apps/aifabrics.eda.nokia.com/v1alpha1\",\n                \"title\": \"AIFabrics Application APIs\"\n            },\n            \"serverRelativeURL\": \"/openapi/v3/apps/aifabrics.eda.nokia.com/v1alpha1\",\n            \"title\": \"AIFabrics Application APIs\"\n        },\n        \"/apps/appstore.eda.nokia.com/v1\": {\n            \"x-eda-nokia-com\": {\n                \"serverRelativeURL\": \"/openapi/v3/apps/appstore.eda.nokia.com/v1\",\n                \"title\": \"App Store Application APIs\"\n            },\n            \"serverRelativeURL\": \"/openapi/v3/apps/appstore.eda.nokia.com/v1\",\n            \"title\": \"App Store Application APIs\"\n        },\n        // snipped\n    }\n}\n</code></pre>"},{"location":"development/api/#fetching-the-api-specifications","title":"Fetching the API Specifications","text":"<p>For each of the App/version and the Core, the <code>serverRelativeURL</code> is the full URI to the API specifications for that specific App/version. You can use that to fetch the full OpenAPIv3 Specifications for the resources used and exposed by that specific App and version. Below is an example for the <code>connect</code> App. With an authenticated client you can execute the following <code>curl</code> command to fetch the OpenAPIv3 specification of the <code>connect.eda.nokia.com/v1alpha1</code> app.</p> <pre><code>curl -s http://${EDA_HOST}/openapi/v3/apps/connect.eda.nokia.com/v1alpha1 \\\n  -H 'Authorization: Bearer ${TOKEN}' \\\n  -H 'Content-Type: application/json'\n</code></pre> <ol> <li> <p>https://documentation.nokia.com/eda/25-8/books/user/change-internal-passwords.html#keycloak-and-the-eda-ui \u21a9</p> </li> <li> <p>Try EDA installation is a perfect fit for experimenting with the API.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/","title":"There's an app for that","text":"<p>EDA is all about extensibility, and the packaging of this extensibility is referred to as an \"app\".</p> <p>What's an app again?</p> <p>If you need a refresher on what an app is, check out apps.</p> <p>With base configuration your EDA cluster points to an app catalog supplied by Nokia. This gives you access to official Nokia-supported applications, including upgrades via the EDA store. If you're anything like us you have your own opinions about how you'd like to solve your automation problems! This is where building your own app comes in.</p> <p>Apps in general let you:</p> <ul> <li>Template inputs to resources within your cluster.     Have strong opinions about how your users interact with resources - set defaults, enforce constraints, and provide a consistent user experience.</li> <li>Define your own inputs, and the execution logic that should run in response to those inputs.     Generate configuration for targets, respond to telemetry events, trigger workflows, and much, much more.</li> <li>Generate alarms, normalize telemetry data.</li> <li>Define your own dashboards and other UI visualizations.</li> <li>Define your own workflows - one-shot operations that you'd like to expose to your users.</li> </ul> <p>An application may consist of one or more of these components, or none of them!</p>"},{"location":"development/apps/#why-build-on-eda","title":"Why build on EDA?","text":"<p>You've likely used other infrastructure automation tools before, and you may be wondering why you should build on EDA. Here are a few reasons:</p> <ul> <li>EDA operates on a deterministic, declarative, abstracted, and event-driven model.     This means that you can define the state you want your infrastructure to be in, and EDA will take care of making sure it gets there. No more handling deltas or worrying about order of operations. This massively simplifies application logic - given a certain input what would you like the output to be?</li> <li>Built for all your state streaming needs.     Simply define the set of things you'd like to monitor, and what you'd like to have happen on any updates. EDA takes care of subscriptions, and event triggers for you, providing a generic means to raise alarms, publish status of infrastructure, and normalize telemetry data.</li> <li>EDA is built on top of Kubernetes, which means you get all the benefits of Kubernetes - scalability, reliability, and a rich ecosystem of tools.</li> <li>And all of this comes with the multivendor capabilities.</li> </ul>"},{"location":"development/apps/#development-workflow","title":"Development workflow","text":"<p>In its simplest form, an app builders workflow consists of the following steps:</p> <ul> <li>Define the resources you want to handle - the abstractions or inputs you expect your users to provide.</li> <li>Define the logic you need - the scripts (or sometimes referred to as intents) that will run in response to changes in those resources. These scripts are written in Python<sup>1</sup>.</li> <li>Define the relationships between the above - what logic is triggered by what resources.</li> </ul> <p>In its more advanced form you may:</p> <ul> <li>Write Kubernetes-controller style apps, which are a bit more complex, but also more powerful.     This effectively lets you build and package your own Kubernetes controllers, which can be used to manage any Kubernetes resource, or any EDA resource.</li> <li>Define any views required - the dashboards that will display the state of your resources, or any other information you want to expose or visualize.</li> <li>Define the workflows you need - the one-shot operations that you want your users to be able to perform. Think ping, upgrade, verify, etc.</li> </ul>"},{"location":"development/apps/#next-steps","title":"Next steps","text":"<p> Setup the dev environment</p> <ol> <li> <p>MicroPython to be precise. We will explain why MicroPython in later sections.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/build-publish/","title":"Build and Publish","text":"<p>We take pride in EDA's extensibility through applications, and one of the key aspects of this extensibility is the ease of build, publish, share and install workflows. EDA uses standard, well-known and established toolchains for this purpose:</p> <ul> <li>OCI image as a packaging format for the application</li> <li>Container registry as a storage for the application images</li> <li>Git for catalog and application discovery and sharing</li> </ul> <p>From the distribution point of view, EDA app consists of two distinct artifacts that are coupled together:</p> <ol> <li>An app manifest file that describes the app components, including the URL/tag of the app image</li> <li>An OCI image that contains the app components</li> </ol> <p>This structure can be visualized as:</p> <p>In this chapter we will cover the process of building and publishing an application.</p>"},{"location":"development/apps/build-publish/#building-an-oci-app-image","title":"Building an OCI App Image","text":"<p>We refer to the process of packaging the application artifacts into an OCI image format as \"building\" the image. But building the image alone won't make the app installable, as the image needs to be hosted in an OCI container registry that is reachable from your EDA cluster. As these two steps are tightly coupled, we have a single command in the <code>edabuilder</code> CLI that takes care of both operations at once - <code>edabuilder build-push</code>.</p> <p>Since most container registries require authentication, we first need to login to the registry. The <code>edabuilder</code> has a <code>login registry</code> subcommand that takes in two arguments - username and password. For example, to login to a free ghcr.io registry, you would use the following command:</p> <pre><code>edabuilder login registry -u &lt;username&gt; -p &lt;password&gt; ghcr.io #(1)!\n</code></pre> <ol> <li> <p>If you're using GitHub CLI, then instead of providing the token as a password, you can make use of the <code>gh</code> CLI tool and perform the following:</p> <p>Add <code>write:packages</code> scope to your token:</p> <pre><code>gh auth login -s 'write:packages'\n</code></pre> <p>And then use the token as:</p> <pre><code>edabuilder login registry -u hellt -p $(gh auth token) ghcr.io\n</code></pre> </li> </ol> <p>With the authentication step out of the way, we need to make sure that the application manifest has the correct container image URL and tag set. When <code>edabuilder</code> scaffolds an application it sets the image name in the app's manifest. If you have followed the quickstart guide, your <code>banners</code> app manifest file will contain the following:</p> banners/manifest.yaml<pre><code>apiVersion: core.eda.nokia.com/v1\nkind: Manifest\nmetadata:\n  name: banners\nspec:\n  # omitted for brevity\n  group: banners.eda.local\n  image: change.me/banners:v0.0.0\n</code></pre> <p>As an app owner, you set the image value to an image URI that points to the registry where you want the image to be published in the app manifest file<sup>1</sup>. As we are using ghcr.io for this example, we could set the image value to e.g.:</p> <pre><code>- image: change.me/banners:v0.0.0\n+ image: ghcr.io/eda-labs/banners:v2.1.0\n</code></pre> <p>Now, <code>edabuilder build-push</code> has everything it needs - an image URI and the credentials for the container registry the image points to. Simply point the command towards your manifest and its build context<sup>2</sup>, like so:</p> run from the project's directory<pre><code>edabuilder build-push --app manifest=banners/manifest.yaml #(1)!\n</code></pre> <ol> <li>Note that the <code>banners</code> directory in the <code>--app manifest=banners/...</code> argument is the directory containing the application manifest. If you named your app differently you will have to change this value accordingly.</li> </ol> <p>A successful <code>build-push</code> action ends by prompting you with \"Successfully pushed OCI Image\". Your app image should now show up in the registry. If you intend to have your image accessible without authentication, make your image public using the interface of your registry provider.</p>"},{"location":"development/apps/build-publish/#publishing-an-app","title":"Publishing an App","text":"<p>The second pillar of an app is its manifest file<sup>3</sup>, which we still need to publish to a catalog<sup>4</sup> of our choice.</p> <p>The first thing you need to ensure is that you have a git repository created that you intend to use as an App Catalog for your EDA applications. In this example, we will be using our eda-labs/catalog repository that we use for our community-oriented applications.</p> <p>Start off by logging into the Git provider of your choice to make sure you are authorized to push the manifest to the repository:</p> <pre><code>edabuilder login git -u hellt -p $(gh auth token) https://github.com/eda-labs/catalog #(1)!\n</code></pre> <ol> <li>Change the user, password and repository URL to the appropriate values for your repository.</li> </ol> <p>After a successful login we can publish our application manifest to the repository:</p> <pre><code>edabuilder publish https://github.com/eda-labs/catalog \\\n--app manifest=banners/manifest.yaml\n</code></pre> <p>A successful publish of the manifest should result in the following output:</p> <pre><code>Publishing to branch 'main'\nNo app version given, using the manifest image tag as app version: \nStaging `banners` at version `v2.1.0`\nSuccessfully published Apps\n</code></pre> <p>Now you should see the application manifest published in your Git repository following the <code>vendors/&lt;vendor-name&gt;/apps/&lt;app-name&gt;</code> path:</p> <p></p> <p>The app version will be matching the version from the image tag found in the manifest, unless the version is provided inline with the <code>--app</code> argument.</p> <p>To republish an app, i.e. override an existing version, add <code>--force</code> flag to the command.</p>"},{"location":"development/apps/build-publish/#configuring-eda-store-with-your-publishing-authority","title":"Configuring EDA Store with your publishing authority","text":"<p>Just uploading the OCI image and the manifest to a catalog won't make your application available in the EDA Store. You need to make the store aware of any new OCI registries and/or catalogs. The procedure for adding a registry to the EDA store can be found here, the procedure for catalogs can be found here.</p> <p>In our example we are using ghcr.io. If you've deployed EDA through the Playground, this registry is already registered with the EDA store, so nothing needs to be done.  </p> <p>We do need to apply a catalog CR, though. Here is the Catalog CR that adds a catalog named \"eda-labs\" and references the Git repo we pushed our manifest to in the previous step:</p> Catalog CRApply command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: eda-labs\nspec:\n  remoteType: git\n  remoteURL: https://github.com/eda-labs/catalog\n  skipTLSVerify: false\n  title: EDA Labs Catalog\n  # auth secret is not required, as our Catalog repo is public\n  # authSecretRef: ''\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: eda-labs\nspec:\n  remoteType: git\n  remoteURL: https://github.com/eda-labs/catalog\n  skipTLSVerify: false\n  title: EDA Labs Catalog\n  # auth secret is not required, as our Catalog repo is public\n  # authSecretRef: ''\nEOF\n</code></pre> <p>Once added, the EDA Store will start parsing the referenced Git repo and display them as available applications in the EDA Store.</p> <p>Since our repo is public, we did not utilize the <code>authSecretRef</code> reference; if your Git repo is private, you would need to create a Secret and reference it.</p>"},{"location":"development/apps/build-publish/#local-development","title":"Local development","text":"<p>The three sections above describe what you need to do when you're ready to publish an app. It's a bit of manual work, and having to do this over and over again while your app is still under development is cumbersome. That is where <code>edabuilder deploy</code> comes in. This command is designed to help you iterate on your app in a frictionless manner during development. Under the hood, it makes use of the concepts described above, but <code>edabuilder</code> juggles around some of the URIs in order to use an intermediary development catalog and registry inside of your EDA cluster.</p> <p>Concretely, when you want to try out a new version of your code, simply travel down to your app directory (the one containing the <code>manifest.yaml</code>), and execute</p> <pre><code>edabuilder deploy #(1)!\n</code></pre> <ol> <li>This command also has support for the <code>--app</code> flag, so technically you don't have to travel down to the app directory.</li> </ol> <p>This does the following:</p> <ol> <li>create a development catalog repository in the git server in your EDA cluster</li> <li>create a secret and Catalog CR for the dev catalog to configure the EDA Store</li> <li>create a simple<sup>5</sup> development registry (Deployment, Service, and Secret and Registry CR to configure the EDA Store)</li> <li><code>edabuilder generate</code> to keep all of your Python models, CRDs, etc. up-to-date</li> <li>rewrite the manifest AppImage URI (in memory) to point to the development registry, then <code>edabuilder build-push</code></li> <li><code>edabuilder publish</code> to the development catalog</li> <li>apply an app install Workflow to (re)install the app and wait for the installation result</li> </ol> <p>When you run <code>edabuilder deploy</code> for the first time, step 3 could take a while if the registry image needs to be pulled.</p>"},{"location":"development/apps/build-publish/#bring-your-own-catalogregistry","title":"Bring your own catalog/registry","text":"<p>The <code>edabuilder deploy</code> command is customisable through a configuration file, located at <code>~/.config/edabuilder/config.yaml</code><sup>6</sup>. It allows you to provide multiple custom OCI registries and/or application catalogs (Git repositories) by specifying the URL of the corresponding component and to select the current one to use for the <code>edabuilder deploy</code> command.</p> <p>Consult with the  deploy targets section of the <code>edabuilder</code> CLI documentation for more information on how to use this configuration file.</p> <ol> <li> <p>When creating your app development project through <code>edabuilder init</code>, you can use the <code>-r | --registry</code> option to specify your production registry. If you do so, the PROJECT file will store the registry and it will automatically be included in the image URI of any newly created apps' manifests.\u00a0\u21a9</p> </li> <li> <p>For more information on the <code>--app</code> flag, and build context in general, refer to terminology.\u00a0\u21a9</p> </li> <li> <p>For more information on manifests, refer to terminology \u21a9</p> </li> <li> <p>For more information on catalogs, refer to terminology \u21a9</p> </li> <li> <p>A basic CNCF Distribution Registry image is used here.\u00a0\u21a9</p> </li> <li> <p>You can provide a custom location for this file by setting the <code>EDABUILDER_CONFIG</code> environment variable.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/components/","title":"Application Components","text":"<p>As was covered in the Project Layout section, each app has its own directory in the EDA project. Taking the quickstart app as a starting point, your project directory will contain the <code>banners</code> directory that hosts everything an application might feature.</p> contents of the banners app directory<pre><code>.\n\u251c\u2500\u2500 api\n\u251c\u2500\u2500 crds\n\u251c\u2500\u2500 intents\n\u251c\u2500\u2500 openapiv3\n\u251c\u2500\u2500 rbac\n\u251c\u2500\u2500 workflows\n\u251c\u2500\u2500 test\n\u251c\u2500\u2500 ui\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 go.sum\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 manifest.yaml\n\u2514\u2500\u2500 README.md\n</code></pre> <p>The components that can be found in an application bundle are:</p> <ul> <li> <p>Application API:</p> <ul> <li>To define application APIs, edabuilder uses the same pattern as kubebuilder, i.e. the API is defined by the Go files in the <code>api/</code> directory.</li> <li>Based on the source API types defined in <code>.go</code> files, <code>edabuilder generate</code> manages the following components:</li> <li>Python models equivalent to your API structs defined in Go</li> <li>Custom Resource Definitions (CRDs)</li> <li>OpenAPI schema files, which describe extensions to the schema of both Kubernetes and EDA  </li> </ul> <p>Many subcommands start off by running <code>edabuilder generate</code> to make sure your app state is always up-to-date. * Intents aka Scripts, which are executable code that can be run in the context of a resource. These are typically used to implement the logic of the application for non-Kubernetes-controller apps. * Views, which are UI dashboards. This is typically used to bundle dashboards alongside the resources within the application.</p> </li> </ul> <ul> <li>Workflows, which are run to completion logic that can be triggered by resources. This is typically used to implement the logic of the application for one-shot operations - things like upgrades or other operations that are not ongoing.</li> <li>RBAC objects - optional rbac roles that an application might require.</li> <li>Bootstrap resources, which are similar to resources, but are immutable - they're intended primarily as a means for bootstrapping new <code>Namespace</code> resources in EDA. It is typically to see things like allocation pools or default resources in this category.</li> </ul> <p>A simple application may contain only one of the above, while a more complex application may contain all of them.</p>"},{"location":"development/apps/edabuilder/","title":"EDABuilder","text":"<p><code>edabuilder</code> is a standalone CLI tool for performing EDA Store operations such as building and publishing EDA apps or scaffolding the boilerplate code for new apps. The download instructions are mentioned in Environment setup page.</p> <p><code>edabuilder</code> has the following capabilities:</p> <ul> <li><code>init</code>: initialise a directory as a project that will hold multiple apps.</li> <li><code>create app</code>: scaffold the boilerplate for a new application.</li> <li><code>create resource</code>: create a new API resource. These resources are the inputs and outputs of your app, i.e. the main way to interact with your app.</li> <li><code>create intent</code>: scaffold boilerplate code for a new config/state intent for one of your API resources, if you hadn't done so already at the time of creating the resource.</li> <li><code>create version</code>: create a new API version.</li> <li><code>build-push</code>: package an app and host it in a registry<sup>1</sup>.</li> <li><code>publish</code>: publish your app to a catalog<sup>1</sup>.</li> <li><code>generate</code>: based on your API resources, defined in the Go files under <code>api/</code>, generate equivalent python models to be used as an SDK in your intents, CRDs, OpenAPI specs, and keep your manifest up-to-date.</li> <li><code>generate appsettings</code>: Scaffold a new <code>settings</code> directory, which you can further customise to provide documentation for your app's settings.</li> <li><code>generate appsettings-openapi</code>: Generate an OpenAPI spec based on the settings struct in your <code>settings</code> directory.</li> <li><code>deploy</code>: build, publish and install your application in your EDA cluster, allowing you to test it immediately and iteratively, during development<sup>1</sup>.</li> </ul> <p>Working directories</p> <p><code>edabuilder</code> will run using the current working directory as context. You should run project related commands from the root of your project (<code>edabuilder init</code> for example), and application related commands from the root of your applications (<code>edabuilder create</code> for example).</p>"},{"location":"development/apps/edabuilder/#initialising-a-project","title":"Initialising a project","text":"<p>When you run <code>edabuilder init [&lt;project-name&gt;]</code>, either the current directory or a new one, named <code>project-name</code>, will be initialised for app development. This entails populating a couple of directories (<code>common/</code>, <code>test/</code>, <code>utils/</code>) with common libraries to be imported in the app scripts you will be writing, as well as creating a PROJECT file that keeps track of some project-wide parameters, such as the publishing authority of your apps, your production registry, etc. These parameters can all be passed via arguments to the command. To see the available options, run <code>edabuilder init -h</code>.</p>"},{"location":"development/apps/edabuilder/#creating-an-app","title":"Creating an app","text":"<p>Running <code>edabuilder create app &lt;app-name&gt;</code> from the root of your project will net you a new directory containing a scaffolded structure for an app with a couple of subdirectories created in it. They all have self-explanatory, categorised, names that suggest where to put app files. Additionally, a <code>manifest.yaml</code> file is created. The <code>edabuilder</code> tool will maintain parts of this manifest along the way. More on that in the other sections.</p>"},{"location":"development/apps/edabuilder/#creating-a-resource","title":"Creating a resource","text":"<p>As stated earlier, resources are the main way to interact with your app. Run <code>edabuilder create resource MyCoolKind</code> to scaffold a barebones resource: the \"API definition\" is the Go file located at <code>api/&lt;apiversion&gt;/mycoolkind_types.go</code>.</p> <p>From this file, the equivalent python models are generated at <code>api/&lt;apiversion&gt;/pysrc/mycoolkind.py</code>, as well as a CRD under <code>crds/</code> and the OpenAPI spec under <code>openapiv3/</code>. Your manifest is automatically kept up-to-date with this change, meaning this new <code>pysrc</code> and the CRD are ready to be packaged in your app already.</p>"},{"location":"development/apps/edabuilder/#creating-an-intent","title":"Creating an intent","text":"<p>In and of itself, a resource consisting of only a CRD is not very useful. You likely intend to trigger some code when an instance of your resource is created, updated, or deleted. We call the scripts containing the code for these trigger events \"intents\".</p> <p>Two types of intents exist: config intents and state intents. The config intent is really meant for direct interaction: A user creates a resource with some desired parameters, and the intent code is subsequently triggered, performing some action in the cluster. A resource bundled with a config intent is called a \"config resource\".</p> <p>The state intent will in most cases be more of a watcher: Based on some observed state of the cluster, the code e.g. performs some translations or exports some metrics. A resource bundled with a state intent is called a \"state resource\".</p> <p>Since intents and resources are such tightly coupled concepts, intent code of either type can be scaffolded at the time of creating a resource, with the <code>--scaffold-config</code> or <code>--scaffold-state</code> options. If you forgot to scaffold the intent boilerplate at resource creation time, you can add it after the fact by using the <code>edabuilder create intent</code> subcommand.</p> <p>After creating an intent (or creating a resource with one of the intent scaffolding options for that matter), your manifest is kept up-to-date with the appropriate scripts and trigger events.</p>"},{"location":"development/apps/edabuilder/#creating-a-version","title":"Creating a Version","text":"<p>Through <code>edabuilder create version</code> you can create a new API version, e.g. when you are introducing backwards compatibility breaking changes over the lifetime of your app. Here you have the option to carry over API resources from a previous version. If you choose to do so, a boilerplate migration script will be scaffolded per resource that is present in your old API version. The API version in the manifest specification is automatically updated to the new version, and conversion scripts are tracked in the manifest as well.</p>"},{"location":"development/apps/edabuilder/#generating-your-app","title":"Generating your app","text":"<p><code>edabuilder generate</code> is an idempotent command designed to keep any generated code in your app up-to-date. It uses your API resources as input to generate a python SDK under <code>api/&lt;apiversion&gt;/pysrc</code>, CRDs and OpenAPI. It also ensures your manifest is up-to-date.</p> <p>Many of the other subcommands use <code>generate</code> under the hood, so it's likely you won't have to run it explicitly very often.</p>"},{"location":"development/apps/edabuilder/#adding-app-settings","title":"Adding App Settings","text":"<p>There are two <code>edabuilder</code> commands which allow you to provide install-time settings for your application. For instance, if your app includes a resource, (e.g. a k8s deployment) for which you want the user to be able to specify configurable parameters like CPU limit, etc.</p> <p>The first command, <code>edabuilder generate appsettings</code>, will evaluate all CRs that are linked in your app's Manifest and look for settings annotations. A setting is annotated with <code># app-set: ${&lt;setting name&gt;}</code>. To continue the example of a CPU limit set for a Deployment resource, the Deployment CR linked in the Manifest would look something like:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-controller\nspec:\n  # omitted for brevity\n  containers:\n    - image: ghcr.io/your-container-image-uri\n      resources:\n        limits:\n          cpu: \"4\" # app-set: ${controllerCpuLimit}\n</code></pre> <p>Where the setting JSON name is <code>controllerCpuLimit</code> and its default value is <code>\"4\"</code>. After gathering all the settings you have annotated in your app CRs, <code>edabuilder</code> will collect these in a single Go struct that becomes the source of truth for your settings' OpenAPI specification. This struct, <code>AppSettingsSpec</code>, is located at <code>&lt;app-root&gt;/settings/appsettings_types.go</code>. For the CPU limit example above, this is the resulting struct:</p> <pre><code>// AppSettingsSpec defines the desired state of AppSettings.\ntype AppSettingsSpec struct {\n    // Document the 'ControllerCpuLimit' setting here, so it shows up nicely in your generated OpenAPI spec.\n    // +kubebuilder:default=\"4\"\n    // +eda:ui:title=\"ControllerCpuLimit\"\n    ControllerCpuLimit string `json:\"controllerCpuLimit,omitempty\"`\n}\n</code></pre> <p>You should manually review and edit this struct to make sure the documentation comments and field types are correct before continuing. Given that a single structure defines the app settings means that the settings' names should be unique across all CRs of your app.</p> <p>Iterating on settings</p> <p>The <code>generate appsettings</code> command is strictly meant for the initial scaffolding of the application' settings structure. Rerunning this command (which requires the <code>-f</code> flag) is a destructive operation, in the sense that it will revert all manual changes you may have done in <code>AppSettingsSpec</code>.</p> <p>If you have already scaffolded the settings and made updates to the <code>AppSettingsSpec</code> struct and would like to add a new setting, then simply add a field to the struct for your new setting and do not rerun the <code>generate appsettings</code> command.</p> <p>Once you're done documenting your app settings, you can finalise your app settings for the EDA Store with the second command, <code>edabuilder generate appsettings-openapi</code>. It will generate an OpenAPI spec under <code>&lt;app-root&gt;/appsettings-openapi/</code>. Your Manifest will be updated automatically to include this file.</p> <p>Your app is now ready to be installed by the EDA Store with install-time settings.</p> <p>Installing with a non-default value of a setting</p> <p>App settings support is limited to Workflow-based installs in this release, i.e. it is not possible to provide the settings via EDA UI.</p> <p>To provide a custom value for a setting, add the <code>&lt;setting-name&gt;: &lt;custom-value&gt;</code> key-value pair to the list entry of the appropriate app in the Workflow's <code>spec.input.apps[*].appSettings</code> map.</p> <p>Here is an example Workflow to install some app with a custom value for the <code>controllerCpuLimit</code> setting:</p> Install Workflow <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: app-install-workflow-with-settings\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: &lt;your-app-with-cpu-limit-setting&gt;\n      catalog: &lt;your catalog&gt;\n      version:\n        value: v0.0.0\n      appSettings:\n        controllerCpuLimit: \"8\"\n</code></pre>"},{"location":"development/apps/edabuilder/#configuring-deploy-targets","title":"Configuring deploy targets","text":"<p>The <code>edabuilder deploy</code> command is customisable through a configuration file located at <code>~/.config/edabuilder/config.yaml</code><sup>2</sup>. It allows a user to provide the so called deploy targets - the custom OCI registry and application catalog pairs that a user can select from when deploying an app. The configuration file is structured as follows:</p> <pre><code># a map of named deploy targets\ndeploy-targets:\n  internal-target: # first deploy target\n    # Is authentication required to read from both registry and catalog?\n    # When set to false or omitted, indicates that the registry/catalog are public\n    read-authentication: false\n    registry:\n      # URL of your registry, i.e. [&lt;scheme&gt;]&lt;fqdn&gt;[:port]\n      url: corporateregistry.internal\n      # Whether to skip TLS verification for the registry [default: false]\n      skip-tls-verify: true\n    catalog:\n      # URL of your catalog repo, i.e. [&lt;scheme&gt;]&lt;fqdn&gt;[:port]/&lt;repository&gt;.git\n      url: https://gitlab.mycorp.internal/dev/eda-apps.git\n      skip-tls-verify: true\n\n  external-target: # second deploy target\n    registry:\n       url: ghcr.io\n    catalog:\n      url: https://github.com/someorg/eda-apps.git\n\n# the name of the currently active deploy target\n# in-cluster is a special value that indicates the in-cluster deploy target\ncurrent-deploy-target: in-cluster\n</code></pre> <p>The deployment targets are defined in the <code>config.yaml</code> file in the edabuilder config directory using the following top level keys:</p> <ul> <li><code>deploy-targets</code> - a YAML object that is a map of deploy target configurations.</li> <li><code>current-deploy-target</code> - a string value that matches one of the configured deploy-target names. Defaults to in-cluster which is a reserved name for a deploy target being the EDA cluster itself, with the dev registry and dev catalog deployed in it.</li> </ul>"},{"location":"development/apps/edabuilder/#in-cluster-deploy-target","title":"<code>in-cluster</code> deploy target","text":"<p>The default deploy target is the <code>in-cluster</code> target, which is a reserved name for the OCI registry and Catalog deployed by <code>edabuilder</code> in the EDA cluster itself. The <code>edabuilder deploy</code> command will use this target by default if no other target is specified.</p>"},{"location":"development/apps/edabuilder/#current-deploy-target","title":"Current deploy target","text":"<p>After you have added the desired deploy targets to the <code>config.yaml</code> file, you can set the current deploy target by running either by specifying its name in the configuration file, or using the CLI command:</p> <pre><code>edabuilder deploy use-target &lt;target-name&gt;\n</code></pre> <p>To reset the current deploy target to the default <code>in-cluster</code> target, you can run:</p> <pre><code>edabuilder deploy reset-target\n</code></pre>"},{"location":"development/apps/edabuilder/#read-authentication","title":"Read authentication","text":"<p>Both the catalog and registry may require authentication for cloning or fetching. Private Git repositories and private registries always require authentication. This means that, for the app store to pull the corresponding artifacts, a secret containing the necessary authentication or token data must be provided.</p> <p>However, when using public registries and catalogs, users do not need to provide authentication data for read operations.</p> <p>To provide this flexibility, the <code>read-authentication</code> boolean setting is available at the deploy-target level.</p> <ul> <li>When set to <code>false</code> (or when not present), both the catalog and registry are considered public, and reads can be performed without authentication.</li> <li>When set to <code>true</code>, authentication is required to read from the registry and catalog. In this case, during the <code>deploy</code> command, a prompt will appear asking if you want <code>edabuilder</code> to configure the associated secrets using authentication data previously provided via the <code>edabuilder login registry</code> or <code>edabuilder login catalog</code> commands (stored in <code>~/.config/edabuilder/auth.json</code><sup>3</sup>).</li> </ul> <p>If you choose \"Yes,\" the matching authentication data is provisioned as a Kubernetes secret and referenced in the corresponding catalog or registry. If you select \"No,\" no secrets are configured, and a prompt will inform you that these secrets should be created manually.</p> <ol> <li> <p>For more information on packaging, publishing and iteratively deploying apps, refer to Build and Publish \u21a9\u21a9\u21a9</p> </li> <li> <p>You can provide a custom location for this file by setting the <code>EDABUILDER_CONFIG</code> environment variable.\u00a0\u21a9</p> </li> <li> <p>You can provide a custom location for this file by setting the <code>EDABUILDER_AUTH_CONFIG</code> environment variable.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/project-layout/","title":"Project Layout","text":"<p>When you followed the quickstart and initialized a new EDA project with the <code>banners</code> application in it, your top level project directory should look like this:</p> <pre><code>.\n\u251c\u2500\u2500 banners # dir\n\u251c\u2500\u2500 common  # dir\n\u251c\u2500\u2500 test    # dir\n\u251c\u2500\u2500 utils   # dir\n\u251c\u2500\u2500 PROJECT\n\u251c\u2500\u2500 go.work\n\u251c\u2500\u2500 go.work.sum\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 ruff.toml\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .envrc\n\u2514\u2500\u2500 .gitignore\n</code></pre> <p>Let's cover the purpose of each directory in more detail.</p>"},{"location":"development/apps/project-layout/#application","title":"Application","text":"<p>The <code>banners</code> directory contains the <code>banners</code> application files that <code>edabuilder</code> created for us when we executed <code>edabuilder create app banners</code>. We cover the contents of this directory in the App Components section.</p>"},{"location":"development/apps/project-layout/#common","title":"Common","text":"<p>The <code>common</code> directory contains the common python functions and constants that apps can use. It is auto-generated by <code>edabuilder</code> and typically should not be modified manually.</p>"},{"location":"development/apps/project-layout/#test","title":"Test","text":"<p>The <code>test</code> directory contains python packages that enable application unit testing. The app testing documentation is a work in progress.</p>"},{"location":"development/apps/project-layout/#utils","title":"Utils","text":"<p>In the <code>utils</code> directory you will find utility functions that abstract some EDA API interactions via convenience functions.</p>"},{"location":"development/apps/project-layout/#project","title":"Project","text":"<p>The <code>PROJECT</code> file contains the metadata a project was initialized with. For example, if you are reading this after the quickstart, your project file should look like this:</p> <pre><code>builderVersion: v25.4.1\ndomain: eda.local\nname: example\nvendor: community\n</code></pre> <p>The <code>builderVersion</code> contains the EDA release version that is used by this particular version of the <code>edabuilder</code> tool.</p> <p>The rest of the fields are self explanatory and were passed as CLI arguments during the project instantiation.</p>"},{"location":"development/apps/project-layout/#go-workspace","title":"Go workspace","text":"<p>The <code>go.work</code> file defines the Go Workspace configuration and includes (via <code>uses</code> statement) all apps created in the project. Since the project may contain more than one app, the workspace makes it possible to develop multiple apps in parallel without modifying each apps's Go module file.</p> <p>Most users will never need to modify the workspace file, and edabuilder will add new apps to the workspace automatically.</p>"},{"location":"development/apps/project-layout/#python-project","title":"Python project","text":"<p>You will find the <code>pyproject.toml</code> and <code>ruff.toml</code> files in the root of your project. The <code>pyproject.toml</code> file contains the Python project metadata and the <code>ruff.toml</code> file contains the Python linting rules.</p> <p>Since most EDA applications are written in Python<sup>1</sup><sup>2</sup> as an application developer you would want to initialize a virtual environment for your EDA app project to ensure that you get code autocompletion and basic linting in place.</p> <p>You may use any virtual environment tool of your choice, and in the quickstart we used <code>uv</code> to init the virtual environment by running <code>uv sync</code> while being in the project directory.</p>"},{"location":"development/apps/project-layout/#environment","title":"Environment","text":"<p>A couple of environment files - <code>.envrc</code> and <code>.env</code> - contain environment variables that should help your editor to resolve the local python packages and select the local <code>.venv</code> as an acting python environment.</p>"},{"location":"development/apps/project-layout/#git-ignore","title":"Git ignore","text":"<p>And finally, you will find a <code>.gitignore</code> file that contains a list of files and directories that should be ignored by Git.</p> <ol> <li> <p>Technically, with MicroPython runtime.\u00a0\u21a9</p> </li> <li> <p>There are two different classes of EDA apps - intent apps that are written in Python, and Controller-based apps, that can be written in any language.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/quick-start/","title":"Quick Start","text":"<p>As explained in the introduction, an application in EDA can contain many things and do way more than just generating node configurations from the abstracted input. But, still, the most common thing you're going to want an app for is to generate some configuration for a target, and potentially publishing some state relating to that configuration and/or target.</p> <p>To fast track this common case an example demonstrating how to build an app is baked into the <code>edabuilder</code> CLI tool. In this quickstart we'll use the baked in example of an app that configures the login banner on a device and walk you through the steps required to build the app from scratch, iterate on it during the development cycle, and then publish it to a custom Catalog so you can share it with others.</p> <p>Without further ado, let's get started by going into a directory where we want to create our project.</p> <ol> <li> <p>Create a new project</p> <p>We begin with initializing a new project that will contain our demo application that will configure the login banner on a device.</p> <p>To create a project, supply the application vendor<sup>1</sup> and the project name as an argument to the <code>edabuilder init</code> command:</p> <pre><code>edabuilder init --vendor community example &amp;&amp; cd example\n</code></pre> <p>You find yourself in the <code>example</code> directory that we just initialized with some top-level project files and directories scaffolded out for you.</p> </li> <li> <p>Create a Python virtual environment</p> <p>Now is a good time to create a Python virtual environment that we will use to get autocompletion, code formatting and linting for our application code.</p> <p>If you have <code>uv</code> installed like was suggested in the setting the dev environment section, you can just run:</p> <pre><code>uv sync\n</code></pre> <p>You are free to use any other means to create a venv.</p> </li> <li> <p>Create an app</p> <p>From the <code>./example</code> project directory, we proceed with creating a directory that will contain our EDA application.</p> <p>An important thing to note is that an application in EDA is a group that contains one or more of the following resources:</p> <ul> <li>config and/or state intents that declaratively describe the desired configuration and state of a target.</li> <li>operational workflows associated with this app</li> <li>dashboards</li> </ul> <p>Let's call our application - <code>banners</code> - since we will scaffold an app that provisions a login banner on the network devices.</p> <pre><code>edabuilder create app banners &amp;&amp; cd banners #(1)!\n</code></pre> <ol> <li> <p>Warning</p> <p>If your application name is more than one word, the name must be in a kebab-case format.</p> <p>In this example, the app name is simply <code>banners</code>, but if you wanted to name it \"my banners\", then you should've named it <code>my-banners</code>.</p> </li> </ol> <p>This step should generate the <code>banners</code> directory and change the current working directory to it. Inside the <code>banners</code> directory you will find the scaffolded layout of the application with no particular logic implemented yet.</p> </li> <li> <p>Create a resource</p> <p>At this stage, you would start writing the API types, code for your configuration and state intents, crafting alarms and creating the workflows and dashboards. But for the sake of this quickstart, we want to have something quick and easy, and let you build real things later once you've got the hang of it. For that, we have baked in the example Banner resource inside the <code>edabuilder</code> CLI tool to demonstrate the dev workflow using a real example.</p> <p>custom resource ~ intent</p> <p>We are often use the terms \"intent\" and \"custom resource\" interchangeably. Both mean the same thing: a declarative definition of the desired configuration or state object with an associated Python script that implements it<sup>2</sup>.</p> <p>With the <code>edabuilder create resource Banner</code> command, we will create the Banner resource, and when augmented with the <code>-d | --scaffold-demo</code> flag, it will also generate the scaffolding for the configuration and state scripts for the Banner resource.</p> <pre><code>edabuilder create resource Banner -d #(1)!\n</code></pre> <ol> <li> <p>Warning</p> <p>The resource name must be in a CamelCase format.</p> </li> </ol> <p>As a result of this command, you will find</p> <ul> <li>the API specification for the Banner and BannerState custom resources created in the <code>banners/api/v1alpha1</code> directory<sup>3</sup></li> <li>built out configuration and state resources (aka intents) with the corresponding scripts in the <code>intents/banner</code> and <code>intents/bannerstate</code> directories. Without the <code>-d</code> flag the resource will be created without scripts, which you can add later.</li> </ul> <p>We leave the app logic implementation details for a later deep dive. All we need to know for now, that an application that is capable of configuring banner message on the supported Network OSes has been scaffolded and we can deploy it onto the EDA cluster to see it in action.</p> </li> <li> <p>Deploy the app</p> <p>During the app development you would want to quickly test the changes you made to the app by deploying it to EDA cluster. Edabuilder comes with a one-shot command to do just that:</p> <pre><code>edabuilder deploy\n</code></pre> <p>The <code>deploy</code> command will package app components in an OCI container image, push it to the container registry deployed for you in the EDA cluster and install the app.</p> <p><code>deploy</code> command requirements</p> <ol> <li>The <code>kubectl</code> should be using the context that points to the EDA cluster for the operation to succeed.</li> <li>Your cluster should have a LoadBalancer implementation such that service of type <code>LoadBalancer</code> can be created with a reachable address.<sup>4</sup></li> </ol> </li> <li> <p>Try the app</p> <p>After deploying the development version of the app directly to the EDA cluster, you can try it out by creating an instance of the <code>Banner</code> resource via any of the EDA interfaces. Here are two of them:</p> EDA UIKubernetes API/kubectl <p>In the EDA UI you should see a new group menu named Banner appear in the list of the resources:</p> <p></p> <p>Selecting the Banner menu will take you to the list of instances of the <code>Banner</code> resource, where you can create a new instance of the resource and commit this transaction.</p> <p>To leverage the Kubernetes API one can create a custom resource in the YAML format like shown below:</p> <p>Resource:</p> <pre><code>apiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: demo-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf11\n  loginBanner: Hello EDA!\n</code></pre> <p>Apply:</p> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: demo-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf11\n  loginBanner: Hello EDA!\nEOF\n</code></pre> <p>Regardless of the interface you choose, the result of your actions should be a new instance of the <code>Banner</code> resource in the EDA cluster and the appropriate login banner configured on the targets matching your selection.</p> </li> </ol>"},{"location":"development/apps/quick-start/#what-just-happened","title":"What just happened?","text":"<p>Quite a lot! Here's a breakdown of what you just did:</p> <ol> <li>You initialized a new project.</li> <li>You created a new app.</li> <li>You created a new resource - Banner - with the generated scripts for the Banner and BannerState intents.</li> <li>You generated code-generated artifacts (OpenAPI schemas, CRDs, etc.) for your app.</li> <li>You deployed your app to your EDA cluster.</li> <li>You created an instance of your new resource via Kubernetes API or EDA UI.</li> <li>And observed the results of your app in action by logging into the SR Linux CLI and seeing a new login banner in effect.</li> </ol>"},{"location":"development/apps/quick-start/#where-to-from-here","title":"Where to from here?","text":"<p>First, get to know the project layout and the role of each directory and files they contain in the Project Layout section.</p> <p>Next, dive into the application components to learn what makes up an EDA app in the Components section.</p> <p>After that, you are ready to learn how the demo Banner app works. How it selects the nodes, generates the config snippets, creates resources in EDA cluster and so on. This is covered in the Banner script deep dive section.</p> <ol> <li> <p>A vendor is the publishing authority of your app. It can be an arbitrary string, but typically it matches your company name, personal name or a community name.\u00a0\u21a9</p> </li> <li> <p>The actual runtime used in EDA to run those scripts is MicroPython, but we will dive into these details in a later sections.\u00a0\u21a9</p> </li> <li> <p>In the <code>banner_types.go</code> and <code>bannerstate_types.go</code> files correspondingly. The path is provided from the root of the project's repository.\u00a0\u21a9</p> </li> <li> <p>If you cluster does not have a LoadBalancer service support, you can build and publish your app to an external registry and catalog. See Build and Publish for more details.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/setup-env/","title":"Setting up the dev environment","text":"<p>Before you start building an app, you'll need to prepare the development environment. This guide assumes you have EDA installed already and if you don't, you can quickly spin one up by following the Try EDA guide.</p> <p>Your primary tools when developing an app:</p> <ul> <li><code>edabuilder</code> for scaffolding, building, and publishing your app.</li> <li><code>go</code> sdk for authoring the API of your custom resources.</li> <li><code>python</code> runtime for getting syntax highlighting and IDE support when writing intents optional.</li> <li><code>kubectl</code> for creating resources.</li> <li><code>edactl</code> for verifying installation workflows and debugging.</li> </ul> <p>These tools are available for all major OSes and architectures, so you can develop on your preferred platform, no matter where you are.</p> <code>edabuilder</code><code>go</code><code>python</code><code>kubectl</code><code>edactl</code> <p><code>edabuilder</code> is a CLI tool that helps to scaffold a new EDA app, build the container for it and then publish the application to the catalog. The CLI can be downloaded from the GitHub repository as well as from the <code>eda-toolbox</code><sup>1</sup> Pod.</p> Download from GitHubDownload from eda-toolbox <p>Download the latest <code>edabuilder</code> binary from the GitHub repository directly, or leverage the downloader script that comes with the EDA Playground:</p> Run in the EDA Playground repository<pre><code>make download-edabuilder\n</code></pre> <p>This will download the <code>edabuilder</code> binary to the <code>./tools</code> directory in the EDA Playground repository. For convenience, you can move the binary somewhere to your <code>$PATH</code>.</p> <p>If you're developing on a linux/amd64 machine, you can get the <code>edabuilder</code> binary from the <code>eda-toolbox</code> Pod:</p> <pre><code>TOOLBOX_POD=$(kubectl get -n eda-system pod -l eda.nokia.com/app=eda-toolbox \\\n  -o jsonpath='{.items[0].metadata.name}')\nkubectl -n eda-system \\\ncp ${TOOLBOX_POD}:/eda/tools/edabuilder /usr/local/bin/edabuilder\nsudo chmod +x /usr/local/bin/edabuilder\n</code></pre> <p>We will define the API of our declarative apps exactly like in Kubernetes - by crafting the Go files that extend the API of the EDA core. For this, we need a Go SDK.</p> <p>Install Go SDK by following the upstream installation instructions.</p> <p>Note</p> <p>The minimum required Go version is <code>1.24.0</code>.</p> <p>While being optional, we recommend installing the Python runtime and initialize a virtual environment for development.</p> <p>If you already have a Python environment dialed in, you can skip this step, but if not, then the easiest way to get Python on your dev machine is by installing uv - a modern multiplatform Python distribution and package manager.</p> <p><code>kubectl</code> is the Kubernetes command-line tool. During development, you may find it easier to create resources with it, rather than venturing into the EDA UI.</p> <p>If you have completed the Try EDA step, then kubectl has already been downloaded for you and you can just copy it out to a permanent location in your <code>$PATH</code>.</p> <p><code>edactl</code> will help you query the EDA cluster and debug your application. You don't even need to download it directly, you can use an alias to run it from within the EDA cluster as explained in the CLI Tools guide.</p> <p>And now with these tools in your toolchest, you've got everything you need to start building your first app! Choose your preferred path, would you want to put the code to the compiler right away or want to beef up your knowledge on the matter?</p> <ul> <li> <p> Quick start</p> <p>Prefer to dive into a hands on example?</p> <p> Create your first app</p> </li> <li> <p> More reading?</p> <p>Thirsting for knowledge?</p> <p> Learn what makes up an app</p> </li> </ul> <ol> <li> <p><code>eda-toolbox</code> pod is by default deployed in the <code>eda-system</code> namespace.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/terminology/","title":"Terminology and concepts","text":"<p>Like any development environment, EDA has its own set of terminology and concepts that are useful to understand in order to build an app.</p>"},{"location":"development/apps/terminology/#projects","title":"Projects","text":"<p>Your initial starting point for building an app is a project. A project is a directory containing one or more app directories, and a collection of shared libraries that are used/lifecycled together for all apps in the project. You likely only need one project for your organization, but you may have more if you have different teams or different use cases. As a reference, Nokia has a single project for all of its apps.</p>"},{"location":"development/apps/terminology/#applications","title":"Applications","text":"<p>Within a project, you have one or more applications. Your packaging/distribution boundary is at the application level, NOT the project level. This means that you can have multiple applications in a single project, and each application can be versioned and distributed independently, all sharing a common set of libraries.</p>"},{"location":"development/apps/terminology/#manifest","title":"Manifest","text":"<p>Like a packing slip that describes the contents of a parcel, the application manifest describes what the application consists of and where to find all of its contents.</p>"},{"location":"development/apps/terminology/#application-build-context","title":"Application build context","text":"<p>The build context of an app is a location on your local file system. Combined with the build context, any relative path in an app's manifest should resolve to an actual file location.</p>"},{"location":"development/apps/terminology/#resources","title":"Resources","text":"<p>Resources are the core building blocks of an app. They are the inputs and outputs of your app, and are the primary way that users interact with your app. Resources can be of many types, but the most common are:</p>"},{"location":"development/apps/terminology/#catalog","title":"Catalog","text":"<p>A catalog can be any git repository that is structured in a way that the EDA store can parse it for published apps. Using <code>edabuilder publish</code> with a git repository makes sure it is always structured as such.</p>"},{"location":"development/apps/terminology/#registry","title":"Registry","text":"<p>A registry is a location where apps are stored. In EDA, the apps are stored as OCI artifacts (container images) and therefore any OCI-compliant registry can be used as a registry.</p>"},{"location":"development/apps/terminology/#eda-store","title":"EDA Store","text":"<p>EDA Store is software component within EDA core that manages the lifecycle of the EDA applications. Through EDA Store users add/delete apps, and manage associated catalogs and registries.</p>"},{"location":"development/apps/scripts/","title":"Scripts","text":"<p>Scripts (also often referred to as intents) are MicroPython code that is executed as a result of some external event. The simplest event is a user creating a resource with a script watching it.</p> <p>There exists three types of scripts:</p> <ul> <li><code>config</code></li> <li><code>state</code></li> <li><code>conversion</code></li> </ul> <p>Among these, <code>config</code> and <code>state</code> are the most common. <code>config</code> scripts execute inside Config Engine, and result in transactions to targets and Kubernetes describing intended configuration.</p> <p><code>state</code> scripts execute inside State Engine and are responsible for alarm generation, subscription and normalization of telemetry data, and publishing updates to the <code>status</code> field of resources, or the creation of state-only resources.</p> <p><code>conversion</code> scripts are run when a resource is converted from one version to another, i.e. only during upgrades and resource version translation.</p>"},{"location":"development/apps/scripts/banner-script/","title":"Banner Script Walkthrough","text":"<p>To better understand how script apps work, we invite you to walk through the demo Banner application that is bundled with EDABuilder CLI and was part of the quickstart guide.</p> <p>The Banner app has a very simple purpose: to provision a login banner on the supported targets by submitting an abstracted input. This is the task of the configuration component of the app. The state script of the Banner app simply lists the nodes that the Banner has been provisioned to.</p> <p>The simple scope of the app allows us to focus on the generic app development, rather than going into the weeds of the implementation logic.</p> <p>We are starting this walkthrough assuming you left off at the end of the quickstart guide, with the app named \"banners\" has been scaffolded with the Banner resource in it.</p>"},{"location":"development/apps/scripts/banner-script/#api","title":"API","text":"<p>Recall, that the \"banners\" application we created is meant to be a grouping for resources that make up the banners app. Each resource is an abstracted intent that is characterized by a set of inputs (spec) and outputs (status).</p> <p>During the scaffolding process we added the Banner resource to the \"banners\" application. This Banner resource is our abstracted intent that should be able to provision a login banner message on a list of target nodes based on the node selector.</p> <p>The starting point of the app development is defining the API surface of the resource to match the intent of the app. Application's API is defined in <code>.go</code> files following the kubebuilder pattern that is familiar to most K8s app developers.</p> <p>Let's have a look how <code>edabuilder</code> scaffolded the Banner resource API:</p> executed from the root of the example repo<pre><code>tree -L 2 banners/api\n</code></pre> <pre><code>banners/api\n\u2514\u2500\u2500 v1alpha1\n    \u251c\u2500\u2500 bannerstate_types.go\n    \u251c\u2500\u2500 banner_types.go\n    \u251c\u2500\u2500 groupversion_info.go\n    \u251c\u2500\u2500 pysrc\n    \u2514\u2500\u2500 zz_generated.deepcopy.go\n</code></pre> <p>We are focusing on the <code>banner_types.go</code> and <code>bannerstate_types.go</code> files, which defines the API surface of the Banner and BannerState resources.</p> <p>Banner and BannerState?</p> <p>Why the two resources you may ask? When in the quickstart we scaffolded the Banner resource and provided the <code>-d</code> flag to it, we got two types of resource:</p> <ol> <li><code>Banner</code> - the configuration type that defines the abstracted input for the configuration intent.</li> <li><code>BannerState</code> - the state type that defines the abstracted input for the state intent.</li> </ol> <p>These two resources are the two sides of the same coin. One is responsible for configuring the target based on the input, and the other one is responsible for gathering the state of the intent, generating alarms and populating the resource's status field with the relevant data.</p>"},{"location":"development/apps/scripts/banner-script/#configuration","title":"Configuration","text":"<p>Open up the <code>banner_types.go</code> file and you will see the following code:</p> <pre><code>// BannerSpec defines the desired state of Banner\ntype BannerSpec struct {\n    // List of nodes on which to configure the banners.\n    Nodes []string `json:\"nodes,omitempty\"`\n\n    // Labe selector to select nodes on which to configure the banners.\n    NodeSelector []string `json:\"nodeSelector,omitempty\"`\n\n    // This is the login banner displayed before a user has logged into the Node.\n    LoginBanner string `json:\"loginBanner,omitempty\"`\n}\n\n// BannerStatus defines the observed state of Banner\ntype BannerStatus struct {\n    // +eda:ui:title=\"Nodes\"\n    // List of nodes this banner has been applied to\n    Nodes []string `json:\"nodes,omitempty\"`\n}\n</code></pre> <p>The two Go types <code>BannerSpec</code> and <code>BannerStatus</code> define the specification and the status fields that our <code>Banner</code> resource should have. The fields in these two structure effectively describe the API surface of the Banner resource:</p> <pre><code>// Banner is the Schema for the banners API\ntype Banner struct {\n    metav1.TypeMeta   `json:\",inline\"` //(1)!\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec   BannerSpec   `json:\"spec,omitempty\"`\n    Status BannerStatus `json:\"status,omitempty\"`\n}\n</code></pre> <ol> <li><code>TypeMeta</code> and <code>ObjectMeta</code> fields are common to every k8s resource and implement the fields like <code>apiVersion</code>, <code>kind</code>, <code>namespace</code>, <code>labels</code> and so on.</li> </ol> What's with extra comments? <p>Did you notice the extra comments all around the types and type fields? These are annotations:</p> <pre><code>type BannerSpec struct {\n // +kubebuilder:validation:Optional\n // +eda:ui:columnspan=2\n // +eda:ui:orderpriority=100\n // +eda:ui:autocomplete=`{\"group\":\"core.eda.nokia.com\", \"version\":\"v1\", \"resource\":\"toponodes\"}`\n // +eda:ui:title=\"Nodes\"\n // List of nodes on which to configure the banners.\n Nodes []string `json:\"nodes,omitempty\"`\n</code></pre> <p>These are important parts of the API as with annotations we define validation rules, UI behavior and other aspects of the application. The annotations are covered in their own documentation section.</p> <p>Looking again at the <code>BannerSpec</code> type, we can clearly see what the app is supposed to do:</p> <ol> <li>The <code>Nodes</code> field is a list of string values that will accept target node names to which the login banner should apply.</li> <li>The <code>NodeSelector</code> is a list of string values where each element is a valid label selector. With this field we extend our Banner API to not only work on exact target node names, but on a dynamic set of nodes based on their labels.</li> <li>And the last element of the spec is the <code>LoginBanner</code> string - simply a message that will be displayed at login time.</li> </ol> <p>The <code>BannerStatus</code> is rather simple, both in implementation and the desired behavior:</p> <pre><code>// BannerStatus defines the observed state of Banner\ntype BannerStatus struct {\n    // List of nodes this banner has been applied to\n    Nodes []string `json:\"nodes,omitempty\"`\n}\n</code></pre> <p>With the above we say that the Banner's status container will only have one field - <code>Nodes</code> - that is a list of node names this banner has been applied to.</p> <p>Combining the spec, status and the common metadata fields, our API can be used with a resource defined in YAML format like this:</p> <pre><code>apiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: example-banner\n  namespace: eda\nspec:\n  nodeSelector:\n    - eda.nokia.com/role=leaf\n  loginBanner: Hello EDA!\n</code></pre>"},{"location":"development/apps/scripts/banner-script/#state","title":"State","text":"<p>Besides the <code>Banner</code> resource, we have the <code>BannerState</code> resource that serves a trigger to the state script of our app. The concept of the configuration and state scripts being triggered by the Banner and BannerState resources respectively is a core concept of the EDA framework that might be new to you.</p> <p>The reason the state script is triggered by its own resource is based on the high scalability aspect and the separation of concerns between the configuration and state scripts.</p> <p>In case of the <code>BannerState</code> resource, the API is very simple - it only has a single <code>Nodes</code> field. This field defines a list of node names this banner has been applied to.</p> <pre><code>// BannerStateSpec defines the desired state of BannerState\ntype BannerStateSpec struct {\n    // List of TopoNodes this login banner has been applied to\n    Nodes []string `json:\"nodes,omitempty\"`\n}\n\n// BannerStateStatus defines the observed state of BannerState\ntype BannerStateStatus struct {\n}\n\n// BannerState is the Schema for the bannerstates API\ntype BannerState struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec   BannerStateSpec   `json:\"spec,omitempty\"`\n    Status BannerStateStatus `json:\"status,omitempty\"`\n}\n</code></pre> <p>We will see later how the configuration and state scripts make use of the API we defined for both <code>Banner</code> and <code>BannerState</code> resources.</p>"},{"location":"development/apps/scripts/banner-script/#config-script","title":"Config script","text":"<p>It is time to have a look at the actual application code of the configuration script that uses the API we discussed above and implements the intent of the app.</p> <p>Both config and state intents are located in the <code>./&lt;app-name&gt;/intents</code> directory. In particular, the listing of the configuration script directory is as follows:</p> <pre><code>tree banners/intents/banner\n</code></pre> <pre><code>banners/intents/banner\n\u251c\u2500\u2500 config_intent.py\n\u251c\u2500\u2500 handlers.py\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 init.py\n\u251c\u2500\u2500 srl.py\n\u2514\u2500\u2500 sros.py\n</code></pre> <ul> <li><code>config_intent.py</code> - the main entrypoint of the configuration script.</li> <li><code>handlers.py</code> - contains the logic to select the particular vendor implementation for the configuration task.</li> <li><code>srl.py</code> - contains the logic of the configuration script for Nokia SR Linux.</li> <li><code>sros.py</code> - contains the logic of the configuration script for Nokia SR OS.</li> </ul>"},{"location":"development/apps/scripts/banner-script/#entrypoint","title":"Entrypoint","text":"<p>When you create an instance of the Banner resource, it triggers the execution of the config script, and the entrypoint for the script is the <code>process_cr</code> function in the <code>banners/intents/banner/config_intent.py</code> file:</p> <pre><code>def process_cr(cr):\n</code></pre> <p>The entrypoint function takes in a custom resource (cr) in form of a dictionary. The dictionary's content is a raw representation of the Banner resource as user submitted it to EDA.</p> <p>For example, if you commit a Banner resource in the following form, you get the respective dictionary:</p> Banner resourcedictionary input <pre><code>apiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: example-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf11\n  loginBanner: Hello EDA!\n</code></pre> <pre><code>{\n    \"metadata\": {\n        \"name\": \"example-banner\",\n        \"namespace\": \"eda\"\n    },\n    \"kind\": \"Banner\",\n    \"spec\": {\n        \"loginBanner\": \"Hello EDA!\",\n        \"nodes\": [\n            \"leaf11\"\n        ]\n    }\n}\n</code></pre>"},{"location":"development/apps/scripts/banner-script/#initialization-and-validation","title":"Initialization and Validation","text":"<p>After receiving the input to the entrypoint function, we can create an instance of the Banner class:</p> <pre><code>from banners.api.v1alpha1.pysrc.banner import Banner\nfrom utils.log import log_msg\n\ndef process_cr(cr):\n    \"\"\"Process Banner CR.\"\"\"\n    log_msg(\"Banner CR:\", dict=cr)\n    cr_obj = Banner.from_input(cr)\n    if cr_obj is None:\n        return\n\n    cr_name = cr_obj.metadata.name\n</code></pre> <p>EDABuilder generates the python classes, such as <code>Banner</code>, from the API schema we defined. The python classes are stored in the <code>banners.api.v1alpha1.pysrc</code> python package and a class has a method <code>from_input</code> that creates an instance of the class from the raw input dictionary. We store that instance in the <code>cr_obj</code> variable.</p> <p>When the object is created we can validate it and initialized some defaults if needed:</p> <pre><code>from banners.intents.banner.init import init_globals_defaults, validate\n\ndef process_cr(cr):\n# continuation of the process_cr function\n    validate(cr_obj)\n    init_globals_defaults(cr_obj)\n</code></pre> <p>In the Banner's case, these two functions are merely placeholder.</p>"},{"location":"development/apps/scripts/banner-script/#selecting-targets","title":"Selecting targets","text":"<p>The script progresses to its next logical step: selecting targets. Almost all configuration scripts will have a piece of their logic dedicated to selecting the nodes to apply config to.</p> <p>If you remember, the Banner's resource API provides two options how the targets can be selected by the user:</p> <ol> <li>selecting the targets based on the provided list of names</li> <li>selecting the targets based on the provided label selectors</li> </ol> <p>EDA API provides convenience functions to support both methods of node selection, and since our API allows both, we have implementations for both:</p> <pre><code>import utils.exceptions as e\nimport utils.node_utils as nutils\n\ndef process_cr(cr):\n# continuation of the process_cr function\n    nodes = {}\n\n    if cr_obj.spec.nodeSelector is not None and len(cr_obj.spec.nodeSelector) &gt; 0:\n        log_msg(\"Filtering nodes with node selectors:\", dict=cr_obj.spec.nodeSelector)\n        for node_cr in nutils.list_nodes(filter=[], label_filter=cr_obj.spec.nodeSelector):\n            node_name = node_cr[\"metadata\"][\"name\"]\n            nodes[node_name] = node_cr\n            log_msg(\"Found node:\", dict=node_name)\n\n    if cr_obj.spec.nodes is not None and len(cr_obj.spec.nodes) &gt; 0:\n        for node in cr_obj.spec.nodes:\n            if node not in nodes:\n                node_cr = nutils.get_node(name=node)\n                if node_cr is None:\n                    msg = f\"Node {node} not found\"\n                    raise e.InvalidInput(msg)\n                nodes[node] = node_cr\n</code></pre> <p>Using the <code>list_node</code> and <code>get_node</code> functions from the <code>utils.node_utils</code> package we can get a list of nodes for a selector or a single node by its name. We store the list of Node objects in the <code>nodes</code> variable.</p> <p>Once we have all nodes fetched, it is time to perform configuration action on them.</p>"},{"location":"development/apps/scripts/banner-script/#multivendor-handlers","title":"Multivendor handlers","text":"<p>Regardless if we provided the nodes by name or by selectors, the node list may include Network OSes from different vendors. In the case of the Try EDA topology we have Nokia SR Linux and Nokia SR OS nodes, which are two very distinct operating systems. Yet, our Banner resource should be applied to all supported nodes, how does it work?</p> <p>The answer lies in the NOS-specific handlers that each app implements individually. Let's look at the code block that follows the node selection:</p> <pre><code>from banners.intents.banner.handlers import get_config_handler\nfrom common.constants import PLATFORM_SRL, PLATFORM_SROS\n\ndef process_cr(cr):\n# continuation of the process_cr function\n\n    for node, node_cr in nodes.items():\n        if node_cr is not None:\n            node_spec = node_cr[\"spec\"]\n            if node_spec.get(\"operatingSystem\", None) is not None:\n                if node_spec.get(\"operatingSystem\") == PLATFORM_SRL:\n                    srl_handler = get_config_handler(PLATFORM_SRL)\n                    if srl_handler is not None:\n                        srl_handler.handle_cr(cr_obj, node_cr)\n                elif node_spec.get(\"operatingSystem\") == PLATFORM_SROS:\n                    sros_handler = get_config_handler(PLATFORM_SROS)\n                    if sros_handler is not None:\n                        sros_handler.handle_cr(cr_obj, node_cr)\n                else:\n                    msg = f\"Operating system unsupported for {node}, os is {node_spec.get('operatingSystem', None)}\"\n                    raise e.InvalidInput(msg)\n            else:\n                msg = f\"Operating system unsupported for {node}, os is {node_spec.get('operatingSystem', None)}\"\n                raise e.InvalidInput(msg)\n</code></pre> <p>Here, the nodes we iterate on are the <code>TopoNode</code> objects from the <code>core.eda.nokia.com</code> API group. Based on the <code>operatingSystem</code> value in the TopoNode spec, the code selects either SR Linux or SR OS handler.</p> <p>The handler-selection function is quite simple:</p> banners/intents/banner/handlers.py<pre><code>from common.constants import PLATFORM_SRL, PLATFORM_SROS\nfrom .srl import SrlBaseConfigHandler\nfrom .sros import SrosBaseConfigHandler\n\n_config_handlers = {\n    f\"{PLATFORM_SRL}\": SrlBaseConfigHandler(),\n    f\"{PLATFORM_SROS}\": SrosBaseConfigHandler(),\n}\n\n\ndef get_config_handler(os) -&gt; SrlBaseConfigHandler | SrosBaseConfigHandler | None:\n    return _config_handlers.get(os)  # pragma: no cover\n</code></pre> <p>The corresponding handler class is typically stored in its own file - <code>banners/intents/banner/srl.py|sros.py</code> - and this class implements translation of the abstracted vendor-agnostic intent to the node-specific configuration.</p>"},{"location":"development/apps/scripts/banner-script/#node-specific-config","title":"Node-specific config","text":"<p>Now that we know how different handlers are instantiated, let's have a look again at how they are being used:</p> <pre><code>def process_cr(cr):\n# continuation of the process_cr function\n\n    for node, node_cr in nodes.items():\n        if node_cr is not None:\n            node_spec = node_cr[\"spec\"]\n            if node_spec.get(\"operatingSystem\", None) is not None:\n                if node_spec.get(\"operatingSystem\") == PLATFORM_SRL:\n                    srl_handler = get_config_handler(PLATFORM_SRL)\n                    if srl_handler is not None:\n                        srl_handler.handle_cr(cr_obj, node_cr)\n                elif node_spec.get(\"operatingSystem\") == PLATFORM_SROS:\n                    sros_handler = get_config_handler(PLATFORM_SROS)\n                    if sros_handler is not None:\n                        sros_handler.handle_cr(cr_obj, node_cr)\n</code></pre> <p>Based on the <code>operatingSystem</code> field in the node CR, the appropriate handler is instantiated and the <code>handle_cr</code> method is called with the Banner instance and the TopoNode passed as arguments. At this point, we pass the abstracted, high-level Banner intent, and we expect that the appropriate handler will turn this into the node-specific config.</p> <p>Here is how the implementation of the SR Linux handler class:</p> <pre><code>class SrlBaseConfigHandler:\n    def handle_cr(self, cr_obj: Banner, node_cr=None):\n        configs = []\n        log_msg(f\"cr_obj: {cr_obj}\")\n        log_msg(f\"node_cr: {node_cr}\")\n        node_name = node_cr[Y_METADATA][Y_NAME]\n        self._generate_config(cr_obj, configs)\n        eda.update_cr(\n            schema=s.CONFIG_SCHEMA,\n            name=f\"banner-{cr_obj.metadata.name}-{node_name}\",\n            spec={\"node-endpoint\": node_name, \"configs\": configs},\n        )\n\n    def _generate_config(self, cr_obj: Banner, configs: list):\n        _config = {}\n        if cr_obj.spec.loginBanner is not None:\n            _config[\"login-banner\"] = cr_obj.spec.loginBanner\n\n        configs.append(\n            {\n                \"path\": \".system.banner\",\n                \"config\": json.dumps(_config),\n                \"operation\": \"Create\",\n            },\n        )\n</code></pre> <p>We focus on the <code>handle_cr</code> method that receives the Banner and the TopoNode resources. The high-level operation of any handler function would look like this:</p> <ol> <li>Receive the abstracted intent</li> <li>Process the received abstracted intent and emit sub resource(s)<ol> <li>The sub resource may be any sub resource registered within EDA, for example the Fabric application may emit BridgeDomain, ISL and so on.</li> <li>For simple apps that can translate the abstracted intent directly into the node configuration, they emit <code>NodeConfig</code> resource that Config Engine provisions on the nodes via NPPs.</li> </ol> </li> <li>Create the state intent to trigger the state processing.</li> </ol> <p>Looking more closely at the <code>handle_cr</code> of our Banner script we can spot that it follows this pattern to the dot and generates the <code>NodeConfig</code> resource as part of its operation.</p> <p>With <code>eda.update_cr</code> method we create a <code>NodeConfig</code> resource in EDA by providing the schema of the NodeConfig resource and its specification:</p> <pre><code>eda.update_cr(\n    schema=s.CONFIG_SCHEMA, #(1)!\n    name=f\"banner-{cr_obj.metadata.name}-{node_name}\",\n    spec={\"node-endpoint\": node_name, \"configs\": configs},\n)\n</code></pre> <ol> <li><code>schema=s.CONFIG_SCHEMA</code> - the schema of the <code>NodeConfig</code> resource</li> </ol> <p>The specification of the <code>NodeConfig</code> gets the node-endpoint which is the node name fetched from the <code>node_cr</code> variable and the <code>configs</code> which is the list of configurations generated in the <code>_generate_config</code> method.</p> <p>The same process is followed by the SR OS handler, which you will find in the <code>sros.py</code>.</p> <p>Ultimately, even if an application script does not directly generate the <code>NodeConfig</code> resource, the emitted sub-resources will eventually resolve to the <code>NodeConfig</code> instances and this is how EDA unwraps the high level abstract intent to an actual node-level implementation.</p>"},{"location":"development/apps/scripts/banner-script/#creating-state-resource","title":"Creating state resource","text":"<p>At the very end of the <code>banners/intents/banner/config_intent.py</code> script you will find a peculiar code piece:</p> <pre><code>eda.update_cr(\n    schema=BANNERSTATE_SCHEMA,\n    name=cr_name,\n    spec={\n        \"nodes\": list(nodes.keys()),\n    },\n)\n</code></pre> <p>This is how the configuration intent triggers the state intent run - it creates the <code>BannerState</code> resource for this. As we just defined the API specification of the <code>BannerState</code> resource ourselves, we know that the <code>BannerState</code> specification receives a list of nodes to which we provisioned the login banner.</p> <p>In the same spirit as with the configuration script, the corresponding state script will be triggered based on the fact that the <code>BannerState</code> resource appeared in the system.</p>"},{"location":"development/apps/scripts/banner-script/#state-script","title":"State script","text":"<p>State scripts are executed in the State Engine component and are triggered by the corresponding state resource. State scripts are meant to be used to achieve the following:</p> <ol> <li>Compute the state for the corresponding abstracted resource</li> <li>Generate alarms for the resource</li> </ol> <p>State script is not a mandatory app component, but you will find that most applications have one.</p> <p>Our Banner application has a state script and you can find it in the <code>bannerstate</code> directory:</p> <pre><code>tree banners/intents/bannerstate \n</code></pre> <pre><code>banners/intents/bannerstate\n\u251c\u2500\u2500 eda.py\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 init.py\n\u251c\u2500\u2500 state_handlers.py\n\u2514\u2500\u2500 state_intent.py\n</code></pre> <p>The entrypoint for the state script is, like in the config script case, implemented as the <code>process_cr</code> function found in the <code>state_intent.py</code> file. It takes in the customer resource input:</p> <pre><code>def process_state_cr(cr):\n    log_msg(\"BannerState CR:\", dict=cr)\n    cr_obj = BannerState.from_input(cr)\n    validate(cr_obj)\n    init_globals_defaults(cr_obj)\n    handler = get_state_handler(PLATFORM_EDA)\n    handler.handle_cr(cr_obj)\n</code></pre> <p>In contrast with the config intent, the state script does not have require different NOS-specific handlers, instead a single EDA handler is used.</p> <p>The handler does a trivial task of updating the status field of the <code>Banner</code> resource:</p> <pre><code>class EdaStateHandler:\n    def handle_cr(self, cr_obj: BannerState):\n        nodes = cr_obj.spec.nodes\n        eda.update_cr(\n            schema=BANNER_SCHEMA,\n            name=cr_obj.metadata.name,\n            status={\n                Y_NODES: nodes,\n            },\n        )\n</code></pre> <p>It is worth reiterating, that the state script does not target the state BannerState resource, but updates the status field of the configuration - <code>Banner</code> - resource. It is somewhat and indirect way of populating the status field of the Banner resource and is done in that way to achieve high scale.</p> <p>Technically, the <code>Banner</code> resource does not need a state script at all, as we could've updated its status directly from the config script, but this is done to demonstrate how state scripts work when you start writing applications that compute some more elaborated state.</p>"},{"location":"development/apps/scripts/config/","title":"Configuration scripts","text":"<p>Configuration scripts execute in Config Engine, and are deterministic, run-to-completion logic that is responsible for deriving the set of configurations to push to targets. Scripts can do this by either creating any other resource (like the script in the <code>Fabric</code> app creates VNET resource and so on), or by directly emitting <code>NodeConfig</code> resources - being the lowest level resource that is pushed to a target.</p> <p>Due to executing in Config Engine, configuration scripts are limited to the following libraries available in its runtime:</p> <ul> <li><code>eda_common</code></li> <li><code>eda_config</code>, for interacting with allocation pools (resources)</li> </ul>"},{"location":"development/apps/scripts/config/#triggering-scripts","title":"Triggering scripts","text":"<p>A configuration script is attached to a particular resource via the applications <code>manifest.yaml</code>:</p> snippet of the Banner app manifest<pre><code>apiVersion: core.eda.nokia.com/v1\nkind: Manifest\nmetadata:\n  name: banners\nspec:\n  components:\n    - crd:\n        api:\n          expose: readWrite\n        path: banners/crds/banners.eda.local_banners.yaml\n        schema: banners/openapiv3/eda_oas_banners.eda.local_banners.json\n        ui:\n          category: Banner\n          name: Banner\n    - script:\n        path: banners/intents/banner/config_intent.py\n        trigger:\n          kind: Banner\n        type: config\n</code></pre> <p>The manifest presented above results in the logic contained in <code>banners/intents/banner/config_intent.py</code> script being run whenever a <code>Banner</code> resource is created or updated. The <code>Banner</code> resource is added to the EDA API via the <code>crd</code> component defined in the same manifest file.</p>"},{"location":"development/apps/scripts/config/#entrypoint","title":"Entrypoint","text":"<p>The entrypoint to a configuration script is the <code>process_cr</code> function, which is called by Config Engine with the resource object passed as a dictionary to the function.</p> <pre><code>def process_cr(cr):\n    \"\"\"Process Banner CR.\"\"\"\n    ...\n</code></pre> <p>The main task of a configuration script is to take this input dict which represents the declarative abstracted intent and either directly transform it to the node-specific configuration blob, or to emit sub-resources which will be processed by other scripts.</p> <p>The configuration script also emits the input for the state script and triggers its execution.</p>"},{"location":"development/apps/scripts/debugging/","title":"Debugging","text":"<p>Generic debugging capabilities first introduced in 25.4.1</p> <p>EDA script apps run in a remote execution environment (config or state engine, depending on the script type) and this makes the usual debugging techniques not easy to apply. Adding <code>print</code> statements to the script files and fish for a printed message in a potentially very crowded stream of logs messages is not a great developer experience.</p> <p>Yet, it is crucial to give developers a way to introspect the data their scripts operate on or produce. And EDA has a built-in mechanism to help with that.</p>"},{"location":"development/apps/scripts/debugging/#edactl-debug","title":"<code>edactl</code> debug","text":"<p>If you look at the demo <code>banners</code> application scaffolded by <code>edabuilder</code>, you will notice that both configuration and state scripts<sup>1</sup> have the <code>log_msg</code><sup>2</sup> function; it is used to log debug messages in such a way that can be intercepted by the <code>edactl</code> tool and printed out for you on demand. During the normal application operation no debug messages are being printed, they are only printed when a developer uses <code>edactl intent debug</code> command.</p> <p>To start debugging a state or a configuration script, use the following command:</p> <pre><code>edactl -n &lt;namespace&gt; intent [config | state] debug &lt;resource kind&gt;\n</code></pre> <p>Let's see how this debugging workflow works.</p>"},{"location":"development/apps/scripts/debugging/#logging-and-monitoring","title":"Logging and monitoring","text":"<p>To get us a clean start, let's remove any instances of the Banner resource from your cluster:</p> <pre><code>kubectl delete --all -A banners.banners.eda.local\n</code></pre> <p>We will start with a basic task of seeing what exactly happens within our Banner application when we create the Banner resource. We can use the <code>edactl intent config debug &lt;config resource kind&gt;</code> command to start monitoring the logs of this app.</p> <p>Split the shell in two panes, and start the debug monitor in the left pane:</p> <pre><code>edactl intent config debug banners\n</code></pre> <p>This starts a debug monitor for the configuration intent of the <code>banners</code> app. The associated intent script is going to run when we create the Banner resource that triggers the script to run in the config engine pod. Let's create one in the right panel:</p> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: demo-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf11\n  loginBanner: Hello EDA!\nEOF\n</code></pre> <p>Immediately after creating the Banner resource you should see the debug messages appear in the left pane:</p> <p>The debug monitor will show the <code>Input CR</code> that triggered the intent script to run as well as every <code>log_msg</code> function call. For instance, the following output that you find in the output:</p> <pre><code>Banner CR:\n{\"metadata\": {\"name\": \"demo-banner\", \"namespace\": \"eda\"}, \"kind\": \"Banner\", \"spec\": {\"loginBanner\": \"Hello EDA!\", \"nodes\": [\"leaf11\"]}}\n</code></pre> <p>comes from the <code>log_msg</code> function defined in the <code>config_intent.py</code> script of the Banner app:</p> <pre><code>from utils.log import log_msg\n\ndef process_cr(cr):\n    \"\"\"Process Banner CR.\"\"\"\n    log_msg(\"Banner CR:\", dict=cr) #(1)!\n</code></pre> <ol> <li>This log message is rudimentary, since the Input CR is printed by default by the debug monitor.</li> </ol> <p><code>log_msg</code></p> <p>The <code>log_msg</code> function has the following signature:</p> <pre><code>def log_msg(*msg, dict=None)\n</code></pre> <p>You can also see that the debug output outputs any Errors raised during the script execution, and we happen to have one in the script:</p> <pre><code>Error:\nTraceback (most recent call last):\n  File \"banners/intents/banner/config_intent.py\", line 40, in process_cr\n</code></pre> <p>Having a look at the line 40 in our <code>config_intent.py</code> file we can spot what raises that:</p> <pre><code>    if cr_obj.spec.nodes is not None and len(cr_obj.spec.nodes) &gt; 0:\n        for node in cr_obj.spec.nodes:\n            if node not in nodes:\n                node_cr = nutils.get_node(name=node)\n                if node_cr is None:\n                    msg = f\"Node {node} not found\"\n                    raise e.InvalidInput(msg) #(1)!\n</code></pre> <ol> <li>The error is raised using the utility module <code>import utils.exceptions as e</code> which has different classes for different types of errors.</li> </ol> <p>Since our input CR provided a node name in the <code>nodes</code> field of the spec, the script went up querying the TopoNode resources for the one with the name <code>leaf11</code>, but our topology does not have such a node. This raised an error and our script execution stopped. Thanks to <code>edactl intent debug</code> we can clearly find the error in the logs.</p> <p>Let's fix our typo in the node name by passing a corrected Banner resource that references the <code>leaf-1</code> node that we have in our topology:</p> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: demo-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf-1\n  loginBanner: Hello EDA!\nEOF\n</code></pre> <p>With the corrected resource our debug monitor shows that the script completes and displays the resources the script generated and written to the EDB:</p> <p>The config script for the Banner app generated two custom resources during its run:</p> <ol> <li><code>BannerState</code> resource to trigger the state script</li> <li><code>NodeConfig</code> resource that contains the configuration snippets for the nodes matching our node selection.</li> </ol> <p>Similarly, you can debug state scripts by changing the command to <code>edactl -n &lt;namespace&gt; intent state debug &lt;state resource kind&gt;</code></p>"},{"location":"development/apps/scripts/debugging/#triggering-your-resource","title":"Triggering your resource","text":"<p>In the previous section we triggered the configuration script execution by creating or changing the <code>Banner</code> resource. But during the development cycle it is not convenient to delete+add or modify the resource whenever you want the config or state script to run.</p> <p>To assist with this workflow, the <code>debug</code> subcommand is equipped with the <code>--trigger | -t</code> flag that can be used to trigger the associated script to run as if the resource was created or changed. Here is a demonstration of this in action.</p> <p>If we were to start the debug monitor for the bannerstate resource just like before, we would not see anything in the output, because the BannerState resource has been created once the config script finished execution.</p> <pre><code>edactl -n eda intent state debug bannerstate\nMatched 1 instances in namespace eda\n</code></pre> <p>If we want to run our state script again without republishing BannerState CR, we could add the <code>-t</code> flag to the command, and this would trigger the script execution with the same BannerState CR passed to it as was recorded before:</p> <pre><code>edactl -n eda intent state debug bannerstate -t\n</code></pre> <pre><code>Matched 1 instances in namespace eda\nTriggered 1 instances\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 eda BannerState/v1alpha1/BannerState demo-banner \u2500\u2500\u2500\nInputCR:\n    {\n      \"kind\": \"BannerState\",\n      \"metadata\": {\n        \"name\": \"demo-banner\",\n        \"namespace\": \"eda\"\n      },\n      \"spec\": {\n        \"nodes\": [\n          \"leaf-1\"\n        ]\n      }\n    }\nStdout:\nBannerState CR:\n{\"kind\": \"BannerState\", \"metadata\": {\"name\": \"demo-banner\", \"namespace\": \"eda\"}, \"spec\": {\"nodes\": [\"leaf-1\"]}}\n\nInputDb:\nOutputDb:\n  .namespace{.name==\"eda\"}.resources.cr-status.banners_eda_local.v1alpha1.banner{.name==\"demo-banner\"}\n    -&gt; {\"apiVersion\":\"banners.eda.local/v1alpha1\",\"kind\":\"Banner\",\"metadata\":{\"name\":\"demo-banner\"},\"status\":{\"nodes\":[\"leaf-1\"]}}\nSubscriptions:\n</code></pre> <p>The trigger flag can be added to both config and state intents.</p> <ol> <li> <p>You will find them by the following paths:</p> <ul> <li><code>banners/intents/banner/config_intent.py</code></li> <li><code>banners/intents/bannerstate/state_intent.py</code></li> </ul> <p>\u21a9</p> </li> <li> <p>imported with <code>from utils.log import log_msg</code> \u21a9</p> </li> </ol>"},{"location":"development/apps/scripts/state/","title":"State scripts","text":"<p>State scripts enable EDA's unique ability to provide and act on the state of abstracted resources. They are being executed inside State Engine and are responsible for alarm generation, subscription and normalization of telemetry data, and publishing updates to the status field of resources, or the creation of state-only resources.</p> <p>State scripts perform more work than just providing the state of a declarative abstracted intent. It adds operational capabilities to the EDA platform in a broad sense.</p>"},{"location":"development/apps/scripts/state/#triggering-scripts","title":"Triggering scripts","text":"<p>A state script is attached to a particular resource via the applications <code>manifest.yaml</code> exactly the same way as configuration script:</p> snippet of the Banner app manifest<pre><code>apiVersion: core.eda.nokia.com/v1\nkind: Manifest\nmetadata:\n  name: banners\nspec:\n  components:\n    - crd:\n        path: banners/crds/banners.eda.local_bannerstates.yaml\n        schema: banners/openapiv3/eda_oas_banners.eda.local_bannerstates.json\n    - script:\n        path: banners/intents/bannerstate/state_intent.py\n        trigger:\n          kind: BannerState\n        type: state\n</code></pre> <p>The manifest presented above results in the logic contained in <code>banners/intents/bannerstate/state_intent.py</code> script being run whenever a <code>BannerState</code> resource is created or updated. The <code>BannerState</code> resource is added to the EDA API via the <code>crd</code> component defined in the same manifest file.</p> <p>The state-related custom resource (<code>BannerState</code> in the example above) is typically created by the configuration script attached to the resource it represents.</p>"},{"location":"development/apps/scripts/state/#entrypoint","title":"Entrypoint","text":"<p>Again, similar to configuration scripts, the entrypoint to a state script is the <code>process_state_cr</code> function, which is called by State Engine with the state resource object passed as a dictionary to the function.</p> <pre><code>def process_state_cr(cr):\n    \"\"\"Process Banner State CR.\"\"\"\n    ...\n</code></pre> <p>The state script then can:</p> <ul> <li>query the EDA in-memory database (EDB) for more state information using <code>eda_state.list_db</code> method</li> <li>update the EDB using <code>eda_state.update_db</code> method</li> <li>generate alarms using <code>eda_state.update_alarm</code> method when thresholds are crossed</li> <li>normalize paths and present the state data in a vendor-agnostic way</li> </ul>"},{"location":"development/terraform/","title":"Terraform","text":"<p> Nokia EDA Providers Reference \u00b7 Beta release</p> <p>Terraform is open-source infrastructure as code software that allows users to define resources in human-readable configuration files, which can be versioned, reused, and shared.</p> <p>Terraform can manage low-level components such as compute, storage, and networking resources, as well as high-level components like DNS entries and SaaS features. In the context of Nokia EDA, Terraform is used to declaratively manage EDA Resources<sup>1</sup> by defining them in Terraform files and applying them to the EDA cluster using providers from Nokia.</p>"},{"location":"development/terraform/#terraform-providers-for-eda","title":"Terraform Providers for EDA","text":"<p>Terraform creates and manages resources on cloud platforms and other services through their application programming interfaces (APIs). Providers enable Terraform to interact with virtually any platform or service that exposes an API.</p> <p>In the diagram above, the Nokia EDA API server represents the Target API, and the Terraform providers published by Nokia are used by Terraform to interface with it.</p> <p>Nokia EDA offers unprecedented extensibility, allowing users to install EDA applications at any time. As a result, its API surface is highly dynamic and extensible. Rather than a single Terraform provider for EDA, each EDA application has its own standalone provider. Terraform users install providers for each EDA application they wish to manage, specifying the desired API version.</p> <p>The Terraform providers for EDA are open sourced and published under the nokia-eda namespace in the Terraform registry.</p>"},{"location":"development/terraform/#versions","title":"Versions","text":"<p>Providers include two types of versioning information:</p>  API Version  <p>This refers to the specific application API version for which the provider is built. In EDA, applications may have several API versions (e.g., <code>v1alpha1</code>, <code>v1</code>, <code>v2</code>, and so on). The provider's name will include the API version; for example, the interfaces-v1alpha1 provider is designed to be used with the Interfaces v1alpha1 API version.</p> <p>This means automation users should focus on the API version supported, rather than the installed application version.</p>  Provider Version  <p>This is the version of the Terraform provider itself, which is independent of the Application API version. It follows Semantic Versioning principles and indicates changes to the provider's functionality, compatibility, documentation, and more. The provider version is visible in the registry UI and in the Git repository where the provider's code is stored.</p> <p>In summary, for the provider with the name <code>interfaces-v1alpha1</code> and version <code>0.1.0</code>:</p> <ul> <li>the application this provider is built for is <code>Interfaces</code></li> <li>the Interfaces API version is <code>v1alpha1</code></li> <li>and the provider version is <code>0.1.0</code>.</li> </ul>"},{"location":"development/terraform/#installation","title":"Installation","text":"<p>To install the Terraform providers for Nokia EDA, add the required provider block to your Terraform file<sup>2</sup>:</p> providers.tf<pre><code>terraform {\n  required_providers {\n    interfaces-v1alpha1 = {\n      source  = \"nokia-eda/interfaces-v1alpha1\"\n      version = \"0.0.5\"\n    }\n  }\n}\n</code></pre> <p>The <code>version</code> can be omitted; Terraform will default to the latest version.</p> <p>When you have the <code>required_providers</code> block in place, the Terraform CLI will download the required provider binary when initializing a working directory. It can automatically download providers from a Terraform registry:</p> Terraform initOutput <pre><code>terraform init\n</code></pre> <pre><code>Initializing the backend...\nInitializing provider plugins...\n- Finding nokia-eda/interfaces-v1alpha1 versions matching \"0.0.5\"...\n- Installing nokia-eda/interfaces-v1alpha1 v0.0.5...\n- Installed nokia-eda/interfaces-v1alpha1 v0.0.5 (self-signed, key ID 6F5BC22CD9F83F19)\nPartner and community providers are signed by their developers.\nIf you'd like to know more about provider signing, you can read about it here:\nhttps://developer.hashicorp.com/terraform/cli/plugins/signing\nTerraform has created a lock file .terraform.lock.hcl to record the provider\nselections it made above. Include this file in your version control repository\nso that Terraform can guarantee to make the same selections by default when\nyou run \"terraform init\" in the future.\n\n\nTerraform has been successfully initialized!\n\nYou may now begin working with Terraform. Try running \"terraform plan\" to see\nany changes that are required for your infrastructure. All Terraform commands\nshould now work.\n\nIf you ever set or change modules or backend configuration for Terraform,\nrerun this command to reinitialize your working directory. If you forget, other\ncommands will detect it and remind you to do so if necessary.\n</code></pre>"},{"location":"development/terraform/#configuration","title":"Configuration","text":"<p>The provider needs to be configured with the proper credential information before it can be used. Provider configuration is typically defined in the same file as your provider specifications. For example, if you defined your provider in the <code>providers.tf</code> file above, you can add the provider configuration block there as well:</p> providers.tf<pre><code>terraform {\n  required_providers {\n    interfaces-v1alpha1 = {\n      source  = \"nokia-eda/interfaces-v1alpha1\"\n      version = \"0.1.0\"\n    }\n  }\n}\n\nprovider \"interfaces-v1alpha1\" {\n  # Configuration options\n}\n</code></pre>"},{"location":"development/terraform/#options","title":"Options","text":"<p>At a minimum, provider configuration<sup>3</sup> specifies the API server address and authentication parameters.</p>  Base URL  <p>With <code>base_url</code> provider configuration, users set the address of the EDA API server. This is the same address you use to access the EDA UI and includes the schema and port. For example: <code>https://eda-demo.test.io:9443</code>.</p>  Authentication options  <p>Terraform, like other non-browser-based API clients, uses the Resource Owner Password Credentials Grant OAuth flow for authentication. This flow requires the API client to provide the following parameters:</p>  EDA Client ID  <p>The <code>eda_client_id</code> is an identifier for your API client. It is used to authenticate your requests to the EDA API. By default EDA comes with a pre-created client id of <code>eda</code>. Administrators can create other clients.</p> <p>Default value: <code>eda</code>.</p>  EDA Client Secret  <p>The secret that is associated with the <code>eda_client_id</code>. Stored in Keycloak and can be retrieved by administrators and provided to the users of the API. Refer to the API documentation to see how to fetch the <code>eda_client_secret</code> using Keycloak UI.</p> <p>Warning</p> <p>If you omit the <code>eda_client_secret</code> parameter, the provider will try to fetch the secret by authenticating with the Keycloak service using <code>kc_*</code> variables that are set to their default values. While this might be tempting to use, this method is not recommended and should not be used in production.</p>  EDA Username and Password  <p>The API client - Terraform - should have credentials of the EDA user it authenticates as. This is done by providing the <code>eda_username</code> and <code>eda_password</code> parameters in the provider configuration.</p> <p>Default value for both is <code>admin</code> if not set.</p>  TLS Verification  <p>With <code>tls_skip_verify</code> boolean flag a user can select whether to verify the TLS certificate presented by EDA's API server or not.</p> <p>Default value: <code>false</code> (means validate certificate)</p> <p>With the mandatory options set, the provider configuration takes the following form:</p> snippet from providers.tf<pre><code>provider \"interfaces-v1alpha1\" {\n  base_url          = \"https://eda-demo.test.io:9443\"\n  eda_client_id     = \"eda\" # default value, can be omitted if not changed\n  eda_client_secret = \"your_client_secret\"\n  eda_username      = \"your_username\"\n  eda_password      = \"your_password\"\n}\n</code></pre>"},{"location":"development/terraform/#environment-variables","title":"Environment variables","text":"<p>All configuration variables that can be provided to the EDA providers have a matching environment variable. The below table summarizes all available options:</p> TF variable OS env variable Default Description base_url EDA_BASE_URL Base URL kc_username KC_USERNAME \"admin\" Keycloak Username kc_password KC_PASSWORD \"admin\" Keycloak Password kc_realm KC_REALM \"master\" Keycloak Realm kc_client_id KC_CLIENT_ID \"admin-cli\" Keycloak Client ID eda_username EDA_USERNAME \"admin\" EDA Username eda_password EDA_PASSWORD \"admin\" EDA Password eda_realm EDA_REALM \"eda\" EDA Realm eda_client_id EDA_CLIENT_ID \"eda\" EDA Client ID eda_client_secret EDA_CLIENT_SECRET EDA Client Secret tls_skip_verify TLS_SKIP_VERIFY false TLS skip verify rest_debug REST_DEBUG false REST Debug rest_timeout REST_TIMEOUT \"15s\" REST Timeout rest_retries REST_RETRIES 3 REST Retries rest_retry_interval REST_RETRY_INTERVAL \"5s\" REST Retry Interval"},{"location":"development/terraform/#bulk-installation","title":"Bulk Installation","text":"<p>If selecting and configuring providers in an a-la-carte manner feels like a cumbersome approach given they share the same config values, here is an all-you-can-eat buffet approach that lists a bunch of providers you can put in your <code>providers.tf</code> file and configure them all using variables:</p> Bulk install and configure example <pre><code>variable \"base_url\" {\n  default = \"https://eda-demo.test.io:9443\"\n}\n\nvariable \"eda_client_secret\" {\n  default = \"your_client_secret\"\n}\n\nvariable \"eda_username\" {\n  default = \"your_username\"\n}\n\nvariable \"eda_password\" {\n  default = \"your_password\"\n}\n\nterraform {\n  required_providers {\n    interfaces-v1alpha1 = {\n      source = \"nokia-eda/interfaces-v1alpha1\"\n    }\n    fabrics-v1alpha1 = {\n      source = \"nokia-eda/fabrics-v1alpha1\"\n    }\n    # add more providers here\n  }\n}\n\nprovider \"interfaces-v1alpha1\" {\n  base_url          = var.base_url\n  eda_client_secret = var.eda_client_secret\n  eda_username      = var.eda_username\n  eda_password      = var.eda_password\n}\n\nprovider \"fabrics-v1alpha1\" {\n  base_url          = var.base_url\n  eda_client_secret = var.eda_client_secret\n  eda_username      = var.eda_username\n  eda_password      = var.eda_password\n}\n\n# add more providers configs here if needed\n</code></pre>"},{"location":"development/terraform/#using-the-providers","title":"Using the Providers","text":"<p>With the providers configured a user can start managing their infrastructure in EDA using Terraform by defining the resources and data-sources that the providers expose.</p>"},{"location":"development/terraform/#resources","title":"Resources","text":"<p>Resources are the most important element in the Terraform language. Each resource block describes one or more infrastructure objects in general, and in EDA's case, these are the resources you create in EDA, such as an Interface, a Virtual Network, a Fabric, a User, etc.</p> <p>Each provider exposes its own set of resources and they are documented in the provider's documentation on Terraform registry, for example, here is a link to the list of resources provided by the Interfaces provider.</p> <p>The most obvious resource in the Interfaces app is the interface itself which, as the name suggests, allows users to manage Interface resources in EDA. The Terraform resources are modelled after the EDA resources, therefore it is very easy to map between the two, they are essentially the same.</p> <p>For example, let's compare what it takes to define an interface <code>ethernet-1/14</code> on <code>leaf1</code> using the Try EDA Playground from the Getting Started guide using EDA UI and Terraform:</p> EDA UITerraform <p>Navigating to the Topology \u2192 Interfaces in the left sidebar and creating a new interface with the following parameters:</p> <ul> <li>name: leaf1-ethernet-1-14</li> <li>namespace: eda</li> <li>enabled: true</li> <li>description: \"set via UI\"</li> <li>lldp: true</li> <li>encapType: 'null'</li> <li>members:<ul> <li>interface: ethernet-1-14</li> <li>node: leaf1</li> </ul> </li> </ul> <p>Would be represented like this in the UI:</p> <p>Now look what would be the equivalent Terraform configuration in the next tab.</p> <p>With terraform, the resources contain the same fields<sup>4</sup> and take in the same values as in the UI. Some may say \"obviously\", because at the end they use the same EDA API to create and manage the resources.</p> <p>Here is the definition of the same interface in the Hashicorp Configuration Language that Terraform uses:</p> <pre><code>resource \"interfaces-v1alpha1_interface\" \"leaf1-ethernet-1-14\" {\n  metadata = {\n    name      = \"leaf1-ethernet-1-14\"\n    namespace = \"eda\"\n  }\n  spec = {\n    enabled     = true\n    encap_type  = \"null\"\n    type        = \"interface\"\n    lldp        = true\n    description = \"set via Terraform\"\n    members = [{\n      enabled   = true\n      node      = \"leaf1\"\n      interface = \"ethernet-1-14\"\n    }]\n  }\n}\n</code></pre> <p>Warning</p> <p>Terraform style guide prescribes that the resource fields should be defined in <code>snake_case</code>, which is why you see <code>encap_type</code> instead of <code>encapType</code> as in the UI.</p> <p>Always consult the provider documentation for the exact field names.</p> <p>As shown in the Terraform tab above, the resources for the EDA applications are almost indistinguishable from the YAML representation you see in the EDA UI. One thing to note is that the Terraform resource omits the <code>apiVersion</code> and <code>kind</code> fields, because they are set by the provider already.</p>"},{"location":"development/terraform/#data-sources","title":"Data-sources","text":"<p>Data sources allow Terraform to use information defined outside of Terraform, defined by another separate Terraform configuration. Each provider exposes its own set of data-sources and they are documented in the provider's documentation on Terraform registry, for example, here is a link to the list of resources provided by the Interfaces provider.</p> <p>You will notice that the data-sources follow a particular pattern: a data-source ending with <code>_list</code> fetches multiple instances of a resource, while a data-source without it fetches a single instance. Here are some examples of how data sources can be used in different scenarios:</p> <pre><code># Get all interfaces.\ndata \"interfaces-v1alpha1_interface_list\" \"all\" {\n  namespace = \"eda\"\n}\n\n# Get all interfaces with label selector\ndata \"interfaces-v1alpha1_interface_list\" \"interswitch\" {\n  namespace     = \"eda\"\n  labelselector = \"eda.nokia.com/role=interSwitch\"\n}\n\n# Get a single interface by name\ndata \"interfaces-v1alpha1_interface\" \"leaf1_ethernet_1_1\" {\n  namespace = \"eda\"\n  name      = \"leaf1-ethernet-1-1\"\n}\n</code></pre>"},{"location":"development/terraform/#import","title":"Import","text":"<p>Terraform supports importing existing resources into your Terraform state. This is useful for managing resources that were created before you started to use Terraform or were created outside of Terraform. This is known as a brownfield deployment scenario.</p> <p>The import documentation covers various ways to import resources, including the generate configuration method that we show below to import a couple of existing interfaces into the <code>interfaces.tf</code> file<sup>5</sup>:</p> <pre><code>import {\n  to = interfaces-v1alpha1_interface.leaf1-ethernet-1-1\n  id = \"eda/leaf1-ethernet-1-1\"\n}\n\nimport {\n  to = interfaces-v1alpha1_interface.leaf2-ethernet-1-1\n  id = \"eda/leaf2-ethernet-1-1\"\n}\n</code></pre> <p>By adding these import statements to your module and running <code>terraform plan -generate-config-out=interfaces.tf</code>, Terraform will:</p> <ol> <li>Check the state file for the imported resources and proceed with fetching them if the state does not contain them.</li> <li>Reach out to the EDA API fetching the resources using the <code>.import.id</code> value defined.</li> <li>Create the <code>interfaces.tf</code> file where the imported resources will be written.</li> </ol> <p>After the successful import, you can remove the <code>import</code> blocks.</p> <p>The import ID is a unique identifier for the resource being imported. In EDA, this will typically be the resource's namespace and name, formatted as <code>namespace/name</code>.</p>"},{"location":"development/terraform/#issues-and-limitations","title":"Issues and Limitations","text":"<ol> <li>Workflows cannot be triggered via Terraform.</li> <li>Transaction-based operations are not supported yet. These operations, where resources are jointly committed via the Transaction API, are instead managed via REST API calls to the respective application endpoints, not through the Transaction API.</li> <li>Direct calls to application endpoints in the current release do not store node/resource diffs. Node diffs are only stored when using the Transaction API.</li> </ol> <ol> <li> <p>Such as interfaces, fabrics, virtual networks and so on.\u00a0\u21a9</p> </li> <li> <p>Often the providers configuration goes into the <code>providers.tf</code> file as per the style guide.\u00a0\u21a9</p> </li> <li> <p>Full list of options you can find in the providers documentation hosted on Terraform registry.\u00a0\u21a9</p> </li> <li> <p>But represented with <code>snake_case</code> instead of <code>camelCase</code>.\u00a0\u21a9</p> </li> <li> <p>The file must not exist before the <code>terraform plan</code> command is run.\u00a0\u21a9</p> </li> </ol>"},{"location":"digital-twin/","title":"Digital Twin","text":"<p>The key ingredient in a recipe for a reliable infrastructure automation is the rigorous testing of the changes before they are applied to the production environment. And when networks are concerned, the testing is better done in a controlled environment that resembles the production as closely as possible. This is where the Digital Twin feature of Nokia EDA comes into play.</p> <p>The Digital Twin provides scalable and flexible simulation platform for testing the changes in a controlled virtual environment, ensuring that your infrastructure remains stable and reliable.</p> <p>The component that implements the Digital Twin feature is called <code>eda-cx</code>, therefore, you may see us using the CX term when referring to the Digital Twin feature.</p> <p>If you completed the quickstart, you noticed that the small three-node network topology that the Try EDA cluster comes with is in fact powered by the Digital Twin feature. The <code>eda-cx</code> component is responsible for creating a virtual representation of the network, allowing you to test changes without affecting the production environment.</p> <p>EDA's Digital Twin packs a powerful set of distinctive and unique features that sets it apart from other network virtualization solutions:</p> <ul> <li>Scalability: The Digital Twin uses the Kubernetes platform to horizontally scale the simulation environment to match the size of your network. This means that you can deploy virtual topologies comprising hundreds of nodes and links, and the Digital Twin will schedule the nodes efficiently.</li> <li>Declarative API: As everything else in EDA, the Digital Twin operates in a declarative manner. The TopoNode and TopoLink resources that are used to define the physical topology of the network are also used to define the virtual topology in the Digital Twin. This means that you can use the same resources to define both the physical and virtual topologies, and the Digital Twin will automatically create the virtual representation of the network.</li> <li>Multivendor support: For every vendor device that is supported by EDA, there is a corresponding virtual simulator in the Digital Twin that you can use to create multivendor topologies.<sup>1</sup>.</li> </ul> <p>EDA's Digital Twin does not use Containerlab nor Clabernetes. It is a custom, production-grade virtual simulation engine that delivers support for massive scale and a tight integration with the EDA platform to achieve the goals of building the virtual replica of a production network. However, if you want to use EDA with a network topology that is built with Containerlab, you can do so by using the Containerlab integration.</p>"},{"location":"digital-twin/#digital-twin-mode","title":"Digital Twin Mode","text":"<p>When installing EDA software, users can choose if they want spin up the EDA cluster for Digital Twin or for the use with the hardware devices. By default, the cluster is deployed in the \"Digital Twin\" mode, where the virtual simulators are created for all the supported vendors based on the TopoNode and TopoLink resources that are defined in the EDA cluster.</p> <p>To deploy the cluster for production use, set the <code>SIMULATE=false</code> in the preferences file during the installation customization.</p> <p>Warning</p> <p>Once the EDA cluster is deployed, you can't change the mode of the cluster without redeploying it.</p> <p>To check what mode your EDA cluster is deployed in, you can use the command:</p> <pre><code>kubectl get -n eda-system engineconfig \\\n-o custom-columns=\"SIMULATE MODE:.spec.simulate\"\n</code></pre>"},{"location":"digital-twin/#creating-virtual-topologies","title":"Creating Virtual Topologies","text":"<p>One of the key responsibilities of the Digital Twin system is to create and manage the virtual topologies that typically represent a virtual network running network simulators and client endpoints. These networks are then managed by the EDA platform to mimic the behavior of the physical network and allow users to test and model the network changes, validate the designs, develop automation solutions and much more.</p> <p>In EDA, the network topology (be it physical or virtual) is defined by the <code>TopoNode</code> and <code>TopoLink</code> resources. As the names suggest, they represent the network devices and the connections between them, respectively. The Digital Twin uses these resources to create the virtual simulators and connect them together in a topology that matches the physical network.</p> Physical topology <p>In EDA, this topology is represented by the <code>TopoNode</code> and <code>TopoLink</code> objects mirroring the physical design:</p> Digital Twin topology <p>Check the  Topologies section for more information on how to create and manage the topologies in EDA.</p> <p>When a user deploys the topology onto the EDA cluster running in the Digital Twin mode, each TopoNode resource is backed by a virtual simulator instance<sup>2</sup> and each TopoLink resource is implemented as a datapath connection between the simulators or between a simulator and a testing endpoint.</p> <p>The Digital Twin uses the Kubernetes platform to create a deployment for each TopoNode resource, which in turn creates a pod that runs the virtual simulator and the datapath wiring component - CXDP. The simulators are scheduled on the EDA's Kubernetes cluster based on the resource requests Kubernetes scheduler. This ensures that the virtual topology can horizontally scale to match the size of the emulated network.</p>"},{"location":"digital-twin/#connecting-to-the-digital-twin-nodes","title":"Connecting to the Digital Twin Nodes","text":"<p>By the virtue of being Kubernetes-native, each simulator node in the Digital Twin is represented by a pod that runs the network OS and the datapath component. Therefore, you can connect and expose the simulator nodes using the standard Kubernetes tooling and methods.</p> <p>For long-term access to the simulated nodes an administrator might create a service and an ingress or loadbalancer resource. This typically requires some additional configuration and infrastructure setup, but achieves persistent access to the selected ports and protocols.</p> <p>Typically, though, users would want to connect with SSH to the simulator nodes to inspect the configuration, logs or run ad-hoc commands. Start with listing the TopoNodes in your namespace using <code>kubectl</code>. If you are running the Try EDA cluster, you can expect to see the three nodes in the output:</p> <pre><code>kubectl -n eda get toponodes \n</code></pre> <pre><code>NAME     PLATFORM       VERSION   OS    ONBOARDED   MODE     NPP         NODE     AGE\nleaf1    7220 IXR-D3L   25.3.2    srl   true        normal   Connected   Synced   99m\nleaf2    7220 IXR-D3L   25.3.2    srl   true        normal   Connected   Synced   99m\nspine1   7220 IXR-H2    25.3.2    srl   true        normal   Connected   Synced   99m\n</code></pre> <p>As we explained earlier, each TopoNode is backed by a Kubernetes deployment that runs the simulator. These deployments are spawned in the EDA core namespace (<code>eda-system</code> by default) and have the <code>eda.nokia.com/app-group=cx-cluster</code> label set:</p> <pre><code>kubectl -n eda-system get deploy -l eda.nokia.com/app-group=cx-cluster\n</code></pre> <pre><code>NAME                          READY   UP-TO-DATE   AVAILABLE   AGE\ncx-eda--leaf1-sim             1/1     1            1           3h32m\ncx-eda--leaf2-sim             1/1     1            1           3h32m\ncx-eda--spine1-sim            1/1     1            1           3h32m\ncx-eda--testman-default-sim   1/1     1            1           3h32m\n</code></pre> If you are running the Try EDA cluster, you will see the <code>testman</code> deployment as well. This is a special testing agent that we will cover in a later section. <p>As per the virtual topology that comes with the Try EDA cluster, we got three simulator deployments for leaf1, leaf2 and spine1 nodes. Using <code>kubectl</code> we can connect to the node's shell and execute the CLI process to get the CLI access:</p> <pre><code>kubectl --namespace eda-system exec -it \\\n$(kubectl --namespace eda-system get pods -l cx-pod-name=leaf1 \\\n-o=jsonpath='{.items[*].metadata.name}') \\\n-- bash -l -c 'sudo sr_cli'\n</code></pre> <pre><code>Defaulted container \"leaf1\" out of: leaf1, cxdp\nLoading environment configuration file(s): ['/etc/opt/srlinux/srlinux.rc']\nWelcome to the Nokia SR Linux CLI.\n\n--{ + running }--[  ]--\nA:root@leaf1#\n</code></pre> <p>But typing in this multiline command is a bit too much for a repetitive process, so here is a little script that you can put in your <code>$PATH</code> to quickly SSH to the desired node by its name:</p> <code>node-ssh</code> script to connect to a simulator node scriptadding to <code>$PATH</code> <pre><code>#!/bin/bash\n\n# Script to SSH into a specific node in the EDA topology\n# Usage: ./node-ssh &lt;node-name&gt; [&lt;user-namespace&gt;] [&lt;core-namespace&gt;]\n\n# provide the TopoNode name as the first argument\n# e.g. bash node-ssh.sh leaf1\nNODE_NAME=${1}\n\n# user namespace to look up the TopoNode in\n# default is eda\nUSER_NS=${2:-eda}\n\n# core namespace to cx pods in\n# default is eda\nCORE_NS=${3:-eda-system}\n\nfunction list_nodes() {\n  kubectl --namespace ${CORE_NS} get pods -l cx-cluster-name=eda \\\n  -o=jsonpath='{.items[*].metadata.labels.cx-pod-name}' | tr ' ' '\\n'\n}\n\nif [ -z \"${NODE_NAME}\" ]; then\n  echo \"Usage: $0 &lt;node-name&gt; [&lt;namespace&gt;]\"\n  echo \"  Available nodes are:\"\n  list_nodes | sed 's/^/    /'\n  exit 1\nfi\n\nNODE_ADDR=$(kubectl -n ${USER_NS} get targetnode \"${NODE_NAME}\" -o jsonpath='{.spec.address}')\nif [ -z \"${NODE_ADDR}\" ]; then\n  echo \"Node ${NODE_NAME} not found in namespace ${USER_NS}; available nodes are:\"\n  list_nodes | sed 's/^/    /'\n  exit 1\nfi\n\nUSERNAME=admin\n# SSH to the node from the eda-toolbox pod\nkubectl -n ${CORE_NS} exec -it \\\n  $(kubectl get -n ${CORE_NS} pods \\\n  -l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n  -- ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \\\n  -p 22 \"${USERNAME}@${NODE_ADDR}\" || {\n  echo \"Failed to SSH into node ${NODE_NAME} at ${NODE_ADDR}\"\n  exit 1\n}\n</code></pre> <p>You can paste this command in your terminal to add the script to <code>/usr/local/bin</code> directory, and make it executable:</p> <pre><code>cat &lt;&lt; 'EOF' | sudo tee /usr/local/bin/node-ssh\n#!/bin/bash\n\n# Script to SSH into a specific node in the EDA topology\n# Usage: ./node-ssh &lt;node-name&gt; [&lt;user-namespace&gt;] [&lt;core-namespace&gt;]\n\n# provide the TopoNode name as the first argument\n# e.g. bash node-ssh.sh leaf1\nNODE_NAME=${1}\n\n# user namespace to look up the TopoNode in\n# default is eda\nUSER_NS=${2:-eda}\n\n# core namespace to cx pods in\n# default is eda\nCORE_NS=${3:-eda-system}\n\nfunction list_nodes() {\n  kubectl --namespace ${CORE_NS} get pods -l cx-cluster-name=eda \\\n  -o=jsonpath='{.items[*].metadata.labels.cx-pod-name}' | tr ' ' '\\n'\n}\n\nif [ -z \"${NODE_NAME}\" ]; then\n  echo \"Usage: $0 &lt;node-name&gt; [&lt;namespace&gt;]\"\n  echo \"  Available nodes are:\"\n  list_nodes | sed 's/^/    /'\n  exit 1\nfi\n\nNODE_ADDR=$(kubectl -n ${USER_NS} get targetnode \"${NODE_NAME}\" -o jsonpath='{.spec.address}')\nif [ -z \"${NODE_ADDR}\" ]; then\n  echo \"Node ${NODE_NAME} not found in namespace ${USER_NS}; available nodes are:\"\n  list_nodes | sed 's/^/    /'\n  exit 1\nfi\n\nUSERNAME=admin\n# SSH to the node from the eda-toolbox pod\nkubectl -n ${CORE_NS} exec -it \\\n  $(kubectl get -n ${CORE_NS} pods \\\n  -l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n  -- ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \\\n  -p 22 \"${USERNAME}@${NODE_ADDR}\" || {\n  echo \"Failed to SSH into node ${NODE_NAME} at ${NODE_ADDR}\"\n  exit 1\n}\nEOF\nsudo chmod +x /usr/local/bin/node-ssh\n</code></pre> <p>With the script in place, you can connect to any node in your Digital Twin by its name:</p> <pre><code>node-ssh spine1\n</code></pre>"},{"location":"digital-twin/#configuring-simulator-resource-requests","title":"Configuring Simulator Resource Requests","text":"<p>When EDA CX component creates the virtual simulators in the Digital Twin, it creates a Kubernetes deployment for each simulator node in the topology. To guarantee that the simulators have enough resources to run under potentially high load, the deployments are configured with the resource requests for CPU and memory.</p> <p>For example, if you have the Try EDA cluster deployed, you can check the resource requests for the leaf1 simulator node with the command:</p> <pre><code>kubectl get pods -n eda-system -l cx-pod-name=leaf1 \\\n-o custom-columns=\"POD:.metadata.labels.cx-pod-name,\\\nCPU_REQUEST:.spec.containers[*].resources.requests.cpu,\\\nMEM_REQUEST:.spec.containers[*].resources.requests.memory\"\n</code></pre> <pre><code>POD     CPU_REQUEST   MEM_REQUEST\nleaf1   200m,200m     1Gi,250Mi\n</code></pre> <p>You will see at least two values reported for the CPU and memory requests. The first value is the resources requested for the simulator node itself, and the second value is the resources requested for the topology wiring service that EDA's Digital Twin uses to connect the simulator nodes in the topology. In the example above, the leaf1 simulator node requests 200m of CPU and 1Gi of memory for itself, and 200m of CPU and 250Mi of memory for the topology wiring service, resulting in a total of 400m of CPU and 1.25Gi of memory requested per the simulator node of the SR Linux type.</p> <p>The default values for the resource requests are chosen to ensure that the simulators can run under medium load. However, you may want to adjust the resource requests based on your specific use case and either increase or decrease them. Often, you may want to decrease the default values to save resources in the cluster and fit more simulator nodes, especially if you run development clusters with a limited amount of hardware resources.</p> <p>EDA allows you to configure CPU and memory requests and limits for the supported simulator types via the Config Engine setting. For example, to change the CPU and memory requests for the SR Linux simulator nodes and the CXDP (topology wiring service), start by entering the edit mode for the Config Engine:</p> <pre><code>kubectl edit -n eda-system engineconfig\n</code></pre> <p>Add the following block to the <code>spec</code> section:</p> <pre><code>customSettings:\n- applicationName: cx\n  settings:\n  - name: SrlCpuRequest\n    value: 100m\n  - name: SrlMemoryRequest\n    value: 500Mi\n  - name: CxdpCpuRequest\n    value: 50m\n  - name: CxdpMemoryRequest\n    value: 200Mi\n</code></pre> <p>This will change the default requests for the SR Linux simulator nodes and the Cxdp container.</p> <p>After editing the Config Engine resource, you need to redeploy the topology for the changes to take effect.</p> Full list of setting names for the CX application Setting Name Default Value Description Nokia SR Linux <code>SrlCpuRequest</code> 200m SR Linux CPU request <code>SrlMemoryRequest</code> 1Gi SR Linux Memory request <code>SrlCpuLimit</code> SR Linux CPU limit <code>SrlMemoryLimit</code> SR Linux Memory limit Nokia SR OS <code>SrosCpuRequest</code> 200m SR OS CPU request <code>SrosMemoryRequest</code> 1Gi SR OS Memory request <code>SrosCpuLimit</code> SR OS CPU limit <code>SrosMemoryLimit</code> SR OS Memory limit Cisco NX OS <code>NxosCpuRequest</code> 200m NX-OS CPU request <code>NxosMemoryRequest</code> 1Gi NX-OS Memory request <code>NxosCpuLimit</code> NX-OS CPU limit <code>NxosMemoryLimit</code> NX-OS Memory limit Arista EOS <code>EosCpuRequest</code> 200m EOS CPU request <code>EosMemoryRequest</code> 1Gi EOS Memory request <code>EosCpuLimit</code> EOS CPU limit <code>EosMemoryLimit</code> EOS Memory limit Nokia EDA Edge Sim <code>EdgeSimCpuRequest</code> 200m EdgeSim CPU request <code>EdgeSimMemoryRequest</code> 500Mi EdgeSim Memory request <code>EdgeSimCpuLimit</code> EdgeSim CPU limit <code>EdgeSimMemoryLimit</code> EdgeSim Memory limit Nokia EDA CXDP <code>CxdpCpuRequest</code> 200m CXDP CPU request <code>CxdpMemoryRequest</code> 250Mi CXDP Memory request <code>CxdpCpuLimit</code> CXDP CPU limit <code>CxdpMemoryLimit</code> CXDP Memory limit <p>After editing the Config Engine resource and redeploying the topology, you can check that the new values have been applied:</p> <pre><code>kubectl get pods -n eda-system -l cx-pod-name=leaf1 \\\n-o custom-columns=\"POD:.metadata.labels.cx-pod-name,\\\nCPU_REQUEST:.spec.containers[*].resources.requests.cpu,\\\nMEM_REQUEST:.spec.containers[*].resources.requests.memory\"\n</code></pre> <pre><code>POD     CPU_REQUEST   MEM_REQUEST\nleaf1   100m,50m      500Mi,100Mi\n</code></pre> <ol> <li> <p>EDA does not bundle the virtual simulators for the 3<sup>rd</sup>-party vendors. Users should obtain the simulators themselves and made them available to the Digital Twin.\u00a0\u21a9</p> </li> <li> <p>Like Nokia SR Linux, Nokia SR OS (SR-SIM) or third-party vendor simulator, e.g. Arista EOS.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting-started/installation-process/","title":"Try EDA Installation process","text":"<p>The unattended \"Try EDA\" install procedure powered by the <code>make try-eda</code> step does a lot of steps in the background, making the installation process quick and easy. However, going over most important steps of the playground installation process will give you a better understanding of the underlying operations and can assist you in troubleshooting issues.</p> <p>Note</p> <ol> <li>If you want just to install EDA the easy way, you can skip this chapter and use the Try EDA procedure.</li> <li>This chapter explains the generic installation steps based on the Makefile operations and is not a reference for a production installation.</li> <li>The outlined steps are not meant to be executed in the way they presented. This page just explains some core installation steps, without maintaining a close relationship between them.</li> </ol> <p>The key installation step that the \"Try EDA\"<sup>1</sup> installation performs are:</p> <p> Setting up a development Kubernetes cluster if one does not exist.  Downloading and installing the external and EDA core packages using <code>kpt</code><sup>2</sup>.  Installing an initial set of EDA applications provided by Nokia.  Exposing UI/API endpoint to a user.</p> <p>The <code>make try-eda</code> command sets up the whole thing for you; Let us explain some steps it carries out in more details.</p>"},{"location":"getting-started/installation-process/#tools","title":"Tools","text":"<p>Who likes to manually install a bunch of tools that are needed for the installation process manually? Not us! That's why we automated the tools procurement our installation process relies on:</p> <pre><code>make download-tools #(1)!\n</code></pre> <ol> <li> <p>This will download <code>kind</code>, <code>kubectl</code>, <code>kpt</code>, and <code>yq</code> into a <code>tools</code> folder relative to the current working directory.</p> <p>Subsequent steps use these versions of the binaries - you may use your own binaries for your own interactions. If you don't have <code>kubectl</code> in your <code>$PATH</code>, then consider copying the <code>kubectl</code> binary from the <code>tools</code> directory to a location in your <code>$PATH</code> to make use of it in the following steps.</p> </li> </ol> <p>You will have to install the container runtime (e.g. <code>docker</code>) manually.</p>"},{"location":"getting-started/installation-process/#eda-packages","title":"EDA packages","text":"<p>EDA is packaged using <code>kpt</code>, and uses this package manager tool to install core EDA components as well as external tools like cert-manager. The installer downloads EDA kpt packages by cloning the nokia-eda/kpt. These packages install EDA core and some external components onto the k8s cluster in the later steps.</p> <p>But EDA kpt packages only install the core EDA components, such as its config engine, digital sandbox and so on. The EDA applications, though, are distributed via application catalogs, which are just git repositories with application manifests. The app catalog that \"Try EDA\" downloads contains Nokia apps such as Fabrics, Interfaces, AAA and other basic apps you get installed with EDA.</p> <p>To clone both EDA kpt packages and the app catalog, the makefile packs the following target:</p> <pre><code>make download-pkgs\n</code></pre>"},{"location":"getting-started/installation-process/#kind-cluster","title":"KinD cluster","text":"<p>EDA is a set of containerized applications that are meant to run in a Kubernetes cluster. Try EDA setup uses Kubernetes-in-Docker project, a.k.a <code>kind</code>, to setup a local k8s cluster<sup>3</sup>.</p> Already have a cluster? <p>Using the <code>kind</code> cluster for the quickstart is the easiest way to get started, but you are welcome to try EDA on a cluster of your own and even use the same <code>Makefile</code> to install EDA on it. Here is a short guide how to do that.</p> <p>The <code>make try-eda</code> step will setup the KinD cluster automatically for you and you should be able to verify that a one-node cluster is running with:</p> <pre><code>kubectl get nodes #(1)!\n</code></pre> <ol> <li><code>kubectl</code> is also installed during the <code>make download-tools</code> step; you will find the binary in the <code>./tools</code> directory.</li> </ol> <pre><code>NAME                     STATUS   ROLES           AGE   VERSION\neda-demo-control-plane   Ready    control-plane   88s   v1.25.3\n</code></pre>"},{"location":"getting-started/installation-process/#external-packages","title":"External packages","text":"<p>EDA relies on some open source projects like <code>fluentd</code> for logging, <code>certmanager</code> for certificate management and <code>gogs</code> for Git. You may provide these components as part of your own cluster installation, or the EDA install can add them for you. It is highly recommended if EDA is the only workload in the cluster to allow EDA to manage the installation of these dependencies.</p> <p>The external packages that EDA uses are defined in the <code>nokia-eda/kpt/eda-external-packages</code> directory and is installed as part of the <code>try-eda</code> step via this target:</p> <pre><code>make install-external-packages\n</code></pre>"},{"location":"getting-started/installation-process/#deployment-configuration","title":"Deployment configuration","text":"<p>To provide configuration flexibility for EDA installation, <code>kpt</code> packages have a lot of fields marked with the <code># kpt-set:</code> annotation. These fields can be set with the <code>kpt</code> CLI to change their default values. Parameters like TLS configuration, proxies, default credentials and more are configurable via <code>kpt</code> setters.</p> <p>Installation Customization section provides a deep dive on all customization options.</p> <p>For example, it is common for EDA to be behind a load balancer, with clients terminating on the load balancer address and having their traffic forwarded from there. As EDA performs redirects it needs to know the name/IP clients will use to reach it. This can be accomplished via the setters in <code>kpt</code>, but for persistency and convenience, the most common settings can be set via the <code>prefs.mk</code> file that is part of the playground repository.</p> subset of the options in the prefs.mk file<pre><code># EXT_DOMAIN_NAME = \"&lt;Domain name or IP address&gt;\"\n# EXT_HTTP_PORT = \"&lt;Port for http access&gt;\"\n# EXT_HTTPS_PORT = \"&lt;Port for https access&gt;\"\n# EXT_IPV4_ADDR = \"&lt;LB IP or external route&gt;\"\n# EXT_IPV6_ADDR = \"&lt;Same thing but in ipv6&gt;\"\n</code></pre> <p>Check out Trying EDA Like a Pro post for tips and tricks on how to configure EDA.</p>"},{"location":"getting-started/installation-process/#http-proxies","title":"HTTP Proxies","text":"<p>If your cluster requires an HTTP proxy to access the resources outside of it, you will need to set the <code>HTTPS_PROXY</code>, <code>HTTP_PROXY</code>, <code>NO_PROXY</code>, and their lowercase counterparts.</p> <p>The logic inside the <code>eda-configure-core</code> target will set these values automatically to the values in your environment. But if you're installing on a machine that has different proxy settings, you will need to set them manually in the <code>prefs.mk</code> file before running the <code>eda-configure-core</code> target.</p> <p>Once the desired values are set in the <code>prefs.mk</code> file, the <code>eda-configure-core</code> target can be run to set the values in the <code>eda-kpt</code> package:</p> <pre><code>make eda-configure-core\n</code></pre> <p>The end result of this command is that the manifests contained in the <code>eda-kpt</code> directory will have the corresponding values set to the values you provided.</p>"},{"location":"getting-started/installation-process/#installing-eda","title":"Installing EDA","text":"<p>An EDA deployment is composed of three parts:</p> <ol> <li>External packages: 3<sup>rd</sup> party, open source components EDA relies on. Like <code>fluentd</code> for logging or <code>cert-manager</code> for certificate management.     As we already discussed the external packages installation, the focus now is on the EDA core and apps.</li> <li>Core: this is a set of applications that bring the core functionality of EDA. It includes applications like the Config Engine, EDA Store, State Controller, and others.</li> <li>Applications: these are applications that extend EDA's core functionality. They are pluggable by nature and decoupled from the Core. Users can install and uninstall Nokia-provided applications as needed, as well as develop their own or consume third-party applications.</li> </ol>"},{"location":"getting-started/installation-process/#core","title":"Core","text":"<p>EDA Core is a <code>kpt</code> package located at <code>nokia-eda/kpt/eda-kpt-base</code> directory and is installed as part of the <code>try-eda</code> step with:</p> <pre><code>make eda-install-core #(1)!\n</code></pre> <ol> <li>Feel free to look at the <code>Makefile</code> to understand what happens during the install.</li> </ol> <p>The EDA deployments, daemonsets and services will be created by this target, and after ~2-5 minutes you should be able to see the EDA core components running.</p> Check deployment status <p>Check the deployment status with the following command, you want to see all the deployments ready:</p> <pre><code>kubectl -n eda-system get deploy | awk 'NR==1 || /eda/'\n</code></pre> <pre><code>NAME              READY   UP-TO-DATE   AVAILABLE   AGE\neda-api           1/1     1            1           117s\neda-appstore      1/1     1            1           117s\neda-asvr          1/1     1            1           117s\neda-bsvr          1/1     1            1           117s\neda-ce            1/1     1            1           2m37s\neda-cx            1/1     1            1           117s\neda-fe            1/1     1            1           117s\neda-fluentd       1/1     1            1           41m\neda-git           1/1     1            1           40m\neda-git-replica   1/1     1            1           40m\neda-keycloak      1/1     1            1           117s\neda-postgres      1/1     1            1           117s\neda-sa            1/1     1            1           117s\neda-sc            1/1     1            1           117s\neda-toolbox       1/1     1            1           2m37s\n</code></pre> <p>You can also check the <code>EngineConfig</code> to verify the ConfigEngine has started correctly, checking the <code>.status.run-status</code> field:</p> <pre><code>kubectl -n eda-system get engineconfig engine-config -o jsonpath='{.status.run-status}{\"\\n\"}'\n</code></pre> <pre><code>Started\n</code></pre> <p><code>Started</code> is good, anything else is bad!</p> <p>You can quickly verify the deployment with yet another target!</p> <pre><code>make eda-is-core-ready\n</code></pre> <p>If everything checks out, you're ready to install the apps!</p>"},{"location":"getting-started/installation-process/#apps","title":"Apps","text":"<p>EDA is an automation framework that is powered by Applications - the little nuggets of automation goodness that you're probably interested in using. Almost everything in EDA is considered an app - from the abstracted building blocks of the network services to the composite workflows enabling the automation of complex tasks.</p> <p>A basic set of Nokia-provided applications delivered via the default App Catalog is installed with:</p> <pre><code>make eda-install-apps #(1)!\n</code></pre> <ol> <li>Curious which apps are going to be installed? Check the <code>Makefile</code> and the <code>eda-install-apps</code> target.</li> </ol>"},{"location":"getting-started/installation-process/#bootstrap-eda","title":"Bootstrap EDA","text":"<p>By installing the applications we made EDA aware of them, but we haven't created any concrete instances of these apps yet. In the bootstrap step we create some example instances of these application types as well as some initial configuration.</p> <pre><code>make eda-bootstrap\n</code></pre> <p>The bootstrap step uses the <code>eda-kpt-playground</code> kpt package that contains the instances of the installed applications. For example, the concrete allocation pools or bootstrap configs for the networking nodes.</p>"},{"location":"getting-started/installation-process/#whats-next","title":"What's next?","text":"<p>You now have a ready-to-use EDA installation, with core services and some apps installed. What we miss is some network to automate. Let's have one!</p> <p> Virtual network</p> <ol> <li> <p>Try EDA is an installation mode for labs and demos. For production installation consult with the Software Installation document.\u00a0\u21a9</p> </li> <li> <p>kpt - pronounced \"kept\" - is a Kubernetes Packaging Tool. EDA uses <code>kpt</code> to package up all the resources needed to deploy EDA. See https://kpt.dev for more information.\u00a0\u21a9</p> </li> <li> <p>If you are using macOS you might be using another, non-KinD, k8s provider.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting-started/reset/","title":"Resetting the Playground","text":"<p>If you want to start fresh, or just shut down your playground, you can do so with the following commands:</p> <pre><code>make teardown-cluster\n</code></pre> <p>This will remove the KinD cluster and all the resources created by the EDA Playground.</p> <p>Then you can remove the existing <code>kpt</code> packages:</p> <pre><code>rm -rf eda-kpt\n</code></pre> <p>And you are ready to start over!</p>"},{"location":"getting-started/try-eda/","title":"Try EDA","text":"<p>We believe that EDA embodies what a network automation of the modern age should look like - declarative and programmable abstractions for both configuration and state, streaming-based engine, equipped with network-wide queries, extensible and multivendor-capable. And we don't want you to blindly take our word for it, instead we made EDA easily accessible<sup>1</sup> so that both network engineers and cloud practitioners could be the judge. With no license and no registration required, you are mere couple commands away from having the full EDA experience wherever you are - with your laptop, in the cloud or logged in the VM.</p> <p>To deliver the \"Try EDA\" experience, we have created an EDA playground - a repository that contains everything you need to install and provision a demo EDA instance with the virtual network on the side. Let us guide you through the installation process.</p> Quickstart video walkthrough <p>If you prefer a video walkthrough that starts from the very beginning, we have you covered! Check out the Event-Driven Automation playlist where Andy Lapteff walks you through the entire process step-by-step starting with installing a hypervisor all the way to the running EDA instance.</p> <ol> <li> <p>Choose where to run EDA</p> <p>Since EDA uses Kubernetes as its application platform, you can deploy the EDA Playground anywhere a k8s cluster runs. The most popular way to install the demo EDA instance is on a Linux server/VM, but you can also run it on macOS, in an existing Kubernetes cluster, or on Windows using WSL.</p> <p>If you get stuck with the installation, please reach out to us on Discord, we are happy to help!</p> </li> <li> <p>Ensure minimal system requirements are met</p> <p>Regardless of whether you run EDA Playground locally on a laptop, or in a VM locally or in the cloud, the underlying k8s cluster should have the following resources available to it<sup>2</sup>:</p> <p> 8 vCPUs  16GB of RAM  30GB of SSD storage</p> <p>For a VM-based installation, this means that the VM should be provisioned with (at the minium) this amount of resources.</p> </li> <li> <p>Clone the EDA Playground repository</p> <p>Proceed with cloning the EDA playground repository that contains everything you need to install and provision a demo EDA instance.</p> <p>If you are using a Linux VM or a server to deploy the Playground, you should clone the repository on that VM/server.</p> <p>You will need <code>git</code><sup>3</sup> to clone it:</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; \\\ncd playground\n</code></pre> </li> <li> <p>Prepare the VM/Server</p> <p>If you are deploying the EDA Playground on a VM/Server, you should take care of the following:</p> <p>Install <code>make</code> that orchestrates the installation of the EDA Playground.</p> aptyum <pre><code>sudo apt install -y make\n</code></pre> <pre><code>sudo yum install -y make\n</code></pre> <p>Install <code>docker</code> using our automated installer, if you don't have it already installed:</p> <pre><code>make install-docker\n</code></pre> <p>Or install it manually, by following the official Docker installation guide for your OS. If you installed docker via the package manager of your distribution, remove it and install as per the Docker installation guide.</p> Ensure sudo-less docker access <p>After completing the docker installation, check if you can run docker commands without <code>sudo</code> by running:</p> <pre><code>docker ps\n</code></pre> <p>If you get a <code>permission denied</code> error, then you need to add your user to the <code>docker</code> group:</p> <ol> <li> <p>Create the docker group.</p> <pre><code>sudo groupadd docker\n</code></pre> </li> <li> <p>Add your user to the docker group.</p> <pre><code>sudo usermod -aG docker $USER\n</code></pre> </li> <li> <p>Log out and log back in so that your group membership is re-evaluated.</p> </li> </ol> <p>Ensure the relevant sysctl values are properly sized by pasting and running the following:</p> <pre><code>make configure-sysctl-params\n</code></pre> </li> <li> <p>Install the EDA Playground</p> <p>A single command separates you from the EDA Playground installation. But before you run it, if you want to enable the Natural Language support for the EDA Query functionality, provide the LLM key (OpenAI) with an environment variable<sup>4</sup>:</p> <pre><code>export LLM_API_KEY=&lt;your-OpenAI-API-key&gt;\n</code></pre> <p>Now, run the EDA installer:</p> <pre><code>make try-eda\n</code></pre> <p>The installation will take approximately 10 minutes to complete. Once it is done, you can optionally verify the installation.</p> EDA License <p>As you may have noticed, the EDA Playground installation does not require a license. We wanted to ensure that automation with EDA is accessible to everyone, anytime. The EDA system can perfectly run without a license with the following caveats:</p> <ul> <li>Only the nodes inside the EDA's Digital Twin can be used. These include the SR Linux nodes that will be deployed for you by the time <code>make try-eda</code> step finishes as well as any 3<sup>rd</sup> party vendors supported by EDA's Digital Twin. No hardware nodes can be used in an unlicensed EDA mode<sup>5</sup>.</li> <li>No integration with the cloud systems such as OpenShift, VMware, etc.</li> </ul> </li> <li> <p>Access the UI</p> <p>EDA is an API-first framework, with its UI being a client of the very same API. After the <code>make try-eda</code> finishes, you will be able to access the EDA UI using the address printed in the terminal:</p> <pre><code>--&gt; The UI can be accessed using https://10.10.1.1:9443 #(1)!\n--&gt; INFO: EDA is launched\n</code></pre> <ol> <li>Instead of <code>10.10.1.1</code> IP you may see the IP address of the VM/Server where you installed EDA Playground or its hostname. You can use any address that resolves to the VM/Server hosting the Try EDA installation, not only the one printed in the terminal.</li> </ol> <p>Open your web browser and navigate to provided URL to access the EDA UI. As you would expect, credentials are required in order to log in. The default credentials are as follow:</p> <ul> <li>Username: <code>admin</code> </li> <li>Password: <code>admin</code></li> </ul> </li> </ol> <p>Now that you completed the installation, you can either read more on the installation details, or continue with creating your first unit of automation with EDA.</p> <ul> <li> <p> Creating a resource</p> <p>Now, that you are logged in, you are ready for your first EDA automation experience!</p> <p> Creating your first unit of automation</p> </li> <li> <p> How does install work?</p> <p>If you want to understand how EDA playground installer works and what makes up the EDA installation, you can continue with the Installation process section.</p> <p> Learn more about installation process</p> </li> </ul> Production installation <p>For a production installation instructions, please refer to the Software Installation document.</p> <ol> <li> <p>As no other framework of comparable scale.\u00a0\u21a9</p> </li> <li> <p>This as well accounts for the playground network topology. Running a bigger topology or changing the node types may require more resources.\u00a0\u21a9</p> </li> <li> <p>Many distributions come with <code>git</code> preinstalled, but if not you should install it via your package manager. For instance with <code>apt</code>-enabled systems:</p> <p><pre><code>sudo apt install -y git\n</code></pre> \u21a9</p> </li> <li> <p>You can provide the LLM key after the installation as well.\u00a0\u21a9</p> </li> <li> <p>Containerlab-deployed SR Linux nodes are planned to be supported in the unlicensed mode in the future.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting-started/units-of-automation/","title":"Units of automation","text":"<p>EDA is an automation framework that follows declarative principles. An operator's input is the desired state of the resources and EDA takes care of the deployment, provisioning, configuration and reconciliation of the resource. In other words, you tell EDA what state you want your infra to be in and EDA carries out the \"how\" for you in a reliable and most efficient way.</p> <p>What is a <code>Resource</code>?</p> <p>In EDA, a resource is a unit of automation and can represent virtually anything:</p> <ul> <li>an interface on a network device</li> <li>a complete fabric configuration<sup>1</sup></li> <li>a network service like a VPN or a VRF<sup>2</sup></li> <li>and even non-network related resources like a user account, a DNS record, or a firewall rule.</li> </ul> <p>As a Kubernetes citizen, EDA represents its resources via Custom Resources (CRs) of Kubernetes that can be created using multiple methods including the Kubernetes (K8s) API, the EDA API, or through a User Interface (UI).</p> <p>You probably wonder what resources are available in EDA and how to interact with them. Great question! EDA resources become available as soon as you install an EDA Application which is a way to extend EDA with new resources and capabilities on the fly. Applications may be provided by anyone: Nokia, our partners or indie developers - EDA is an open platform!</p> <p>Nothing beats a hands-on experience, so let's learn more about Resources by following a short but powerful example of configuring a fabric on top of our 3-node topology deployed as part of our playground.</p>"},{"location":"getting-started/units-of-automation/#a-fabric-resource","title":"A Fabric resource","text":"<p>You heard it right! We will configure a DC fabric using a single EDA resource in a fully declarative and reliable way. The Fabric resource is a high-level abstraction that allows you to define a fabric configuration suitable for environments ranging from small, single-node edge configurations to large, complex multi-tier and multi-pod networks.</p> <p>What is a Fabric?</p> <p>To put it simply, a Fabric resource represents a DC fabric configuration with all its components like:</p> <ul> <li>a set of leaf and spine devices</li> <li>allocation pools for system IPs, ASN numbers</li> <li>inter-switch links flavor (numbered, unnumbered, vlans)</li> <li>underlay protocol (eBGP, IGP)</li> <li>overlay protocol</li> </ul> <p>At the end of the day, a Fabric resource defines and configures everything a DC fabric needs to support overlay networks or L2/L3 services.</p> <p>The Fabric resource documentation provides a detailed description of the resource, its attributes and behavior. To not repeat ourselves, we will proceed with creating a Fabric resource and leave the exploration of its attributes to a reader.</p> <p>Recall, that you can create EDA resources using the Kubernetes API, the EDA API or through a User Interface (UI). Let's start with the Kubernetes API.</p>"},{"location":"getting-started/units-of-automation/#creating-a-resource-with-kubernetes-api","title":"Creating a resource with Kubernetes API","text":"<p>To create a resource via the Kubernetes API, you must first define a Kubernetes Custom Resource (CR) specific to your needs. As we set ourselves to create a Fabric resource, we need to define a Fabric CR using our Fabric resource documentation.</p> <p>To create the abstracted declarative definition of our Fabric in EDA we will use <code>kubectl</code><sup>3</sup> CLI tool. Paste the below command in your terminal to create a Fabric resource named <code>myfabric-1</code> in the <code>eda</code> namespace.</p> <p>Have a look at the Fabric CR input below as it highlights the power of abstraction and declarative configuration. In twenty lines of simple YAML, we defined an entire Fabric configuration, selected which leafs and spines, what inter switch links to select, and chose the underlay and overlay protocols.</p> <code>kubectl</code>YAML <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: myfabric-1\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n\nEOF\n</code></pre> <pre><code>apiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: myfabric-1\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n</code></pre> <p>Just like that, in a single command we deployed the Fabric resource, as we can verify with:</p> <pre><code>kubectl -n eda get fabric myfabric-1 #(1)!\n</code></pre> <ol> <li> <p>You can see the Fabric with the name <code>myfabric-1</code> in the EDA UI as well under the Fabrics section.</p> <p></p> </li> </ol> <pre><code>NAME         LAST CHANGE   OPERATIONAL STATE\nmyfabric-1   1m            up\n</code></pre> <p>Ok, we see that the Fabric resource named <code>myfabric-1</code> has been created in our cluster, but what exactly has happened? Let's find out.</p> <p>Without getting you overwhelmed with the details, let's just say that EDA immediately recognized the presence of the Fabric resource and turned an abstracted declarative Fabric definition to dozens of important fabric-related sub-resources. The sub-resources in their turn have been translated to the node-specific configuration blobs and were pushed in an all-or-nothing, transactional manner to all of the nodes in our virtual topology; all of this in a split second.</p> <p>You see the power of abstraction and automation in action, where the complex configuration task is reduced to a single declarative statement that is reliably transacted to the nodes, just as it should be.</p> <p>\"I don't think that the Fabric should be abstracted like that\"</p> <p>It is absolutely fine if your view how the Fabric abstraction should look like is different from ours. EDA doesn't tell you how to do your infrastructure automation, EDA is here to help you do it.</p> <p>Leveraging the power of pluggable applications, you can create your own Fabric abstraction and use them to configure your fabric in a way that is most convenient for you.</p> <p>Now, when the abstracted and declarative input has been processed by EDA, a fully functional Fabric configuration has been deployed on the nodes of our virtual topology. Don't take our word for it, let's connect to the nodes and check what config they have now. Do you remember that all the nodes in our fabric had no configuration at all? Let's see what changed after we applied the fabric resource:</p> Checking the running configuration on <code>leaf1</code> <p>We can connect to the nodes with a single command like <code>make leaf1-ssh</code> and check the running configuration with <code>info</code> command:</p> <pre><code>interface ethernet-1/1 {\n    admin-state enable\n    subinterface 0 {\n        admin-state enable\n        ipv6 {\n            admin-state enable\n            router-advertisement {\n                router-role {\n                    admin-state enable\n                    max-advertisement-interval 10\n                    min-advertisement-interval 4\n                }\n            }\n        }\n    }\n}\ninterface ethernet-1/2 {\n    admin-state enable\n    subinterface 0 {\n        admin-state enable\n        ipv6 {\n            admin-state enable\n            router-advertisement {\n                router-role {\n                    admin-state enable\n                    max-advertisement-interval 10\n                    min-advertisement-interval 4\n                }\n            }\n        }\n    }\n}\ninterface ethernet-1/3 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/4 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/5 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/6 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/7 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/8 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/9 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/10 {\n    description lag-leaf1-e1011-local\n    admin-state enable\n    ethernet {\n        aggregate-id lag1\n        lacp-port-priority 32768\n    }\n}\ninterface ethernet-1/11 {\n    description lag-leaf1-e1011-local\n    admin-state enable\n    ethernet {\n        aggregate-id lag1\n        lacp-port-priority 32768\n    }\n}\ninterface ethernet-1/12 {\n    description lag-leaf1-2-e1212-local\n    admin-state enable\n    ethernet {\n        aggregate-id lag2\n        lacp-port-priority 32768\n    }\n}\ninterface lag1 {\n    description lag-leaf1-e1011-local\n    admin-state enable\n    vlan-tagging true\n    lag {\n        lag-type lacp\n        min-links 1\n        lacp-fallback-mode static\n        lacp-fallback-timeout 60\n        lacp {\n            interval FAST\n            lacp-mode ACTIVE\n            admin-key 1\n            system-id-mac FE:2F:AA:00:00:01\n            system-priority 32768\n        }\n    }\n}\ninterface lag2 {\n    description lag-leaf1-2-e1212-local\n    admin-state enable\n    vlan-tagging true\n    lag {\n        lag-type lacp\n        min-links 1\n        lacp-fallback-mode static\n        lacp-fallback-timeout 60\n        lacp {\n            interval FAST\n            lacp-mode ACTIVE\n            admin-key 2\n            system-id-mac FE:2F:AA:00:00:02\n            system-priority 32768\n        }\n    }\n}\ninterface mgmt0 {\n    admin-state enable\n    subinterface 0 {\n        admin-state enable\n        ipv4 {\n            admin-state enable\n            dhcp-client {\n                trace-options {\n                    trace [\n                        messages\n                    ]\n                }\n            }\n        }\n        ipv6 {\n            admin-state enable\n            dhcp-client {\n                trace-options {\n                    trace [\n                        messages\n                    ]\n                }\n            }\n        }\n    }\n}\ninterface system0 {\n    subinterface 0 {\n        admin-state enable\n        ipv4 {\n            admin-state enable\n            address 11.0.0.1/32 {\n            }\n        }\n    }\n}\nsystem {\n    configuration {\n        role sudo {\n        }\n    }\n    aaa {\n        authentication {\n            authentication-method [\n                local\n            ]\n            admin-user {\n                password $y$j9T$2efd42dad2479d9f$nGS3iroL4eaDjeQBcoj.A8C8gcLddS5sSHM05UexSQ/\n            }\n        }\n        authorization {\n            role sudo {\n                superuser true\n                services [\n                    cli\n                    gnmi\n                    netconf\n                ]\n            }\n        }\n        server-group local {\n            type local\n        }\n    }\n    ssh-server mgmt {\n        admin-state enable\n        network-instance mgmt\n    }\n    boot {\n        autoboot {\n            admin-state enable\n        }\n    }\n    lldp {\n        interface ethernet-1/1 {\n            admin-state enable\n        }\n        interface ethernet-1/2 {\n            admin-state enable\n        }\n        interface ethernet-1/3 {\n            admin-state enable\n        }\n        interface ethernet-1/4 {\n            admin-state enable\n        }\n        interface ethernet-1/5 {\n            admin-state enable\n        }\n        interface ethernet-1/6 {\n            admin-state enable\n        }\n        interface ethernet-1/7 {\n            admin-state enable\n        }\n        interface ethernet-1/8 {\n            admin-state enable\n        }\n        interface ethernet-1/9 {\n            admin-state enable\n        }\n        interface ethernet-1/10 {\n            admin-state enable\n        }\n        interface ethernet-1/11 {\n            admin-state enable\n        }\n        interface ethernet-1/12 {\n            admin-state enable\n        }\n    }\n    name {\n        host-name leaf1\n    }\n    grpc-server mgmt {\n        admin-state enable\n        rate-limit 65535\n        session-limit 1024\n        metadata-authentication true\n        tls-profile EDA\n        network-instance mgmt\n        port 57400\n        services [\n            gnmi\n            gnoi\n            gnsi\n        ]\n        gnmi {\n            commit-save false\n        }\n    }\n    network-instance {\n        protocols {\n            evpn {\n                ethernet-segments {\n                    bgp-instance 1 {\n                        ethernet-segment lag-leaf1-2-e1212-local {\n                            admin-state enable\n                            esi 00:FE:2F:AA:00:00:02:00:00:00\n                            multi-homing-mode all-active\n                            interface lag2 {\n                            }\n                            df-election {\n                                algorithm {\n                                    type default\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n            bgp-vpn {\n                bgp-instance 1 {\n                }\n            }\n        }\n    }\n}\nnetwork-instance default {\n    type default\n    admin-state enable\n    description \"fabric: myfabric-1 role: leaf\"\n    router-id 11.0.0.1\n    ip-forwarding {\n        receive-ipv4-check false\n    }\n    interface ethernet-1/1.0 {\n    }\n    interface ethernet-1/2.0 {\n    }\n    interface system0.0 {\n    }\n    protocols {\n        bgp {\n            admin-state enable\n            autonomous-system 102\n            router-id 11.0.0.1\n            dynamic-neighbors {\n                interface ethernet-1/1.0 {\n                    peer-group bgpgroup-ebgp-myfabric-1\n                    allowed-peer-as [\n                        101\n                    ]\n                }\n                interface ethernet-1/2.0 {\n                    peer-group bgpgroup-ebgp-myfabric-1\n                    allowed-peer-as [\n                        101\n                    ]\n                }\n            }\n            ebgp-default-policy {\n                import-reject-all true\n                export-reject-all true\n            }\n            afi-safi evpn {\n                admin-state enable\n                multipath {\n                    allow-multiple-as true\n                    maximum-paths 64\n                }\n                evpn {\n                    inter-as-vpn true\n                }\n            }\n            afi-safi ipv4-unicast {\n                admin-state enable\n                multipath {\n                    allow-multiple-as true\n                    maximum-paths 2\n                }\n                ipv4-unicast {\n                    advertise-ipv6-next-hops true\n                    receive-ipv6-next-hops true\n                }\n                evpn {\n                    rapid-update true\n                }\n            }\n            afi-safi ipv6-unicast {\n                admin-state enable\n                multipath {\n                    allow-multiple-as true\n                    maximum-paths 2\n                }\n                evpn {\n                    rapid-update true\n                }\n            }\n            preference {\n                ebgp 170\n                ibgp 170\n            }\n            route-advertisement {\n                wait-for-fib-install false\n            }\n            group bgpgroup-ebgp-myfabric-1 {\n                admin-state enable\n                export-policy [\n                    ebgp-isl-export-policy-myfabric-1\n                ]\n                import-policy [\n                    ebgp-isl-import-policy-myfabric-1\n                ]\n                afi-safi evpn {\n                    admin-state enable\n                }\n                afi-safi ipv4-unicast {\n                    admin-state enable\n                    ipv4-unicast {\n                        advertise-ipv6-next-hops true\n                        receive-ipv6-next-hops true\n                    }\n                }\n                afi-safi ipv6-unicast {\n                    admin-state enable\n                }\n            }\n        }\n    }\n}\nnetwork-instance mgmt {\n    type ip-vrf\n    admin-state enable\n    description \"Management network instance\"\n    interface mgmt0.0 {\n    }\n    protocols {\n        linux {\n            import-routes true\n            export-routes true\n        }\n    }\n}\nrouting-policy {\n    prefix-set prefixset-myfabric-1 {\n        prefix 11.0.0.0/8 mask-length-range 32..32 {\n        }\n    }\n    policy ebgp-isl-export-policy-myfabric-1 {\n        default-action {\n            policy-result reject\n        }\n        statement 10 {\n            match {\n                prefix-set prefixset-myfabric-1\n                protocol local\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 15 {\n            match {\n                protocol bgp\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 20 {\n            match {\n                protocol aggregate\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 25 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            1\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 30 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            2\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 35 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            3\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 40 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            4\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 45 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            5\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n    }\n    policy ebgp-isl-import-policy-myfabric-1 {\n        default-action {\n            policy-result reject\n        }\n        statement 10 {\n            match {\n                protocol bgp\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 25 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            1\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 30 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            2\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 35 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            3\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 40 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            4\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 45 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            5\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>The result of the deployed Fabric app is a fully configured BGP EVPN fabric that is configured on all of the nodes in our topology.</p> <p>We can list the BGP neighbors on <code>leaf1</code> to see that it has established BGP sessions with <code>leaf2</code> and <code>spine1</code>.</p> <pre><code>--{ + running }--[  ]--\nA:leaf1# show network-instance default protocols bgp neighbor *\n--------------------------------------------------------------------------------------------------------------------------------------------\nBGP neighbor summary for network-instance \"default\"\nFlags: S static, D dynamic, L discovered by LLDP, B BFD enabled, - disabled, * slow\n+----------------+-----------------------+----------------+------+---------+-------------+-------------+-----------+-----------------------+\n|    Net-Inst    |         Peer          |     Group      | Flag | Peer-AS |    State    |   Uptime    | AFI/SAFI  |    [Rx/Active/Tx]     |\n|                |                       |                |  s   |         |             |             |           |                       |\n+================+=======================+================+======+=========+=============+=============+===========+=======================+\n| default        | fe80::53:beff:feff:1% | bgpgroup-ebgp- | D    | 101     | established | 0d:0h:16m:2 | evpn      | [0/0/0]               |\n|                | ethernet-1/1.0        | myfabric-1     |      |         |             | 2s          | ipv4-     | [2/2/1]               |\n|                |                       |                |      |         |             |             | unicast   | [0/0/0]               |\n|                |                       |                |      |         |             |             | ipv6-     |                       |\n|                |                       |                |      |         |             |             | unicast   |                       |\n| default        | fe80::53:beff:feff:2% | bgpgroup-ebgp- | D    | 101     | established | 0d:0h:16m:2 | evpn      | [0/0/0]               |\n|                | ethernet-1/2.0        | myfabric-1     |      |         |             | 2s          | ipv4-     | [3/2/3]               |\n|                |                       |                |      |         |             |             | unicast   | [0/0/0]               |\n|                |                       |                |      |         |             |             | ipv6-     |                       |\n|                |                       |                |      |         |             |             | unicast   |                       |\n+----------------+-----------------------+----------------+------+---------+-------------+-------------+-----------+-----------------------+\nSummary:\n0 configured neighbors, 0 configured sessions are established, 0 disabled peers\n2 dynamic peers\n</code></pre> <p>Everything a fabric needs has been provisioned and configured on the nodes in a declarative way, taking the inputs from the abstracted, sweet and short Fabric CR that everyone can understand.</p>"},{"location":"getting-started/units-of-automation/#state-of-a-resource","title":"State of a resource","text":"<p>Too often, the automation platforms are built solely around the configuration problem, leaving state handling to a different set of applications. In EDA we believe that the state of a resource is as important as the configuration, and state-triggered automation is a key part of the EDA's philosophy.</p> <p>Be it a higher-level abstracted resource such as Fabric or a lower-level Interface, you will find the state reported for every EDA-managed resource. The relationship between the resource's specification and its state allows us to work with the abstracted configuration and the abstracted state.</p> <p>Take the recently deployed Fabric resource which spans multiple nodes, and consists of multiple sub-resources. How do we know that the Fabric is healthy? Checking the operational status of every BGP peer and every inter-switch link is not a practical approach.</p> <p>In EDA, the application developer can define the rules to calculate the state of a resource and populate the resource with this information. By looking at the Fabric's state field an operator can confidently determine the health of the Fabric, without having to inspect the configuration of every single node.</p> <p>Users can access the status of a resource using <code>edactl</code>, <code>kubectl</code>, or UI.</p> <p><code>edactl</code></p> <p>Not all resources are published into K8s and therefore it is recommended to use <code>edactl</code> to view the status of resources. <code>edactl</code> is a CLI tool that runs in the toolbox pod in a cluster and provides a way to interact with the EDA API.</p> <p>To leverage <code>edactl</code>, paste the following command into your terminal to install a shell alias that would execute <code>edactl</code> in the toolbox pod each time you call it.</p> Install <code>edactl</code> alias<pre><code>alias edactl='kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- edactl'\n</code></pre> <p>Now we can inspect the created Fabric resource using both <code>edactl</code> and <code>kubectl</code>.</p> <code>edactl</code><code>kubectl</code> <pre><code>edactl -n eda get fabrics myfabric-1 -o yaml\n</code></pre> <pre><code>kind: Fabric\nmetadata:\n  annotations: {}\n  name: myfabric-1\n  namespace: eda\nspec:\n# -- snipped --\nstatus:\n  health: 100\n  healthScoreReason: |\n    Breakdown:\n    Metric \"ISL Health\", weight: 1, score: 100, calculation method: divide\n    Metric \"DefaultRouter Health\", weight: 1, score: 100, calculation method: divide\n  lastChange: \"2024-12-15T17:24:50.000Z\"\n  leafNodes:\n  - node: leaf1\n    operatingSystem: srl\n    operatingSystemVersion: 24.10.1\n    underlayAutonomousSystem: 102\n  - node: leaf2\n    operatingSystem: srl\n    operatingSystemVersion: 24.10.1\n    underlayAutonomousSystem: 100\n  operationalState: up\n  spineNodes:\n  - node: spine1\n    operatingSystem: srl\n    operatingSystemVersion: 24.10.1\n    underlayAutonomousSystem: 101\n</code></pre> <pre><code>kubectl -n eda get fabrics myfabric-1 -o yaml\n</code></pre> <p>The output will be the same as with <code>edactl</code>, but this is because the Fabric resource was \"the input\" resource, and EDA publishes those resources into K8s.</p> <p>Note, how the <code>health</code> and <code>operationalState</code> of the whole Fabric resource is reported in the <code>status</code> field. Having the abstracted state is as important as the configuration, since it allows operators to focus on the important information, without having to inspect the configuration of every single node or component of a composite resource.</p> <p>The operational state can have different values that would help an operator to determine the health of the Fabric. It is totally up to the application developer to define what status is reported for a given resource based on what is relevant for the application.</p> <p>And, of course, the same information can be layed out nicely in the UI using resources dashboards (you guessed it, they are also customizable by the application developer).</p> <p>With a glance at the Fabric's dashboard an operator can determine the state of the whole fabric, without having to inspect a dozen of dashboards in a separate system.</p>"},{"location":"getting-started/units-of-automation/#transactions","title":"Transactions","text":"<p>The Kubernetes reconciliation loop mechanism offers a way to enable the declarative approach for the infrastructure management. Define the desired state of the infrastructure stack, in the Kubernetes Resource Model, apply it, and the corresponding controllers start to reconcile the actual state of the infrastructure with the desired state.  </p> <p>Sounds great, but what if the desired state is not achievable? What if you deploy a workload with three replicas, but your infrastructure at the moment can only host two of them? The reconciliation loop will keep trying to reconcile the desired state with the actual state, and while it reconciles, you end up living with just two replicas running.</p> <p>Doesn't sound like a big deal? Yes, maybe if you deploy three web servers and have two only two of them running for some time it is not the end of the world. But in the networking world, having a partially deployed service is a big, big problem.</p> <ul> <li>What if your CPM filter is partially deployed?</li> <li>What if your routing policy has been deployed on a subset of edge nodes?</li> <li>What if your service has been added to 100 out of 110 leafs?</li> </ul> <p>In EDA every configuration change is done in an all-or-nothing fashion and transacted in Git. Always. If the desired state is not achievable even on a single target node, the whole transaction is pronounced failed and the changes are reverted immediately from all of the nodes. The transactions are network-wide.</p> <p>When you create any resource, EDA automatically initiates a transaction and publishes its result. To view the list of existing transactions, use <code>edactl</code>:</p> <pre><code>edactl transaction\n</code></pre> <pre><code> ID  Result  Age     Detail   DryRun  Username    Description\n 27  OK      56h37m  SUMMARY          workflow    [workflow 10] Installing App: services.nokia: v2.0.0+24.12.1 (catalog=eda-catalog-builtin-apps)\n 28  OK      56h37m  DEBUG            workflow    [workflow 9] Installing App: protocols.nokia: v2.0.0+24.12.1 (catalog=eda-catalog-builtin-apps)\n 29  OK      56h37m  DEBUG            kubernetes\n 30  OK      56h37m  DEBUG            kubernetes\n 31  OK      56h37m  DEBUG            kubernetes\n 32  OK      56h36m  DEBUG            kubernetes\n 33  OK      56h36m  DEBUG            kubernetes\n 34  OK      56h35m  DEBUG            kubernetes\n 35  OK      56h35m  DEBUG            kubernetes\n 36  OK      1h22m   DEBUG            kubernetes\n</code></pre> <p>The transaction list shows the transaction ID, the status and the user who initiated the transaction. The transaction ID can be used to view the details of the transaction, including the changes made to the resources. Transactions are sequential and can be viewed in the order they were initiated.</p> <p>What did we do last in this quickstart? Created a Fabric resource! Let's see what the latest transaction has to say about it:</p> <pre><code>edactl transaction 36\n</code></pre> <pre><code>input-crs:\n    gvk: fabrics.eda.nokia.com/v1alpha1, kind=Fabric name: myfabric-1 action: CreateUpdate\nintents-run:\n  - fabrics.eda.nokia.com/v1alpha1, kind=Fabric, myfabric-1\n    output-crs:\n    - fabrics.eda.nokia.com/v1alpha1, kind=FabricState, myfabric-1\n    - fabrics.eda.nokia.com/v1alpha1, kind=ISL, isl-leaf1-spine1-1\n# clipped\n    pool-allocs:\n    - template: Index:asn-pool name: global key: myfabric-1-spine value: 101\n    script:\n    - execution-time: 18.688ms\n  - fabrics.eda.nokia.com/v1alpha1, kind=ISL, isl-leaf1-spine1-1\n# clipped\n  - routingpolicies.eda.nokia.com/v1alpha1, kind=PolicyDeployment, policy-ebgp-isl-import-policy-myfabric-1-node-spine1\n      output-crs:\n      - core.eda.nokia.com/v1, kind=NodeConfig, policy-cfg-ebgp-isl-import-policy-myfabric-1-spine1\n      script:\n      - execution-time: 26.559ms\nnodes-with-config-changes:\n  - name: leaf1\n  - name: leaf2\n  - name: spine1\ngeneral-errors:\ncommit-hash: 0b0e155356a3b451e05b5aafacb92188729fecf4\nexecution-summary: intents-run: 43, nodes-changed: 3, engine-time=135.150566ms, push-to-node=2.045243438s, publish-cr=27.772\u00b5s, git-save=543.984017ms\ntimestamp: 2024-12-15 17:24:41 +0000 UTC [2024-12-15T17:24:41Z] - 1h23m ago\nresult: OK\ndry-run: false\n</code></pre> <p>You will see a lot of details, some of them we clipped from the output to keep it short, but essentially the transaction logged the input resource (kind=Fabric name: myfabric-1) and the output products of this resource being created (output-crs). Each of these outputs constitute a Fabric resource.</p> <p>At the very end of the transaction output you will see the identified nodes that are affected by this change and the result of the transaction. Since the result is OK, we are rightfully see the resulting configs applied to the nodes in our virtual network.</p>"},{"location":"getting-started/units-of-automation/#creating-a-resource-in-ui","title":"Creating a resource in UI","text":"<p>You've seen how to create a resource using the k8s API, and were introduced to the concept of transactions. Now, let's see how we can change an existing resource, perform a dry-run and finally commit the changes.</p> <p>Usually quickstarts show some simple operations to keep the flow clean and simple, like adding a VLAN to a switch. We won't bother you with these basics, instead lets swap the overlay protocol for every node in our Fabric from eBGP to iBGP with a single operation.</p> <p>Here is what happened in these 60 seconds:</p> <ol> <li>We've found the <code>myfabric-1</code> Fabric resource created earlier with <code>kubectl</code> in the UI under the Fabrics section.</li> <li>We opened the resource and navigated its configuration schema all the way to the Overlay Protocol section.</li> <li>We changed the overlay protocol from eBGP to iBGP and provided the required iBGP bits such as ASN number, Router ID.</li> <li>We also provided the labels for the nodes that should be used as RR (route reflector) and RR clients; Our topology has been labeled with <code>role: spine</code> and <code>role: leaf</code> when we deployed it.</li> <li>Instead of applying the change right away, we added it to the transaction basket. We could've added more changes to it, but for now we were ok with a single change.</li> <li>Before applying the change we ran the Dry-Run, which started the process of unwrapping the abstracted high-level Fabric resource into the sub-resources and dependent resources.</li> <li>The dry-run provided us with the extensive diff view of the planned changes to the nodes and all sub-resources touched by our single protocol change.</li> <li>We've reviewed the diff and decided that it is good to commit the change.</li> <li>Once we committed the change, we ensured that the change was immediately applied to the nodes by looking at <code>leaf1</code> show output and seeing how iBGP appeared in the output of peer neighbors.</li> </ol> <p>Have a look at the Fabric dashboard</p> <p>Once the change is committed, BGP will take some time to converge. During this period you can see the resource's state in action by opening a Fabric dashboard and observing how the Fabric status transitions from \"Degraded\" to \"Healthy\".</p> <p>Transactions made by a user in the UI<sup>5</sup> are also visible in the Transactions UI<sup>4</sup>:</p> <p>Congratulations, your fabric is now using iBGP as its overlay protocol  From a tiny change in the Fabric' declarative abstraction through the transformation to sub-resources and eventually to the node-level configurations, that are reliably transacted and pushed to the constituent nodes. How cool is that?</p> <ol> <li> <p>Like the Fabric resource documented in the Apps section.\u00a0\u21a9</p> </li> <li> <p>Like the Virtual Network resource documented in the Apps section.\u00a0\u21a9</p> </li> <li> <p>You can find the <code>kubectl</code> CLI tool in the <code>tools</code> folder of your playground repository. You can copy it to the <code>/usr/local/bin</code> dir to make it globally available.\u00a0\u21a9</p> </li> <li> <p>Soon you will be able to see the transactions made via the k8s API as well, when the relevant permissions are granted.\u00a0\u21a9</p> </li> <li> <p>Transactions made via kubectl will be visible in the UI in a later release.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting-started/verification/","title":"Verifying an install","text":"<p>When using the <code>make try-eda</code> command you will hopefully have a running EDA instance in under 10 minutes without any manual intervention. We embedded necessary checks in the Makefile to ensure that the steps are executed in the correct order and that the system is in a healthy state.</p> <p>However, while testing the setup process on several different platforms, we couldn't cover all the possible cases. If you encounter installation issues, this section may help you pinpoint the issue.</p>"},{"location":"getting-started/verification/#eda-core","title":"EDA core","text":"<p>You should be able to use <code>kubectl -n eda-system get pods</code> to verify that EDA core components have started and in the Ready state:</p> <pre><code>kubectl -n eda-system get pods | awk 'NR==1 || /eda/'\n</code></pre> <pre><code>NAME                                  READY   STATUS    RESTARTS   AGE\ncx-eda--leaf1-sim-864b97d58d-g9zq2    2/2     Running   0          12h\ncx-eda--leaf2-sim-6698fc668f-4blcm    2/2     Running   0          12h\ncx-eda--spine1-sim-677f5499cf-fn2pg   2/2     Running   0          12h\neda-api-9985cb78-gphnk                1/1     Running   0          12h\neda-appstore-8d679c5b-fqmt6           1/1     Running   0          12h\neda-asvr-dc9877c8d-5j62k              1/1     Running   0          12h\neda-bsvr-6bf77b64c-9l2zx              1/1     Running   0          12h\neda-ce-84c6486cb7-f8jzc               1/1     Running   0          12h\neda-cx-5dc6cf9d96-dcrrf               1/1     Running   0          12h\neda-fe-54d8db877f-xk7l8               1/1     Running   0          12h\neda-fluentbit-hkwvd                   1/1     Running   0          12h\neda-fluentd-54cf4bd5d7-j98zg          1/1     Running   0          12h\neda-git-754df68df5-8kgx4              1/1     Running   0          12h\neda-git-replica-784dbdbfc8-5zdzz      1/1     Running   0          12h\neda-keycloak-5d569565b7-2gmc7         1/1     Running   0          12h\neda-metrics-server-799d54cb7-688nz    1/1     Running   0          12h\neda-npp-eda-leaf1                     1/1     Running   0          12h\neda-npp-eda-leaf2                     1/1     Running   0          12h\neda-npp-eda-spine1                    1/1     Running   0          12h\neda-postgres-cd89bfc57-q56cc          1/1     Running   0          12h\neda-sa-576c98865f-66vq9               1/1     Running   0          12h\neda-sc-84546648c5-djr49               1/1     Running   0          12h\neda-se-1                              1/1     Running   0          12h\neda-toolbox-84c95bd8c6-lqxh7          1/1     Running   0          12h\n</code></pre> <p>You can also check the <code>EngineConfig</code> to verify the ConfigEngine has started correctly, checking the <code>.status.run-status</code> field:</p> <pre><code>kubectl -n eda-system get engineconfig engine-config \\\n-o jsonpath='{.status.run-status}{\"\\n\"}'\n</code></pre> <pre><code>Started\n</code></pre> <p><code>Started</code> is good, anything else is bad!</p>"},{"location":"getting-started/verification/#node-connectivity","title":"Node connectivity","text":"<p>The example topology deployed as part of the quickstart resulted in creation of topology nodes, with each node represented by an SR Linux simulator. The topology nodes in EDA are represented by the <code>TopoNode</code> resource, and this resource has a status field to indicate its health.</p> <p>The easiest way to tell the current state of nodes is via the UI, or via <code>kubectl</code>:</p>  All nodes are healthy Not all nodes are healthy <pre><code>kubectl -n eda get toponodes #(1)!\n</code></pre> <ol> <li><code>TopoNode</code> resources are scoped in the <code>eda</code> namespace, hence the <code>-n eda</code> flag.</li> </ol> <pre><code>NAME     PLATFORM       VERSION   OS    ONBOARDED   MODE     NPP         NODE     AGE\nleaf1    7220 IXR-D3L   24.10.1   srl   true        normal   Connected   Synced   12h\nleaf2    7220 IXR-D3L   24.10.1   srl   true        normal   Connected   Synced   12h\nspine1   7220 IXR-D5    24.10.1   srl   true        normal   Connected   Synced   12h\n</code></pre> <p>In this example the <code>leaf1</code> and <code>spine1</code> nodes are not healthy, since the NPP components are not connected to the nodes and the nodes are not synced: <pre><code>kubectl get toponodes\n</code></pre></p> <pre><code>NAME     PLATFORM       VERSION   OS    ONBOARDED   MODE     NPP         NODE     AGE\nleaf1    7220 IXR-D3L   24.7.1    srl   true        normal                        23h\nleaf2    7220 IXR-D3L   24.7.1    srl   true        normal   Connected   Synced   23h\nspine1   7220 IXR-D5    24.7.1    srl   true        normal   Connected   Synced   23h\n</code></pre> <p>In particular, the <code>NPP</code> and <code>NODE</code> columns define the state of the ConfigEngine to NPP connection, and the NPP to node connection. A node must be <code>Synced</code> or it will reject transactions.</p> <p>It is useful to verify the underlying Pod resources for the network simulator nodes have been created - this can take a while if it is your first time starting a simulator of a given version. You should see all your sims and the associated NPP (Node Push Pull) pods running:</p>  All pods running Not all pods running <pre><code>kubectl -n eda-system get pod | awk 'NR==1 || /cx-eda|npp/'\n</code></pre> <pre><code>NAME                                  READY   STATUS    RESTARTS   AGE\ncx-eda--leaf1-sim-864b97d58d-g9zq2    2/2     Running   0          14h\ncx-eda--leaf2-sim-6698fc668f-4blcm    2/2     Running   0          14h\ncx-eda--spine1-sim-677f5499cf-fn2pg   2/2     Running   0          14h\neda-npp-eda-leaf1                     1/1     Running   0          14h\neda-npp-eda-leaf2                     1/1     Running   0          14h\neda-npp-eda-spine1                    1/1     Running   0          14h\n</code></pre> <pre><code>kubectl -n eda-system get pod | awk 'NR==1 || /cx-eda|npp/'\n</code></pre> <pre><code>NAME                                 READY   STATUS    RESTARTS      AGE\ncx-eda--leaf1-sim-864b97d58d-g9zq2    2/2     Running   0          14h\ncx-eda--leaf2-sim-6698fc668f-4blcm    2/2     Running   0          14h\ncx-eda--spine1-sim-677f5499cf-fn2pg   2/2     Running   0          14h\neda-npp-eda-leaf1                     1/1     Running   0          14h\n</code></pre> <p>Note the <code>cx-eda-*</code> Pods (one for each <code>TopoNode</code> in the topology), these pods are SR Linux container images. You should also note there are three NPP Pods (also one for each <code>TopoNode</code>) each designated to a corresponding <code>TopoNode</code>.</p>"},{"location":"getting-started/verification/#transactions","title":"Transactions","text":"<p>EDA's brain - Config Engine - works off a sequential transaction log, processing transactions as they come in. \"in\" here is doing some heavy lifting, as items for processing may come in via:</p> <ul> <li>the UI.</li> <li>the API.</li> <li>the Kubernetes API.</li> </ul> <p>For items coming in via the UI and API, a failed transaction does not impact future transactions. For Kubernetes this behavior is inverse - the ConfigEngine will always try to ingest the full set of changes available for processing, and so an object that can never transact can cause other items to fail. You can verify transactions in the system with:</p> <pre><code>kubectl -n eda-system get transactionresults\n</code></pre> <pre><code>NAME                    RESULT   AGE    DRYRUN   DESCRIPTION\ntransaction-000000001   OK       151m            startup - no core manifest\ntransaction-000000002   OK       129m            Installing core:{v1.0.0+24.8.1-rc semver} (from eda-catalog-builtin-apps)\n-- snip --\ntransaction-000000013   OK       10m\ntransaction-000000014   OK       10m\n-- snip --\ntransaction-000000069   Failed   2m\n</code></pre> <p>If you see any transactions with a result of <code>Failed</code>, these should be investigated - especially if they came in via the Kubernetes interface. Like in the example the last transaction has a <code>Failed</code> result.</p> <p>You can investigate the transaction further with:</p> <pre><code>kubectl -n eda-system get transactionresults transaction-000000069 -o yaml\n</code></pre> <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: TransactionResult\nmetadata:\n  creationTimestamp: \"2024-04-29T22:17:40Z\"\n  generation: 3\n  name: transaction-000000069\n  namespace: default\n  resourceVersion: \"600591\"\n  uid: fc0ce238-dfed-44a5-badd-7b3a56f14706\nspec:\n  execution-summary: 'input-crs: 2, intents-run: 12, nodes-changed: 0, engine-time=725.396191ms,\n    push-to-node=10m0.052663836s'\n  general-errors:\n  - 'pod is not running or does not have an IP address ''spine1'': NPP pod ''eda-npp-spine1''\n    did not spin up'\n  - 'pod is not running or does not have an IP address ''leaf1'': NPP pod ''eda-npp-leaf1''\n    did not spin up'\n# -- snip --\n</code></pre> <p>The transaction details will give you a hint as to what went wrong. In the example above NPP Pod for <code>leaf1</code> and <code>spine1</code> did not start, and so the transaction to push the configs failed.</p>"},{"location":"getting-started/verification/#ui-access","title":"UI access","text":"<p>As covered in the Configure your deployment section, the EDA service requires a user to provide the desired DNS name/IP and port for external access. These parameters become the part of the Engine Config resource that, as the name suggests, configures the central part of EDA - the Config Engine.</p> <p>The values you provided in the prefs.mk file or in the CLI can be found in the Engine Config resource:</p> <pre><code>kubectl -n eda-system get engineconfig engine-config \\\n-o jsonpath='{.spec.cluster.external}' | yq -p json #(1)!\n</code></pre> <ol> <li>The <code>yq</code> CLI tool is installed in the <code>./tools</code> directory of the playground repo.</li> </ol> <pre><code>domainName: vm.home.lab\nhttpPort: 9200\nhttpsPort: 9443\nipv4Address: 10.1.0.11\nipv6Address: fd7a:115c:a1e0::be01:ff2f\n</code></pre> <p>The configuration above means that the EDA UI client (a browser) should use <code>https://vm.home.lab:9443</code> to access the EDA UI. You can change the <code>engine-config</code> resource post-install and change the <code>domainName</code> and/or port numbers, the changes will be in effect immediately without requiring a redeploy of the EDA.</p> <p>Secure-by-design</p> <p>In the secure-by-design paradigm, EDA exposes APIs and UI for its users only over the secure transport. That makes HTTPS the only supported transport for UI access.</p> <p>EDA UI is exposed in the k8s cluster via the <code>eda-api</code> service</p>"},{"location":"getting-started/virtual-network/","title":"Virtual network","text":"<p>To make sure that you can get the full EDA experience without upfronting any hardware investment, EDA is packaged with a Digital Sandbox solution called CX. CX is in charge of creating and managing virtual topologies running in the cluster.</p> <p>Note</p> <p>If you completed the Try EDA procedure the virtual network is already created for you. This section provides details on how the virtual network is created, what it consists of, and how to connect to the virtual nodes.</p>"},{"location":"getting-started/virtual-network/#example-topology","title":"Example topology","text":"<p>An example 3-node Leaf/Spine topology is provided with this quickstart and is automatically deployed when you run the all-in-one <code>try-eda</code> installation command.</p> <p>As part of this command a separate make target is called to load the topology resources into the cluster which, in its turn, triggers CX controller to start spinning up the nodes and wiring links between them.</p> <pre><code>make topology-load #(1)!\n</code></pre> <ol> <li> <p>No need to run this target if you already completed the Try EDA step, it has happened already.</p> <p><code>topology-load</code> targets loads the example topology provided in the json file as a ConfigMap into the cluster. The CX controller watches for ConfigMap changes and creates the corresponding topology resources.</p> </li> </ol> <p>As a result you will get you the following topology running in your cluster:</p> <p>As you would expect, it takes some time to spin up the nodes and establish the connections, you can check the status of the deployed topology in the Verify section of the quickstart.</p>"},{"location":"getting-started/virtual-network/#connecting-to-the-nodes","title":"Connecting to the nodes","text":"<p>Your network engineering roots may ask to check out what is going on on an individual node, which requires you to start a shell in the Pod running the SR Linux simulator. This can be accomplished with these simple commands:</p> <pre><code>make leaf1-ssh #(1)!\n</code></pre> <ol> <li>Of course, changing <code>leaf1</code> to <code>leaf2</code> or <code>spine1</code> will log you in the other nodes.</li> </ol> <pre><code>Using configuration file(s): ['/etc/opt/srlinux/srlinux.rc']\nWelcome to the srlinux CLI.\nType 'help' (and press &lt;ENTER&gt;) if you need any help using this.\n--{ + running }--[  ]--\nA:leaf1#\n</code></pre>"},{"location":"getting-started/virtual-network/#initial-configuration","title":"Initial configuration","text":"<p>The SR Linux nodes (the leaf and spine switches) that make up the virtual network come up with a minimal node configuration - only the bits that are required by EDA to onboard the nodes. By connecting to the node and running <code>info</code> command you can see the initial configuration and verify that it has no configuration besides the basic management settings.</p> <p>With this barebones topology deployed we can start exploring EDA automation powers. Let's explore how EDA framework can be used to provision complex services with simple declarative abstractions.</p> <p> Automating fabric configuration</p>"},{"location":"getting-started/virtual-network/#tearing-down-the-topology","title":"Tearing down the topology","text":"<p>In case you break your topology nodes beyond repair, you can always start over by tearing down the topology:</p> <pre><code>make teardown-topology\n</code></pre> <p>This will remove the topology nodes resources, the accompanying simulators and NPP pods associated with them.</p>"},{"location":"software-install/","title":"Software Installation Guide","text":"<p>This document describes prerequisites for installing EDA in a production environment; to install EDA in a lab, development or test environment, see Getting Started. It includes procedures for preparing the nodes that host the application, installing the application, upgrading and uninstalling.</p> <p>Note</p> <p>This document covers the current release and may also contain some content that will be released in later maintenance loads. See the EDA Release Notes for information about features supported in each load.</p>"},{"location":"software-install/#precautionary-and-information-messages","title":"Precautionary and information messages","text":"<p>Danger</p> <p>Danger warns that the described activity or situation may result in serious personal injury or death. An electric shock hazard could exist. Before you begin work on this equipment, be aware of hazards involving electrical circuitry, be familiar with networking environments, and implement accident prevention procedures.</p> <p>Warning</p> <p>Warning indicates that the described activity or situation may, or will, cause equipment damage, serious performance problems, or loss of data.</p> <p>Caution</p> <p>Caution indicates that the described activity or situation may reduce your component or system performance.</p> <p>Note</p> <p>Note provides additional operational information.</p> <p>Tip</p> <p>Tip provides suggestions for use or best practices.</p>"},{"location":"software-install/eda-installation-overview/","title":"EDA installation overview","text":"<p>This chapter describes the Nokia Event Driven Automation (EDA) components, the requirements for these components, and provides an overview of the installation process.</p>"},{"location":"software-install/eda-installation-overview/#components","title":"Components","text":"<p>Several key concepts are used throughout the documentation; following is an overview of these concepts and components:</p> Talos Linux and Kubernetes EDA uses Talos Linux and Kubernetes to host its services. Talos Linux is a minimalistic, locked-down, read-only and secured Linux environment purposely built to run Kubernetes. This ensures a more secure environment with significantly lower security footprint than regular Linux and Kubernetes environments. Playground git repository The Playground git repository is publicly available and is used to deploy EDA itself. <code>edaadm</code> <p>A tool that will be used for several steps in the process:</p> <ul> <li>Get the location to download the base Talos image for KVM and VMware environments.</li> <li>Generate Talos machine configuration files for the deployment of both the Assets VM and the EDA Kubernetes cluster VMs.</li> <li>Initiate Talos Kubernetes clusters.</li> </ul> <code>edaadm</code> git repository <p>A publicly available git repository that contains details and definitions for:</p> <ul> <li>Assets bundles for air-gapped installations: EDA Assets are defined in different bundles, based on their purpose. The repository provides the bundles and the means to download the content of the bundles from the internet and then upload them to the deployed Assets VM.</li> <li>A KPT package to initiate the Assets VM.</li> </ul> Air-gapped Assets VM <p>Used in an air-gapped environment, the Assets VM is a Virtual Machine deployed on a KVM or VMware environment. It is a single VM K8s cluster that will run:</p> <ul> <li>A container registry to host all the container images used by EDA.</li> <li>A git server to host the App Store Catalog.</li> <li>A web server to host certain artifacts used by EDA.</li> </ul> Air-gapped Bundles Used in air-gapped installations, a bundle is a definition of a group of assets that are related. For instance a bundle for the core components of EDA for a specific version, or a bundle of the standard Apps for a specific version. Bundles are downloaded using the <code>edaadm</code> tool from the internet, and then uploaded using <code>edaadm</code> to the Assets VM. The product comes with a set of standard bundles and custom bundles can be created based on their examples. Air-gapped EDA Shipyard A name used to describe the combination of the container registry, git server and web server running on the Assets VM."},{"location":"software-install/eda-installation-overview/#deployment-models","title":"Deployment models","text":"<p>Nokia EDA is deployed as an application on a compatible Kubernetes cluster comprised of one, three, or more nodes (validated for up to six nodes). The nodes (VMs) run a Kubernetes cluster with the following composition:</p> <ul> <li>One or three Kubernetes master nodes that also function as worker nodes: one, in case a single-VM deployment is used; otherwise three Kubernetes master nodes.</li> <li>Any remaining nodes (in a four or more node deployment) function as worker nodes.</li> <li>One, two or more nodes must also be designated as storage nodes. For redundancy, two is the minimum in a three or more node deployment. These nodes still function as worker (and potentially master) nodes as well. Rook-Ceph is used to create a storage cluster across the nodes indicated as storage nodes.</li> <li>(Optional) An Assets VM which will hold all the resources and files needed in case of an air-gapped environment.</li> </ul>"},{"location":"software-install/eda-installation-overview/#openshift","title":"OpenShift","text":"<p>Nokia EDA can also be deployed on an existing OpenShift v4.16+ cluster<sup>1</sup> with the Security Context Constraint (SCC) resource applied prior to installing EDA packages. The SCC manifest is provided in nokia-eda/edaadm/openshift/eda-scc.yaml file.</p> <p>Adding the SCC resource is the only additional requirement that needs to be satisfied, the rest of the installation procedure remains the same.</p>"},{"location":"software-install/eda-installation-overview/#networking-for-eda-nodes","title":"Networking for EDA nodes","text":"<p>This guide describes the deployment of EDA on a Kubernetes cluster with a single network, where access from both users and orchestrators to the UI and API, and access from EDA to the fabric (for example, SR Linux devices) go over the same interface.</p> <p>It is possible to use two separate networks for the EDA nodes:</p> <ul> <li> <p>OAM network     This interface is used to access the UI and the API of Nokia EDA. It is also through this network that the deployment tool reaches the nodes.</p> </li> <li> <p>Fabric management network     This interface is used to communicate with the management interfaces of the fabric (for example, SR Linux devices) and is where Nokia EDA exposes its DHCP and ZTP services.</p> </li> </ul>"},{"location":"software-install/eda-installation-overview/#eda-nodes","title":"EDA nodes","text":"<p>The Nokia EDA nodes are the VMware vSphere-based or KVM-based virtual machines (VMs) that host the Kubernetes environment on which the Nokia EDA application and Digital Sandbox are run.</p> <p>These nodes run a hardened Talos Kubernetes environment. Talos is a secure, up-to-date and hardened platform for running Kubernetes.</p> <p>EDA supports the following deployment models:</p> <ul> <li>an environment with one node, which hosts only the Nokia EDA application for small scale deployments</li> <li>an environment with three or more nodes, which hosts only the Nokia EDA application</li> </ul>"},{"location":"software-install/eda-installation-overview/#requirements-for-deployment","title":"Requirements for deployment","text":"<p>This section describes the platform requirements, node requirements, and virtual IP requirements for deploying EDA.</p>"},{"location":"software-install/eda-installation-overview/#installation-platform-requirements","title":"Installation platform requirements","text":"<p>To execute the installation process, you need access to a Linux environment<sup>2</sup> with the following components installed:</p> <p>Component</p> <p>Requirement</p> <p>Linux environment</p> <p>Any Linux distribution. The procedures provided in this document are validated on Ubuntu.</p> <p>Container runtime</p> <p>Docker must be running and you should be able to run containers</p> <p>Tools</p> <ul> <li><code>make</code> - Used to execute several installation steps.</li> <li><code>git</code> - Used to check out git repositories.</li> <li><code>curl</code> - Used to download files.</li> <li><code>jq</code> and <code>yq</code> - Used to parse JSON and YAML files.</li> <li><code>sed</code> - Used to parse and replace content.</li> <li><code>tar</code> and <code>zip</code> - Used to create and unpack bundles and assets for the Air-gapped installation process.</li> <li><code>edaadm</code> - Used to generate configuration for Talos and other useful commands to initiate the Talos environments. It can be downloaded from the <code>edaadm</code> repository releases page.</li> <li><code>htpasswd</code> - (Optional) Used in case a custom username and password is required for the Assets VM web server.</li> <li><code>base64</code> - (Optional) Used in case a custom username and password is required for the Assets VM web server or git server.</li> <li><code>ovftool</code> - (Optional) Used to deploy the VMs in a VMware vSphere environment. Can be downloaded from the Broadcom Developer Portal</li> </ul> <p>The following tools are also helpful. If they are not present, the installation tool downloads them later:</p> <ul> <li><code>kubectl</code></li> <li><code>helm</code></li> <li><code>k9s</code></li> <li><code>kpt</code></li> </ul> <p>Internet access</p> <p>Required for Internet-based installations. For Air-gapped installations, at least one system needs internet access.</p> <p>Either directly or through a proxy.</p> <p>Note</p> <p>In case of an Air-gapped installation, the guide will refer to two tools-systems, one with public internet access and one in the air-gapped environment. These can be the same system that is moved from the public side to the air-gapped side after downloading all the resources; or it can be two different systems.</p>"},{"location":"software-install/eda-installation-overview/#nokia-eda-node-requirements","title":"Nokia EDA node requirements","text":"<p>The Nokia EDA nodes are deployed as virtual machine servers. Node requirements summarizes the requirements of Nokia EDA nodes in KVM and VMware hypervisor.</p> <p>Component</p> <p>Requirement</p> <p>CPU</p> <p>32 vCPU on a modern x86-64 CPU that supports virtualization</p> <p>Memory</p> <p>64 GB</p> <p>Storage</p> <ul> <li>Operating system: 100GB of available SSD-based storage</li> <li>Storage nodes: 300GB of available SSD-based storage on a separate virtual disk</li> </ul> <p>Networking</p> <ul> <li>at least one 10 Gbps NIC</li> <li>the configured DNS servers must be reachable, functional, and able to resolve the hostnames used for the Nokia EDA nodes</li> <li>for internet-based installations: Internet access directly or through a proxy</li> </ul> <p>Virtualization platform</p> <p>You can run the Nokia EDA nodes as virtual machines using the following virtualization platforms:</p> <ul> <li>operating system: VMware vSphere 7.0 or 8.0 or RHEL/Rocky</li> <li>hypervisor: ESXi 7.0 or 8.0 or KVM</li> <li>resource reservation for CPU, memory, and disks must be set to 100% for the Nokia EDA node virtual machines</li> </ul>"},{"location":"software-install/eda-installation-overview/#nokia-eda-assets-vm-requirements","title":"Nokia EDA Assets VM requirements","text":"<p>Note</p> <p>This only applies if you plan to use the Air-gapped installation process.</p> <p>The Assets VM runs as a single VM inside the air-gapped environment. This VM holds all of the assets and can be used across multiple deployments and EDA versions, containing the assets for multiple versions. This VM has the following requirements:</p> <p>Component</p> <p>Requirement</p> <p>CPU</p> <p>4 vCPU on a modern x86-64 CPU that supports virtualization</p> <p>Memory</p> <p>16 GB</p> <p>Storage</p> <ul> <li>Operating system: 300GB</li> </ul> <p>Networking</p> <ul> <li>1 Gbps NIC</li> <li>1 IPv4 IP and optionally 1 IPv6 IP</li> <li>Preferably in the same OAM network as the EDA Kubernetes VMs, but minimally accessible by the EDA Kubernetes VMs via the OAM network</li> </ul> <p>Virtualization platform</p> <p>You can run the EDA Assets VM as a virtual machine using the following virtualization platforms:</p> <ul> <li>operating system: VMware vSphere 7.0 or 8.0 or RHEL/Rocky</li> <li>hypervisor: ESXi 7.0 or 8.0 or KVM</li> </ul>"},{"location":"software-install/eda-installation-overview/#virtual-ip-requirements","title":"Virtual IP requirements","text":"<p>The deployment of EDA requires two virtual IP addresses in the management network:</p> <ul> <li>Kubernetes VIP: the virtual IP address used by all the control plane nodes in the Kubernetes cluster.</li> <li>Nokia EDA API/UI VIP: the virtual IP address used by the Nokia EDA API and UI.</li> </ul>"},{"location":"software-install/eda-installation-overview/#installation-process-overview","title":"Installation process overview","text":"<p>The installation consists of the following high-level tasks:</p>"},{"location":"software-install/eda-installation-overview/#general-preparation","title":"General preparation","text":"<p>These tasks must be completed for both Internet based installations and Air-gapped installations.</p> <ol> <li> <p>Downloading the EDA Installation playground     This task describes how to access the EDA installation playground for use during the installation. It also covers how to configure the playground.</p> </li> <li> <p>Downloading the EDA EDAADM repository     This task describes how to download the EDAADM repository and the <code>edaadm</code> tool, used for several steps in the installation process.</p> </li> <li> <p>Download the Talos machine image     This task describes how to download the Talos base image from the official Talos image factory for your environment.</p> </li> </ol>"},{"location":"software-install/eda-installation-overview/#air-gapped-setup","title":"Air-gapped setup","text":"<p>In case the installation will be Air-gapped, this section provides steps on how to set up the Assets VM and load it with the necessary assets for deploying EDA in an Air-gapped environment.</p> <ol> <li> <p>Preparing the Assets VM     This task describes how to create the Asset VM image on a system with Internet access, so it can be used to deploy the Assets VM in the Air-gapped environment.</p> </li> <li> <p>Downloading the Assets     This task describes how to download all the necessary assets using a system with Internet access, so they can be used to deploy EDA in the Air-gapped environment.</p> </li> <li> <p>Preparing the Air-gapped environment     Describes how to prepare the Air-gapped environment by copying the files downloaded on the Internet facing system to the Air-gapped environment and prepare it so it can be used to install the Assets VM and EDA.</p> </li> <li> <p>Deploying the Assets VM     Deploys the Assets VM in the Air-gapped environment, bootstraps it and uploads all the Assets to the it.</p> </li> </ol>"},{"location":"software-install/eda-installation-overview/#deploying-eda","title":"Deploying EDA","text":"<ol> <li> <p>Preparing the EDAADM configuration file     This task describes the details of the EDAADM configuration file and how to set it up.</p> </li> <li> <p>Generating the Talos machine configurations     Using the <code>edaadm</code> tool and the configuration file, this task generates specific Talos machine configuration files for each Talos VM.</p> </li> <li> <p>Deploying the Talos virtual machines     This task describes how to use the Talos base image and machine configuration files to deploy the Talos VMs in your KVM or VMware vSphere environment.</p> </li> <li> <p>Bootstrap the Talos Kubernetes cluster     This task bootstraps the Talos Kubernetes environment using the VMs you have created.</p> </li> <li> <p>Installing the EDA application     Using the EDA Installation playground, this step installs EDA on the Kubernetes environment in the EDA nodes.</p> </li> </ol> <ol> <li> <p>Alpha support in the current release.\u00a0\u21a9</p> </li> <li> <p>This system might also be referred to as the \"tools-system\" further in this documentation.\u00a0\u21a9</p> </li> </ol>"},{"location":"software-install/exposing-ui-api/","title":"Exposing the EDA UI/API","text":"<p>In a regular cluster you typically have an Ingress or Gateway API controller that handles the external traffic and routes them to the services running inside the cluster. For instance, to let external users reach the EDA UI/API service. These controllers are not part of EDA installation, and are typically managed by the cluster administrator.</p> <p>Still, in this chapter we will talk about how to configure Ingress or Gateway resources to expose the EDA UI/API service particularly.</p> <p>EDA UI and API are exposed inside a cluster via the <code>eda-api</code> service of type \"LoadBalancer\" and its <code>apiserver</code> (port 80) and <code>apiserverhttps</code> (port 443) ports:</p> <pre><code>kubectl -n eda-system get service eda-api -o yaml | \\\nyq e '.spec.ports[0,1]' - #(1)!\n</code></pre> <ol> <li>Using <code>yq</code> to extract the service port configuration.</li> </ol> <pre><code>name: apiserver\nnodePort: 32609\nport: 80\nprotocol: TCP\ntargetPort: 9200\nname: apiserverhttps\nnodePort: 30302\nport: 443\nprotocol: TCP\ntargetPort: 9443\n</code></pre> <p>Despite having port 80 in the service configuration, EDA UI/API is only served over HTTPS inside the cluster, therefore the external traffic should be routed to the <code>apiserverhttps</code> port. Generally speaking, there are two modes of exposing the EDA UI/API service using Ingress or Gateway API:</p> <ol> <li>Terminating TLS on Ingress/Gateway     External users have their TLS session terminated on the Ingress/Gateway and then the another HTTPS connection is established from the Ingress/Gatway to the <code>eda-api</code> deployment via the same-named service and its <code>apiserverhttps</code> port.</li> <li>Pass-through TLS     External users have their TLS session transparently passed through Ingress/Gateway and terminated on the <code>eda-api</code> deployment that has internal TLS certificate configured.</li> </ol> <p>Terminating TLS on Ingress/Gateway has an undeniable benefit of allowing users to use their own TLS certificates on ingress. Whereas the pass-through mode uses the internal TLS certificate configured on the <code>eda-api</code> deployment and raise a warning in the browser since the certificate is not trusted.</p> <p>In this section we will show how both modes can be configured using Ingress and Gateway API resources.</p>"},{"location":"software-install/exposing-ui-api/#cert-manager","title":"Cert Manager","text":"<p>By default, Ingress controllers come with a self-generated TLS certificate to allow TLS termination in test and development environments. For production installations users strive to have an Ingress service with a trusted certificate configured using the domain name designated for EDA UI/API access.</p> <p>Creation of a TLS certificate is easy when using cert-manager - a Kubernetes-native way to automate the management and issuance of TLS certificates from various issuing sources. EDA itself uses cert-manager to issue the internal TLS certificates for various components, thus users can also leverage it and create the Issuer that will handle the certificate creation.</p> <p>Creation of an Issuer is out of the scope of this guide, and is well explained in the cert-manager documentation.</p>"},{"location":"software-install/exposing-ui-api/#ingress-nginx","title":"Ingress Nginx","text":"<p>Ingress Nginx is a popular community-managed Ingress Controller based on NGINX.</p>"},{"location":"software-install/exposing-ui-api/#terminating-tls-on-ingress","title":"Terminating TLS on Ingress","text":"<p>To configure Ingress Nginx to terminate the TLS on the Ingress, you can create an Ingress resource with the following configuration.</p> <p>The code block annotations explain the important fields of the resource.</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    nginx.ingress.kubernetes.io/backend-protocol: HTTPS #(1)!\n    cert-manager.io/issuer: letsencrypt-issuer #(2)!\n    nginx.ingress.kubernetes.io/add-base-url: \"false\"\n    nginx.ingress.kubernetes.io/affinity: cookie\n    nginx.ingress.kubernetes.io/proxy-buffer-size: 128k\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"600\"\n    nginx.ingress.kubernetes.io/session-cookie-name: route\n  name: ingress\n  namespace: eda-system #(3)!\nspec:\n  ingressClassName: nginx\n  rules: #(4)!\n    - host: eda.rocks\n      http:\n        paths:\n          - backend:\n              service:\n                name: eda-api\n                port:\n                  number: 443\n            path: /\n            pathType: Prefix\n  tls: #(5)!\n    - hosts:\n        - eda.rocks\n      secretName: eda-rocks-cert\n</code></pre> <ol> <li>EDA UI/API is only served over HTTPS inside the cluster, therefore the external traffic should be routed to TLS secured <code>apiserverhttps</code> port. For this reason we need to set HTTPS as a backend protocol.</li> <li>For cert-manager to issue the certificate, we need to configure the <code>cert-manager.io/issuer</code> annotation with the name of the <code>Issuer</code> resource that has to be present in the same namespace as the Ingress resource.</li> <li>If eda-api service is deployed in the <code>eda-system</code> namespace, we need to create the Ingress resource in the same namespace.</li> <li>The Ingress's <code>rules</code> section defines the access rules and the routing of the incoming requests. Here we say that the requests destined to the <code>eda.rocks</code> domain should be routed to the <code>eda-api</code> service and its 443 port.</li> <li>The <code>tls</code> section defines the TLS configuration for the Ingress. Here we say that the Ingress should use the <code>eda-rocks-cert</code> secret to terminate the TLS and the SAN field in the cert should contain <code>eda.rocks</code> domain.</li> </ol> <p>With an Ingress resource like this created, users would be able to access the EDA UI/API using the <code>eda.rocks</code> domain.</p>"},{"location":"software-install/exposing-ui-api/#gateway-api","title":"Gateway API","text":"<p>If you're riding the Gateway API wave, you can create a <code>Gateway</code> resource to define your cluster gateway. As with the Ingress, the choice is yours if you want to terminate the TLS on the Gateway or not.</p> <p>As a demonstration, we will create the Gateway resource with the TLS listener so that we will pass the TLS traffic to the EDA UI service, without terminating it on the Gateway.</p> <p>Here is how you can create the <code>Gateway</code> resource:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: gateway.networking.k8s.io/v1\nkind: Gateway\nmetadata:\n  name: eda-gw-https\n  namespace: eda-system\nspec:\n  gatewayClassName: cilium\n  listeners:\n    - allowedRoutes:\n        namespaces:\n          from: Same\n      name: tls-gw\n      port: 8080\n      protocol: TLS\n      tls:\n        mode: Passthrough\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;'EOF'\napiVersion: gateway.networking.k8s.io/v1\nkind: Gateway\nmetadata:\n  name: eda-gw-https\n  namespace: eda-system\nspec:\n  gatewayClassName: cilium\n  listeners:\n    - allowedRoutes:\n        namespaces:\n          from: Same\n      name: tls-gw\n      port: 8080\n      protocol: TLS\n      tls:\n        mode: Passthrough\n\nEOF\n</code></pre> <p>Now, let's create the <code>TLSRoute</code> resource that will bind our <code>Gateway</code> to the <code>eda-api</code> resource to provide the connectivity to the EDA UI:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: gateway.networking.k8s.io/v1alpha2\nkind: TLSRoute\nmetadata:\n  name: eda-ui\n  namespace: eda-system\nspec:\n  parentRefs:\n    - name: eda-gw-https\n      namespace: eda-system\n  rules:\n    - backendRefs:\n        - kind: Service\n          name: eda-api\n          port: 443\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;'EOF'\napiVersion: gateway.networking.k8s.io/v1alpha2\nkind: TLSRoute\nmetadata:\n  name: eda-ui\n  namespace: eda-system\nspec:\n  parentRefs:\n    - name: eda-gw-https\n      namespace: eda-system\n  rules:\n    - backendRefs:\n        - kind: Service\n          name: eda-api\n          port: 443\n\nEOF\n</code></pre> <p>Now you should be able to access the EDA UI by navigating to the Gateway's URL.</p>"},{"location":"software-install/preparing-for-installation/","title":"Preparing for installation","text":""},{"location":"software-install/preparing-for-installation/#download-the-eda-installation-playground","title":"Download the EDA Installation playground","text":"<p>Ensure that your Linux installation<sup>1</sup> environment meets the requirements described in Installation platform requirements.</p> <p>Clone the playground repository to your tools-system.</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; cd playground \n</code></pre>"},{"location":"software-install/preparing-for-installation/#installing-additional-tools","title":"Installing additional tools","text":"<p>Download additional tools that can be used during the installation.</p> <pre><code>make download-tools\n</code></pre> <p>As a result of this command, the <code>kind</code>, <code>kubectl</code>, <code>kpt</code>, and <code>yq</code> utilities will be installed in the <code>./tools</code> directory.</p>"},{"location":"software-install/preparing-for-installation/#obtaining-the-eda-packages","title":"Obtaining the EDA packages","text":"<p>EDA is packaged using the Kubernetes Package Tool (kpt). EDA uses this package manager tool to install core EDA components. The installer downloads two kpt packages by downloading their relevant git repositories.</p> <p>To obtain the EDA package, enter the following command:</p> <pre><code>make download-pkgs\n</code></pre> <p>This command downloads the following git repositories to their respective directories:</p> <ul> <li>EDA kpt package in the <code>eda-kpt</code> directory</li> <li>EDA built-in catalog in the <code>catalog</code> directory</li> </ul>"},{"location":"software-install/preparing-for-installation/#download-the-eda-edaadm-repository","title":"Download the EDA EDAADM repository","text":"<p>Ensure that your Linux installation environment meets the requirements described in Installation platform requirements.</p> <p>Clone the EDAADM repository to your tools system and change to the directory.</p> <pre><code>git clone https://github.com/nokia-eda/edaadm &amp;&amp; cd edaadm\n</code></pre>"},{"location":"software-install/preparing-for-installation/#download-extra-tools","title":"Download extra tools","text":""},{"location":"software-install/preparing-for-installation/#bundle-tools","title":"Bundle tools","text":"<p>Go to the bundles directory in the <code>edaadm</code> repository.  </p> execute from the root of the edaadm repository<pre><code>cd bundles\n</code></pre> <p>And download the tools for the bundles.</p> execute from the bundler directory<pre><code>make download-tools\n</code></pre> <p>This step downloads<sup>2</sup> the <code>edaadm</code> CLI tool for your architecture in the <code>edaadm/bundles/tools</code> directory.</p> <p>The <code>edaadm</code> tool is used to generate configuration files for use while deploying the Talos Linux virtual machines and the Kubernetes environment. You can copy or move the <code>edaadm</code> tool from the <code>./tools</code> directory to a location in your <code>$PATH</code> to make it available in your shell for future use.</p>"},{"location":"software-install/preparing-for-installation/#kpt-tools","title":"kpt tools","text":"<p>After downloading the tools for bundles, download the tools for kpt. Go to the kpt directory in the <code>edaadm</code> repository.</p> relative path assumes you are in the bundles directory<pre><code>cd ../kpt\n</code></pre> <p>And download the tools for the kpt package.</p> <pre><code>make download-tools\n</code></pre> <p>This step downloads the <code>kpt</code> and <code>kubectl</code> tools in the <code>edaadm/kpt/tools</code> directory.</p>"},{"location":"software-install/preparing-for-installation/#download-the-talos-machine-image","title":"Download the Talos machine image","text":"<p>The <code>edaadm</code> tool provides you with the URL to download the latest Talos machine image for use with VMware or KVM.</p> <p>To deploy the Talos Kubernetes environment, download the Talos Machine image based on the environment in which you want to deploy the VMs.</p>"},{"location":"software-install/preparing-for-installation/#downloading-the-kvm-image","title":"Downloading the KVM image","text":"<p>Use the <code>edaadm</code> tool to display the URL from where you can download the latest image for use with KVM for the supported Talos version.</p> <pre><code>edaadm images --mach-type nocloud\n</code></pre> <pre><code>Schematic ID is :376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba\nAsset URLs are:\nhttps://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/nocloud-amd64.iso\nhttps://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/nocloud-amd64.raw.xz\n</code></pre> <p>Download the <code>nocloud-amd64.iso</code> image from the ISO URL, filepath.iso.</p> <p>You can download using your browser or you can use the curl command.</p>"},{"location":"software-install/preparing-for-installation/#downloading-the-vmware-ova-image","title":"Downloading the VMware OVA image","text":"<p>Use the <code>edaadm</code> tool to display the URL from where you can download latest image for use with VMware vSphere for the supported Talos version.</p> <pre><code>edaadm images --mach-type vmware\n</code></pre> <pre><code>Schematic ID is :903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40\nAsset URLs are:\nhttps://factory.talos.dev/image/903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40/v1.9.2/vmware-amd64.iso\nhttps://factory.talos.dev/image/903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40/v1.9.2/vmware-amd64.ova\n</code></pre> <p>Download the <code>vmware-amd64.ova</code> image from the OVA URL, filepath.ova.</p> <p>You can download using your browser or you can use the curl or wget commands. You can also use the URL directly with the ovftool command to deploy the OVA to your VMware vSphere environment.</p> <ol> <li> <p>This system might also be referred to as the \"tools-system\" further in this documentation.\u00a0\u21a9</p> </li> <li> <p>The <code>edaadm</code> binary for different platforms can be manually downloaded from https://github.com/nokia-eda/edaadm/releases/.\u00a0\u21a9</p> </li> </ol>"},{"location":"software-install/air-gapped/","title":"Air-gapped setup","text":"<p>In case the installation will be Air-gapped, this section provides steps on how to set up the Assets VM and load it with the necessary assets for deploying EDA in an Air-gapped environment.</p>"},{"location":"software-install/air-gapped/#conceptual-overview","title":"Conceptual Overview","text":"<p>In an Air-Gapped environment, an Assets VM is deployed that will provide the services that will serve the container images, git repositories and artifacts used during installation of the EDA Talos Kubernetes cluster and EDA itself.</p> <p>The goal of the Air-Gapped solution design is to allow flexibility in the deployment and content of the Assets VM in the Air-Gapped environment. By providing a standalone Assets VM without any assets automatically included, there is freedom of choice of what assets are uploaded to the Assets VM.</p> <p>It allows for a single Assets VM to be used for multiple deployments and versions of EDA, as the assets for multiple versions of EDA can be uploaded to the same Assets VM.</p> <p>Similarly, by splitting up the assets in bundles, it is possible to only upload specific content to the Assets VM. The bundle concept also allows for the creation of custom bundles, for instance for 3<sup>rd</sup> party Apps, so they can also be hosted on the Assets VM.</p>"},{"location":"software-install/air-gapped/#environments","title":"Environments","text":"<p>Two environments will be discussed and used in an air-gapped installation:</p> Public Environment This environment has internet access. You use a system with Internet access to create the Assets VM image and to download all the necessary assets and tools. Air-Gapped Environment This environment that does not have internet access. It is the environment in which EDA is deployed. <p>In each environment, you must have a system from which you can execute the steps. You can use a system to first connect to the internet, execute the steps for the public network and then move the same system to the Air-Gapped environment to continue. Or, you can have two systems, and you would copy the data from the public system to the Air-Gapped system. More details on the requirements for these systems are included later in this document.</p> <p>For each section, there will be a note in which environment the section applies.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/","title":"Deploying the Assets VM","text":"<p>Caution</p> <p>This applies to the Air-Gapped environment, and is executed in the air-gapped tools-system.</p> <p>Deploying the Assets VM is very similar to deploying an EDA Kubernetes cluster.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#preparing-the-assets-vm-edaadm-configuration-file","title":"Preparing the Assets VM EDAADM Configuration File","text":"<p>The EDAADM configuration file for the Assets VM is very similar to the EDAADM configuration file of a EDA Kubernetes environment, with a few minor changes:</p> <ul> <li>It is a config file for a single machine.</li> <li>The <code>clusterName</code> must be unique and different from the EDA Kubernetes cluster.</li> <li> <p>The following additions are made to the machine definition:</p> <pre><code>enableImageCache: true\nlocalPathProvisioner: \"/var/local-path-provisioner\"\n</code></pre> </li> </ul> <p>Otherwise, the configuration is very similar to the Preparing the EDAADM configuration file section.</p> <p>Note</p> <p>The Assets VM only needs one network interface, preferably on the OAM network of the EDA Kubernetes cluster. It must be reachable from the OAM network of the EDA Kubernetes cluster.</p> <p>Caution</p> <p>The <code>edaadm</code> tool still expects the definition of a storage disk in the machine definition, but this can be a reference to a non-existing disk.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#example-assets-vm-edaadm-configuration-file","title":"Example Assets VM EDAADM Configuration file","text":"<p>The below configuration file is an example for an Assets VM using local DNS and NTP servers.</p> <pre><code>version: 25.4.1\nclusterName: eda-airgap-assets\nmachines:\n    - name: eda-assets.domain.tld\n      endpoint: 192.0.2.228\n      enableImageCache: true\n      localPathProvisioner: \"/var/local-path-provisioner\"\n      interfaces:\n        - name: eth0\n          dhcp: false\n          interface: eth0\n          addresses:\n            - 192.0.2.228/23\n          routes:\n            - network: 0.0.0.0/0\n              gateway: 192.0.2.1\n          mtu: 9000\n      disks:\n        os: /dev/vda\n        storage: /dev/vdb\nk8s:\n    stack: ipv4\n    primaryNode: eda-assets.domain.tls\n    endpointUrl: https://192.0.2.228:6443\n    allowSchedulingOnControlPlanes: true\n    control-plane:\n        - eda-assets.domain.tld\n    time:\n        disabled: false\n        servers:\n            - 192.0.2.253\n            - 192.0.2.254\n    nameservers:\n        servers:\n            - 192.0.2.254\n            - 192.0.2.253\n</code></pre>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#generating-the-talos-machine-configuration-files","title":"Generating the Talos Machine Configuration Files","text":"<p>After creating the Assets VM EDAADM configuration file, the next step is to generate all the configuration files that are necessary to deploy the Kubernetes environment using Talos.</p> <p>This step is very similar to the Generating the Talos machine configurations section.</p> <p>Use the <code>edaadm</code> tool to generate the Talos configuration out of the EDAADM configuration file:</p> <pre><code>edaadm generate -c eda-assets-deployment.yaml\n</code></pre> <p>The output should look similar to the following (a portion has been removed):</p> <pre><code>ConfigFile is eda-assets-deployment.yaml\n...\n[1/5] Validating Machines\n[1/5] Validated Machines\n[2/5] Validating Primary Node\n[2/5] Validated Primary Node\n[3/5] Validating Endpoint URL\n[3/5] Validated Endpoint URL\n[4/5] Validating Virtual IP\n[4/5] Validated Virtual IP\n[5/5] Validating Storage\n[5/5] Validated Storage\n[  OK  ] Spec is validated\nGenerating secrets for eda-airgap-assets\nCreated eda-airgap-assets/secrets.yaml\ngenerating PKI and tokens\nCreated eda-airgap-assets/eda-assets.domain.tld.yaml\nCreated eda-airgap-assets/talosconfig.yaml\nCreated eda-airgap-assets/rook-ceph-operator-values.yaml\nCreated eda-airgap-assets/rook-ceph-cluster-values.yaml\n</code></pre>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#deploy-the-assets-vm","title":"Deploy the Assets VM","text":"<p>The Assets VM can be deployed on a KVM or VMware vSphere environment. This process is very similar to the documented procedures in the Deploying the Talos virtual machines section.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#creating-the-vm-on-a-bridged-network-on-kvm","title":"Creating the VM on a bridged network on KVM","text":"<p>Caution</p> <p>This procedure is executed on the KVM Hypervisor which will host the Assets VM.</p> <p>Following are the differences from the procedure in the Creating the VM on bridged networks on KVM section:</p> <ul> <li>Use the Assets VM ISO image generated by in the Creating the KVM Assets VM Image step, instead of the standard Talos KVM image.</li> <li>Use the Talos machine config file generated in the Generating the Talos Machine Configuration Files step for <code>user-data</code>.</li> <li>Make sure the root disk is set to 300GB instead of 100GB.</li> <li>No need to create a storage disk on the VM.</li> </ul> <p>An example <code>virt-install</code> command to deploy the Assets VM in KVM:</p> <pre><code>virt-install -n eda-assets \\ \n  --description \"EDA Assets Vm for EDA\" \\ \n  --noautoconsole --os-type=generic \\ \n  --memory 16384 --vcpus 4 --cpu host \\ \n  --disk eda-assets-rootdisk.qcow2,format=qcow2,bus=virtio,size=300 \\ \n  --cdrom eda-asset-vm-nocloud-amd64.iso  \\ \n  --disk eda-assets-data.iso,device=cdrom \\ \n  --network bridge=br0,model=virtio\n</code></pre>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#creating-the-vm-on-a-bridged-network-on-vmware-vsphere","title":"Creating the VM on a bridged network on VMware vSphere","text":"<p>Caution</p> <p>This procedure is executed on the Air-Gapped tools-system.</p> <p>Following are the differences from the procedure in the Creating the VM on bridged networks on VMware vSphere section:</p> <ul> <li>Use the Assets VM ISO image generated by in the Creating the VMware Assets VM Image step, instead of the standard Talos VMware image.</li> <li>Use the Talos machine config file generated in the Generating the Talos Machine Configuration Files step for <code>user-data</code>.</li> <li>No need to create a storage disk on the VM.</li> <li>After deploying the VM using the OVA image:<ul> <li>Increase the number of vCPUs to 4.</li> <li>Increase the memory to 16G.</li> <li>Increase the main disk size to 300G. On boot, Talos automatically extends the file system.</li> <li>Enable 100% resource reservation for the CPU, memory and disk.</li> </ul> </li> </ul> <p>Create a base64 encoded hash from the Talos machine configuration for the node. For example:</p> <pre><code>export NODECONFIG=$(base64 -i eda-assets.domain.tld.yaml)\n</code></pre> <p>An example <code>ovftool</code> command to deploy the Assets VM in VMware vSphere:</p> <pre><code>ovftool --acceptAllEulas --noSSLVerify \\ \n -dm=thin \\ \n -ds=DATASTORE \\ \n -n=eda-assets \\ \n --net:\"VM Network=OAM\" \\ \n --prop:talos.config=\"${NODECONFIG}\" \\ \neda-asset-vm-vmware-amd64.ova \\ \nvi://administrator%40vsphere.local@vcenter.domain.tld/My-DC/host/My-Cluster/Resources/My-Resource-Group\n</code></pre>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#bootstrap-the-assets-vm","title":"Bootstrap the Assets VM","text":"<p>Similar to bootstrapping an EDA Kubernetes cluster, the Assets VM can be bootstrapped using the <code>edaadm</code> tool.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#bootstrapping-kubernetes-on-the-assets-vm","title":"Bootstrapping Kubernetes on the Assets VM","text":"<p>Use the <code>edaadm</code> command with the EDAADM configuration file for the Assets VM to bootstrap Kubernetes:</p> <pre><code>edaadm boostrap-k8s -c eda-assets-deployment.yaml\n</code></pre>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#obtaining-the-kubernetes-config-file-for-kubectl","title":"Obtaining the Kubernetes Config File for kubectl","text":"<p>Use the <code>edaadm</code> command to obtain the Kubernetes configuration file for use with kubectl.</p> <ol> <li> <p>Obtain the Kubernetes configuration file.</p> <p>Execute the following command in the folder with the <code>eda-assets-deployment.yaml</code> EDAADM configuration file.</p> <pre><code>edaadm get-kubeconfig -c eda-assets-deployment.yaml\n</code></pre> </li> <li> <p>Configure the Kubernetes configuration file in your environment.</p> <p>You can configure your environment to use the \u200bkubeconfig\u200b file for use with the <code>kubectl</code> command.</p> <pre><code>export KUBECONFIG=eda-airgap-assets/kubeconfig\n</code></pre> </li> <li> <p>Inspect your server and check if all nodes are up and running.</p> <p>You can use the typical <code>kubectl</code> commands.</p> <pre><code>kubectl get nodes\n</code></pre> </li> </ol> <p>When the node is up and ready, continue with deploying the Assets VM services.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#deploying-the-assets-vm-services","title":"Deploying the Assets VM Services","text":"<p>After deploying and bootstrapping the Assets VM itself, the container registry, git server and web server need to be deployed.</p> <ol> <li> <p>Go to the correct directory in the <code>edaadm</code> repository.</p> <p>In the <code>edaadm</code> repository that you have cloned or downloaded, go to the <code>kpt</code> folder.</p> <pre><code>cd path/to/edaadm-repository/kpt\n</code></pre> </li> <li> <p>Deploy the Assets VM services.</p> <p>Make sure your kubeconfig environment variable points to the kubeconfig of the Assets VM as you got it from the Obtaining the Kubernetes Config File for <code>kubectl</code> section.</p> <pre><code>make eda-setup-shipyard\n</code></pre> </li> </ol>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#uploading-the-assets-to-the-assets-vm","title":"Uploading the Assets to the Assets VM","text":"<p>Now that the Assets VM and its services are up and running, upload all the assets that you downloaded previously to the Assets VM.</p> <ol> <li> <p>Go to the correct directory in the <code>edaadm</code> repository.</p> <p>In the <code>edaadm</code> repository that you have cloned or downloaded, go to the <code>bundles</code> folder.</p> <pre><code>cd path/to/edaadm-repository/bundles\n</code></pre> </li> <li> <p>Upload the assets.</p> <p>Make sure your kubeconfig environment variable points to the kubeconfig of the Assets VM as you got it from the Obtaining the Kubernetes Config File for <code>kubectl</code> section.</p> <p>Make sure to replace the <code>ASSET_HOST</code> IP with the IP of your Asset VM.</p> <pre><code>make load-all-bundles \\\n  ASSET_HOST=192.0.2.228 \\\n  ASSET_HOST_GIT_USERNAME=\"ZWRh\" \\\n  ASSET_HOST_GIT_PASSWORD=\"ZWRh\" \\\n  ASSET_HOST_ARTIFACTS_USERNAME=\"ZWRh\" \\\n  ASSET_HOST_ARTIFACTS_PASSWORD=\"ZWRh\"\n</code></pre> <p>Note</p> <p>The username and passwords will be configurable in the near future.</p> </li> </ol> <p>Once all uploads have finished successfully, the Assets VM is ready for use with the installation process of EDA.</p>"},{"location":"software-install/air-gapped/downloading-the-assets/","title":"Downloading the Assets","text":"<p>Caution</p> <p>This applies to the Public environment, and is executed in the public tools-system.</p> <p>There are two types of assets that need to be downloaded:</p> <ul> <li>Assets Bundles - The bundles that contain all the resources needed to run Nokia EDA. This includes container images, repositories, tools and more.</li> <li>Base Talos VM Image - The base images for the EDA Kubernetes nodes (VMs) that will run the EDA application.</li> </ul> Make sure the user in the public tools-system is logged in for <code>docker.io</code>. <p>Docker has started to rate limit pulling images from docker.io more aggressively. To avoid the rate limit, ensure that you have a user account on docker.io and that you logged into it on your public tools-system with:</p> <pre><code>docker login docker.io\n</code></pre>"},{"location":"software-install/air-gapped/downloading-the-assets/#downloading-the-assets-bundles","title":"Downloading the Assets Bundles","text":"<ol> <li> <p>Go to the correct directory in the <code>edaadm</code> repository.</p> <p>In the <code>edaadm</code> repository that you have cloned or downloaded, go to the <code>bundles</code> folder.</p> <pre><code>cd path/to/edaadm-repository/bundles\n</code></pre> </li> <li> <p>Download the Assets Bundles.</p> <p>The following command will download all Assets Bundles defined in the <code>bundles</code> folder and store them in the <code>eda-cargo</code> folder.</p> <pre><code>make save-all-bundles\n</code></pre> Downloading individual bundles <p>In case individual bundles need to be downloaded, use the following command to list the available bundles:</p> <pre><code>make ls-bundles\n</code></pre> <p>Using the following command, you can then use the following command to download a specific bundle:</p> <pre><code>make save-&lt;bundle-name&gt;\n</code></pre> </li> </ol>"},{"location":"software-install/air-gapped/downloading-the-assets/#downloading-the-base-talos-vm-images","title":"Downloading the Base Talos VM Images","text":"<p>To deploy the EDA Kubernetes VMs, the base Talos image is needed for KVM or VMware vSphere. This can also be done using the edaadm bundles folder as described below.</p> <ol> <li> <p>Go to the correct directory in the <code>edaadm</code> repository.</p> <p>In the <code>edaadm</code> repository that you have cloned or downloaded, go to the <code>bundles</code> folder.</p> <pre><code>cd path/to/edaadm-repository/bundles\n</code></pre> </li> <li> <p>Download the base Talos images.</p> <p>The following command downloads all images for both KVM and VMware vSphere.</p> <pre><code>make download-talos-stock-boot-media\n</code></pre> <p>The output should look similar to the following:</p> <pre><code>--&gt; INFO: List of goals: download-talos-stock-boot-media\n--&gt; Downloading boot media for vmware\n    From: https://factory.talos.dev/image/903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40/v1.9.2/vmware-amd64.iso\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/vmware-amd64.iso\n############################################################################################################################### 100.0%\n    From: https://factory.talos.dev/image/903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40/v1.9.2/vmware-amd64.ova\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/vmware-amd64.ova\n############################################################################################################################### 100.0%\n--&gt; Downloading boot media for nocloud\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/nocloud-amd64.iso\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/nocloud-amd64.iso\n############################################################################################################################### 100.0%\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/nocloud-amd64.raw.xz\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/nocloud-amd64.raw.xz\n############################################################################################################################### 100.0%\n--&gt; Downloading boot media for metal\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/metal-amd64.iso\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/metal-amd64.iso\n############################################################################################################################### 100.0%\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/metal-amd64.raw.zst\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/metal-amd64.raw.zst\n############################################################################################################################### 100.0%\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/metal-amd64.qcow2\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/metal-amd64.qcow2\n############################################################################################################################### 100.0%\n</code></pre> </li> </ol>"},{"location":"software-install/air-gapped/preparing-the-air-gapped-environment/","title":"Preparing the Air-gapped environment","text":"<p>After downloading all the tools, packages, repositories, bundles and images, the data needs to be made available in the Air-Gapped Enviroment. Two options are available:</p> <ol> <li>Move the Public tools-system to the Air-Gapped environment. For instance, if it is a laptop or a VM, you can easily move to the Air-Gapped environment by changing its network configuration.</li> <li>Copy the data from the Public tools-system to the Air-Gapped tools-system using a USB key or a temporary network connection. The data should include:<ul> <li>The playground repository which includes the tools and standard installation KPT packages.</li> <li>The edaadm repository which includes the bundles folder holding the <code>eda-cargo</code> folder that has all the Air-Gapped data (bundles, asset VM image and Talos base VM images).</li> </ul> </li> </ol>"},{"location":"software-install/air-gapped/preparing-the-air-gapped-environment/#loading-the-kpt-setters-image","title":"Loading the KPT Setters image","text":"<p>Note</p> <p>This applies to the Air-Gapped environment, and is executed in the air-gapped tools-system</p> <p>The procedures for setting up the Assets VM and installing EDA use KPT. For both tasks, you may need to configure some setting in the KPT packages; KPT uses a container called kpt-apply-setters for this purpose. This image must be present in the local Docker image cache of the air-gapped tools-system.</p> <p>The container image is part of the <code>eda-bundle-tools</code> bundle in the <code>edaadm/bundles</code> list. If you used the <code>save-all-bundles</code> option when downloading the bundles, you will have that bundle on your air-gapped tools-system. If you do not have it yet, you can download the bundle on the public tools-system and copy over the content of the bundle to the air-gapped tools-system before executing the steps.</p> <p>To load the <code>kpt-apply-setters</code> image from the <code>eda-bundle-tools</code> bundle, follow these steps:</p> <ol> <li> <p>Go to the correct directory in the <code>edaadm</code> repository</p> <p>In the <code>edaadm</code> repository that you have cloned or downloaded, go to the <code>bundles</code> folder.</p> <pre><code>cd path/to/edaadm-repository/bundles\n</code></pre> </li> <li> <p>Import the image into the local docker image cache</p> <p>Note that the version of the bundle might update to a newer version in the future. In that case, replace the <code>1-0-0</code> with the appropriate version and the correct <code>kpt-apply-setters</code> version as well.</p> <pre><code>docker load -i eda-cargo/eda-bundle-tools-1-0-0/images/srl-labs-kpt-apply-setters-0-1-1\n</code></pre> </li> </ol>"},{"location":"software-install/air-gapped/preparing-the-assets-vm/","title":"Preparing the Assets VM","text":"<p>The Assets VM will run as a single Virtual Machine inside the Air-Gapped environment. This VM will hold all of the assets and can be used across multiple deployments and EDA versions, containing the assets for multiple versions.</p> <p>These steps help create the Assets VM from a base Talos VM image for KVM or VMware, rebuild it with the local cache needed to deploy the VM, Kubernetes and the Assets VM Services in the Air-Gapped environment.</p> <p>Caution</p> <p>This applies to the Public environment, and is executed in the public tools-system</p>"},{"location":"software-install/air-gapped/preparing-the-assets-vm/#preparing-to-create-the-assets-vm-image","title":"Preparing to create the Assets VM image","text":"<p>Before creating the Assets VM Image for a specific environment, the following steps need to be taken:</p> <ol> <li> <p>Go to the correct directory in the <code>edaadm</code> repository.</p> <p>In the <code>edaadm</code> repository that you have cloned or downloaded, go to the <code>bundles</code> folder.</p> <pre><code>cd path/to/edaadm-repository/bundles\n</code></pre> </li> <li> <p>Log in to <code>ghcr.io</code> with <code>docker</code> so the system can pull private images from <code>ghcr.io</code>.</p> <p>Log in with a user account that has access to images hosted by Nokia EDA; for example, the <code>nokia-eda-bot</code> user.</p> <pre><code>docker login ghcr.io -u nokia-eda-bot\n</code></pre> Getting the password/token for the <code>nokia-eda-bot</code> user <p>The token (password) for the <code>nokia-eda-bot</code> user is present in every bundle file in the <code>edaadm</code> repository, where it is twice encoded using <code>base64</code>.</p> <p>This token is a read-only token and is not a secret, no sensitive information is accessible using this token.</p> </li> <li> <p>Prepare the image cache for the Assets VM.</p> <p>This step downloads and prepares an image cache from which the Assets VM is built.</p> <pre><code> make create-assets-host-bootstrap-image-cache\n</code></pre> </li> </ol>"},{"location":"software-install/air-gapped/preparing-the-assets-vm/#creating-the-kvm-assets-vm-image","title":"Creating the KVM Assets VM Image","text":"<p>Note</p> <p>This is only needed if you plan to deploy the Assets VM on KVM.</p> <p>Follow these steps to create the Assets VM Image for KVM. This will generate an ISO file based on the Talos VM base image containing a local cache. This image is different from the base Talos image ISO file that you will use for the EDA Kubernetes VMs, but is based on it.</p> <ol> <li> <p>Go to the correct directory in the <code>edaadm</code> repository.</p> <p>In the <code>edaadm</code> repository that you have cloned or downloaded, go to the <code>bundles</code> folder.</p> <pre><code>cd path/to/edaadm-repository/bundles\n</code></pre> </li> <li> <p>Generate the Assets VM ISO for KVM.</p> <p>Execute the following command to generate the KVM Talos ISO for the Assets VM.</p> <pre><code>make create-asset-vm-nocloud-boot-iso\n</code></pre> <p>The output should look similar to:</p> <pre><code>--&gt; INFO: List of goals: create-asset-vm-nocloud-boot-iso\ndocker pull ghcr.io/siderolabs/imager:v1.9.2\nv1.9.2: Pulling from siderolabs/imager\nDigest: sha256:b99d29d04df9eea89d50cb0d13d57e1e035e54cbd9970a26af99b18154e443a9\nStatus: Image is up to date for ghcr.io/siderolabs/imager:v1.9.2\nghcr.io/siderolabs/imager:v1.9.2\nskipped pulling overlay (no overlay)\nprofile ready:\narch: amd64\nplatform: nocloud\nsecureboot: false\nversion: v1.9.2\ninput:\n  kernel:\n    path: /usr/install/amd64/vmlinuz\n  initramfs:\n    path: /usr/install/amd64/initramfs.xz\n  baseInstaller:\n    imageRef: ghcr.io/siderolabs/installer:v1.9.2\n  imageCache:\n    imageRef: \"\"\n    ociPath: /image-cache.oci\noutput:\n  kind: iso\n  imageOptions:\n    diskSize: 2147483648\n  outFormat: raw\nskipped initramfs rebuild (no system extensions)\nkernel command line: talos.platform=nocloud console=tty1 console=ttyS0 net.ifnames=0 talos.halt_if_installed=1 init_on_alloc=1 slab_nomerge pti=on consoleblank=0 nvme_core.io_timeout=4294967295 printk.devkmsg=on ima_template=ima-ng ima_appraise=fix ima_hash=sha512\nISO ready\noutput asset path: /out/nocloud-amd64.iso\n</code></pre> </li> <li> <p>Rename the KVM Assets VM image.</p> <p>Rename the generated image to a convenient name so that you can copy or use it in the future.</p> <pre><code>mv eda-cargo/talos-asset-vm-boot-imgs/nocloud-amd64.iso eda-cargo/talos-asset-vm-boot-imgs/eda-asset-vm-nocloud-amd64.iso\n</code></pre> </li> </ol>"},{"location":"software-install/air-gapped/preparing-the-assets-vm/#creating-the-vmware-assets-vm-image","title":"Creating the VMware Assets VM Image","text":"<p>Note</p> <p>This is only needed if you plan to deploy the Assets VM on VMware vSphere.</p> <p>Follow these steps to create the Assets VM Image for VMware vSphere. This will generate an ISO file based on the Talos VM base image containing a local cache. This image is different from the base Talos image ISO file that you will use for the EDA Kubernetes VMs, but is based on it.</p> <ol> <li> <p>Go to the correct directory in the <code>edaadm</code> repository.</p> <p>In the <code>edaadm</code> repository that you have cloned or downloaded, go to the <code>bundles</code> folder.</p> <pre><code>cd path/to/edaadm-repository/bundles\n</code></pre> </li> <li> <p>Generate the Assets VM OVA for VMware vSphere.</p> <p>Execute the following command to generate the VMware vSphere Talos OVA for the Assets VM.</p> <pre><code>make create-asset-vm-vmware-boot-ova\n</code></pre> <p>The output should look similar to:</p> <pre><code>--&gt; INFO: List of goals: create-asset-vm-vmware-boot-ova\ndocker pull ghcr.io/siderolabs/imager:v1.9.2\nv1.9.2: Pulling from siderolabs/imager\nDigest: sha256:b99d29d04df9eea89d50cb0d13d57e1e035e54cbd9970a26af99b18154e443a9\nStatus: Image is up to date for ghcr.io/siderolabs/imager:v1.9.2\nghcr.io/siderolabs/imager:v1.9.2\nskipped pulling overlay (no overlay)\nprofile ready:\narch: amd64\nplatform: vmware\nsecureboot: false\nversion: v1.9.2\ninput:\n  kernel:\n    path: /usr/install/amd64/vmlinuz\n  initramfs:\n    path: /usr/install/amd64/initramfs.xz\n  baseInstaller:\n    imageRef: ghcr.io/siderolabs/installer:v1.9.2\n  imageCache:\n    imageRef: \"\"\n    ociPath: /image-cache.oci\noutput:\n  kind: image\n  imageOptions:\n    diskSize: 2147483648\n    diskFormat: ova\n  outFormat: raw\nskipped initramfs rebuild (no system extensions)\nkernel command line: talos.platform=vmware talos.config=guestinfo console=tty0 console=ttyS0 earlyprintk=ttyS0,115200 net.ifnames=0 init_on_alloc=1 slab_nomerge pti=on consoleblank=0 nvme_core.io_timeout=4294967295 printk.devkmsg=on ima_template=ima-ng ima_appraise=fix ima_hash=sha512\ndisk image ready\noutput asset path: /out/vmware-amd64.ova    \n</code></pre> </li> <li> <p>Rename the VMware vSphere Assets VM image.</p> <p>Rename the generated image to a convenient name so that you can copy or use it in the future.</p> <pre><code>mv eda-cargo/talos-asset-vm-boot-imgs/vmware-amd64.ova eda-cargo/talos-asset-vm-boot-imgs/eda-asset-vm-vmware-amd64.ova\n</code></pre> </li> </ol>"},{"location":"software-install/deploying-eda/","title":"Deploying EDA","text":"<p>These are the major steps for installing the EDA deployment. This applies to both Air-gapped installations and Internet based installations. Some steps will differ depending on the type of install, this will be clearly called out highlighting both options.</p> <ol> <li> <p>Preparing the EDAADM configuration file     This task describes the details of the EDAADM configuration file and how to set it up.</p> </li> <li> <p>Generating the Talos machine configurations     Using the EDA ADM tool and the configuration file, this task generates specific Talos machine configuration files for each Talos VM.</p> </li> <li> <p>Deploying the Talos virtual machines     This task describes how to use the Talos base image and machine configuration files to deploy the Talos VMs in your KVM or VMware vSphere environment.</p> </li> <li> <p>Bootstrap the Talos Kubernetes cluster     This task bootstraps the Talos Kubernetes environment using the VMs you have created.</p> </li> <li> <p>Installing the EDA application     Using the EDA Installation playground, this step installs EDA on the Kubernetes environment in the EDA nodes.</p> </li> </ol>"},{"location":"software-install/deploying-eda/bootstrap-the-talos-kubernetes-cluster/","title":"Bootstrap the Talos Kubernetes cluster","text":"<p>When all the virtual machines are deployed and running, you can set up the Kubernetes cluster on the virtual machines using Talos.</p> <p>Note</p> <p>The procedures in this chapter use the <code>edaadm</code> command. Ensure that the command is available, as well as the original EDAADM configuration file from which you generated Talos files.</p>"},{"location":"software-install/deploying-eda/bootstrap-the-talos-kubernetes-cluster/#bootstrapping-kubernetes-on-the-primary-node","title":"Bootstrapping Kubernetes on the primary node","text":"<p>After booting the Talos VMs, you can now bootstrap the Kubernetes cluster using the <code>edaadm</code> command.</p> <p>Execute the following command:</p> <pre><code>edaadm bootstrap-k8s -c eda-input-6-node.yaml #(1)!\n</code></pre> <ol> <li><code>-c</code>: Specifies the EDAADM configuration file.</li> </ol> <p>Wait for several minutes for the Kubernetes cluster to come up and for all the nodes join the cluster. The process should take less than 15 minutes.</p>"},{"location":"software-install/deploying-eda/bootstrap-the-talos-kubernetes-cluster/#obtaining-the-kubernetes-config-file-for-kubectl","title":"Obtaining the Kubernetes config file for kubectl","text":"<p>Use the talosctl command to obtain the Kubernetes configuration file for use with kubectl.</p> <p>Obtain the Kubernetes configuration file with:</p> <pre><code>edaadm get-kubeconfig -c eda-6-node-deployment.yaml #(1)!\n</code></pre> <ol> <li><code>-c</code>: Specifies the EDAADM configuration file.</li> </ol> <p>You can configure your environment to use the <code>\u200bkubeconfig</code>\u200b file for use with the kubectl command.</p> <pre><code>export KUBECONFIG=eda-compute-cluster/kubeconfig\n</code></pre> <p>Inspect your k8s cluster and check if all nodes are up and running.</p> <pre><code>kubectl get nodes\n</code></pre> <p>When all the nodes are up and Kubernetes is stable, continue with Setting up the Rook Ceph storage cluster.</p>"},{"location":"software-install/deploying-eda/bootstrap-the-talos-kubernetes-cluster/#setting-up-the-rook-ceph-storage-cluster","title":"Setting up the Rook Ceph storage cluster","text":"<p>EDA uses Rook Ceph as a secure, distributed, and redundant data store for all the data it stores. Using Ceph guarantees redundancy and high availability of all data by providing multiple copies of all data. The following steps guide you through the configuration and deployment of Rook Ceph.</p> <ol> <li> <p>Add the Rook Ceph Helm chart.</p> <p>Caution</p> <p>Only do this step for an Internet based installation, not for an Air-Gapped installation.</p> <pre><code>helm repo add rook-release https://charts.rook.io/release\n</code></pre> </li> <li> <p>Using the <code>rook-ceph-operator-values.yaml</code> file that edaadm generated based on the configuration, deploy the Rook Ceph Operator.</p> Internet based installationAir-gapped installation <pre><code>helm install --create-namespace \\\n  --namespace rook-ceph \\\n  -f path/to/rook-ceph-operator-values.yaml \\\n  rook-ceph rook-release/rook-ceph  \n</code></pre> <pre><code>helm install --create-namespace \\\n  --namespace rook-ceph \\\n  --version v1.15.0 \\\n  -f path/to/rook-ceph-operator-values.yaml \\\n  rook-ceph \\\n  http://eda:eda@&lt;ASSETS VM IP&gt;/artifacts/rook-ceph-v1.15.0.tgz\n</code></pre> </li> <li> <p>Using the <code>rook-ceph-cluster-values.yaml</code> file that the <code>edaadm</code> tool generated, deploy the Rook Ceph Cluster.</p> Internet based installationAir-gapped installation <pre><code>helm install \\\n  --namespace rook-ceph \\\n  --set operatorNamespace=rook-ceph \\\n  -f path/to/rook-ceph-cluster-values.yaml \\\n  rook-ceph-cluster rook-release/rook-ceph-cluster\n</code></pre> <pre><code>helm install \\ \n  --namespace rook-ceph \\ \n  --set operatorNamespace=rook-ceph \\ \n  -f path/to/rook-ceph-cluster-values.yaml \\ \n  rook-ceph-cluster \\\n  http://eda:eda@&lt;ASSETS VM IP&gt;/artifacts/rook-ceph-cluster-v1.15.0.tgz\n</code></pre> <p>The output from this command can report missing CRDs; wait until the Rook Ceph Operator is running in the Kubernetes cluster.</p> </li> <li> <p>Using <code>kubectl</code> commands, verify that the operator is deployed and the necessary pods are deployed before installing the EDA application.     This example is for a six-node cluster, with six storage nodes.</p> <pre><code>kubectl -n rook-ceph get pods\n</code></pre> <p> <pre><code>NAME                                               READY   STATUS      RESTARTS        AGE\ncsi-cephfsplugin-22rmj                             2/2     Running     1 (6m32s ago)   7m6s\ncsi-cephfsplugin-25p9d                             2/2     Running     1 (6m30s ago)   7m6s\ncsi-cephfsplugin-2gr8v                             2/2     Running     4 (5m16s ago)   7m6s\ncsi-cephfsplugin-48cwk                             2/2     Running     1 (6m30s ago)   7m6s\ncsi-cephfsplugin-fknch                             2/2     Running     2 (5m32s ago)   7m6s\ncsi-cephfsplugin-provisioner-67c8454ddd-mpq4w      5/5     Running     1 (6m1s ago)    7m6s\ncsi-cephfsplugin-provisioner-67c8454ddd-qmdrq      5/5     Running     1 (6m18s ago)   7m6s\ncsi-cephfsplugin-vfxnf                             2/2     Running     1 (6m32s ago)   7m6s\nrook-ceph-mds-ceph-filesystem-a-7c54cdf5bc-lmf6n   1/1     Running     0               2m40s\nrook-ceph-mds-ceph-filesystem-b-6dc794b9f4-2lc64   1/1     Running     0               2m37s\nrook-ceph-mgr-a-55b449c844-wpps8                   2/2     Running     0               4m30s\nrook-ceph-mgr-b-5f97fd5746-fzngx                   2/2     Running     0               4m30s\nrook-ceph-mon-a-76fcb96c4c-vscnc                   1/1     Running     0               5m53s\nrook-ceph-mon-b-68bf5974bb-p2vnj                   1/1     Running     0               4m57s\nrook-ceph-mon-c-6d7c64dcb6-phs99                   1/1     Running     0               4m47s\nrook-ceph-operator-5f4c4bff8d-2fsq2                1/1     Running     0               7m54s\nrook-ceph-osd-0-bf89f779-zh4kd                     1/1     Running     0               3m49s\nrook-ceph-osd-1-64dcd64c5f-7xcbm                   1/1     Running     0               3m49s\nrook-ceph-osd-2-54ddd95489-5qkdt                   1/1     Running     0               3m49s\nrook-ceph-osd-3-56cbd54bd6-7mt8w                   1/1     Running     0               3m39s\nrook-ceph-osd-4-567dcff476-wljll                   1/1     Running     0               2m56s\nrook-ceph-osd-5-6f69c998b6-2l5wp                   1/1     Running     0               2m54s\nrook-ceph-osd-prepare-eda-dev-node01-7rfkn         0/1     Completed   0               4m8s\nrook-ceph-osd-prepare-eda-dev-node02-rqdkx         0/1     Completed   0               4m8s\nrook-ceph-osd-prepare-eda-dev-node03-xtznb         0/1     Completed   0               4m8s\nrook-ceph-osd-prepare-eda-dev-node04-db4v8         0/1     Completed   0               4m7s\nrook-ceph-osd-prepare-eda-dev-node05-29wwm         0/1     Completed   0               4m7s\nrook-ceph-osd-prepare-eda-dev-node06-zxp2x         0/1     Completed   0               4m7s\nrook-ceph-tools-b9d78b5d4-8r62p                    1/1     Running     0               7m6s\n</code></pre> </p> <p>Note</p> <p>Some of the pods may restart as they initiate Ceph. This behavior is expected.</p> </li> </ol>"},{"location":"software-install/deploying-eda/installing-the-eda-application/","title":"Installing the EDA application","text":"<p>After setting up EDA nodes and bootstrapping the Talos Kubernetes cluster, you can now install Nokia EDA applications using the playground repository cloned during the preparation phase.</p>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#customizing-the-installation","title":"Customizing the installation","text":"<p>The Kpt Kubernetes package manager is used to configure and install EDA components. As any other package manager, kpt packages can be customized to allow users to customize EDA installation according to their needs.</p>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#preferences-file","title":"Preferences file","text":"<p>The most common customization options are provided in the <code>prefs.mk</code> preferences file you find at the playground directory's root.</p> <p>This file contains customization parameters that you can set to adjust the essential installation parameters, such as the EDA version to install, the installation components to include, the Kubernetes namespace where EDA components are installed, proxy settings, the reachability settings for the EDA cluster, and so on. You will find the list of all the available parameters in the section below.</p> Customizable parameters in the <code>prefs.mk</code> file: <p>Parameter</p> <p>Description</p> Namespace settings for EDA components <p><code>EDA_CORE_NAMESPACE</code></p> <p>Sets the kubernetes namespace where the EDA core components are installed.</p> <p>Default: <code>eda-system</code></p> <p><code>EDA_USER_NAMESPACE</code></p> <p>Sets the kubernetes and EDA namespace where the user components are installed.</p> <p>Default: <code>eda</code></p> Version selection for EDA packages <p><code>EDA_CORE_VERSION</code></p> <p>Version of the EDA core components to install.</p> <p>Defaults to the latest stable version.</p> <p><code>EDA_APPS_VERSION</code></p> <p>Version of the EDA applications to install.</p> <p>Defaults to the latest stable version.</p> KinD cluster options <p><code>NO_KIND</code></p> <p>When set to any non-zero value will skip the KinD cluster deployment used for lab/demo installations. Must be set to <code>yes</code> for production installation.</p> <p><code>KIND_CONFIG_FILE</code></p> <p>Path to the KinD configuration file.</p> <p>Default: <code>configs/kind.yaml</code> - the path to the KinD configuration file in the playground directory.</p> <p><code>KIND_CLUSTER_NAME</code></p> <p>Name of the KinD cluster.</p> <p>Default: <code>eda-demo</code>.</p> <p><code>KIND_API_SERVER_ADDRESS</code></p> <p>IP address to use for the KinD API server. If you want to reach your cluster from outside of the host machine, you must set this to the IP address of the host machine.</p> <p>Default: <code>127.0.0.1</code>.</p> <p><code>NO_HOST_PORT_MAPPINGS</code></p> <p>When set to <code>yes</code> will not create the extra port mappings in the KinD cluster and will not create the nodePort service to expose the EDA UI/API.</p> <p>Default: variable is not set. Results in port mappings and nodePort service being created.</p> Cluster reachability settings <p><code>METALLB_VIP</code></p> <p>Specifies the VIP address of your EDA deployment. Make sure to use a CIDR format, preferably as a /32 (or /128 for an IPv6 VIP).</p> <p>If you use two networks, this VIP address must be the one used on the fabric management network. \u200b\u200bIf you use a single network, this setting must match the VIP address used for <code>\u200bEXT_DOMAIN_NAME\u200b</code> FQDN or IP.\u200b</p> <p>Example: <code>203.0.113.10/32</code></p> <p><code>EXT_DOMAIN_NAME</code></p> <p>The FQDN that resolves to the EDA VIP or the VIP itself.</p> <p>This value must be the FQDN or VIP address that is used to access the UI. If you use two networks, this value must be the FQDN or IP address of the OAM network.</p> <p><code>EXT_HTTP_PORT</code></p> <p>The HTTP port that the EDA UI/API should use to redirect to HTTPS. Set to 80.</p> <p><code>EXT_HTTPS_PORT</code></p> <p>The HTTPS port on which the EDA UI/API listens. Set to 443.</p> <p><code>EXT_IPV4_ADDR</code></p> <p>The IPv4 IP address used as the VIP address.</p> <p>If you use two networks, this VIP address must be the one used on the fabric management network.\u200b \u200bIf you use a single network, this VIP address must be the VIP that matches your \u200bEXT_DOMAIN_NAME\u200b FQDN (or IP address).</p> <p><code>EXT_IPV6_ADDR</code></p> <p>The IPv6 IP address used as the VIP.</p> <p>If you use two networks, this VIP address must be the one used on the fabric management network.\u200b \u200bIf you use a single network, this VIP address must be the VIP that matches your \u200bEXT_DOMAIN_NAME\u200b FQDN (or IP address).</p> Proxy settings <p><code>HTTPS_PROXY</code> and <code>https_proxy</code></p> <p>Optional: The proxy address for the HTTPS proxy.</p> <p><code>HTTP_PROXY</code> and <code>http_proxy</code></p> <p>Optional: The proxy address for the HTTP proxy.</p> <p><code>NO_PROXY</code> and <code>no_proxy</code></p> <p>Optional: The list of IP addresses, IP ranges and hostnames that should not be proxied.</p> Asset host settings <p><code>USE_ASSET_HOST</code></p> <p>Must be set to <code>1</code> for an Air-gapped Installation and set to <code>0</code> for an Internet based installation. <code>0</code> is the default value if not set.</p> <p><code>ASSET_HOST</code></p> <p>The IP address of the Assets VM for the Air-gapped installation.</p> <p><code>ASSET_HOST_GIT_USERNAME</code></p> <p>The username for the git server running on the Asset VM. Needs to be set to <code>eda</code>, in the future this will be changeable.</p> <p><code>ASSET_HOST_GIT_PASSWORD</code></p> <p>The password for the git server running on the Asset VM. Needs to be set to <code>eda</code>, in the future this will be changeable.</p> <p><code>ASSET_HOST_ARTIFACTS_USERNAME</code></p> <p>The username for the artifact server running on the Asset VM. Needs to be set to <code>eda</code>, in the future this will be changeable.</p> <p><code>ASSET_HOST_ARTIFACTS_PASSWORD</code></p> <p>The password for the artifact server running on the Asset VM. Needs to be set to <code>eda</code>, in the future this will be changeable.</p> KPT settings <p><code>KPT_SETTERS_FILE</code></p> <p>Advanced configuration file for kpt.</p> <p><code>KPT_LIVE_INIT_FORCE</code></p> <p>Set to <code>1</code> to ignore if a kpt package was already initialized against a cluster. Results in an overwrite of the existing inventory (resource group).</p> <p>Default: <code>0</code></p> <p><code>KPT_INVENTORY_ADOPT</code></p> <p>Set to <code>1</code> to adopt already applied and unmanaged resources that the kpt package is trying to clear, it will update/reconcile any differences.</p> <p>Default: <code>0</code></p> External packages settings <p><code>NO_CERT_MANAGER_INSTALL</code></p> <p>Set to <code>yes</code> to skip the installation of the Cert Manager package. This is useful if you want to use an existing Cert Manager running in the <code>cert-manager</code> namespace.</p> <p>Default: unset - the Cert Manager package is installed.</p> <p><code>NO_CSI_DRIVER_INSTALL</code></p> <p>Set to <code>yes</code> to skip the installation of the Cert Manager's CSI driver. This is useful if you want to use an existing Cert Manager CSI driver running in the <code>cert-manager</code> namespace.</p> <p>Default: unset - the Cert Manager CSI driver package is installed.</p> <p><code>NO_EDA_ISSUER_API_INSTALL</code></p> <p>Set to <code>yes</code> to skip the installation of the certificate issuers for EDA.</p> <p>Default: unset - the EDA certificate issuers are installed.</p> Other settings <p><code>LLM_API_KEY</code></p> <p>Optional: The OpenAI API key for the EDA Natural Language Query functionality.</p> <p><code>SINGLESTACK_SVCS</code></p> <p>Optional: Indicates that internal services should be single stack instead of dual stack, if Kubernetes is dual stack. Boolean.</p> <p><code>SIMULATE</code></p> <p>Specifies if the EDA deployment is to manage simulated workloads (Digital Sandbox) or real hardware.</p> <p>Values:</p> <ul> <li><code>true</code> - EDA installation will manage only simulated nodes (Digital Sandbox)</li> <li><code>false</code> - EDA installation will manage only real hardware nodes.</li> </ul> <p>By default, this parameter is set to <code>true</code> if the parameter is not provided in the file.</p> <p>Caution</p> <p>The simulation mode can't be changed post-install.</p> <p>You can find examples of the <code>prefs.mk</code> file contents for Internet based and Air-gapped installations for your reference:</p> Internet based installationAir-gapped installation <pre><code>NO_KIND=1\nSIMULATE=false\nMETALLB_VIP=203.0.113.10/32\nEXT_DOMAIN_NAME=eda.domain.tld \nEXT_HTTP_PORT=80 \nEXT_HTTPS_PORT=443 \nEXT_IPV4_ADDR=203.0.113.10\nEXT_IPV6_ADDR=\"\"\nHTTPS_PROXY=http://192.0.2.254:8080 \nHTTP_PROXY=http://192.0.2.254:8080 \nNO_PROXY=192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108 \nhttps_proxy=http://192.0.2.254:8080 \nhttp_proxy=http://192.0.2.254:8080 \nno_proxy=192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108 \nLLM_API_KEY=...\n</code></pre> <pre><code>NO_KIND=1\nSIMULATE=false\nMETALLB_VIP=203.0.113.10/32\nEXT_DOMAIN_NAME=eda.domain.tld \nEXT_HTTP_PORT=80 \nEXT_HTTPS_PORT=443 \nEXT_IPV4_ADDR=203.0.113.10\nEXT_IPV6_ADDR=\"\"\nHTTPS_PROXY=http://192.0.2.254:8080 \nHTTP_PROXY=http://192.0.2.254:8080 \nNO_PROXY=192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108 \nhttps_proxy=http://192.0.2.254:8080 \nhttp_proxy=http://192.0.2.254:8080 \nno_proxy=192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108 \nLLM_API_KEY=...\nUSE_ASSET_HOST=1\nASSET_HOST=192.0.2.228\nASSET_HOST_GIT_USERNAME=\"eda\"\nASSET_HOST_GIT_PASSWORD=\"eda\"\nASSET_HOST_ARTIFACTS_USERNAME=\"eda\"\nASSET_HOST_ARTIFACTS_PASSWORD=\"eda\"\n</code></pre>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#kpt-setters","title":"Kpt setters","text":"<p>For the most part, the <code>prefs.mk</code> file is just a hand-picked selection of the most common customization options that the installation procedure passes over to the Kpt package manager.</p> <p>In Kpt, the customization of packages is done by setting the values of the parameters marked with the <code>kpt-set</code> annotation. Consider the Catalog manifest from the <code>eda-kpt-base</code> package:</p> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: eda-catalog-builtin-apps\n  namespace: eda-system # kpt-set: ${EDA_CORE_NAMESPACE}\nspec:\n  title: EDA built in apps catalog\n  remoteURL: https://github.com/nokia-eda/catalog.git # kpt-set: ${APP_CATALOG}\n  authSecretRef: gh-catalog\n</code></pre> <p>The <code># kpt-set: ${APP_CATALOG}</code> annotation indicates that the <code>.spec.remoteURL</code> value of the manifest can be overwritten using the <code>APP_CATALOG</code> Kpt setter.</p> <p>When you use the <code>prefs.mk</code> file and set the values for the variables exposed there you essentially provide the Kpt setters values, that will be used to customize the Kpt packages during the installation. However, the <code>prefs.mk</code> file exposes only a limited set of variables, while there are many more Kpt setters available in the EDA Kpt packages.</p> <p>EDA uses three Kpt packages published in the <code>nokia-eda/kpt</code> repository:</p> <ul> <li><code>eda-external-packages</code> - the package that contains the external packages used by EDA, such as Fluentd and Cert Manager.</li> <li><code>eda-kpt-base</code> - the core package that contains the EDA components, such as the Config Engine, the necessary secrets and configmaps.</li> <li><code>eda-kpt-playground</code> - the package that contains the EDA resources that bootstrap your EDA cluster with the node profiles, allocation pools and node users.</li> </ul> <p>Each package has its own set of Kpt setters that you can choose to use to overwrite the default values in the manifests. You will find the complete list of setters and the default values in the block below.</p> Kpt setters reference <p>Run <code>make list-kpt-setters-external-packages</code>, <code>make list-kpt-setters-core</code> or <code>make list-kpt-setters-playground</code> to see the list of setters for the respective package in your terminal and their current values.</p> eda-external-packageseda-kpt-baseeda-kpt-playground Name Current Value eda-external-packages/cert-manager/cert-manager.yaml <code>CORE_IMG_CREDENTIALS</code> core <code>CMCA_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-cainjector:v1.16.2\" <code>CMCT_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-controller:v1.16.2\" <code>CM_ARGS</code> Non scalar value, see the file for details. <code>CMWH_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-webhook:v1.16.2\" Name Current Value eda-external-packages/csi-driver/cert-manager-csi-driver.in.yaml <code>EDA_CORE_NAMESPACE</code> eda-system <code>CSI_REGISTRAR_IMG</code> \"ghcr.io/nokia-eda/ext/sig-storage/csi-node-driver-registrar:v2.12.0\" <code>CSI_LIVPROBE_IMG</code> \"ghcr.io/nokia-eda/ext/sig-storage/livenessprobe:v2.12.0\" <code>CSI_DRIVER_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-csi-driver:v0.10.1\" Name Current Value eda-external-packages/eda-api-ingress-https-passthrough/api-ingress-ssl-passthrough.yaml <code>EXT_DOMAIN_NAME</code> \"\" <code>INT_HTTPS_PORT</code> 443 Name Current Value eda-external-packages/eda-api-ingress-https/eda-api-ingress-cert.yaml <code>EXT_IPV4_ADDR</code> \"\" <code>EXT_IPV6_ADDR</code> \"\" Name Current Value eda-external-packages/fluentd/fluentd-bit-ds.yaml <code>FB_IMG</code> ghcr.io/nokia-eda/core/fluent-bit:3.0.7-amd64 Name Current Value eda-external-packages/fluentd/fluentd.yaml <code>FD_IMG</code> ghcr.io/nokia-eda/core/fluentd:v1.17.0-debian-1.0 Name Current Value eda-external-packages/git-no-pvc/gogs-admin-user.yaml <code>EDA_GOGS_NAMESPACE</code> eda-system <code>GOGS_ADMIN_USER</code> ZWRhCg== <code>GOGS_ADMIN_PASS</code> ZWRhCg== Name Current Value eda-external-packages/git-no-pvc/gogs-deployment-no-pvc.yaml <code>GOGS_IMG_TAG</code> ghcr.io/nokia-eda/core/gogs:0.13.0 Name Current Value eda-external-packages/git-no-pvc/gogs-replica-service.yaml <code>GIT_SVC_TYPE</code> ClusterIP Name Current Value eda-external-packages/git/gogs-pv-claim.yaml <code>GOGS_PV_CLAIM_SIZE</code> 24Gi Name Current Value eda-external-packages/git/gogs-replica-pv-claim.yaml <code>GOGS_REPLICA_PV_CLAIM_SIZE</code> 24Gi Name Current Value eda-external-packages/trust-manager/trust-manager.yaml <code>EDA_TRUSTMGR_NAMESPACE</code> eda-system <code>TRUSTMGRBUNDLE_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-package-debian:20210119.0\" <code>TRUSTMGR_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/trust-manager:v0.15.0\" <code>TRUSTMGR_ARGS</code> Non scalar value, see the file for details. <code>EDA_TRUSTMGR_ISSUER_DNSNAMES</code> Non scalar value, see the file for details. Name Current Value eda-kpt-base/appstore-gh/catalog-secret.yaml <code>GH_CATALOG_TOKEN</code> SomeCatalogToken <code>GH_CATALOG_USER</code> bm9raWEtZWRhLWJvdA== <code>EDA_CORE_NAMESPACE</code> eda-system Name Current Value eda-kpt-base/appstore-gh/catalog.yaml <code>APP_CATALOG</code> https://github.com/nokia-eda/catalog.git Name Current Value eda-kpt-base/appstore-gh/registry-secret.yaml <code>GH_REGISTRY_TOKEN</code> SomeRegistryToken <code>GH_REGISTRY_USER</code> bm9raWEtZWRhLWJvdA== Name Current Value eda-kpt-base/appstore-gh/registry.yaml <code>APP_REGISTRY</code> ghcr.io <code>APP_REGISTRY_SKIPTLSVERIFY</code> false <code>APP_REGISTRY_MIRROR</code> \"\" Name Current Value eda-kpt-base/core/apps/bootstrap.yaml <code>INT_DHCPV6_PORT</code> 547 <code>INT_DHCPV4_PORT</code> 67 Name Current Value eda-kpt-base/core/apps/ce-deployment.yaml <code>CORE_IMG_CREDENTIALS</code> core <code>CE_IMG</code> ghcr.io/nokia-eda/core/config-engine:25.4.3 <code>CE_LIMIT_CPU</code> \"2\" <code>CE_LIMIT_MEM</code> \"2Gi\" <code>CE_REQ_CPU</code> \"1\" <code>CE_REQ_MEM</code> \"1Gi\" <code>HTTP_PROXY</code> \"\" <code>HTTPS_PROXY</code> \"\" <code>NO_PROXY</code> \"\" <code>http_proxy</code> \"\" <code>https_proxy</code> \"\" <code>no_proxy</code> \"\" Name Current Value eda-kpt-base/core/apps/cxdp-image-config-map.yaml <code>CXDP_IMG</code> ghcr.io/nokia-eda/core/cxdp:25.4.3 Name Current Value eda-kpt-base/eda-toolbox/eda-toolbox-deployment.yaml <code>EDA_TOOLBOX_IMG</code> ghcr.io/nokia-eda/core/eda-toolbox:25.4.3 Name Current Value eda-kpt-base/engine-config/engineconfig.yaml <code>CLUSTER_MEMBER_NAME</code> engine-config <code>GIT_SERVERS</code> Non scalar value, see the file for details. <code>EXT_DOMAIN_NAME</code> \"\" <code>EXT_HTTP_PORT</code> 0 <code>EXT_HTTPS_PORT</code> 0 <code>EXT_IPV4_ADDR</code> \"\" <code>EXT_IPV6_ADDR</code> \"\" <code>INT_HTTP_PORT</code> 80 <code>INT_HTTPS_PORT</code> 443 <code>GIT_REPO_CHECKPOINT</code> /eda/customresources.git <code>GIT_REPO_APPS</code> /eda/apps.git <code>GIT_REPO_USER_SETTINGS</code> /eda/usersettings.git <code>GIT_REPO_SECURITY</code> /eda/credentials.git <code>GIT_REPO_IDENTITY</code> /eda/identity.git <code>ASVR_IMG</code> ghcr.io/nokia-eda/core/artifact-server:25.4.3 <code>ASVR_LIMIT_CPU</code> \"\" <code>ASVR_LIMIT_MEM</code> \"\" <code>ASVR_REQ_CPU</code> \"\" <code>ASVR_REQ_MEM</code> \"\" <code>BSVR_IMG</code> ghcr.io/nokia-eda/core/bootstrap-server:25.4.3 <code>BSVR_LIMIT_CPU</code> \"\" <code>BSVR_LIMIT_MEM</code> \"\" <code>BSVR_REQ_CPU</code> \"\" <code>BSVR_REQ_MEM</code> \"\" <code>ECC_IMG</code> ghcr.io/nokia-eda/core/cert-checker:25.4.3 <code>ECC_LIMIT_CPU</code> \"\" <code>ECC_LIMIT_MEM</code> \"\" <code>ECC_REQ_CPU</code> \"\" <code>ECC_REQ_MEM</code> \"\" <code>CX_IMG</code> ghcr.io/nokia-eda/core/cx:25.4.3 <code>CX_LIMIT_CPU</code> \"\" <code>CX_LIMIT_MEM</code> \"\" <code>CX_REQ_CPU</code> \"\" <code>CX_REQ_MEM</code> \"\" <code>CXCLUSTER_ISAGENT</code> false <code>CXCLUSTER_ADDR</code> eda-cx-standalone <code>CXCLUSTER_PORT</code> 52200 <code>EMS_IMG</code> ghcr.io/nokia-eda/core/metrics-server:25.4.3 <code>EMS_LIMIT_CPU</code> \"\" <code>EMS_LIMIT_MEM</code> \"\" <code>EMS_REQ_CPU</code> \"\" <code>EMS_REQ_MEM</code> \"\" <code>NPP_IMG</code> ghcr.io/nokia-eda/core/npp:25.4.3 <code>NPP_LIMIT_CPU</code> \"\" <code>NPP_LIMIT_MEM</code> \"\" <code>NPP_REQ_CPU</code> \"\" <code>NPP_REQ_MEM</code> \"\" <code>SE_IMG</code> ghcr.io/nokia-eda/core/state-engine:25.4.3 <code>SE_REPLICAS</code> 1 <code>SE_LIMIT_CPU</code> \"\" <code>SE_LIMIT_MEM</code> \"\" <code>SE_REQ_CPU</code> \"\" <code>SE_REQ_MEM</code> \"\" <code>SA_IMG</code> ghcr.io/nokia-eda/core/state-aggregator:25.4.3 <code>SA_REPLICAS</code> 1 <code>SA_LIMIT_CPU</code> \"\" <code>SA_LIMIT_MEM</code> \"\" <code>SA_REQ_CPU</code> \"\" <code>SA_REQ_MEM</code> \"\" <code>SC_IMG</code> ghcr.io/nokia-eda/core/state-controller:25.4.3 <code>SC_LIMIT_CPU</code> \"\" <code>SC_LIMIT_MEM</code> \"\" <code>SC_REQ_CPU</code> \"\" <code>SC_REQ_MEM</code> \"\" <code>FE_IMG</code> ghcr.io/nokia-eda/core/flow-engine:25.4.3 <code>FE_LIMIT_CPU</code> \"\" <code>FE_LIMIT_MEM</code> \"\" <code>FE_REQ_CPU</code> \"\" <code>FE_REQ_MEM</code> \"\" <code>API_IMG</code> ghcr.io/nokia-eda/core/api-server:25.4.3 <code>API_REPLICAS</code> 1 <code>API_SVC_ENABLE_LB_NODE_PORTS</code> false <code>API_LIMIT_CPU</code> \"\" <code>API_LIMIT_MEM</code> \"\" <code>API_REQ_CPU</code> \"\" <code>API_REQ_MEM</code> \"\" <code>ASC_IMG</code> ghcr.io/nokia-eda/core/appstore-server:25.4.3 <code>ASC_LIMIT_CPU</code> \"\" <code>ASC_LIMIT_MEM</code> \"\" <code>ASC_REQ_CPU</code> \"\" <code>ASC_REQ_MEM</code> \"\" <code>ASF_IMG</code> ghcr.io/nokia-eda/core/appstore-flow:25.4.3 <code>TM_IMG</code> ghcr.io/nokia-eda/core/testman:25.4.3 <code>TM_LIMIT_CPU</code> \"\" <code>TM_LIMIT_MEM</code> \"\" <code>TM_REQ_CPU</code> \"\" <code>TM_REQ_MEM</code> \"\" <code>KC_IMG</code> ghcr.io/nokia-eda/core/eda-keycloak:25.4.3 <code>KC_LIMIT_CPU</code> \"\" <code>KC_LIMIT_MEM</code> \"\" <code>KC_REQ_CPU</code> \"\" <code>KC_REQ_MEM</code> \"\" <code>PG_IMG</code> ghcr.io/nokia-eda/core/eda-postgres:25.4.3 <code>PG_LIMIT_CPU</code> \"\" <code>PG_LIMIT_MEM</code> \"\" <code>PG_REQ_CPU</code> \"\" <code>PG_REQ_MEM</code> \"\" <code>LLM_API_KEY</code> \"\" <code>LLM_MODEL</code> gpt-4o <code>SIMULATE</code> true <code>SINGLESTACK_SVCS</code> false Name Current Value eda-kpt-base/namespaces/eda.yaml <code>EDA_USER_NAMESPACE</code> eda Name Current Value eda-kpt-base/secrets/identity-realm-auth.yaml <code>SECRET_EDA_ADMIN_USERNAME</code> YWRtaW4= Name Current Value eda-kpt-base/secrets/keycloak-admin-secret.yml <code>SECRET_KC_ADMIN_USERNAME</code> YWRtaW4= <code>SECRET_KC_ADMIN_PASSWORD</code> YWRtaW4= Name Current Value eda-kpt-base/secrets/postgres-db-secret.yml <code>SECRET_PG_DB_USERNAME</code> cG9zdGdyZXM= <code>SECRET_PG_DB_PASSWORD</code> cGFzc3dvcmQ= Name Current Value eda-kpt-playground/allocations/asn-pool.yaml <code>EDA_USER_NAMESPACE</code> eda Name Current Value eda-kpt-playground/cx/cx-cxdp-init.yaml <code>EDA_CORE_NAMESPACE</code> eda-system Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.1/engine_v1_nodeprofile_srlinux_24.10.1.yaml <code>SRL_24_10_1_GHCR</code> ghcr.io/nokia/srlinux:24.10.1-492 <code>CORE_IMG_CREDENTIALS</code> core Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.1/llm-embeddings-db-srlinux-24.10.1.yaml <code>LLM_DB_REMOTE_URL</code> https://github.com/nokia-eda/llm-embeddings/releases/download/nokia-srl-v24.10.1/llm-embeddings-srl-24-10-1.tar.gz Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.1/yang-srlinux-24.10.1.yaml <code>YANG_REMOTE_URL</code> https://github.com/nokia/srlinux-yang-models/releases/download/v24.10.1/srlinux-24.10.1-492.zip Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.2/engine_v1_nodeprofile_srlinux_24.10.2.yaml <code>SRL_24_10_2_GHCR</code> ghcr.io/nokia/srlinux:24.10.2-357 Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.3/engine_v1_nodeprofile_srlinux_24.10.3.yaml <code>SRL_24_10_3_GHCR</code> ghcr.io/nokia/srlinux:24.10.3-201 Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.4/engine_v1_nodeprofile_srlinux_24.10.4.yaml <code>SRL_24_10_4_GHCR</code> ghcr.io/nokia/srlinux:24.10.4-244 Name Current Value eda-kpt-playground/srlinux-ghcr-25.3.2/engine_v1_nodeprofile_srlinux_25.3.2.yaml <code>SRL_25_3_2_GHCR</code> ghcr.io/nokia/srlinux:25.3.2-312 <p>If you need to customize the installation besides the parameters provided in the <code>prefs.mk</code> file, you should create the YAML file with the Kpt setters key/value pairs that follows the Kpt setters format like this:</p> <code>my-setters.yml</code><pre><code>apiVersion: v1\nkind: ConfigMap #(1)!\nmetadata:\n  name: my-setters\ndata:\n  GOGS_REPLICA_PV_CLAIM_SIZE: 10Gi #(2)!\n  # add more setters if required\n</code></pre> <ol> <li>The setters file resembles a K8s ConfigMap resource, but it is not applied to your cluster, it is only used by the kpt tool to read the values from it.</li> <li>The setter's key must match the name of the setter variable in the manifest file.</li> </ol> <p>Now that you have your setters file with the necessary values, you should set the path to it in the preferences file:</p> <pre><code>KPT_SETTERS_FILE := my-setters.yml\n</code></pre> <p>And that's it! The kpt will read the values from the setters file and apply them to the manifests when you run the installation commands.</p>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#credentials-and-secrets","title":"Credentials and secrets","text":"<p>Nokia EDA platform uses a set of credentials to authenticate and authorize access to various components. These credentials are set to their respective default values and can be modified pre and post installation. The tables below lists the components, the associated credentials and the matching Kpt setters that an admin can use to customize them at the installation time.</p>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#git","title":"Git","text":"Component Default value Kpt Setter Notes Internal Git server (Gogs) admin username <code>eda</code> <code>GOGS_ADMIN_USER</code> Sets the username for the internal Git server. Not applicable if an external Git server is used. Base64 encoded Internal Git server (Gogs) admin password <code>eda</code> <code>GOGS_ADMIN_PASS</code> Same note as for the admin username. Base64 encoded Config Engine Git username <code>eda</code> <code>CE_GIT_USERNAME</code> Should match the Git server admin username. Base64 encoded Config Engine Git password <code>eda</code> <code>CE_GIT_PASSWORD</code> Should match the Git server admin password. Base64 encoded <p>In case the value of <code>GOGS_ADMIN_USER</code>/<code>CE_GIT_USERNAME</code> was changed, make sure to set the setters for the repository paths as per the table below. The path values are provided as raw text values.</p> Component Default value Kpt Setter Notes Custom resources repo <code>/eda/customresources.git</code> <code>GIT_REPO_CHECKPOINT</code> Apps repo <code>/eda/apps.git</code> <code>GIT_REPO_APPS</code> User settings repo <code>/eda/usersettings.git</code> <code>GIT_REPO_USER_SETTINGS</code> Credentials repo <code>/eda/credentials.git</code> <code>GIT_REPO_SECURITY</code> Identity repo <code>/eda/identity.git</code> <code>GIT_REPO_IDENTITY</code>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#eda-user","title":"EDA user","text":"<p>EDA users are managed by the Keycloak identity provider and by default an admin user is created during the installation process. Using the following setter it is possible to change the default admin user password<sup>1</sup>.</p> Component Default value Kpt Setter Notes EDA admin password <code>admin</code> <code>SECRET_EDA_ADMIN_PASSWORD</code> Base64 encoded"},{"location":"software-install/deploying-eda/installing-the-eda-application/#keycloak","title":"Keycloak","text":"<p>The Keycloak identity provider is managed by its own admin user and its credentials can be customized using the following setters:</p> Component Default value Kpt Setter Notes Keycloak admin username <code>admin</code> <code>SECRET_KC_ADMIN_USERNAME</code> Base64 encoded Keycloak admin password <code>admin</code> <code>SECRET_KC_ADMIN_PASSWORD</code> Base64 encoded"},{"location":"software-install/deploying-eda/installing-the-eda-application/#postgres-db","title":"Postgres DB","text":"<p>Lastly, there is a postgres database used by the Keycloak. The database password can also be customized:</p> Component Default value Kpt Setter Notes Postgres DB password <code>password</code> <code>SECRET_PG_DB_PASSWORD</code> Base64 encoded"},{"location":"software-install/deploying-eda/installing-the-eda-application/#installing-nokia-eda","title":"Installing Nokia EDA","text":"<p>When the necessary parameters are set, follow these steps to install EDA.</p> <p>Note</p> <p>Steps 1 and 2 can be skipped if these have already been executed during the preparation phase of the installation procedure.</p> <ol> <li> <p>Download the latest tools.</p> <pre><code>make download-tools\n</code></pre> </li> <li> <p>Set the desired EDA version. (optional)</p> <p>To install a specific version of EDA instead of the latest version, set the <code>EDA_CORE_VERSION</code> and <code>EDA_APPS_VERSION</code> variables in the preferences file. For example, to choose the 25.8.1 version of EDA, add the following lines to the <code>prefs.mk</code> file:</p> <pre><code>EDA_CORE_VERSION=25.8.1\nEDA_APPS_VERSION=25.8.1\n</code></pre> <p>In the current release, both variables must be set to the same version.</p> </li> <li> <p>Download EDA packages.</p> <pre><code>make download-pkgs\n</code></pre> </li> <li> <p>Set up the MetalLB environment for VIP management.</p> <pre><code>make metallb\n</code></pre> </li> <li> <p>Install the necessary external packages.</p> <pre><code>make install-external-packages\n</code></pre> <p>Note</p> <p>If this command exits with an error, wait 30 seconds and try again. Sometimes Kubernetes is a bit slower in reconciling the change than the command waits for.</p> </li> <li> <p>Change the eda-git Kubernetes service to a ClusterIP service instead of a LoadBalancer type.</p> <pre><code>kubectl -n eda-system patch service eda-git -p '{\"spec\": {\"type\": \"ClusterIP\"}}'\n</code></pre> </li> <li> <p>Generate the EDA core configuration.</p> <pre><code>make eda-configure-core\n</code></pre> </li> <li> <p>Install EDA core components.</p> <pre><code>make eda-install-core\n</code></pre> <p>Note</p> <p>If the command hangs for a long time (&gt;5 minutes) on \"reconcile pending\" for a workflow definition, cancel the command and try again; KPT is designed to handle these cases. This can happen occasionally depending on the Kubernetes cluster.</p> </li> <li> <p>Verify that the EDA Config Engine is up and running.</p> <pre><code>make eda-is-core-ready\n</code></pre> </li> <li> <p>Install all the standard EDA apps.</p> <p>This step can take approximate 5 to 15 minutes, depending on your connectivity.</p> <pre><code>make eda-install-apps\n</code></pre> </li> <li> <p>Bootstrap EDA.</p> <p>Bootstrapping will create base resources into the EDA cluster, such as IP pools.</p> <pre><code>make eda-bootstrap\n</code></pre> </li> <li> <p>Configure two-networks deployment.</p> <p>If your deployment uses two networks, create a second VIP pool for the OAM VIP address.</p> <pre><code>make metallb-configure-pools METALLB_VIP=&lt;OAM VIP&gt; LB_POOL_NAME=pool-nb\n</code></pre> <p>And create the OAM UI/API service using the new VIP pool.</p> <pre><code>make eda-create-api-lb-svc API_LB_POOL_NAME=pool-nb\n</code></pre> </li> <li> <p>Optional: Deploy an example topology.</p> <p>If you configured EDA to manage the simulated network (Digital Sandbox), you can load an example topology that will be instantiated as virtual simulators in the same EDA cluster by running:</p> <pre><code>make topology-load\n</code></pre> </li> </ol>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#accessing-the-eda-deployment","title":"Accessing the EDA deployment","text":"<p>You can now access the new EDA deployment using the following methods:</p> <ul> <li>use <code>https://OAM-VIP</code> if Virtual IP (VIP) was provided as <code>EXT_DOMAIN_NAME</code> in the preferences file used during the installation.</li> <li>if an FQDN is configured for the <code>EXT_DOMAIN_NAME</code> field, use <code>https://FQDN</code></li> </ul> <p>Both examples assume that <code>EXT_HTTPS_PORT</code> was set to <code>443</code> in the preferences file.</p> <ol> <li> <p>Note, that it is not possible to change the default admin username.\u00a0\u21a9</p> </li> </ol>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/","title":"Setting up the EDA virtual machine nodes","text":"<p>This section describes how to the prepare the configurations file, generate the configuration files, and deploy the Talos virtual machines.</p>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#preparing-the-edaadm-configuration-file","title":"Preparing the EDAADM configuration file","text":"<p>The <code>edaadm</code> tool helps with the creation of the necessary machine configuration files for the Talos VMs that are part of your deployment.</p>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#edaam-configuration-file-fields","title":"EDAAM configuration file fields","text":"<p>The EDAADM configuration file is a YAML file that describes your Talos Kubernetes environment. You can use it to configure the different nodes and the general Kubernetes cluster environment.</p> <p>Top-level parameter</p> <p>Description</p> <p><code>version</code></p> <p>The version of the EDA environment to be deployed. Example: 25.4.1</p> <p><code>clusterName</code></p> <p>The name of your EDA environment. Example: <code>eda-production-cluster</code></p> <p><code>machines</code></p> <p>A list of Kubernetes nodes. Each Kubernetes node has the following settings:</p> <p><code>name</code></p> <p>The name of a node. Example: <code>eda-node01</code></p> <p><code>endpoint</code></p> <p>The IP address on which the node is reachable for Talos to control. Optional.</p> <p><code>interfaces</code></p> <p>A list of interfaces present in the node, each with the following settings:</p> <ul> <li> <p><code>name</code>: the name of the interface.     Example: <code>eth0</code></p> </li> <li> <p><code>dhcp</code>: indicates if DHCP is to be used for the interface.     Values: <code>true</code> or <code>false</code>. For production environments, set to <code>false</code>.</p> </li> <li> <p><code>mtu</code>: the MTU setting for the interface. For an interface used to connect to nodes under management, set to 9000 for best practice. Optional.</p> </li> <li> <p><code>interface</code>: the interface name as it appears in Linux. Typically, <code>eth0</code>, <code>eth1</code>, and so forth. Optional.</p> </li> <li> <p><code>addresses</code>: a list of IP addresses; for dual-stack deployments, you can specify both IPv4 and IPv6 addresses. If DHCP is not provided, specify at least one address.</p> </li> <li> <p><code>routes</code>: a list of static routes to configure, including the default route. Optional. Routes have the following components:</p> <ul> <li> <p><code>gateway</code>: the next-hop or gateway for the route.</p> </li> <li> <p><code>metric</code>: a metric to indicate the priority of the route. Optional.</p> </li> <li> <p><code>mtu</code>: a specific MTU for the route. Optional.</p> </li> <li> <p><code>network</code>: the destination CIDR of the route.</p> </li> <li> <p><code>source</code>: a source interface for the route to apply to. Optional.</p> </li> </ul> </li> <li> <p><code>deviceSelector</code>: specifies how to select the device associated with this interface.</p> <ul> <li> <p><code>busPath</code>: a PCI buspath that can contain wildcards. Optional.</p> </li> <li> <p><code>hardwareAddr</code>: a MAC address that can contain wildcards. Optional.</p> </li> </ul> </li> </ul> <p><code>disks</code></p> <p>Identifies the disks available in the node:</p> <ul> <li> <p><code>os</code>: Specifies which disk to use for the OS. Required setting.</p> <p>Typically <code>/dev/sda</code> or <code>/dev/vda</code>, depending on the hypervisor platform</p> </li> <li> <p><code>storage</code>: Optional disk for use with nodes that are to be part of the storage cluster.</p> </li> </ul> <p><code>k8s</code></p> <p>The Kubernetes-specific configuration. The following parameters define the Kubernetes cluster:</p> <p><code>stack</code></p> <p>Indicates the network stack to support. Values: <code>ipv4</code>, <code>ipv6</code>, or <code>dual</code></p> <p><code>primaryNode</code></p> <p>The first control plane node in the cluster to be used for bootstrapping the Kubernetes cluster.</p> <p>Specify the a the name of a machine.</p> <p><code>endpointUrl</code></p> <p>The URL on which to reach the Kubernetes control plane. This setting uses the Kubernetes VIP address. Example: <code>https://192.0.2.10:6443</code></p> <p><code>allowSchedulingOnControlPlanes</code></p> <p>Specifies if workloads can be deployed on the control plane node. Values: <code>true</code> or <code>false</code>. For best practice, set to <code>true</code>.</p> <p><code>control-plane</code></p> <p>A list of control plane nodes. Specify a machine name.</p> <p><code>worker</code></p> <p>A list of worker nodes. Specify a machine name.</p> <p><code>vip</code></p> <p>The VIP addresses used for Kubernetes and the interfaces to which they should be attached in the control plane nodes. Depending on the IP stack in use, some values are required:</p> <ul> <li> <p><code>interface</code>: the interface to which the VIP is attached on the nodes.</p> <p>Example: <code>eth0</code></p> </li> <li> <p><code>ipv4</code>: the IPv4 VIP address.</p> <p>Example: <code>192.0.2.10</code></p> </li> <li> <p><code>ipv6</code>: the IPv6 VIP address</p> </li> </ul> <p><code>env</code></p> <p>Section that includes the optional proxy settings for the Kubernetes nodes:</p> <ul> <li> <p><code>http_proxy</code>: The HTTP proxy URL to use.</p> <p>Example: <code>http://192.0.2.254:808</code></p> </li> <li> <p><code>https_proxy</code>: the HTTPS proxy URL to use.</p> <p>Example: <code>http://192.0.2.254:808</code></p> </li> <li> <p><code>no_proxy</code>: the no proxy setting for IP addresses, IP ranges, and hostnames</p> </li> </ul> <p><code>time</code></p> <p>Defines NTP settings.</p> <ul> <li><code>disabled</code>: Specifies whether NTP is enabled. For production environments, set to false to enable NTP.</li> <li><code>servers</code>: A list of NTP servers; required for production environments.</li> </ul> <p><code>nameservers</code></p> <p>A list of DNS servers specified under the following sub-element:</p> <ul> <li><code>servers</code>: the list of DNS servers</li> </ul> <p><code>certBundle</code></p> <p>An optional set of PEM-formatted certificates that need to be trusted; this setting is used for trust external services.</p> <p><code>mirror</code></p> <p>Only needed for Air-gapped environment, following settings can be set:</p> <ul> <li><code>name</code>: The name of the mirror</li> <li><code>url</code>: The URL of the mirror</li> <li><code>insecure</code>: should be <code>true</code></li> <li><code>overridePath</code>: should be <code>false</code></li> <li><code>skipFallback</code>: should be <code>true</code></li> <li> <p><code>mirrors</code>: A list of online registry domain names for which the mirror is used. This should look like:</p> <pre><code>- docker.io\n- gcr.io\n- ghcr.io\n- registry.k8s.io\n- quay.io\n</code></pre> </li> </ul>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#example-edaadm-configuration-file","title":"Example EDAADM configuration file","text":"<p>The following examples show an EDAADM configuration file for a 6-node Kubernetes cluster. For a standard Internet based installation, as well as for an Air-gapped installation. These are the same two files, with only the <code>mirror</code> addition on the second tab/file.</p> Internet based installationAir-gapped installation <pre><code>version: 25.4.1\nclusterName: eda-compute-cluster\nmachines:\n  - name: eda-node01\n    endpoint: \"192.0.2.11\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.11/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.11/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node02\n    endpoint: \"192.0.2.12\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.12/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.12/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node03\n    endpoint: \"192.0.2.13\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.13/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.13/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node04\n    endpoint: \"192.0.2.14\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.14/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.14/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n  - name: eda-node05\n    endpoint: \"192.0.2.15\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.15/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.15/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n  - name: eda-node06\n    endpoint: \"192.0.2.16\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.16/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.16/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\nk8s:\n  stack: ipv4\n  primaryNode: eda-node01\n  endpointUrl: https://192.0.2.5:6443\n  allowSchedulingOnControlPlanes: true\n  control-plane:\n    - eda-node01\n    - eda-node02\n    - eda-node03\n  worker:\n    - eda-node04\n    - eda-node05\n    - eda-node06\n  vip:\n    ipv4: 192.0.2.5\n    interface: eth0\n  env:\n    http_proxy: http://192.0.2.254:8080\n    https_proxy: http://192.0.2.254:8080\n    no_proxy: 192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108\n  time:\n    disabled: false\n    servers:\n      - 192.0.2.253\n      - 192.0.2.254\n  nameservers:\n    servers:\n      - 192.0.2.253\n      - 192.0.2.254\n</code></pre> <pre><code>version: 25.4.1\nclusterName: eda-compute-cluster\nmachines:\n  - name: eda-node01\n    endpoint: \"192.0.2.11\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.11/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.11/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node02\n    endpoint: \"192.0.2.12\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.12/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.12/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node03\n    endpoint: \"192.0.2.13\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.13/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.13/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node04\n    endpoint: \"192.0.2.14\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.14/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.14/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n  - name: eda-node05\n    endpoint: \"192.0.2.15\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.15/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.15/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n  - name: eda-node06\n    endpoint: \"192.0.2.16\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.16/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.16/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\nk8s:\n  stack: ipv4\n  primaryNode: eda-node01\n  endpointUrl: https://192.0.2.5:6443\n  allowSchedulingOnControlPlanes: true\n  control-plane:\n    - eda-node01\n    - eda-node02\n    - eda-node03\n  worker:\n    - eda-node04\n    - eda-node05\n    - eda-node06\n  vip:\n    ipv4: 192.0.2.5\n    interface: eth0\n  env:\n    http_proxy: http://192.0.2.254:8080\n    https_proxy: http://192.0.2.254:8080\n    no_proxy: 192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108\n  time:\n    disabled: false\n    servers:\n      - 192.0.2.253\n      - 192.0.2.254\n  nameservers:\n    servers:\n      - 192.0.2.253\n      - 192.0.2.254\n  mirror:\n    name: 192.0.2.228\n    url: https://192.0.2.228\n    insecure: true\n    overridePath: false\n    skipFallback: true\n    mirrors:\n      - docker.io\n      - gcr.io\n      - ghcr.io\n      - registry.k8s.io\n      - quay.io\n</code></pre>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#generating-the-talos-machine-configurations","title":"Generating the Talos machine configurations","text":"<p>After creating the EDAADM configuration file, the next step is to generate all the configuration files that are necessary to deploy the Kubernetes environment using Talos.</p> <p>Use the <code>edaadm</code> tool to generate the deployment files.</p> <pre><code>edaadm generate -c eda-input-6-node.yaml\n</code></pre> <pre><code>$ edaadm generate -c eda-input-6-node.yaml\nConfigFile is eda-input-6-node.yaml\n...\n[1/4] Validating Machines\n[1/4] Validated Machines\n[2/4] Validating PrimaryNode\n[2/4] Validated PrimaryNode\n[3/4] Validating Endpoint URL\n[3/4] Validated Endpoint URL\n[4/4] Validating Virtual IP\n[4/4] Validated Virtual IP\n[  OK  ] Spec is validated\nGenerating secrets for eda-compute-cluster\nCreated eda-compute-cluster/secrets.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node01.yaml\nCreated eda-compute-cluster/talosconfig.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node02.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node03.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node04.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node05.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node06.yaml\n</code></pre> <p>The configuration files created by the <code>edaadm</code> tool are used in the next steps when you deploy the virtual machines.</p> <p>Note</p> <p>Nokia strongly recommends that you store these files securely and keep a backup.</p>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#deploying-the-talos-virtual-machines","title":"Deploying the Talos virtual machines","text":"<p>This section provides the procedures for deploying an EDA node as a virtual machine on KVM or VMware vSphere.</p>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#creating-the-vm-on-bridged-networks-on-kvm","title":"Creating the VM on bridged networks on KVM","text":"<p>Complete the following steps to deploy an EDA node as a virtual machine on KVM. These steps are executed on the RedHat Enterprise Linux or Rocky Linux hypervisor directly. The steps below assume the deployment of the eda-node01 virtual machine as per the above configuration file. Ensure that you use the correct machine configuration file generated by the <code>edaadm</code> tool.</p> <p>Note</p> <p>This procedure expects two networks to be available on the KVM hypervisors. The OAM network is referred to as br0 and the fabric management network is referred to as br1. Both of these networks are standard Linux bridge networks. If you use only one interface, adapt Step <code>7</code> to only use the br0 network only.</p> <ol> <li> <p>Ensure that the virt-install tool is installed on the KVM hypervisor.     If you need to install the tool, use the following command:</p> <pre><code>yum install virt-install\n</code></pre> </li> <li> <p>Verify that the ISO image downloaded in Downloading the KVM image is available on the hypervisor.</p> </li> <li> <p>Copy the machine configuration file generated for this specific node to a file called user-data.</p> <pre><code>cp eda-node01-control-plane.yaml user-data \n</code></pre> </li> <li> <p>Create a file called meta-data for the node.     Use the appropriate instance-id and local-hostname values.</p> <pre><code>instance-id: eda-node01 \nlocal-hostname: eda-node01 \n</code></pre> </li> <li> <p>Create a file called <code>network-config</code> for the node.</p> <p>The file should have the following content:</p> <pre><code>version: 2\n</code></pre> </li> <li> <p>Create an ISO file containing the newly created files.     For ease of use, name the ISO file with the name of the node for which you are creating the ISO.</p> <pre><code>mkisofs -o eda-node01-data.iso -V cidata -J -r meta-data network-config user-data \n</code></pre> </li> <li> <p>Create the virtual machine.     This step uses both the newly created ISO file and the ISO file downloaded from the Talos Machine Factory.</p> <pre><code>virt-install -n eda-node01 \\ \n--description \"Talos 1.9.2 vm for node eda-node01\" \\ \n--noautoconsole --os-type=generic \\ \n--memory 65536 --vcpus 32 --cpu host \\ \n--disk eda-node01-rootdisk.qcow2,format=qcow2,bus=virtio,size=100 \\ \n--disk eda-node01-storagedisk.qcow2,format=qcow2,bus=virtio,size=300 \\ \n--cdrom nocloud-amd64.iso \\ \n--disk eda-node01-data.iso,device=cdrom \\ \n--network bridge=br0,model=virtio \\ \n--network bridge=br1,model=virtio\n</code></pre> <p>Note</p> <p>If the node is not a storage node, you can remove the second --disk line.</p> </li> </ol>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#creating-the-vm-on-bridged-networks-on-vmware-vsphere","title":"Creating the VM on bridged networks on VMware vSphere","text":"<p>Complete the following steps to deploy an EDA node as a virtual machine on VMware vSphere. The steps below assume the deployment of the eda-node01 virtual machine as per the above configuration file. Ensure that you are using the correct machine configuration file generated by the <code>edaadm</code> tool.</p> <p>You can use one of the following methods to deploy the VM on VMware vSphere:</p> <ul> <li> <p>the VMware vSphere vCenter or ESXi UI</p> <p>For instructions, see Deploy an OVF or OVA Template in the VMware vSphere documentation.</p> </li> <li> <p>the VMware Open Virtualization Format Tool CLI (VMware OVF Tool CLI)</p> <p>This procedure provides an example of how to use the VMware OVF Tool CLI.</p> </li> </ul> <p>Note</p> <p>This procedure uses two networks (portgroups) to be available on the ESXi hypervisors. The OAM network is referred to as OAM and the fabric management network is referred to as FABRIC. Both of these networks can be standard PortGroups or distributed PortGroups. If you only use one network, you do not need to create a second interface on the VM.</p> <ol> <li>Download and install the latest version of the VMware OVF Tool from the VMware Developer website.</li> <li> <p>Display details about the OVA image.</p> <pre><code>ovftool vmware-amd64.ova \n</code></pre> <p> <pre><code>OVF version:   1.0\nVirtualApp:    false\nName:          talos\n\nDownload Size:  103.44 MB\n\nDeployment Sizes:\n  Flat disks:   8.00 GB\n  Sparse disks: Unknown\n\nNetworks:\n  Name:        VM Network\n  Description: The VM Network network\n\nVirtual Machines:\n  Name:               talos\n  Operating System:   other3xlinux64guest\n  Virtual Hardware:\n    Families:         vmx-15\n    Number of CPUs:   2\n    Cores per socket: automatic\n    Memory:           2.00 GB\n\n    Disks:\n      Index:          0\n      Instance ID:    4\n      Capacity:       8.00 GB\n      Disk Types:     SCSI-VirtualSCSI\n\n    NICs:\n      Adapter Type:   VmxNet3\n      Connection:     VM Network\n\nProperties:\n  Key:         talos.config\n  Label:       Talos config data\n  Type:        string\n  Description: Inline Talos config\n\nReferences:\n  File:  disk.vmdk\n</code></pre> </p> </li> <li> <p>Create a base64 encoded hash from the Talos machine configuration for the node.</p> <p>In this example, the output is stored as an environment variable to make it easy to use in the command to deploy the image using the OVF Tool.</p> <pre><code>export NODECONFIG=$(base64 -i eda-node01-control-plane.yaml)\n</code></pre> </li> <li> <p>Deploy the OVA image using the OVF Tool.     For details about command line arguments, see the OVF Tool documentation from the VMware website.</p> <p>Note</p> <p>If you prefer using the VMware vCenter UI to create the virtual machines, use the regular method of deploying an OVA/OVF template. In this process, in the Customize template step, when you are prompted to provide the Inline Talos config, you must provide the base64 encoded data from the Talos machine configuration for the node. This very long string that is returned when you execute the base64 -i eda-node01.yaml command. Copy that long string and paste it into the field in the UI, then continue.</p> <pre><code>ovftool --acceptAllEulas --noSSLVerify \\\n-dm=thick \\\n-ds=DATASTORE \\\n-n=eda-node01 \\\n--net:\"VM Network=OAM\" \\\n--prop:talos.config=\"${NODECONFIG}\" \\\nvmware-amd64.ova \\\nvi://administrator%40vsphere.local@vcenter.domain.tld/My-DC/host/My-Cluster/Resources/My-Resource-Group\n</code></pre> <p> <pre><code>Opening OVA source: vmware-amd64.ova\nThe manifest validates\nEnter login information for target vi://vcenter.domain.tld/\nUsername: administrator%40vsphere.local\nPassword: ***********\nOpening VI target: vi://administrator%40vsphere.local@vcenter.domain.tld:443/My-DC/host/My-Cluster/Resources/My-Resource-Group\nDeploying to VI: vi://administrator%40vsphere.local@ vcenter.domain.tld:443/My-DC/host/My-Cluster/Resources/My-Resource-Group  \nTransfer Completed\nCompleted successfully\n</code></pre> </p> <p>This step deploys the VM with the CPU, memory, disk, and NIC configuration of the default OVA image. The next step updates these settings.</p> </li> <li> <p>In vCenter, edit the VM settings.</p> <p>Make the following changes:</p> <ul> <li>Increase the number of vCPU to 32.</li> <li>Increase the memory to 64G.</li> <li>Increase the main disk size to 100G. On boot, Talos automatically extends the file system.</li> <li>Optionally, if this VM is a storage node, add a new disk with a size of 300G.</li> <li>Optionally, add a second network interface and connect it to the FABRIC PortGroup.</li> <li>Enable 100% resource reservation for the CPU, memory and disk.</li> </ul> </li> <li> <p>Power on the virtual machine.</p> </li> </ol>"},{"location":"software-install/non-production/","title":"Installation Overview","text":"<p>There are several non-production deployment options that can be used to run and deploy EDA in a lab environment for testing, development and demo purposes:</p> Own On-prem cluster <p>Use your own Kubernetes cluster to deploy EDA. This can be used for most types of standard Kubernetes clusters.</p> Playground using KinD <p>Deploy EDA in a Kubernetes environment running on Linux server.</p> Playground on macOS <p>Deploy EDA Playground in a Kubernetes environment running on your personal Macbook, whether it is ARM or Intel-based.</p> Playground on WSL <p>Deploy EDA Playground in a Kubernetes environment running on your personal Windows machine, be it a laptop or a desktop.</p> <p>You can also customize your EDA installation following the Installation customization guide. This will provide you with the details on how to manipulate the kpt packages to fit your specific needs and design.</p>"},{"location":"software-install/non-production/kind/","title":"EDA on KinD","text":"<p>Installing EDA on a KinD cluster is covered in the quickstart section.</p>"},{"location":"software-install/non-production/macos/","title":"EDA on macOS","text":"<p>Do you want to get full EDA experience on your macOS machine? Well, can't judge you!</p> <p>Typically, the management and automation platforms of EDA' caliber require a ton of resources to run. But that is not the case with EDA! The microservices architecture and reliance on Kubernetes as a deployment platform make it possible to run EDA on a laptop using open-source tools. And macOS-powered machines (even with M chips<sup>1</sup>) is not an exception!</p> Watch the video <p>This guide will talk you through installing the EDA Playground which consists of a simulated network topology and full EDA platform installation. No EDA licenses are required to run the Playground.</p>"},{"location":"software-install/non-production/macos/#playground-repository","title":"Playground repository","text":"<p>We will need the playground repository on our machine to run EDA installation steps. Pull it, as explained in the Try EDA section.</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; \\\ncd playground\n</code></pre> <p>When the playground repo is cloned (you will need to install <code>git</code> to clone it), let's install the CLI tools that we will need to run EDA installation steps.</p> <pre><code>make download-tools #(1)!\n</code></pre> <ol> <li> <p>This will download <code>kind</code>, <code>kubectl</code>, <code>kpt</code>, and <code>yq</code> into a <code>tools</code> folder relative to the current working directory.</p> <p>Subsequent steps use these versions of the binaries - you may use your own binaries for your own interactions. If you don't have <code>kubectl</code> in your <code>$PATH</code>, then consider copying the <code>kubectl</code> binary from the <code>tools</code> directory to a location in your <code>$PATH</code> to make use of it in the following steps.</p> </li> </ol> <p>The installer is smart enough to download the tools for the right OS/architecture.</p>"},{"location":"software-install/non-production/macos/#macos-prerequisites","title":"macOS prerequisites","text":"<p>Before we begin, let's ensure that you run macOS Sonoma v14.6.1 or newer, as the older versions of macOS might have issues with Rosetta emulation. The version can be checked with <code>sw_vers -productVersion</code> command in your terminal.</p> <p>For Apple products with an M-chip the next step prescribes to check that macOS Rosetta virtualization support enabled. This can be done by running the following command:</p> <pre><code>softwareupdate --install-rosetta\n</code></pre>"},{"location":"software-install/non-production/macos/#docker","title":"Docker","text":"<p>Now it is time to install Docker support on your macOS. There are many options available, the most common ones are:</p> <ol> <li>OrbStack Our pick!</li> <li>Docker Desktop for Mac</li> <li>Rancher Desktop</li> <li>Colima</li> </ol> <p>Below you will find short guides on how to install Docker on your macOS using some of the tools mentioned above. If you already have one installed, you can skip to the next section.</p> OrbStackColima <p>OrbStack is a relatively new software that brings Docker support to macOS. The reason we can recommend it is that it has a great UX, has a VM management support, comes with a lightweight k8s cluster and free for personal use.</p> <p>It is a native macOS app for both Intel and ARM64-based macs, so the installation is as easy as downloading the <code>dmg</code> file and installing it as usual. OrbStack installer will install the Docker CLI on your system, and will provide the Docker VM to run containers and k8s clusters, and enable the kubernetes cluster on the Kubernetes tab:</p> <p>If you are installing Orbstack for the first time, you will see a dialog that asks you what do you plan to use OrbStack for, select \"Kubernetes\".</p> <p>When OrbStack is installed, you can check the app settings to ensure that you have the sufficient resources allocated to an internal VM that runs docker daemon:</p> <p></p> <p>Check the minimum requirements on the Try EDA page, but it is best to have more CPU and Memory available to the OrbStack VM. On the screenshot above 24GB and all CPUs are allocated to the OrbStack VM, and this has no negative/noticable impact on the overall system performance.</p> <p>Colima is an open-source, free and lightweight CLI tool that brings container runtimes to macOS.</p> <p>It has a variety of installation options, with Homebrew being likely the most popular one:</p> <pre><code>brew install colima\n</code></pre> <p>Colima does not provide the Docker CLI client, so you will need to install one separately if you don't have one installed already. Thankfully, it is as easy as running:</p> <pre><code>brew install docker\n</code></pre> <p>Now, Colima can launch a linux/arm64 VM for us; this VM runs the Docker daemon so that we could run KinD with EDA inside. Here is a command to start the VM with 8 vcpu cores and 16 GB of RAM; this should be enough to run the quickstart demo:</p> <pre><code>colima start --cpu 8 --memory 16 --profile eda \\\n--vm-type=vz --vz-rosetta --network-address\n</code></pre> <p>We can ensure that the VM is running by checking the status:</p> <pre><code>colima status -e --profile eda\nINFO[0000] colima [profile=eda] is running using macOS Virtualization\nINFO[0000] arch: aarch64                                \nINFO[0000] runtime: docker                              \nINFO[0000] mountType: virtiofs                          \nINFO[0000] address: 192.168.107.3                       \nINFO[0000] socket: unix:///Users/romandodin/.colima/eda/docker.sock \nINFO[0000] cpu: 8                                       \nINFO[0000] mem: 16GiB                                   \nINFO[0000] disk: 60GiB \n</code></pre> <p>Your docker CLI should also \"sense\" the docker engine availability and set the context to the Colima VM:</p> <pre><code>docker context ls\nNAME           DESCRIPTION                DOCKER ENDPOINT                                    ERROR\ncolima-eda *   colima [profile=eda]       unix:///Users/romandodin/.colima/eda/docker.sock   \n</code></pre> Networking and Load Balancer with Colima <p>The downside of having a VM that runs the Docker daemon is that additional layer of networking is introduced. Hence, the MetalLB Load Balancer that we install in the kind cluster will use the IP range that is not visible from the macOS host.</p> <p>You don't need Load Balancer to enjoy EDA, since you can always expose the UI and the necessary services using <code>kubectl expose</code> command, but if you want to have the Load Balancer you will have to setup additional routes[^3].</p>"},{"location":"software-install/non-production/macos/#kubernetes-cluster","title":"Kubernetes cluster","text":"<p>With the container runtime installed and running via one of the tools mentioned above, we need to ensure we have a k8s cluster running on our macOS. You typically have two options:</p> <ol> <li>Use the embedded k8s cluster provided by the tool that adds Docker support on your mac</li> <li>Setup the kind cluster manually using <code>kind</code>/<code>k3s</code>/etc.</li> </ol> <p>The first option might be the easiest way to get started, since it offers more tight integration with the macOS environment, for example by exposing services and providing a LoadBalancer implementation out of the box.</p> OrbStackKinD <p>If you're running OrbStack, you can spin up an embedded, one-node, lightweight cluster by checking the Enable Kubernetes cluster box in the settings (if unchecked): </p> <p>When OrbStack is done with creating a k8s cluster for you, you will be able to use regular cluster management tools like <code>kubectl</code>/<code>k9s</code>/etc to manage your cluster.</p> <pre><code>kubectl get nodes #(1)!\n</code></pre> <ol> <li><code>kubectl</code> is also installed during the <code>make download-tools</code> step.</li> </ol> <pre><code>NAME       STATUS   ROLES                  AGE   VERSION\norbstack   Ready    control-plane,master   28m   v1.29.3+orb1\n</code></pre> <p>Now, your cluster is ready to run its first EDA installation!</p> <p>Should you choose not to use embedded k8s support in the tool of your choice, you can install a KinD cluster manually.</p> <p>Run the following command from your playground repository to install a KinD cluster:</p> <pre><code>make kind\n</code></pre>"},{"location":"software-install/non-production/macos/#installing-eda","title":"Installing EDA","text":"<p>When running docker/k8s on a mac we have some layered networking to deal with, as the k8s cluster runs in a VM.</p> <p>First, we need to set the <code>EXT_IPV4_ADDR</code> and/or <code>EXT_IPV6_ADDR</code> variables to the IP address of the cluster node. You can find these addresses by running the following command:</p> <pre><code>kubectl get nodes -o jsonpath='{.items[0].status.addresses}'\n</code></pre> <p>And also set a pair of no proxy variables set to the cluster cidr of your cluster. You can get it with:</p> <pre><code>kubectl get nodes -o jsonpath='{.items[0].spec.podCIDR}'\n</code></pre> <p>And once all the variables are known, you can start the installation. If you are running OrbStack, you can use the following command verbatim to install EDA:</p> <pre><code>EXT_IPV4_ADDR=198.19.249.2 \\\nEXT_IPV6_ADDR=fd07:b51a:cc66::2 \\\nEXT_HTTPS_PORT=443 \\\nNO_PROXY=192.168.194.0/25 \\\nno_proxy=192.168.194.0/25 \\\nmake try-eda NO_KIND=yes NO_LB=yes\n</code></pre> <p>Potential turbulence</p> <p>You may experience some hiccups during install, for example</p> <ol> <li>Some application is stuck during install</li> <li>Simulator nodes not starting up</li> <li>NPP pods not starting up</li> </ol> <p>This is all due to the fact that the majority of the images are running under Rosetta virtualization (they are not available yet in ARM64 arch). The workaround is to restart the <code>eda-ce</code> deployment when things get stuck.</p>"},{"location":"software-install/non-production/macos/#connecting-to-the-uiapi","title":"Connecting to the UI/API","text":"<p>Depending on the tool you're using to run k8s, your method of connecting to the UI will vary.</p> OrbStack <p>In OrbStack, the k8s services are already exposed to your by the software, making it possible to access the UI by opening https://eda-api.k8s.orb.local/ in your browser.</p> <p>This integration, though, will make our generic installer bark about the port being already in use when we try to setup the port-forward for the UI access at the very end of the <code>make try-eda</code> command. Please ignore this error, as OrbStack already took care of the UI access for you.</p> <p>macOS 15+</p> <p>If your browser can not resolve the <code>eda-api.k8s.orb.local</code> domain, you need to add enable Local Network access policy for the browser of your choice since <code>.local</code> domain is resolved via mDNS. Check the Apple's documentation and this screenshot showing where the settings are located.</p> <p></p> <p>The default EDA credentials are <code>admin:admin</code>.</p>"},{"location":"software-install/non-production/macos/#tearing-down","title":"Tearing down","text":"<p>If something goes wrong during installation, or if you want to reinstall, or maybe you finished playing with EDA, feel free to destroy the cluster following the documentation for the tool you're using to run k8s.</p> In OrbStack <p>To remove the k8s cluster provided by OrbStack run the following command in the terminal:</p> <pre><code>orb delete k8s\n</code></pre> <p>This will remove the VM that backs up the k8s cluster. To bring back the empty k8s cluster run</p> <pre><code>orb start k8s\n</code></pre> <p>and now you can restart the EDA installation.</p> <ol> <li> <p>These performance cores finally have a purpose!\u00a0\u21a9</p> </li> </ol>"},{"location":"software-install/non-production/on-prem-cluster/","title":"EDA on an on-prem k8s cluster","text":"<p>The quickstart guide did a great job of getting you up and running with a local Kubernetes cluster powered by KinD. However, you may be willing to step away from the beaten path and install EDA in a non-KinD cluster. Well, EDA welcomes courageous souls like you!</p> <p>Note</p> <ol> <li>In this section we are not going into the details of how to install EDA in a production setting, since there are many environment-specific considerations to take into account. Instead, we will focus on bringing up the playground environment on a non-KinD k8s cluster.</li> <li> <p>The default installation procedure assumes that <code>cert-manager</code> does not exist in the cluster and will be installed by the playground installer.</p> <p>If you already have the cert-manager installed in your cluster (cert-manager and cert-manager-csi-driver) you can skip the installation of cert-manager by setting the <code>NO_CERT_MANAGER_INSTALL := yes</code> in your preferences file.</p> </li> </ol> <p>Alright, truth be told, the installation process is almost identical to the one you followed in the quickstart guide. This is one of the perks of running on top of Kubernetes that EDA enjoys - no matter what cluster it is (GKE, Openstack, k3s, minikube, etc), the installation process for the greater part would be the same.</p> <p>Take a seat, we are going to install EDA on a \"real\" k8s cluster running on bare VMs. But first, let's see what we are working with:</p> <pre><code>kubectl get nodes\n</code></pre> <pre><code>NAME         STATUS   ROLES           AGE   VERSION\nrd-eda1-cp   Ready    control-plane   31d   v1.30.1\nrd-eda1-w1   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w2   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w3   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w4   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w5   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w6   Ready    &lt;none&gt;          31d   v1.30.1\n</code></pre> <p> A 6-node k8s cluster running vanilla Kubernetes 1.30.1 release! Each node has 4vCPU and 16GB of RAM amounting to a total of 24vCPU and 96GB of RAM. This is a decent-sized cluster for running EDA playground.</p>"},{"location":"software-install/non-production/on-prem-cluster/#storage-classes","title":"Storage classes","text":"<p>Alright, first thing to ensure (besides of having the right context set in your <code>kubectl</code> of course) is that your cluster has some storage provider that gives you the default storage class. EDA Git deployments will have some PV claims and something needs to satisfy them, right?</p> <p>There are plenty of cloud-native storage solutions to choose from, pick one that suites your needs in case your cluster doesn't have one.</p> <p>To ensure you have one:</p> <pre><code>kubectl get storageclass\n</code></pre> <pre><code>NAME                 PROVISIONER          RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\nlonghorn (default)   driver.longhorn.io   Delete          Immediate           true                   36d\nlonghorn-static      driver.longhorn.io   Delete          Immediate           true                   36d\n</code></pre>"},{"location":"software-install/non-production/on-prem-cluster/#security-context","title":"Security context","text":"<p>If you run a cluster with a Pod Security Policy in place (like in case of a Talos cluster with defaults), make sure to allow a privileged policy for the <code>eda-system</code> namespace. The <code>cert-manager-csi-driver</code> daemonset requires this to run.</p> <pre><code>kubectl create namespace eda-system\n\nkubectl label namespace eda-system \\\npod-security.kubernetes.io/enforce=privileged \\\neda.nokia.com/core-ns=eda-system\n</code></pre>"},{"location":"software-install/non-production/on-prem-cluster/#playground-repository","title":"Playground repository","text":"<p>We will drive the installation process using the instrumentation provided by the Makefile stored in the playground repository. If you haven't done so yet, clone the repository and change into it:</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; \\\ncd playground\n</code></pre> <p>If you already have the repository cloned, make sure to pull in the latest changes and remove the <code>eda-kpt</code> and <code>catalog</code> directories before proceeding.</p>"},{"location":"software-install/non-production/on-prem-cluster/#parametrizing-the-installation","title":"Parametrizing the installation","text":"<p>To no-one's surprise, the EDA installation process on an existing cluster would require us at least to skip the creation of the KinD cluster that <code>make try-eda</code> target would call otherwise. Let's do that by using the prefs.mk file that the playground repository provides and set the following variables:</p> <pre><code># KinD cluster options\n# -----------------------------------------------------------------------------|\n# Do not deploy the kind cluster\n# Uncomment this variable to perform playground installation\n# on an already available k8s cluster\nNO_KIND := yes\n\n# How do clients reach your cluster?\n#  EXT_DOMAIN_NAME can also be set to an ipv4/6 address if no domain record\n#  is present. In that case EXT_IPV4_ADDR = $(EXT_DOMAIN_NAME) or its ipv6\n#  counterpart.\n# -----------------------------------------------------------------------------|\nEXT_DOMAIN_NAME = \"eda.mydomain.com\" #(1)!\nEXT_HTTPS_PORT = \"443\"\n</code></pre> <ol> <li>Set the DNS name or IP address of the cluster' ingress/gateway endpoint.</li> </ol> <p>The key variables to set would be <code>NO_KIND := yes</code> to skip the creation of the KinD cluster and <code>EXT_DOMAIN_NAME</code> and <code>EXT_HTTPS_PORT</code> to set the ingress/gateway endpoint and port.</p>"},{"location":"software-install/non-production/on-prem-cluster/#running-the-installation","title":"Running the installation","text":"<p>With the <code>prefs.mk</code> file populated, we can simply run:</p> <pre><code>make try-eda\n</code></pre> <p>Right, the same target that would otherwise install EDA on a local development KinD cluster can be used to install EDA on an existing cluster, like the one we have in this guide. After the installation process completes, you can use the verification commands to make sure everything is up and running.</p> <p></p> <p>Now you have a fully functional EDA installation running in a real Kubernetes cluster. Congratulations </p> <p>With a real cluster, you would likely want to have a GatewayAPI or Ingress configured so that you can access the EDA UI and API. We've prepared a separate guide to help you with that.</p>"},{"location":"software-install/non-production/wsl/","title":"EDA on Windows (WSL)","text":"<p>Thanks to EDA's deployment model that uses Kubernetes, you can install EDA anywhere where a Kubernetes cluster can run. And Windows is no exception! Thanks to the Windows Subsystem Linux (aka WSL). WSL allows Windows users to run a Linux distribution as a tightly-integrated VM.</p>"},{"location":"software-install/non-production/wsl/#installation-prerequisites","title":"Installation prerequisites","text":""},{"location":"software-install/non-production/wsl/#hardware-requirements","title":"Hardware requirements","text":"<p>Before proceeding with the installation, users have to ensure they meet the hardware requirements for EDA Playground installation that are outlined in the Try EDA section:</p> <p> 8 vCPUs  16GB of RAM  30GB of SSD storage</p> <p>The CPU/Memory/Storage requirements should be available to the WSL virtual machine, and the default settings used by the WSL system may not be enough to meet those requirements.</p> <p>Users can fine tune the resource allocations for the WSL virtual machine to meet their needs. Make sure to allocate the required number of CPU/Memory/Storage resources to the WSL virtual machine.</p>"},{"location":"software-install/non-production/wsl/#wsl-version","title":"WSL version","text":"<p>An important prerequisite for installing EDA on WSL is to have WSL version at 2.5 version or later. Check what version of the WSL you have running on your Windows, by running the following command in the Windows terminal:</p> <pre><code>wsl --version\n</code></pre> <p>If the version is older than 2.5 you will need to upgrade it. At the time of this writing, the WSL version 2.5 is available as a pre-release, to update your WSL to the pre-release version, run the following:</p> <pre><code>wsl --update --pre-release\n</code></pre>"},{"location":"software-install/non-production/wsl/#wsl-distributive","title":"WSL distributive","text":"<p>Windows offers you a choice of distributives you can install on WSL. While you can choose any Linux distributive, we can recommend running the WSL-Containerlab distributive that has been preconfigured with tools like Docker engine.</p> <p>Download the <code>.wsl</code> distributive file from the releases page and simply double click on it to install WSL-Containerlab WSL distributive.</p> <p>You should be able to see \"Containerlab\" as a program in your start menu, and by opening this program you will start the distributive.</p>"},{"location":"software-install/non-production/wsl/#eda-installation","title":"EDA installation","text":"<p>Once you are in the shell of a chosen WSL distributive, proceed with the EDA installation steps as laid out on the Try EDA page.</p>"},{"location":"software-install/non-production/wsl/#uiapi-access","title":"UI/API access","text":"<p>Once the installation of the EDA Playground is complete, you can start the UI/API port forward as outlined in Step 6 from the Try EDA page.</p>"},{"location":"software-install/upgrades/","title":"Upgrading EDA","text":"<p>Assuming you have a working EDA cluster, your upgrade process looks similar to an install + restore. An in place upgrade is not currently supported.</p> <p>The upgrade procedure consists of:</p> <ol> <li>Backup your existing cluster.</li> <li>Pull the latest version of the <code>kpt</code> package.</li> <li>Make any necessary edits to the <code>kpt</code> package.</li> <li>Pause your clusters interaction with your infrastructure.</li> <li>Stop EDA (on both the active and standby members if running geo redundant).</li> <li>Install the new <code>kpt</code> package (on both active and standby members if running geo redundant).</li> <li>Upgrade your applications.</li> <li>Unpause your clusters interaction with your infrastructure.</li> </ol> <p>Nuances for Air-gapped and Geo-redundant clusters</p> <p>The upgrade procedure does not change based on whether you have the Internet or Air-gapped cluster. But keep in mind that with the Air-gapped installation the target release bundles should be uploaded to the Assets VM first before proceeding with an upgrade.</p> <p>In geo redundant clusters, cluster members cannot run different versions. Therefore, before the software upgrade, you must first break cluster redundancy and then restore redundancy after the upgrade. To break the redundancy, remove the <code>.spec.cluster.redundant</code> section from the <code>EngineConfig</code> resource as described later in this document.</p>"},{"location":"software-install/upgrades/#backing-up-your-cluster","title":"Backing up your cluster","text":"<p>Backing up your existing cluster is performed using the <code>edactl</code> CLI tool:</p> <pre><code>edactl platform backup\n</code></pre> <pre><code>Platform backup done at eda-backup-engine-config-2025-04-22_13-51-50.tar.gz\n</code></pre> <p>This will create a backup in a gzipped tarball format, which contains all the necessary information to restore your cluster.</p> <p>Copy this backup outside of your <code>eda-toolbox</code> pod - as this pod is destroyed and recreated during the upgrade. Replace the file name with the one from the <code>edactl platform backup</code> command output and run:</p> <pre><code>toolboxpod=$(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\")\n\nkubectl cp eda-system/$toolboxpod:/eda/eda-backup-engine-config-2025-04-22_13-51-50.tar.gz \\\n    /tmp/eda-backup.tar.gz\n</code></pre> <p>The backup file will be copied to the <code>/tmp/eda-backup.tar.gz</code> file on your system.</p>"},{"location":"software-install/upgrades/#upgrading-eda-kpt-packages","title":"Upgrading EDA kpt packages","text":"<p>The workflow to upgrade the EDA kpt packages slightly differs depending on whether you have the original playground directory present in a system that you used to install EDA originally from or not.</p> If original playground repository presentIf playground repository missing <p>If you have the original playground directory, you should upgrade your kpt packages in place. This is the recommended approach, as it will keep your customizations intact.</p> <p>Change into the playground directory and run:</p> <pre><code>git pull --rebase --autostash -v\n</code></pre> <p>If you don't have the original playground directory, pull the repository again:</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; \\\ncd playground\n</code></pre> <p>If you are not upgrading to the latest version, specify the version of EDA you are upgrading to with adding the following lines to the <code>prefs.mk</code> file. For example, to choose the 25.8.1 version:</p> <pre><code>EDA_CORE_VERSION=25.8.1\nEDA_APPS_VERSION=25.8.1\n</code></pre> <p>Then update the packages by executing the following command from the playground repository:</p> <pre><code>make download-tools download-pkgs\n</code></pre>"},{"location":"software-install/upgrades/#customizing-kpt-packages","title":"Customizing kpt packages","text":"<p>If you have any customizations to your EDA installation, you should reapply them<sup>1</sup> by setting the variables in the prefs.mk file as was done during the installation phase. Reconfigure the EDA core components using the following command:</p> <pre><code>make eda-configure-core\n</code></pre> <p>At a minimum, ensure <code>EXT_DOMAIN_NAME</code> and <code>EXT_HTTPS_PORT</code> are set correctly in your <code>prefs.mk</code> file.</p>"},{"location":"software-install/upgrades/#breaking-geo-redundancy-optional","title":"Breaking geo redundancy (optional)","text":"<p>On your active cluster member, update your <code>EngineConfig</code> to remove the <code>.spec.cluster.redundant</code> section. This will break the geo redundancy and allow you to upgrade the active member without affecting the standby member.</p> <p>Changes on standby members</p> <p>Do not update the EngineConfig resource on standby members. Although stopped, if the standby members were to start, they must continue to look for the active member (and fail to do so) throughout the upgrade.</p>"},{"location":"software-install/upgrades/#pausing-npp-interactions","title":"Pausing NPP interactions","text":"<p>Place your <code>TopoNode</code> resources into <code>emulate</code> mode by setting the resource's <code>.spec.npp.mode</code> from <code>normal</code> to <code>emulate</code>.</p> <ul> <li>In this mode, EDA does not interact with targets, effectively pausing the cluster's interaction with your infrastructure.</li> <li>You can still interact with EDA and the <code>TopoNode</code> resources; changes are pushed upon switching back to <code>normal</code> mode.</li> </ul>"},{"location":"software-install/upgrades/#stopping-eda","title":"Stopping EDA","text":"<p>To stop EDA, enter the following command:</p> <pre><code>edactl platform stop\n</code></pre> <p>This command returns no output, but will result in all Pods packaged as part of <code>eda-kpt-base</code> being stopped and removed from the cluster. You can verify this with (replace with your base namespace if you modified it):</p> <pre><code>kubectl get pods -n eda-system\n</code></pre> <pre><code>NAME                                  READY   STATUS    RESTARTS   AGE\ncert-manager-csi-driver-n9bwk         3/3     Running   0          95m\neda-fluentbit-b7fns                   1/1     Running   0          96m\neda-fluentd-7cd48db9c5-9pvvp          1/1     Running   0          96m\neda-git-5db9dfc7bc-mn4rw              1/1     Running   0          95m\neda-git-replica-f69b9c9f4-bngf8       1/1     Running   0          95m\neda-toolbox-6d598f6db7-thlj7          1/1     Running   0          95m\ntrust-manager-69955c46b8-bghj6        1/1     Running   0          95m\n</code></pre> Nuances for geo redundant clusters <p>For geo redundant clusters, execute the <code>edactl platform stop</code> command on both active and standby members, via their respective <code>eda-toolbox</code> Pods.</p>"},{"location":"software-install/upgrades/#installing-the-new-version-of-eda","title":"Installing the new version of EDA","text":"<p>Enter the following command:</p> <pre><code>make install-external-packages eda-install-core eda-is-core-ready\n</code></pre>"},{"location":"software-install/upgrades/#restoring-your-backup","title":"Restoring your backup","text":"<p>You should execute this in the new <code>eda-toolbox</code> pod (typically in the <code>eda-system</code> Namespace). This will restore your cluster to its previous state.</p> <pre><code>edactl platform restore /tmp/eda-backup.tar.gz\n</code></pre>"},{"location":"software-install/upgrades/#upgrading-your-applications","title":"Upgrading your applications","text":"<p>A default install of EDA will install current-version applications, but your restore will have restored previous versions. These versions may be incompatible with the new version of EDA core, and must be upgraded immediately following the upgrade. The existing <code>Makefile</code> can be used to do so:</p> <pre><code>make eda-install-apps\n</code></pre>"},{"location":"software-install/upgrades/#allowing-npp-interactions","title":"Allowing NPP interactions","text":"<p>Re-enable interactions with your targets by placing your <code>TopoNode</code> resources back into <code>normal</code> mode by changing resource's <code>.spec.npp.mode</code> value from <code>emulate</code> to <code>normal</code>.</p>"},{"location":"software-install/upgrades/#verifying-cluster-health","title":"Verifying cluster health","text":"<p>Check the following to ensure your cluster is healthy:</p> <ul> <li>All pods are running and healthy.</li> <li>All <code>TopoNode</code> resources are in <code>normal</code> mode, and have synced with their targets.</li> <li>No transaction failures exist.</li> <li>All cluster members are synchronized.</li> </ul> <ol> <li> <p>see Installation customization for more details\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/access-control/","title":"Access Control","text":"<p>Warning</p> <p>This page covers access control of the EDA API Server and GUI. The EDA Config Engine can also be operated via the Kubernetes API. Kubernetes RBAC configuration should be considered when securing EDA Config Engine access.</p> <p>Role-based access control (RBAC) restricts access to resources based on the user's role in your organization. EDA uses KeyCloak to authenticate users and group membership, and the EDA API server handles request authorization based on the role(s) assigned to user group(s).</p>"},{"location":"user-guide/access-control/#users-user-groups","title":"Users &amp; User Groups","text":"<p>EDA users and user groups are stored in KeyCloak. The EDA API (and GUI) exposes the most common KeyClock administrative actions including User and User Group management. In the EDA UI, you'll find Users and User Groups in the <code>System Administration</code> panel under <code>User Management</code> &gt; <code>User Management</code>.</p> <p>User passwords set by an administrator can be flagged as temporary; this will prompt the user to change the password on first login. Administrators can also perform password resets, which sends the user an email with a password reset link.</p> <p>Note</p> <p>Email server configuration is not exposed in the EDA API/GUI. This must be configured directly in KeyCloak.</p>"},{"location":"user-guide/access-control/#federations","title":"Federations","text":"<p>Federations configure users and user group synchronization with remote directories such as OpenLDAP or Active Directory. In the GUI, federation providers can be configured in the <code>System Administration</code> panel under <code>User Management</code> &gt; <code>User Management</code>.</p>"},{"location":"user-guide/access-control/#password-policy","title":"Password Policy","text":"<p>A password policy allows a system administrator to define requirements around local user password complexity &amp; brute force protection. Note that these requirements do not apply to users sourced from a remote directory. In the GUI, you'll find Users and User Groups in the <code>System Administration</code> panel under <code>User Management</code> &gt; <code>Password Policy</code>.</p>"},{"location":"user-guide/access-control/#roles","title":"Roles","text":"<p>EDA <code>Cluster Roles</code> and <code>Roles</code> define the which permissions users have for the EDA API/GUI<sup>1</sup>.</p> <p><code>Roles</code> define permissions within a specific namespace, whereas <code>Cluster Roles</code> apply to all namespaces.</p> <p>Non-namespaced API endpoints can only be enforced by <code>Cluster Roles</code>. This includes cluster-wide resources (e.g. httpproxies), EDA administrative APIs, transaction results, etc. Basically, any API that doesn't specify a namespace in the path or payload is enforced by <code>Cluster Roles</code>.</p> <p>The EDA UI allows you to switch between 'All Namespaces' and specific namespace views. In the 'All Namespaces' view, requests use cluster-wide APIs which require ClusterRole permission. Users with permission only for specific namespaces will not see their resources in the 'All Namespaces' view.</p>"},{"location":"user-guide/access-control/#access-rule-types","title":"Access Rule Types","text":"<p>Both <code>ClusterRoles</code> &amp; <code>Roles</code> provide the following rule types:</p> <ul> <li> <p>Resource Rules controls EDA resource and workflow permissions using Group-Version-Kind (GVK) semantics. Each Resource Rule can include one or more API Groups in group/version format (e.g. \"core.eda.nokia.com/v1\") and one or more Resources (i.e. Kind). Either can be an exact match or wildcard (<code>*</code>).</p> </li> <li> <p>Table Rules provides a fine-tuning of permissions for queries to EDB. Table Rules support wildcarding of the final EDA path segment (<code>.*</code>) or multiple EDA path segments (<code>.**</code>)</p> </li> <li> <p>URL Rules define permission for EDA API endpoints based on their URL path. URL Rules support wildcarding of the final URL segment (<code>/*</code>) or multiple URL segments (<code>/**</code>). URL Rule permission is not required for API endpoints which are Resource Rule or Table Rule enforced.</p> </li> </ul>"},{"location":"user-guide/access-control/#requests-matching-multiple-rules","title":"Requests Matching Multiple Rules","text":"<p>Rules in EDA are additive. If a request matches both a <code>read</code> and <code>read write</code> rule, the user is granted <code>read write</code> access. If no rule is matched, the request is implicitly denied.</p> <p><code>None</code> permissions act as an override. If there is a matching <code>none</code> rule, access is always denied.</p> <p>Avoid <code>None</code> Rules</p> <p>If resource/table/URL access is not required for a role, the best practice is to not include a matching rule for that resource/table/URL. This ensures that users with multiple roles receives all required permissions.</p>"},{"location":"user-guide/access-control/#assigning-roles-to-users","title":"Assigning Roles to Users","text":"<p>Roles are associated to Users via User Groups. A User can be part of multiple User Groups, and each User Group may have multiple Roles.</p>"},{"location":"user-guide/access-control/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"user-guide/access-control/#transaction-result-access","title":"Transaction Result Access","text":"<p>Access to Transaction results is based on the user's access to the input resources of that transaction. If the user has read permission for all the input resources of a transaction, they can list all changed resources (both input and derived) and view the resource diffs. If the user has read permission for none or some of the input resources, they can not list any derived resources or view their diffs. Access to Node Configuration diffs must be opted-in using a urlRule. This is because the Node Configuration diff API returns the full node config, and not limited to the scope of the transaction.</p> <p>To revert a transaction, the user must has readWrite permission for all input resources of the transaction. To restore the EDA cluster to a specific transaction, the user must have readWrite permission to the restore API from a ClusterRole URL Rule. Restore is a powerful action which should be limited to trusted administrators.</p>"},{"location":"user-guide/access-control/#workflow-access","title":"Workflow Access","text":"<p>Just like EDA Resources, EDA Workflows follow the Kubernetes Group-Version-Kind (GVK) resource model. resourceRules grant read and readWrite permission to workflows.</p> <p>Additionally, users inherit access to subflows based on their access to the top-level parent flow. For example, a <code>DeployImage</code> workflow creates <code>Ping</code> subflows during it's pre and post check stages. If user A has read permission to the 'DeployImage' workflow definition they will be able to read the subflow results even if they do not have access to the <code>Ping</code> workflow definition.</p>"},{"location":"user-guide/access-control/#topology-access-in-specific-namespaces","title":"Topology Access in Specific Namespaces","text":"<p>Topology diagrams and their overlays are defined cluster-wide in EDA, but the state data which populates the topology diagrams is namespaced. Therefore, to view topologies in the UI for specific namespaces a combination of ClusterRoles and Roles is required.</p> ClusterRole - Physical topology <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: ClusterRole\nmetadata:\n  name: topology-definitions\n  labels: null\n  namespace: eda-system\nspec:\n  description: Access descriptions of physical topology and its overlays\n  urlRules:\n    - path: /core/topology/v1\n      permissions: read\n    - path: /core/topology/v1/topologies.eda.nokia.com_v1alpha1_physical\n      permissions: read\n    - path: /core/topology/v1/topologies.eda.nokia.com_v1alpha1_physical/overlay\n      permissions: read\n    - path: /core/topology/v1/topologies.eda.nokia.com_v1alpha1_physical/overlay/**\n      permissions: read\n  resourceRules: []\n  tableRules: []\n</code></pre> Role - Physical topology <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: Role\nmetadata:\n  name: ns-topo\n  namespace: eda\n  labels: {}\n  annotations: {}\nspec:\n  description: Access physical topology state in namespace 'eda'\n  urlRules:\n    - path: /core/topology/v1/topologies.eda.nokia.com_v1alpha1_physical/state\n      permissions: readWrite\n  resourceRules: []\n  tableRules: []\n</code></pre>"},{"location":"user-guide/access-control/#more-example-roles","title":"More Example Roles","text":"ClusterRole - Read only everything <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: ClusterRole\nmetadata:\n  name: readonly\n  namespace: eda-system\n  labels: null\nspec:\n  description: Read only for everything\n  resourceRules:\n    - apiGroups:\n      - '*'\n      permissions: read\n      resources:\n        - '*'\n  tableRules:\n    - path: .**\n      permissions: read\n  urlRules:\n    - path: /**\n      permissions: read\n</code></pre> ClusterRole - Read and write fabric resources and read-only related resources <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: ClusterRole\nmetadata:\n  name: fabric\n  namespace: eda-system\n  labels: null\nspec:\n  description: Read and Write for Fabrics and read-only for related resources\n  resourceRules:\n    - apiGroups:\n      - fabrics.eda.nokia.com/v1alpha1\n      permissions: readWrite\n      resources:\n        - '*'\n    - apiGroups:\n        - routing.eda.nokia.com/v1alpha1\n        - protocols.eda.nokia.com/v1alpha1\n        - core.eda.nokia.com/v1\n      permissions: read\n      resources:\n        - '*'\n  urlRules:\n    - path: /openapi/**\n      permissions: read\n  tableRules: []\n</code></pre> ClusterRole - run queries and update alarms (ack/delete/suppress/etc) <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: ClusterRole\nmetadata:\n  name: queryandalarms\n  labels: null\n  namespace: eda-system\nspec:\n  description: 'Permission to run queries and update alarms (ack/delete/suppress/etc)'\n  resourceRules: []\n  tableRules:\n    - path: .**\n      permissions: read\n  urlRules:\n    - path: /core/alarm/**\n      permissions: readWrite\n</code></pre> <ol> <li> <p>EDA <code>ClusterRoles</code> &amp; <code>Roles</code> are not the same as Kubernetes <code>ClusterRoles</code> &amp; <code>Roles</code>. Kubernetes RBAC controls are not used by the EDA API.\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/allocation-pools/","title":"Allocation Pools","text":"<p>There comes a time where every automation platform needs to allocate addresses and indexes \u2014 Whether it\u2019s an IP address, CIDR subnet, VLAN ID, subinterface index, autonomous system number, or more.</p> <p>EDA provides users and app developers a simple framework for defining and consuming allocation pools. Behind the scenes EDA ConfigEngine works to ensure:</p> <ul> <li>Deterministic allocations \u2014 If provided the same allocation input, the value of any previous allocation will be returned. No surprises!</li> <li>Persist allocations \u2014 Restarting the platform does not result in any re-indexing.</li> <li>Implicit freeing of allocations \u2014 If a resource is updated and no longer needs an allocation, it\u2019s freed up for something else.</li> </ul> <p>All of that while supporting the resizing of allocation pools, whether you need to grow or shrink them!</p>"},{"location":"user-guide/allocation-pools/#allocation-pool-types","title":"Allocation Pool Types","text":"<p>EDA offers four types of allocation pools:</p> <ol> <li>Indices<ul> <li>Specify a size and starting value</li> <li>Return an integer on allocation</li> </ul> </li> <li>IP Addresses<ul> <li>Specify an IPv4 or IPv6 subnet including mask in CIDR format (e.g. <code>192.0.2.0/24</code>)</li> <li>Return an address from the subnet on allocation, without any mask information (e.g. <code>192.0.2.1</code>)</li> </ul> </li> <li> <p>IP Addresses + Masks</p> <ul> <li>Specify an IPv4 or IPv6 subnet including mask in CIDR format (e.g. <code>192.0.2.0/24</code>)</li> <li>Return an address from the subnet on allocation, with mask information (e.g. <code>192.0.2.1/24</code>) <p>By default, EDA will not allocate the first and last address in the subnet.  </p> <ul> <li>To enable allocation of the first address, set 'Allocate Network Address' to True.</li> <li>To enable allocation of the last address, set 'Allocate Broadcast Address' to True.</li> </ul> </li> </ul> </li> <li> <p>Subnets</p> <ul> <li>Specify an IPv4 or IPv6 subnet including mask in CIDR format (e.g. <code>192.0.2.0/24</code>), and a subnet length (e.g. <code>31</code>)</li> <li>Return a subnet of the specified length from the provided subnet on allocation, with mask information (e.g. <code>192.0.2.8/31</code>)</li> </ul> </li> </ol>"},{"location":"user-guide/allocation-pools/#allocation-pool-segments-and-next-allocation","title":"Allocation Pool Segments and Next Allocation","text":"<p>An allocation pool consists of a set of segments. You can think of a segment as a block of indexes \u2014 some indexes are taken (allocated) and some are free (either because they were freed or have yet to be used).</p> <p>In a fresh system where no resources has been deleted, you would see allocations start in the first segment at index 0, and proceeding forwards by 1 for each allocation (i.e allocations within a segment are sequential and consecutive.)</p> <p>Let\u2019s look at an example. Suppose you have an index pool with two segments:</p> <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: IndexAllocationPool\nmetadata:\n  name: example\n  namespace: eda\nspec:\n  segments:\n  - start: 0\n    size: 5\n  - start: 100\n    size: 5\n</code></pre> <p>Initially, the pool would look like this (where <code>X</code> represents an allocation):</p> <pre><code>| 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|---|---|---|---|---|-----|-----|-----|-----|-----|\n|   |   |   |   |   |     |     |     |     |     |\n</code></pre> <p>Assuming a resource was created and the config script requests one index, the resulting pool would look like this:</p> <pre><code>| 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|---|---|---|---|---|-----|-----|-----|-----|-----|\n| X |   |   |   |   |     |     |     |     |     |\n</code></pre> <p>If the user created five more instances of the resource, the resulting pool would look like:</p> <pre><code>| 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|---|---|---|---|---|-----|-----|-----|-----|-----|\n| X | X | X | X | X |  X  |     |     |     |     |\n</code></pre> <p>Now assume the resource driving the second instance of the script was deleted (which would result in an implicit free), the pool would look like:</p> <pre><code>| 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|---|---|---|---|---|-----|-----|-----|-----|-----|\n| X |   | X | X | X |  X  |     |     |     |     |\n</code></pre> <p>It is hopefully obvious that the next resource to use the same pool would get the index 1, rather than index 101. A more interesting exercise at this point is to introduce a new segment at the start of the pool:</p> <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: IndexAllocationPool\nmetadata:\n  name: example\n  namespace: eda\nspec:\n  segments:\n  - start: 200\n    size: 5\n  - start: 0\n    size: 5\n  - start: 100\n    size: 5\n</code></pre> <p>The resulting pool would now look like:</p> <pre><code>| 200 | 201 | 202 | 203 | 204 | 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|-----|-----|-----|-----|-----|---|---|---|---|---|-----|-----|-----|-----|-----|\n|     |     |     |     |     | X |   | X | X | X |  X  |     |     |     |     |\n</code></pre> <p>Note that if any of the previous config scripts ran for any reason, they would get their existing allocations, as they have registered keys against them.</p> <p>If a new allocation was performed now, it would be drawn from the new segment:</p> <pre><code>| 200 | 201 | 202 | 203 | 204 | 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|-----|-----|-----|-----|-----|---|---|---|---|---|-----|-----|-----|-----|-----|\n|  X  |     |     |     |     | X |   | X | X | X |  X  |     |     |     |     |\n</code></pre> <p>Adding or rearranging segments does not result in any allocation changes.</p> <p>Now let's look at what happens when you shrink a pool by removing a segment:</p> <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: IndexAllocationPool\nmetadata:\n  name: example\n  namespace: eda\nspec:\n  segments:\n  - start: 200\n    size: 5\n  - start: 100\n    size: 5\n</code></pre> <p>Allocations in the removed segment (indexes 0, 2, 3, and 4) are freed, and all config scripts dependent on this pool will rerun. The resulting pool would look like:</p> <pre><code>| 200 | 201 | 202 | 203 | 204 | 100 | 101 | 102 | 103 | 104 |\n|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n|  X  |  X  |  X  |  X  |  X  |  X  |     |     |     |     |\n</code></pre> <p>Note that index 100 was not impacted by the change, nor was index 200.</p> <p>While this example covers an IndexAllocationPool, the principles are the same across all pool types \u2014 the only difference is how you define the segment ranges.</p>"},{"location":"user-guide/allocation-pools/#segment-pre-allocations-reservations","title":"Segment (Pre-)Allocations &amp; Reservations","text":"<p>Do you want to use allocation pools, but there are scenarios where you need to take the wheel and decide which IP address goes where? 'Allocations' and 'Reservations' options are available in all allocation pool segments to give the manual control you need.</p> <ul> <li> <p>Allocations predefine an allocation against a given key.</p> </li> <li> <p>Reservations block a range within the segment, preventing it from being allocated by EDA.</p> </li> </ul> <p>Note</p> <p>The allocation mechanism is also how a default gateway can be provided via a pool and retrieved via an EDA app.</p>"},{"location":"user-guide/allocation-pools/#allocation-scope","title":"Allocation Scope","text":"<p>Not every allocation needs to be global. For example, subinterface indexes in SR Linux are locally significant to their interface. A user shouldn't need to define separate allocation pools for each interface in the network.</p> <p>This is where allocation scope comes in!</p> <p>In EDA, every allocation pool supports scope. Think of the allocation pool resource as a template and the scope as an instance of that template. By default, allocations use the 'global' scope but an app developer can define a scope based on their needs \u2014 whether it\u2019s per interface, per node, or something entirely different. The possibilities are endless!</p>"},{"location":"user-guide/containerlab-integration/","title":"Containerlab Integration","text":"<p>To facilitate end-to-end testing and validation of configuration changes, EDA comes equipped with its own multi vendor network emulation engine abbreviated as CX. CX is a highly scalable network emulation platform that powers EDA's Digital Twin capabilities.</p> <p>Acknowledging that EDA CX is a new network emulation platform that is still in the process of maturing, we wanted to offer a way to integrate EDA with multitude of existing network topologies built with Containerlab.</p> <p>In this section we cover how to integrate EDA with a lab built with Containerlab in a fully automated way first, and then explain how to do this manually with a deep dive on things involved in the onboarding process. To keep things practical, we will take a real lab built with Containerlab - srl-labs/srlinux-vlan-handling-lab and integrate it with EDA.</p> VLAN handling lab <p>This tiny lab consists of two SR Linux nodes and two clients connected to it which is all we need to demonstrate the integration. Let's deploy it like any other containerlab topology:</p> <pre><code>sudo containerlab deploy -t srl-labs/srlinux-vlan-handling-lab #(1)!\n</code></pre> <ol> <li>The lab will be cloned to the current working directory and deployed.</li> </ol> <p>Containerlab, SR Linux, and EDA versions</p> <p>For a successful integration you need to ensure the following minimal version requirements:</p> <ul> <li>Containerlab 0.62.2</li> <li>SR Linux 24.10.1</li> <li>EDA 24.12.1</li> </ul> <p>This article was validated using the following versions:</p> <ul> <li>Containerlab: 0.62.2</li> <li>SR Linux: 24.10.1</li> <li>EDA: 24.12.1</li> </ul> <p>Our end game is to install EDA and integrate it with the Containerlab topology so that we could manage the lab nodes using EDA. The integration scenario is depicted in the diagram below.</p>"},{"location":"user-guide/containerlab-integration/#installing-eda","title":"Installing EDA","text":"<p>The reason we started this section with a mention of EDA CX is because as of EDA v24.12.1 the platform is installed by default with the CX engine enabled. What this means is that EDA will spin up virtual simulator nodes using the CX engine for every topology node. To let EDA manage external nodes (either real hardware or virtual nodes spawned outside of EDA) we need to provide a specific installation option.</p> <p>Clone the EDA Playground repository if you haven't already and uncomment the following line in the preferences (<code>prefs.mk</code>) file :</p> <pre><code>SIMULATE = false\n</code></pre> <p>And start deploying EDA:</p> <pre><code>make try-eda\n</code></pre> <p>With the disabled simulation mode, EDA will be installed without the <code>eda-cx</code> deployment present and no topology loaded.</p> <p>License required</p> <p>Unfortunately, the nodes spawned outside of EDA CX are currently considered as hardware nodes and are licensed. Even the virtual SR Linux nodes that are spawned by Containerlab </p> <p>You can reach out to the EDA PLM team member in discord to check if they can help acquire one.</p> <p>If you have a license, apply it to your cluster like this:</p> License manifestapply command eda-license.yaml<pre><code>apiVersion: core.eda.nokia.com/v1\nkind: License\nmetadata:\n  name: eda-license\n  namespace: eda-system\nspec:\n  enabled: true\n  data: \"YoUrLiCeNsEDaTa\"\n</code></pre> <pre><code>kubectl apply -f eda-license.yaml\n</code></pre>"},{"location":"user-guide/containerlab-integration/#reachability-requirements","title":"Reachability requirements","text":"<p>For EDA to manage nodes spawned outside of the Kubernetes cluster it is deployed in, it must be able to reach them. In this tutorial we are installing EDA in the KinD cluster that comes as a default with the EDA Playground installation; so our EDA installation will be running alongside the Containerlab topology on the same host machine.</p> <p>Yet, even though KinD and Containerlab are running on the same host, these two environments are isolated from each other as prescribed by the Docker networking model and enforced by iptables. In order to allow KinD cluster to communicate with Containerlab nodes Containerlab 0.62.2 release installs allowing iptables rules to the <code>DOCKER-USER</code> chain for v4 and v6 families.</p> <p>To confirm that the communication is indeed allowed, we can take a management IP of one of our Containerlab nodes and ping it from the <code>eda-bsvr</code> pod that is one of the pods requiring connectivity with the Containerlab nodes.</p> <p>Let's issue a ping from the <code>eda-bsvr</code> pod to the <code>clab-vlan-srl1</code> node:</p> copy-paste command to srl1<pre><code>kubectl -n eda-system exec -i \\\n$(kubectl -n eda-system get pods -l eda.nokia.com/app=bootstrapserver \\\n-o=jsonpath='{.items[*].metadata.name}') \\\n-- ping -c 2 $(sudo docker inspect -f '{{.NetworkSettings.Networks.clab.IPAddress}}' clab-vlan-srl1)\n</code></pre> <p>If you managed to copy-paste things right, you should see packets happily flying between EDA and Containerlab nodes. OK, now, with the containerlab topology running, EDA installed and connectivity requirements satisfied, we can proceed with the actual integration.</p>"},{"location":"user-guide/containerlab-integration/#automated-integration","title":"Automated integration","text":"<p>In pursue of a one-click integration experience, we have created the <code>clab-connector</code> CLI tool that automates the integration process.</p>"},{"location":"user-guide/containerlab-integration/#installation","title":"Installation","text":"<p>The <code>clab-connector</code> tool is easily installable using <code>uv</code> package manager, therefore start with installing <code>uv</code> and then <code>clab-connector</code>:</p> Install clab-connector (requires uv)Install uv <pre><code>uv tool install git+https://github.com/eda-labs/clab-connector.git\n</code></pre> <p>If you wanted to save a click, here is a quick one-liner installer from uv website:</p> for Linux and macOS<pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre>"},{"location":"user-guide/containerlab-integration/#usage","title":"Usage","text":"<p>Clab-connector leverages Kubernetes API, EDA API and Containerlab topology export data to automate the integration process. Consequently, the host machine where the <code>clab-connector</code> tool is installed must have access to the kube config file, EDA API endpoint and Containerlab's <code>topology-data.json</code><sup>1</sup> file.</p>"},{"location":"user-guide/containerlab-integration/#integrate","title":"Integrate","text":"<p>If you haven't changed any of the default credentials in your EDA installation, you can integrate EDA with Containerlab as simply as:</p> <pre><code>clab-connector integrate \\\n--eda-url https://your.eda.host \\\n-t ~/path/to/your-lab/clab-yourlab/topology-data.json #(1)!\n</code></pre> <ol> <li>The <code>topology-data.json</code> file is located in the Containerlab Lab Directory, which is created next to the lab's topology file.</li> </ol> <p>If you happen to change the default user credentials, you can provide them with <code>--eda-user</code> and <code>--eda-password</code> flags. Run <code>clab-connector integrate --help</code> to see all the available flags.</p> <p>The connector tool will create a new EDA namespace matching the Containerlab lab name and will create the required resources in it. This allows you to managed as many distinct labs as you want, without having clashing resources between them.</p>"},{"location":"user-guide/containerlab-integration/#remove","title":"Remove","text":"<p>To remove the EDA integration, run:</p> <pre><code>clab-connector remove \\\n--eda-url https://your.eda.host \\\n-t ~/path/to/your-lab/clab-yourlab/topology-data.json\n</code></pre> <p>This will remove the previously created namespace and all the resources inside it.</p>"},{"location":"user-guide/containerlab-integration/#manual-integration","title":"Manual integration","text":"TLDR <p>To integrate SR Linux nodes spawned by Containerlab with EDA in the manual mode you need to:</p> <ol> <li>Apply an EDA license to be able to integrate with SR Linux nodes spawned outside of EDA CX</li> <li>optional Change the default NodeUser resource to use the <code>NokiaSrl1!</code> password</li> <li>Create a NodeProfile resource with the OS/version/yang fields set to the corresponding values</li> <li>Create a TopoNode resource for each SR Linux node</li> <li>Create an Interface resource per each endpoint of SR Linux nodes.</li> <li>Create a TopoLink resource for each link referencing the created Interface resources</li> </ol> Copy/Paste snippets <p>If you want to quickly onboard SR Linux nodes after spawning the srl-labs/srlinux-vlan-handling-lab containerlab topology, you can copy paste the following snippet entirely in your terminal.</p> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: NodeUser\nmetadata:\n  name: admin\n  namespace: eda\nspec:\n  groupBindings:\n    - groups:\n        - sudo\n      nodeSelector:\n        - \"\"\n  username: admin\n  password: NokiaSrl1!\n  sshPublicKeys:\n    # an optional list of ssh public keys for the node user\n    # - \"ssh-ed25519 AAAAC3NzaC1lZYOURKEYHEREYOURKEYHEREYOURKEYHEREYOURKEYHEREHDLeDteKN74\"\n\n$(ssh-add -L | awk '{print \"    - \\\"\"$0\"\\\"\"}')\nEOF\n\ncat &lt;&lt; 'EOF' | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: NodeProfile\nmetadata:\n  name: srlinux-clab-24.10.1\n  namespace: eda\nspec:\n  operatingSystem: srl\n  version: 24.10.1\n  versionPath: .system.information.version\n  versionMatch: v24\\.10\\.1.*\n  images:\n    - image: fake.bin\n      imageMd5: fake.bin.md5\n  port: 57410\n  yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n  onboardingUsername: admin\n  onboardingPassword: NokiaSrl1!\n  nodeUser: admin\n  annotate: true\n\nEOF\n\ncat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl1\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: $(sudo docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' clab-vlan-srl1)\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl2\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: $(sudo docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' clab-vlan-srl2)\nEOF\n\ncat &lt;&lt; 'EOF' | kubectl apply -f -\n#########################\n#### srl1 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl1\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl1-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl1\n  type: interface\n\n#########################\n#### srl2 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl2-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl2\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl2-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl2\n  type: interface\n\nEOF\n\ncat &lt;&lt; 'EOF' | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-client1\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl1-ethernet-1-1\n      remote:\n        node: clab-vlan-client1\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-srl2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl1-ethernet-1-10\n      remote:\n        node: clab-vlan-srl2\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl2-ethernet-1-10\n      type: interSwitch\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl2-client2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl2\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl2-ethernet-1-1\n      remote:\n        node: clab-vlan-client2\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n\nEOF\n</code></pre> <p>Even though automated integration makes the integration so easy, it is the manual integration that explains the moving parts and the underlying concepts. By completing this section you will get a decent understanding of the onboarding process and will breeze through the automated integration later on.</p>"},{"location":"user-guide/containerlab-integration/#sr-linux-configuration","title":"SR Linux configuration","text":"<p>Our goal is to have EDA to discover and onboard the SR Linux nodes running as part of the Containerlab topology. When Containerlab<sup>2</sup> spins up the SR Linux nodes it will add two EDA-specific gRPC servers to the default config; these servers will allow EDA to discover and later manage the nodes.</p> <pre><code>sudo docker exec clab-vlan-srl1 sr_cli info system grpc-server 'eda*'\n</code></pre> <pre><code>    system {\n        grpc-server eda-discovery {\n            admin-state enable\n            rate-limit 65535\n            session-limit 1024\n            metadata-authentication true\n            default-tls-profile true\n            network-instance mgmt\n            port 50052 #(1)!\n            services [\n                gnmi\n                gnsi\n            ]\n        }\n# snipped for brevity\n        grpc-server eda-mgmt {\n            ### Unable to retrieve TLS profile 'EDA'\n            admin-state enable\n            rate-limit 65535\n            session-limit 1024\n            metadata-authentication true\n            tls-profile EDA #(2)!\n            network-instance mgmt\n            port 57410 #(3)!\n            services [\n                gnmi\n                gnoi\n                gnsi\n            ]\n        }\n    }\n</code></pre> <ol> <li>EDA expects the discovery gRPC server to listen on port 50052.</li> <li>The <code>EDA</code> TLS profile is a hardcoded name of the TLS profile that the EDA bootstrap server will install during the onboarding process. Since this profile does not exist until the onboarding process is completed, the annotation says that the profile with this name can not be retrieved. This annotation will be removed once the onboarding process is completed and the TLS profile is created by the bootstrap server.</li> <li>Since Containerlab already sets up the <code>mgmt</code> gRPC server on port 57400 for the SR Linux nodes, the additional <code>eda-mgmt</code> gRPC server is configured to listen on a custom port 57410 that references the <code>EDA</code> TLS profile.</li> </ol> <p>You will find the <code>eda-discovery</code> grpc server that is used by EDA to discover the node and setup the TLS certificates and the <code>eda-mgmt</code> grpc server that is used by EDA to manage the node after the initial discovery using the provisioned TLS certificates.</p>"},{"location":"user-guide/containerlab-integration/#toponode","title":"TopoNode","text":"<p>It is time to let EDA know about the Containerlab topology and onboard the two SR Linux nodes that are running under the names <code>clab-vlan-srl1</code> and <code>clab-vlan-srl2</code>. But how do we do it?</p> <p>It all starts with the TopoNode resource. The TopoNode resource is part of the EDA core and describes an abstracted node in the topology. In order to let EDA know about a node it needs to manage, we need to create a TopoNode resource per each SR Linux node in our Containerlab topology.</p> <p>TopoNode's Custom Resource Definition (CRD) documentation describes the fields a resource of this type might have, but we need only a subset of them. Here are our two TopoNode resources named according to the container names of our SR Linux nodes in the topology:</p> <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl1\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: # IP address of the clab-vlan-srl1 node\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl2\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: # IP address of the clab-vlan-srl2 node\n</code></pre> <p>If you feel lost, don't worry, we will explain what these fields mean in a moment.</p>"},{"location":"user-guide/containerlab-integration/#metadata","title":"Metadata","text":"<p>Following the Kubernetes Resource Model (KRM), we specify the <code>apiVersion</code> and <code>kind</code> of the resource we are describing in YAML format. The TopoNode resource belongs to the <code>core.eda.nokia.com</code> API group of the <code>v1</code> version and the resource kind is - <code>TopoNode</code>.</p> <p>Next comes the metadata section. There, we specify the desired resource name. The name of the TopoNode resource does not have to match anything specific, but to keep things consistent with the Containerlab topology, we will use the corresponding container name of the SR Linux node.</p> <p>In the labels section we need to add a label that describes how the node TLS certificates should be handled. EDA is a secure-first platform where all the communications are secured by default, and interactions with the networking nodes are no exception. With the <code>eda.nokia.com/security-profile: managed</code> label we tell EDA that it needs to manage the certificate lifecycle for the node. Without going into the details, this mode ensures fully automated certificate management for the node.</p> <p>EDA Playground installation comes with a pre-created user namespace called <code>eda</code>. This pre-provisioned namespace should contain all user-provided resources, like TopoNode. Hence, we set the namespace to <code>eda</code> in the <code>metadata</code> section.</p>"},{"location":"user-guide/containerlab-integration/#system-information","title":"System information","text":"<p>Jumping over to the <code>.spec</code> object of the TopoNode resource, we can spot a block with System Information data:</p> <pre><code>operatingSystem: srl\nplatform: 7220 IXR-D2L\nversion: 24.10.1\n</code></pre> <ul> <li>The <code>operatingSystem</code> field is set to <code>srl</code> for Nokia SR Linux nodes we about to get onboarded.</li> <li>And the <code>platform</code> field should contain the SR Linux platform name in its full text form. Since in the Containerlab topology we did not specify the SR Linux platform type, it defaults to 7220 IXR-D2L</li> <li>The <code>version</code> field must match the version of the SR Linux container image we are using in our topology.</li> </ul>"},{"location":"user-guide/containerlab-integration/#address","title":"Address","text":"<p>Since our SR Linux nodes were deployed with Containerlab, EDA can't possibly know the nodes IP addresses. We need to provide this information, and TopoNode resource has a field for that:</p> <pre><code>productionAddress:\n  ipv4: # IP address of the clab-vlan-srl1 node\n</code></pre> <p>We chose to use the IPv4 address assigned by Containerlab, but IPv6 addresses are also supported. EDA will use this IP address to reach the node and start the onboarding process once the TopoNode resource is created in cluster.</p> <p>Providing the production address information disables the whole DHCP/ZTP workflow at the bootstrap server side, as the node is considered to be bootstrapped by an external system (like Containerlab).</p> <p>Bootstrap server in this case will just ensure that the node is reachable and setup a valid TLS certificate.</p>"},{"location":"user-guide/containerlab-integration/#node-profile","title":"Node profile","text":"<p>The last piece in the TopoNode resource that we must set is a NodeProfile.</p> <pre><code>nodeProfile: srlinux-clab-24.10.1\n</code></pre> <p>The NodeProfile, surprise-surprise, defines the profile of the node that a particular TopoNode resource is going to use.</p> <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: NodeProfile\nmetadata:\n  name: srlinux-clab-24.10.1\n  namespace: eda\nspec:\n  operatingSystem: srl\n  version: 24.10.1\n  versionPath: .system.information.version\n  versionMatch: v24\\.10\\.1.*\n  images:\n    - image: fake.bin\n      imageMd5: fake.bin.md5\n  port: 57410\n  yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n  onboardingUsername: admin\n  onboardingPassword: NokiaSrl1!\n  nodeUser: admin\n  annotate: true\n</code></pre> <p>It contains more details about the node transport parameters, imaging information and YANG schema. Let's cover the most important fields of this resource.</p>"},{"location":"user-guide/containerlab-integration/#os-and-version","title":"OS and version","text":"<p>The first thing you see in the NodeProfile spec is the OS and version information. It has to match the OS and version provided in the associated TopoNode resource. Besides that, it also has to specify the path in JSPath notation to use to fetch the version value from the node and the regex to match against the fetched version value.</p> <pre><code>operatingSystem: srl\nversion: 24.10.1\nversionPath: .system.information.version\nversionMatch: v24\\.10\\.1.*\n</code></pre>"},{"location":"user-guide/containerlab-integration/#image","title":"Image","text":"<p>When a hardware node running SR Linux uses the ZTP process, the Bootstrap server provides a ZTP script that contains the initial bootstrap configuration and the target image URL. The URL that the Bootstrap server uses is provided with the <code>.spec.images[].image</code> field of the NodeProfile resource.</p> <pre><code>images:\n  - image: fake.bin\n    imageMd5: fake.bin.md5\n</code></pre> <p>You might ask why we need that for a Containerlab-spawned virtual node that does not need to be imaged? Good question. Since this field is marked as required in the CRD we have to provide some value but for the virtual nodes we can provide a dummy URL. This is exactly what we did in our NodeProfile resource.</p>"},{"location":"user-guide/containerlab-integration/#grpc-port","title":"gRPC port","text":"<p>With the <code>port</code> field we specify the gRPC port number for the server that EDA will use to manage the node. If you remember, in the SR Linux configuration section we mentioned that Containerlab adds <code>eda-mgmt</code> gRPC server listening on port 57410. This port is set in the NodeProfile resource and EDA will use it to connect to the node once the onboarding process is done.</p>"},{"location":"user-guide/containerlab-integration/#yang-schema","title":"YANG schema","text":"<p>One of the EDA's core features is its ability to validate the intents before applying them to the nodes. The validation piece is crucial for the mission-critical networks and EDA takes care of that.</p> <p>To validate the intents, no matter how complex they are, EDA needs to know the YANG schema of the node it talks to. This requirement makes YANG schema a mandatory field in the NodeProfile resource; it should point to an HTTP location where EDA can fetch the YANG schema. We call this YANG bundle a Schema Profile.</p> <pre><code>yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n</code></pre> <p>As part of the EDA Playground installation, the schema profile for SR Linux 24.10.1 version is already provided and is server by the EDA's Artifact server.</p>"},{"location":"user-guide/containerlab-integration/#user","title":"User","text":"<p>EDA uses gNMI protocol to communicate with the nodes, starting from discovery and onboarding. The gNMI server authenticates the client using the username and password pair provided in the gRPC metadata.</p> <p>For the onboarding step to be successful, a pair of credentials needs to be provided via the <code>onboardingUsername</code> and <code>onboardingPassword</code> fields.</p> <pre><code>onboardingUsername: admin\nonboardingPassword: NokiaSrl1!\n</code></pre> <p>When EDA will reach to the node's discovery gRPC server over the predefined <code>50052</code> port it will supply this credentials in the gRPC metadata. The provided credentials must be valid and since we are using the default <code>admin</code> credentials in these fields we can rest assured that the authentication will succeed.</p> <p>But the onboarding user might not be the same as the one used for the ongoing management of the node. When EDA creates the Node Push/Pull (NPP) pods that are responsible for the configuration push and pull operations, these pods will use the credentials of a user defined in the NodeUser resource that we refer to in the NodeProfile as well:</p> <pre><code>nodeUser: admin\n</code></pre> <p>The <code>admin</code> NodeUser resource has been created as part of the EDA Playground installation, but it uses a non-default SR Linux password, that we would like to change. To do that, we will craft a resource manifest that uses the default <code>NokiaSrl1!</code> password, as well as add a public key<sup>3</sup> to enable typing-free SSH access.</p> <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: NodeUser\nmetadata:\n  name: admin\n  namespace: eda\nspec:\n  groupBindings:\n    - groups:\n        - sudo\n      nodeSelector:\n        - \"\"\n  username: admin\n  password: NokiaSrl1!\n  sshPublicKeys:\n    # an optional list of ssh public keys for the node user\n    # - \"ssh-ed25519 AAAAC3NzaC1lZYOURKEYHEREYOURKEYHEREYOURKEYHEREYOURKEYHEREHDLeDteKN74\"\n</code></pre> <p>The NodeUser resource references the NodeGroup resource that contains the AAA parameters this user should inherit.</p>"},{"location":"user-guide/containerlab-integration/#topolink","title":"TopoLink","text":"<p>If we were to apply the TopoNode resource right now, we would end up getting the following topology diagram in EDA UI:</p> <p></p> <p>There is obviously a piece missing - the topology doesn't have any links! And the reason is simple - we haven't defined any topology link resources.</p> <p>The TopoLink resource is responsible for defining the topology links. As the CRD description says:</p> <p>TopoLink represents a logical link between two TopoNodes. It may include more than one physical link, being used to represent a LAG or multihomed link.</p> <p>Looking at our lab diagram we can identify three topology links (highlighted in cyan):</p> TopoLink objects <p>In EDA, we call links between the switches inter switch links, links between the switches and the clients edge links, and loopback links are called just loopback. So our three topology links will be:</p> <ol> <li>The link between <code>srl1</code> and <code>client1</code> - <code>edge</code> link</li> <li>The link between <code>srl1</code> and <code>srl2</code> switches - <code>interSwitch</code> link</li> <li>The link between <code>srl2</code> and <code>client2</code> - <code>edge</code> link</li> </ol> <p>The TopoLink resource definition has a straightforward specification:</p> <pre><code>spec:\n  links:\n    - local: # required\n        interface:\n        interfaceResource: # required\n        node: # required\n      remote: # same as local\n      speed:\n      type: # required\n</code></pre> <p>A TopoLink, like any other link-like object is identified by a local endpoint and an optional remote endpoint. The local/remote endpoints are \"connecting\" to the TopoNode objects via <code>node</code> field.</p> <p>But this is not everything a TopoLink needs. It also requires us to provide a link to the Interface resource via the <code>interfaceResource</code> field, as this is the bind point for the link in a particular node.</p>"},{"location":"user-guide/containerlab-integration/#interface","title":"Interface","text":"<p>The Interface resource creates a physical interface on the node. In our topology we have two physical interfaces per each managed SR Linux node:</p> Interface objects <p>For a TopoLink resource to be valid, the Interface resources must be created first and then referenced in the TopoLink specification.</p> <p>Here is how you would define the <code>ethernet-1/1</code> interface on SR Linux node <code>srl1</code> that connects it to the <code>client1</code> node:</p> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl1\n  type: interface\n</code></pre> <p>As indicated in the spec, the Interface resource has a <code>members</code> field that can contain one (for a single interface) or multiple (for a LAG) interfaces objects. An implementation detail worth calling out is that the physical interface name should be normalized, i.e. SR Linux's <code>ethernet-1/1</code> becomes <code>ethernet-1-1</code>.</p> <p>As we do not have LAG interfaces in our lab topology, all our interfaces will have identical configuration.</p>"},{"location":"user-guide/containerlab-integration/#applying-the-resources","title":"Applying the resources","text":"<p>Let's summarize what we have learned so far:</p> <ol> <li>The TopoNode resource defines the node in the EDA topology.</li> <li>Creation of the TopoNode resource triggers onboarding process for the node.</li> <li>TopoNode resource references the NodeProfile resource that defines the lower level node parameters used in bootstrapping/onboarding and the management workflows.</li> <li>Onboarding happens over the well-known gRPC port 50052, this gRPC server is configured by Containerlab<sup>2</sup> automatically for the SR Linux nodes.</li> <li>Onboarding/Bootstrapping procedure sets up the <code>EDA</code> TLS profile using gNSI for SR Linux nodes. Once the certificate is installed, the node is marked as <code>onBoarded=true</code>.</li> <li>Onboarding user and the user used for the EDA management might be different. The \"permanent\" user is declaratively defined by the NodeUser resource.</li> <li>The gRPC server used for the management of the node is tied to the NodeProfile resource and is identified by the <code>port</code> field. This server should reference a dynamic <code>EDA</code> TLS profile that EDA's bootstrap server sets up during the onboarding workflow.</li> <li>When the node is onboarded, the NPP pod is spawned and connects to the node; it replaces the existing node configuration with the configuration calculated by EDA based on the defined intents.</li> <li>To create TopoLink resources, we need to create Interface resources first and then reference them in the TopoLink resource.</li> </ol> <p>Before we rush to apply the resources, let's capture the state of the current config present on our SR Linux nodes and verify that the configuration will be wiped out and replaced once EDA starts to manage the nodes.</p> <p>If you take a look at the lab's topology file, you will notice that the two SR Linux nodes are defined with the startup config blobs that create a pair of interfaces and attach them to a bridge domain <code>bridge-1</code>. It is easy to verify that:</p> interfacesnetwork instance <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'show interface ethernet-1/{1,10} brief'\n</code></pre> <pre><code>+---------------------+----------+----------+----------+----------+----------+\n|        Port         |  Admin   |   Oper   |  Speed   |   Type   | Descript |\n|                     |  State   |  State   |          |          |   ion    |\n+=====================+==========+==========+==========+==========+==========+\n| ethernet-1/1        | enable   | up       | 25G      |          |          |\n| ethernet-1/10       | enable   | up       | 25G      |          |          |\n+---------------------+----------+----------+----------+----------+----------+\n</code></pre> <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'show network-instance bridge-1 interfaces'\n</code></pre> <pre><code>==================================================================================\nNet instance    : bridge-1\nInterface       : ethernet-1/1.0\nType            : bridged\nOper state      : up\n==================================================================================\nNet instance    : bridge-1\nInterface       : ethernet-1/10.0\nType            : bridged\nOper state      : up\n==================================================================================\n</code></pre>"},{"location":"user-guide/containerlab-integration/#nodeuser","title":"NodeUser","text":"<p>With the initial state captured, let's start applying the resources in the bottom-up order, starting with the NodeUser resource:</p> NodeUser<code>kubectl</code> apply <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: NodeUser\nmetadata:\n  name: admin\n  namespace: eda\nspec:\n  groupBindings:\n    - groups:\n        - sudo\n      nodeSelector:\n        - \"\"\n  username: admin\n  password: NokiaSrl1!\n  sshPublicKeys:\n    # an optional list of ssh public keys for the node user\n    # - \"ssh-ed25519 AAAAC3NzaC1lZYOURKEYHEREYOURKEYHEREYOURKEYHEREYOURKEYHEREHDLeDteKN74\"\n</code></pre> <p>In this command we retrieve the public keys from the SSH agent and add add them to the NodeUser resource.</p> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: NodeUser\nmetadata:\n  name: admin\n  namespace: eda\nspec:\n  groupBindings:\n    - groups:\n        - sudo\n      nodeSelector:\n        - \"\"\n  username: admin\n  password: NokiaSrl1!\n  sshPublicKeys:\n    # an optional list of ssh public keys for the node user\n    # - \"ssh-ed25519 AAAAC3NzaC1lZYOURKEYHEREYOURKEYHEREYOURKEYHEREYOURKEYHEREHDLeDteKN74\"\n\n$(ssh-add -L | awk '{print \"    - \\\"\"$0\"\\\"\"}')\nEOF\n</code></pre>"},{"location":"user-guide/containerlab-integration/#nodeprofile","title":"NodeProfile","text":"<p>With <code>admin</code> NodeUser modified to feature the <code>NokiaSrl1!</code> password, let's create the NodeProfile resource named <code>srlinux-clab-24.10.1</code>:</p> NodeProfile<code>kubectl</code> apply <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: NodeProfile\nmetadata:\n  name: srlinux-clab-24.10.1\n  namespace: eda\nspec:\n  operatingSystem: srl\n  version: 24.10.1\n  versionPath: .system.information.version\n  versionMatch: v24\\.10\\.1.*\n  images:\n    - image: fake.bin\n      imageMd5: fake.bin.md5\n  port: 57410\n  yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n  onboardingUsername: admin\n  onboardingPassword: NokiaSrl1!\n  nodeUser: admin\n  annotate: true\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: NodeProfile\nmetadata:\n  name: srlinux-clab-24.10.1\n  namespace: eda\nspec:\n  operatingSystem: srl\n  version: 24.10.1\n  versionPath: .system.information.version\n  versionMatch: v24\\.10\\.1.*\n  images:\n    - image: fake.bin\n      imageMd5: fake.bin.md5\n  port: 57410\n  yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n  onboardingUsername: admin\n  onboardingPassword: NokiaSrl1!\n  nodeUser: admin\n  annotate: true\n\nEOF\n</code></pre>"},{"location":"user-guide/containerlab-integration/#toponode_1","title":"TopoNode","text":"<p>So far the resources that we have modified or created did not trigger any activity in our EDA cluster; we just prepared the grounds for the next step of creating the TopoNode resources:</p> TopoNode resources<code>kubectl</code> apply <p>When applying the TopoNode resources, the difference between the resources (besides the resource name) is in the <code>productionAddress</code> field. The <code>kubectl</code> apply tab shows how to programmatically fetch the current assigned IP address from the docker state and populate the resources accordingly so that you can copy and paste the command on the host that runs the containerlab topology.</p> <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl1\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: # IP address of the clab-vlan-srl1 node\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl2\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: # IP address of the clab-vlan-srl2 node\n</code></pre> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl1\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: $(sudo docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' clab-vlan-srl1)\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl2\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: $(sudo docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' clab-vlan-srl2)\nEOF\n</code></pre>"},{"location":"user-guide/containerlab-integration/#interface_1","title":"Interface","text":"<p>A topology without links is not a topology. Time to add the links between the nodes. And a prerequisite to creating the TopoLink resources is to create the Interface resources.</p> Interface resources<code>kubectl</code> apply <pre><code>#########################\n#### srl1 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl1\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl1-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl1\n  type: interface\n\n#########################\n#### srl2 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl2-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl2\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl2-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl2\n  type: interface\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\n#########################\n#### srl1 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl1\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl1-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl1\n  type: interface\n\n#########################\n#### srl2 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl2-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl2\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl2-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl2\n  type: interface\n\nEOF\n</code></pre> <p>The moment we created the Interface resources, EDA will configure the associated physical interfaces on the SR Linux nodes. We will see it in the Verification section. Yet, the topology UI will not show the interfaces until we create the TopoLink resources.</p>"},{"location":"user-guide/containerlab-integration/#topolink_1","title":"TopoLink","text":"<p>Now, that we have the Interfaces created we can create the last resource type - TopoLink.</p> Interface resources<code>kubectl</code> apply <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-client1\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl1-ethernet-1-1\n      remote:\n        node: clab-vlan-client1\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-srl2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl1-ethernet-1-10\n      remote:\n        node: clab-vlan-srl2\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl2-ethernet-1-10\n      type: interSwitch\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl2-client2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl2\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl2-ethernet-1-1\n      remote:\n        node: clab-vlan-client2\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-client1\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl1-ethernet-1-1\n      remote:\n        node: clab-vlan-client1\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-srl2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl1-ethernet-1-10\n      remote:\n        node: clab-vlan-srl2\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl2-ethernet-1-10\n      type: interSwitch\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl2-client2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl2\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl2-ethernet-1-1\n      remote:\n        node: clab-vlan-client2\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n\nEOF\n</code></pre>"},{"location":"user-guide/containerlab-integration/#verifying-integration","title":"Verifying integration","text":"<p>Applying the TopoNode resources triggers a lot of activity in EDA. Starting with Bootstrap server to setup the dynamic TLS profile named <code>EDA</code> as part of the bootstrap workflow, finishing with NPP pods connecting to the SR Linux nodes and replacing the existing configuration with the configuration calculated by EDA based on the intents defined in the system.</p> <p>You should see the TopoNode resources and their associated state looking like this after approximately 30-60s after applying the TopoNode resources:</p> <pre><code>kubectl -n eda get toponodes\n</code></pre> <pre><code>NAME             PLATFORM       VERSION   OS    ONBOARDED   MODE     NPP         NODE     AGE\nclab-vlan-srl1   7220 IXR-D2L   24.10.1   srl   true        normal   Connected   Synced   12m\nclab-vlan-srl2   7220 IXR-D2L   24.10.1   srl   true        normal   Connected   Synced   12m\n</code></pre> <p>If you don't see the same output, check the TransactionResults resource that will reveal any potential issues with the transactions.</p> <pre><code>kubectl -n eda-system get transactionresults\n</code></pre> <p>If your TopoNode resources look all good, how about the SR Linux nodes? What has changed there? Remember that we warned you about the config replacement that happens the moment the nodes become managed by EDA? Let's check the configuration on the <code>clab-vlan-srl1</code> node using the same <code>sr_cli</code> commands as we did in the beginning of the Applying the resources section.</p> interfacesnetwork instanceEDA dynamic TLS profile <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'show interface ethernet-1/{1,10} brief'\n</code></pre> <pre><code>+---------------------+---------+---------+---------+---------+---------+\n|        Port         |  Admin  |  Oper   |  Speed  |  Type   | Descrip |\n|                     |  State  |  State  |         |         |  tion   |\n+=====================+=========+=========+=========+=========+=========+\n| ethernet-1/1        | enable  | up      | 25G     |         |         |\n| ethernet-1/10       | enable  | up      | 25G     |         |         |\n+---------------------+---------+---------+---------+---------+---------+\n</code></pre> <p>Note, that the interfaces are all up, because they have been configured when we created Interface resources.</p> <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'show network-instance bridge-1 interfaces'\n</code></pre> <pre><code>================================================================================\n================================================================================\n</code></pre> <p>But contrary to the Interfaces, the <code>bridge-1</code> mac-vrf network instance is completely gone, because we have not created any resources that would trigger a network instance creation.</p> <p>Besides things that were removed, EDA added a new dynamic TLS profile named <code>EDA</code>. The Bootstrap server created it and the <code>eda-mgmt</code> gRPC server has been referring to it as part of the default configuration of SR Linux.</p> <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'info from state system tls server-profile EDA'\n</code></pre> <pre><code>    system {\n        tls {\n            server-profile EDA {\n                key $aes1$AW7HyIAIvykjUG8=$0...Rk=\n                certificate \"-----BEGIN CERTIFICATE-----\nMIIC5DCCAoqgAwIBAgIRANnUH/DLuCeMdQd5vp3VLw8wCgYIKoZIzj0EAwIwMzEO\n...\nQJNoWhdMyz++Nl83AzQOzRXKB7VbWxO7\n-----END CERTIFICATE-----\n\"\n                authenticate-client false\n                dynamic true\n                cipher-list [\n                    ecdhe-ecdsa-aes256-gcm-sha384\n                    ecdhe-ecdsa-aes128-gcm-sha256\n                    ecdhe-rsa-aes256-gcm-sha384\n                    ecdhe-rsa-aes128-gcm-sha256\n                ]\n                certz {\n                    ssl-profile-id EDA\n                    certificate {\n                        version eda-01_05_25_16_01_13\n                        created-on \"2025-01-05T16:01:13.000Z (an hour ago)\"\n                    }\n                }\n            }\n        }\n    }\n</code></pre> <p>This completes the manual integration of EDA with a topology created by Containerlab. You were the witness of the process that is, well, manual, but the good news is that we you can use the clab-connector to automate the process.</p> <ol> <li> <p><code>topology-data.json</code> file is generated by Containerlab when the lab is deployed. It can be found in the Containerlab's Lab Directory.\u00a0\u21a9</p> </li> <li> <p>versions &gt;= 0.61.0\u00a0\u21a9\u21a9</p> </li> <li> <p>set your own public key, this one is for demonstration purposes only\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/queries/","title":"EQL - the EDA Query Language","text":"<p>A key philosophy of EDA is to make state streamable for further processing, where state can be sourced externally via gRPC, internally via core services, or locally via Kubernetes. Beyond being used as event triggers, state is incredibly useful for debugging, and so we required a means to allow humans to interact with it also. Enter the EDA Query Language, or EQL.</p> <p>Loosely based on Jira Query Language, EQL allows the full surface area of the EDA API, all state info in EDB, along with the full surface area of managed endpoints to be queried and parsed in real time. Queries can be made real time in the heat of troubleshooting, with instantaneous, streaming results. Queries can be sourced as data for visualizations, and streamed via the API or StateAggregator, allowing external applications to constrain event triggers.</p> <p>The easiest way to interact with queries is via the UI - simply click <code>Queries</code> in the navigation menu. You optionally can use the REST API, or <code>edactl</code>.</p> <p>A \"query\" consists of:</p> <ul> <li>A <code>Table</code>, being the only mandatory portion, e.g. <code>.namespace.node.srl.interface</code>.</li> <li>A <code>Selector</code> denoted by the <code>fields</code> keyword, defining an array of fields to return (along with any functions to run on said fields), e.g. <code>.namespace.node.srl.interface fields [oper-state, admin-state]</code>.</li> <li>A <code>Filter</code> denoted by the <code>where</code> keyword, defining an expression contained within parenthesis in which to include or exclude results, e.g. <code>.namespace.node.srl.interface where (admin-state = \"disable\" and .node.name = \"leaf1\")</code>.</li> <li>A <code>Sort</code>, denoted by the <code>order by</code> by keyword indicating the sorting that should be applied to the data before it is returned, e.g. <code>.namespace.node.srl.platform.control.process order by [memory-usage descending]</code>.</li> <li>A <code>Limit</code>, denoted by the <code>limit</code> keyword, limiting the number of results returned, e.g. <code>.namespace.node.srl.interface limit 10</code>.</li> <li>A <code>Frequency</code>, denoted by the <code>delta</code> or <code>sample</code> keywords, indicating the minimum update period for the query, e.g. <code>.namespace.node.srl.interface delta milliseconds 1000</code>, or the desire to receive data at a specified interval, irrespective of changes.</li> </ul>"},{"location":"user-guide/queries/#natural-language","title":"Natural language","text":"<p>Shipping in this release is an implementation of queries using natural language. After opening the query interface in the UI, select the drop down and select <code>Natural Language</code>.</p> <p>Tip</p> <p>Try <code>Show me my up interfaces</code></p> <p>Note</p> <p>You may need an API key configured in the <code>.spec.llm</code> context of your <code>EngineConfig</code>.</p>"},{"location":"user-guide/queries/#table","title":"Table","text":"<p>A <code>Table</code> is specified in jspath notation, with a boundary at all lists and containers within a endpoints schema, or within containers/lists provided by StateEngine scripts or external gRPC publishers via StateController.</p> <p>In simple terms each 'node' within the jspath is its own table - <code>.namespace.node</code> is a table, <code>.namespace.node.srl</code> is a table, and <code>.namespace.node.srl.interface</code> is a table. Tables cannot currently be qualified with keys - instead a <code>where</code> should be used.</p> <p>For example, to select all interfaces on a specific node:</p> <pre><code>.namespace.node.srl.interface where (.node.name = \"leaf1\")\n</code></pre> <p>Note</p> <p>Note that <code>.namespace.node.srl</code> is only relevant for SR Linux devices. SR OS devices publish to <code>.namespace.node.sros</code>, and StateEngine apps that normalize data should publish to <code>.namespace.node.normal</code>.</p>"},{"location":"user-guide/queries/#selector","title":"Selector","text":"<p>A <code>Selector</code> is denoted by the <code>fields</code> keyword, where the value is an array of fields to return, along with any functions to run. For example <code>.namespace.node.srl.interface FIELDS [admin-state, description] ORDER BY [oper-state ascending natural]</code>.</p> <p>No fields other than those defined are returned, if no fields are selected then all fields from the table are returned.</p> <p>The <code>fields</code> keyword must precede any <code>where</code> or <code>order by</code> keywords.</p> <p>A set of functions should be available to assist with evaluation and aggregation, for example: average() to evaluate the average of a field matching a Filter over time (the time window here is currently fixed to the current set of data). count() to return the count of unique combinations matching a Filter. sum() to sum the values for a given field matching a Filter.</p>"},{"location":"user-guide/queries/#filter","title":"Filter","text":"<p>A <code>Filter</code> is a string defining any filters to use, a <code>Filter</code> is defined with a <code>where</code> term.</p> <p>A <code>Filter</code> consists of an ordered set of fields, operators, values, and keywords. Keywords may be capitalized or may not, for example both <code>and</code> and <code>AND</code> are valid.</p> <p>Operators include <code>=</code>, <code>!=</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;</code>, <code>in</code>, <code>not in</code>.</p> <ul> <li><code>in</code> is provided an array of values, for example <code>.node.srl.interface where (oper-state in [\"up\", \"down\"])</code>.</li> <li><code>in</code> may also take the values of another field if that field is a leaf-list (i.e. an array).</li> </ul> <p>A <code>Filter</code> may string together multiple criteria through the use of <code>()</code>, and the keywords <code>AND</code>, and <code>OR</code>. Note that even when using a single <code>where</code> statement it must be contained within <code>()</code>.</p> <p>For example <code>.table where ((oper-state = \"down\" and mtu = 1500) or oper-state = \"up\")</code>.</p> <p>A <code>Filter</code> may query ancestor keys and values by referencing their full jspath.</p> <p>For example, to add <code>Filter</code> criteria for a parent key <code>.namespace.node.srl.interface.subinterface where (.node.name = \"leaf1\")</code>.</p> <p>You may not currently filter on parent fields other than the key.</p>"},{"location":"user-guide/queries/#sort","title":"Sort","text":"<p>A <code>Sort</code> is similar to a <code>Filter</code>, but rather than describing how to select data, it describes how to return data. A <code>Sort</code> is denoted by the <code>ORDER BY</code> keywords which control the ordering (sorting) of data.</p> <p>A query may include a single <code>ORDER BY</code> keyword, where the value is an array of (fields, sorting algorithms, and directions) which are evaluated in the order they are presented.</p> <p>For example <code>.namespace.node.srl.interface ORDER by [oper-state ascending natural]</code>.</p> <p>The second value may be either <code>ascending</code> or <code>descending</code>. The third value is optional and indicates the algorithm to use. Only <code>natural</code> is currently supported.</p>"},{"location":"user-guide/queries/#limit","title":"Limit","text":"<p>A <code>Limit</code> is processed after any other operations (perhaps most relevant the <code>Sort</code> operation), denoted by the <code>limit</code> keyword, limiting the number of results that are returned.</p> <p><code>limit</code> accepts a single integer value. This can be combined with <code>Sort</code> to get the 'top' N results, or the 'bottom' N results, where N is the value provided to the <code>limit</code> keyword.</p> <p>The maximum value for <code>limit</code> is <code>1000</code>, and the minimum value is <code>1</code>.</p>"},{"location":"user-guide/queries/#frequency","title":"Frequency","text":"<p>A <code>Frequency</code> allows an end user to control the rate at which data is returned, and is denoted by the <code>delta</code> keyword.</p> <p>The <code>delta</code> keyword must be passed two values - one denoting the units used, and another the actual value. For example <code>.namespace.node.srl.interface.traffic-rate where (in-bps != 0) delta milliseconds 1000</code>. Meaning do not update the client more than once every 1 second.</p> <p>The value is the minimum period at which results will be updated for the query, or put another way it controls the maximum rate at which the client will be updated.</p>"},{"location":"user-guide/topologies/","title":"Topologies","text":"<p>Topologies in EDA cover a lot of ground. Not only do they define the design of a physical or a virtual network used as a Digital Twin, they also drive the visualization of various overlays in the EDA UI.</p> <p>Let's start with a familiar role of a topology - the network topology.</p>"},{"location":"user-guide/topologies/#network-topology","title":"Network topology","text":"<p>A network topology in a broader sense describes the network design. Be it a Clos, a Fat Tree or a Ring design, the topology is what inherently defines the network.</p> <p>Like every topology is defined by its nodes and links, the EDA topology consists of node (<code>TopoNode</code>) and link (<code>TopoLink</code>) objects. The EDA topology nodes are represented by the devices in your network, and the topology links define the connectivity between them.</p> <p>If you come here after finishing the Getting Started guide, you may remember the 3-node topology that we worked on:</p> Physical topology <p>In EDA, this topology is represented by the <code>TopoNode</code> and <code>TopoLink</code> objects mirroring the physical design:</p> EDA topology <p>Almost no difference with a physical topology, right?</p> <p>Note</p> <p>The <code>TopoNode</code> and <code>TopoLink</code> objects in EDA make up the topology that can be backed by the Digital Twin or a real physical network.</p> <p>If the <code>TopoNode</code> and <code>TopoLink</code> objects make up a topology, how do we create them? A straightforward way is to create these resources by hand, but this is going to be a tedious and likely an error-prone process.</p> <p>To assist with the topology creation, EDA provides a couple of methods to generate the required topology resources based on an abstracted input:</p> <ol> <li>Using a topology file</li> <li>Using a topology generator</li> </ol>"},{"location":"user-guide/topologies/#topology-file","title":"Topology file","text":"<p>Instead of creating the topology resources individually, EDA provides a way to describe the topology nodes and links in a topology file. Based on the contents of this file EDA will create the <code>TopoNode</code>, <code>TopoLink</code>, <code>Interface</code> and <code>TopoBreakout</code> resources. This approach enables the users to define topologies in a declarative way.</p> <p>Let's have a look at the topology file structure and a snippet matching it.</p> schemasnippet <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: eda-topology\ndata:\n  eda.yaml: |\n    items:\n      - spec:\n          nodes:\n            - &lt;TopoNode&gt;\n\n          links:\n            - &lt;TopoLink&gt;\n\n          breakouts:\n            - &lt;TopoBreakout&gt;\n</code></pre> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: eda-topology\ndata:\n  eda.yaml: |\n    ---\n    items:\n      - spec:\n          nodes:\n            - name: leaf1\n              labels:\n                eda.nokia.com/role: leaf\n                eda.nokia.com/security-profile: managed\n              spec:\n                operatingSystem: srl\n                version: 25.7.1\n                platform: 7220 IXR-D3L\n                nodeProfile: srlinux-ghcr-25.7.1\n            # remaining nodes omitted for brevity\n          links:\n            - name: leaf1-spine1-1\n              labels:\n                eda.nokia.com/role: interSwitch\n              spec:\n                links:\n                  - local:\n                      node: leaf1\n                      interfaceResource: \"\"\n                      interface: ethernet-1-1\n                    remote:\n                      node: spine1\n                      interfaceResource: \"\"\n                      interface: ethernet-1-1\n                    type: interSwitch\n            # remaining links omitted for brevity\n</code></pre> <p>As you can see, the topology file is provided as a ConfigMap Kubernetes resource with a predefined name - <code>eda-topology</code>. The <code>eda.yaml</code> data key is a YAML document that describes the topology and consists of the three lists: <code>nodes</code>, <code>links</code> and <code>breakouts</code>. Elements of these lists are modelled after the <code>TopoNode</code>, <code>TopoLink</code>, and <code>TopoBreakout</code> resources, respectively. Let's describe the fields you would typically use in these resources.</p> TopoNodeTopoLinkTopoBreakout <p>The list of <code>TopoNode</code> elements will be used to create the <code>TopoNode</code> resources.</p> <pre><code>name: leaf1 #(1)!\nlabels: #(2)!\n  eda.nokia.com/role: leaf\n  eda.nokia.com/security-profile: managed #(7)!\nspec:\n  operatingSystem: srl #(3)!\n  version: 25.7.1 #(4)!\n  platform: 7220 IXR-D3L #(5)!\n  nodeProfile: srlinux-ghcr-25.7.1 #(6)!\n</code></pre> <ol> <li>The name of the <code>TopoNode</code> resource.</li> <li>The labels to be applied to the node.</li> <li>The operating system of the node. <code>srl</code> for Nokia SR Linux, <code>sros</code> for Nokia SR OS, <code>eos</code> for Arista EOS.</li> <li>NOS software version.     NPP/BootstrapServer validate they see this version when connecting.</li> <li>Platform name.     NPP/BootstrapServer validate they see this platform when connecting.</li> <li>Node profile.     A reference to a <code>NodeProfile</code> resource that defines the profile of the node.</li> <li>A label that is used by the <code>NodeSecurityProfile</code> resource to determine the security profile of the node.</li> </ol> <p>The list of <code>TopoLink</code> elements will be used to create the <code>TopoLink</code> resources.</p> <p>TopoLink represents a logical link between two TopoNodes. It may include more than one physical link to represent a LAG or a multihomed link.  </p> <p>To create a point to point link with a single interface on both sides use a single link property. To create a point to point link with a LAG configured on both sides, use two links with matching nodes. A multihomed LAG is created by using two or more links where the local side and/or remote side can be different. Creating a link with only local side specified will create an edge interface.</p> <p>The following examples show common topology link definitions:</p> interSwitch linkedge linkLocal LAGMultihomed LAG <pre><code>name: leaf1-spine1-1 #(1)!\nlabels: #(2)!\n  eda.nokia.com/role: interSwitch\nspec:\n  links:\n    - type: interSwitch #(5)!\n      local: #(3)!\n        node: leaf1\n        interface: ethernet-1-1\n      remote: #(4)!\n        node: spine1\n        interface: ethernet-1-1\n</code></pre> <ol> <li>The name of the <code>TopoLink</code> resource.</li> <li>The labels to be applied to the node.</li> <li>Definition of Local, or \"A\" endpoint of the link. Can contain the following fields:     <code>interface</code> - Normalized name of the interface/port, e.g. ethernet-1-1. <code>interfaceResource</code> - The reference to the existing <code>Interface</code> resource. If set to an empty string, the interface will be created.     <code>node</code> - The reference to the <code>TopoNode</code> resource that this side of the link is connected to.</li> <li>Definition of Remote, or \"B\" endpoint of the link. Contains the same fields as the <code>local</code> definition.</li> <li>The type of link. One of <code>edge</code>, <code>interSwitch</code>, <code>loopback</code></li> </ol> <pre><code>name: leaf1-ethernet-1-10\nlabels:\n  eda.nokia.com/role: edge\nencapType: dot1q\nspec:\n  links:\n    - type: edge\n      local:\n        node: leaf1\n        interface: ethernet-1-10\n</code></pre> <p>The local LAG is created by specifying multiple local interfaces in the <code>links</code> section. Like in the example below, the LAG will consist of ethernet-1-10 and ethernet-1-11 interfaces on the <code>leaf1</code> node.</p> <pre><code>name: leaf1-e1011\nencapType: dot1q\nlabels:\n  eda.nokia.com/role: edge\nspec:\n  links:\n    - type: edge\n      local:\n        node: leaf1\n        interface: ethernet-1-10\n    - type: edge\n      local:\n        node: leaf1\n        interface: ethernet-1-11\n</code></pre> <p>The multihomed LAG (ESI LAG in EVPN) is created by specifying multiple interfaces in the <code>links</code> section where the nodes are referring to different TopoNodes. Like in the example below, the multihomed LAG will consist of ethernet-1-12 on <code>leaf1</code> and <code>leaf2</code> nodes.</p> <pre><code>name: leaf1-2-e1212\nencapType: dot1q\nlabels:\n  eda.nokia.com/role: edge\nspec:\n  links:\n    - type: edge\n      local:\n        node: leaf1\n        interface: ethernet-1-12\n    - type: edge\n      local:\n        node: leaf2\n        interface: ethernet-1-12\n</code></pre> <p>The list of <code>TopoBreakout</code> elements will be used to create the Breakout resources that represent the interface breakout.</p> <p>The example below shows how to define a breakout for ports ethernet-1-10 and ethernet-1-11 on the <code>leaf1</code> and <code>leaf2</code> nodes. The breakout will create 4 channels of 25G speed.</p> <pre><code>nodes:\n  - leaf1\n  - leaf2\ninterface:\n  - ethernet-1-10\n  - ethernet-1-11\nchannels: 4\nspeed: 25G\n</code></pre>"},{"location":"user-guide/topologies/#simplifying-the-topology-file","title":"Simplifying the topology file","text":"<p>Because the topology definition is a YAML-formatted document embedded in a standard ConfigMap resource, we can deal with the topology contents in a separate file and then embed it into the ConfigMap structure. You will see us using this method of defining topologies where a YAML file contains just the <code>items</code> list with the nodes, links and breakout elements, without the ConfigMap wrapping:</p> Topology YAML <p>A topology YAML without the ConfigMap wrapping allows users to enjoy the YAML syntax highlighting and deal with less indentation. This is exactly how the 3-node topology file is defined that we used in the Getting Started guide.</p> <p>The topology file structure may seem verbose with its nodes and links often having the same labels, OS type, version, etc. To reduce the repetition and ensure that the parameters are consistent across the topology resource, you may use YAML anchors and references. This way you can define a set of common parameters once and then reference them in each node or link definition. The snippet below shows how YAML anchors and references can be used to set the node and links parameters once and then reference them in the node and link definitions.</p> Using YAML anchors and references <pre><code># Common node labels\ncommon_node_labels: &amp;common_node_labels\n  eda.nokia.com/security-profile: managed\n\nleaf_labels: &amp;leaf_labels\n  &lt;&lt;: *common_node_labels\n  eda.nokia.com/role: leaf\n\nspine_labels: &amp;spine_labels\n  &lt;&lt;: *common_node_labels\n  eda.nokia.com/role: spine\n\n# Common srl node specs\nsrl_spec: &amp;srl_spec\n  operatingSystem: srl\n  version: 25.3.2\n  nodeProfile: srlinux-ghcr-25.3.2\n\nsrl_leaf_spec: &amp;srl_leaf_spec\n  &lt;&lt;: *srl_spec\n  platform: 7220 IXR-D3L\n\nsrl_spine_spec: &amp;srl_spine_spec\n  &lt;&lt;: *srl_spec\n  platform: 7220 IXR-D5\n\n# Link labels\ninterswitch_labels: &amp;interswitch_labels\n  eda.nokia.com/role: interSwitch\n\nedge_labels: &amp;edge_labels\n  eda.nokia.com/role: edge\n\n####### TOPOLOGY #######\nitems:\n  - spec:\n      nodes:\n        - name: leaf1\n          labels:\n            &lt;&lt;: *leaf_labels\n          spec:\n            &lt;&lt;: *srl_leaf_spec\n        - name: leaf2\n          labels:\n            &lt;&lt;: *leaf_labels\n          spec:\n            &lt;&lt;: *srl_leaf_spec\n        - name: spine1\n          labels:\n            &lt;&lt;: *spine_labels\n          spec:\n            &lt;&lt;: *srl_spine_spec\n\n      links:\n        - name: leaf1-spine1-1\n          labels:\n            &lt;&lt;: *interswitch_labels\n          spec:\n            links:\n              - type: interSwitch\n                local:\n                  node: leaf1\n                  interface: ethernet-1-1\n                remote:\n                  node: spine1\n                  interface: ethernet-1-1\n        - name: leaf1-spine1-2\n          labels:\n            &lt;&lt;: *interswitch_labels\n          spec:\n            links:\n              - type: interSwitch\n                local:\n                  node: leaf1\n                  interface: ethernet-1-2\n                remote:\n                  node: spine1\n                  interface: ethernet-1-2\n</code></pre>"},{"location":"user-guide/topologies/#deploying-topology","title":"Deploying Topology","text":"<p>To deploy a topology a user should take the following steps:</p> <ol> <li>Create the ConfigMap resource named <code>eda-topology</code> in a k8s namespace matching the EDA namespace where you want to have the topology created.</li> <li>Run the <code>api-server-topo</code> CLI command available in the Toolbox pod<sup>1</sup> to apply the defined topology and make EDA create the <code>TopoNode</code>, <code>TopoLink</code>, <code>Interface</code> and <code>Breakout</code> resources based on the topology file contents.</li> </ol> <p>Danger</p> <p>Running the <code>api-server-topo</code> command will remove the <code>TopoNode</code>, <code>TopoLink</code>, <code>Interface</code> and <code>Breakout</code> resources that are not part of the new topology. This will effectively replace any existing node and link objects with the ones defined in the topology file being loaded.</p> <p>To create the <code>eda-topology</code> ConfigMap resource with the topology file contents users can use the make target from the playground repository or a simple shell script that can work without cloning the playground repo.</p> deploy with a make targetdeploy with a shell script <p>In the Try EDA setup the 3-node topology is created with calling the <code>topology-load</code> make target that takes in the topology defined in the YAML file, adds it to the <code>eda-topology</code> ConfigMap in the <code>eda</code> namespace, and calls the <code>api-server-topo</code> CLI tool to apply the topology:</p> <pre><code>make TOPO=topology/3-nodes-srl.yaml topology-load\n</code></pre> <p>Some times the playground repository is not available on the same machine where the topology file is. In this case, users can add the script below to their environment and use it to load the topology file. It performs the same operations as the make target from the playground repository:</p> <ol> <li>Wrap the topology file in the ConfigMap structure.</li> <li>Create the <code>eda-topology</code> ConfigMap resource.</li> <li>Run the <code>api-server-topo</code> CLI tool to apply the topology.</li> </ol> Loading topology YAML with shell script load-topo.sh<pre><code>#!/bin/bash\n\n# Usage:\n#   topo.sh load &lt;path to topology yaml&gt;\n#   topo.sh remove\n\n# command/operation; either `load` or `remove`\nCMD=${1}\n# path to the topology yaml file (required for `load` command)\nTOPO_YAML=${2}\n# namespace where the topology configmap is stored (default: eda)\nTOPO_NS=${TOPO_NS:-eda}\n# namespace where the toolbox pod is running (default: eda-system)\nCORE_NS=${CORE_NS:-eda-system}\n\nif [[ \"${CMD}\" == \"load\" ]]; then\n  if [ -z \"${TOPO_YAML}\" ]; then\n    echo \"Error: Path to topology YAML file is required for 'load'\"\n    exit 1\n  fi\n  if [ ! -f \"${TOPO_YAML}\" ]; then\n    echo \"Topology file ${TOPO_YAML} does not exist\"\n    exit 1\n  fi\n  echo \"Loading topology from ${TOPO_YAML}\"\n  cat &lt;&lt;EOF | kubectl apply -n ${TOPO_NS} -f -\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: eda-topology\ndata:\n  eda.yaml: |\n$(sed 's/^/    /' \"${TOPO_YAML}\")\nEOF\n\nelif [[ \"${CMD}\" == \"remove\" ]]; then\n  echo \"Removing topology from namespace ${TOPO_NS}\"\n  cat &lt;&lt;EOF | kubectl apply -n ${TOPO_NS} -f -\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: eda-topology\ndata:\n  eda.yaml: |\n    {}\nEOF\n\nelse\n  echo \"Usage:\"\n  echo \"  $0 load &lt;path to topology yaml&gt; [TOPO_NS] [CORE_NS]\"\n  echo \"  $0 remove [TOPO_NS] [CORE_NS]\"\n  exit 1\nfi\n\nkubectl -n ${CORE_NS} exec -it \\\n  $(kubectl get -n ${CORE_NS} pods \\\n  -l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n  -- api-server-topo -n ${TOPO_NS}\n</code></pre> <p>With the script added to your current directory or <code>$PATH</code> you can run it to load a topology file:</p> <pre><code>bash topo.sh load my-topology.yaml\n</code></pre> <p>Both methods of deploying a topology rely on the <code>api-server-topo</code> tool available in the Toolbox<sup>1</sup> pod. It reads the topology file from the <code>eda-topology</code> ConfigMap in a specified namespace and generates the following resources in EDA:</p> <ul> <li><code>TopoNode</code> for each node in the topology.</li> <li><code>TopoLink</code> for each link in the topology.</li> <li><code>Interface</code> for each interSwitch and edge link in the topology.</li> <li><code>Breakout</code> for each breakout defined in the topology.</li> </ul> <p>One or more transactions will appear and once they succeed you will see the resources in your cluster and the topology diagram in the EDA UI.</p>"},{"location":"user-guide/topologies/#removing-topology","title":"Removing Topology","text":"<p>By deploying an empty topology file you can remove the existing topology from EDA.</p> remove with a make targetremove with a script <p>A handy make target is available in the playground repository to remove the existing topology:</p> <pre><code>make teardown-topology\n</code></pre> <p>The topology will be removed from the namespace set with the <code>EDA_USER_NAMESPACE</code> variable, or from the <code>eda</code> namespace if the variable is not set.</p> <p>The same script that is used to load the topology can be used to remove it. To remove a topology:</p> <pre><code>bash topo.sh remove\n</code></pre> <p>Path to the topology is not required as the empty topology is assumed for the <code>remove</code> operation.</p> <p>Deploying an empty topology will remove all <code>TopoNode</code>, <code>TopoLink</code>, <code>Interface</code>, and <code>Breakout</code> resources in the specified namespace.</p>"},{"location":"user-guide/topologies/#topology-generation","title":"Topology generation","text":"<p>Topology file provides a flexible way of defining <code>TopoNode</code> and <code>TopoLink</code> resources in a single document, but its flexibility in managing individual nodes and links leads to verbosity when defining larger topologies. For cookie-cutter topologies like Clos, a simpler abstraction can be used to define the topology in a more compact way and scalable way.</p> <p>EDA Topology Generator allows users to define such an abstracted input in format of a JSON file that consists of layers. Each layer represents a set of nodes of the same role, and maps nicely to the tiers/stages of a Clos topology. The layers are then connected to each other based on the <code>NextLayerRole</code> field defined in each layer. This way, the uplinks of one layer connect to the downlinks of the next layer.</p> <p>The example below should help clarify the layered structure and the definition of each field inside a layer.</p> <pre><code>{\n  \"leaf\": { //(1)!\n    \"NodeCount\": 2, //(2)!\n    \"NodeLabels\": {\n      \"eda.nokia.com/security-profile\": \"managed\" //(18)!\n    },\n    \"Platform\": \"7220 IXR-D3L\", //(3)!\n    \"LayerRole\": \"leaf\", //(4)!\n    \"NextLayerRole\": \"spine\", //(5)!\n    \"Uplinks\": 2, //(6)!\n    \"Downlinks\": 2, //(7)!\n    \"GenerateEdge\": true, //(10)!\n    \"EdgeEncapType\": \"dot1q\", //(14)!\n    \"SlotCount\": 1, //(8)!\n    \"PodId\": \"1\", //(9)!\n    \"NodeProfile\": \"srlinux-ghcr-25.7.1\", //(11)!\n    \"Version\": \"25.7.1\", //(12)!\n    \"OperatingSystem\": \"srl\", //(13)!\n    \"RedundancyLabelsOdd\": { //(15)!\n      \"eda.nokia.com/redundancy-group\": \"a\"\n    },\n    \"RedundancyLabelsEven\": { //(16)!\n      \"eda.nokia.com/redundancy-group\": \"b\"\n    },\n    \"CanaryLabels\": { //(17)!\n      \"eda.nokia.com/canary\": \"true\"\n    }\n  },\n  \"spine\": {\n    \"NodeCount\": 1,\n    \"NodeLabels\": {\n      \"eda.nokia.com/security-profile\": \"managed\"\n    },\n    \"Platform\": \"7220 IXR-H2\",\n    \"LayerRole\": \"spine\",\n    \"NextLayerRole\": \"superspine\",\n    \"Uplinks\": 2,\n    \"Downlinks\": 4,\n    \"SlotCount\": 1,\n    \"PodId\": \"1\",\n    \"NodeProfile\": \"srlinux-ghcr-25.7.1\",\n    \"Version\": \"25.7.1\",\n    \"OperatingSystem\": \"srl\"\n  }\n}\n</code></pre> <ol> <li>A layer name. It is an arbitrary name of a layer, but it must be unique across the entire topology.</li> <li>The number of nodes in the layer.</li> <li>The platform of the node.</li> <li>The layer role. An arbitrary string value, but often named after a topology stage, like <code>leaf</code>, <code>spine</code>, etc. The layer role is used in the <code>NextLayerRole</code> field to tie layers together.</li> <li>The role of the next layer that this layer connects to.     In this example the <code>leaf</code> role has the <code>spine</code> role as the next layer, and hence the uplinks of the <code>leaf</code> layer will connect to the <code>spine</code> layer.</li> <li>The number of uplinks each node in this layer has.</li> <li>The number of downlinks each node in this layer has.</li> <li>Used with chassis platforms, and will result in uplinks/downlinks being evenly distributed over line cards.</li> <li>Pod ID groups layers into pods. Layers of the same pod make up a fabric and the pod ID becomes a TopoNode label that is leveraged by the Fabric app when dealing with multi-pod topologies.     Each pod is therefore a separate fabric and the topology generator input would be composed of multiple layer combinations with different pod IDs.</li> <li>Indicating whether to generate Interface resources for the downlinks of the layer. This is typically the leaf layer that has no layer beneath it, and hence its downlinks are edge links.</li> <li>The profile of the node.</li> <li>The software version of the node.</li> <li>The operating system of the node.</li> <li>Sets the encapType value for any Interface resources generated as edge interfaces.</li> <li>Labels on odd TopoNode generated within the layer.</li> <li>Labels on even TopoNode generated within the layer.</li> <li>Labels on the first TopoNode generated within the layer.</li> <li>Security profile label that is used by the <code>NodeSecurityProfile</code> CR as a selector. The managed profile means the certificates for the nodes are managed by EDA.</li> </ol> <p>This input defines a three node topology with one spine and two leaves. The nodes are automatically tagged with the respected labels and edge links are created for the leaf nodes.</p> <p>EDA topology generator is implemented in the <code>edatopogen</code> binary that you can find in the <code>eda-toolbox</code> pod. Feel free to use the makefile in the playground repository to quickly connect to the <code>eda-toolbox</code> pod or create a handy alias for the toolbox to use it from anywhere.</p> <code>toolbox</code> aliasmake target from the playground repository <pre><code>alias edatoolbox='kubectl -n eda-system exec -it \\\n  $(kubectl get -n eda-system pods \\\n  -l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n  -- env \"TERM=xterm-256color\" bash -l'\n</code></pre> <p>And then run <code>edatoolbox</code> to get a shell in the toolbox pod.</p> <p>You can log in to the <code>eda-toolbox</code> pod using the following command executed from the playground repository:</p> <pre><code>make open-toolbox\n</code></pre> <p>Or using this command when running outside the playground repository:</p> <pre><code>kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- env \"TERM=xterm-256color\" bash -l\n</code></pre> <p>Create a topology generator input file and name it something like <code>topo.json</code>. We will just copy the example used before:</p> <pre><code>cat &lt;&lt;EOF &gt; topo.json\n{\n  \"leaf\": {\n    \"NodeCount\": 2,\n    \"NodeLabels\": {\n      \"eda.nokia.com/security-profile\": \"managed\"\n    },\n    \"Platform\": \"7220 IXR-D3L\",\n    \"LayerRole\": \"leaf\",\n    \"NextLayerRole\": \"spine\",\n    \"Uplinks\": 2,\n    \"Downlinks\": 2,\n    \"SlotCount\": 1,\n    \"PodId\": \"1\",\n    \"GenerateEdge\": true,\n    \"NodeProfile\": \"srlinux-ghcr-25.7.1\",\n    \"Version\": \"25.7.1\",\n    \"OperatingSystem\": \"srl\",\n    \"EdgeEncapType\": \"dot1q\",\n    \"RedundancyLabelsOdd\": {\n      \"eda.nokia.com/redundancy-group\": \"a\"\n    },\n    \"RedundancyLabelsEven\": {\n      \"eda.nokia.com/redundancy-group\": \"b\"\n    },\n    \"CanaryLabels\": {\n      \"eda.nokia.com/canary\": \"true\"\n    }\n  },\n  \"spine\": {\n    \"NodeCount\": 1,\n    \"NodeLabels\": {\n      \"eda.nokia.com/security-profile\": \"managed\"\n    },\n    \"Platform\": \"7220 IXR-H2\",\n    \"LayerRole\": \"spine\",\n    \"NextLayerRole\": \"superspine\",\n    \"Uplinks\": 2,\n    \"Downlinks\": 4,\n    \"SlotCount\": 1,\n    \"PodId\": \"1\",\n    \"NodeProfile\": \"srlinux-ghcr-25.7.1\",\n    \"Version\": \"25.7.1\",\n    \"OperatingSystem\": \"srl\"\n  }\n}\nEOF\n</code></pre> <p>Now, run the <code>edatopogen</code> binary to generate the topology file. Use the <code>-y</code> flag to instruct the generator to output the topology file directly in the ConfigMap format.</p> <pre><code>edatopogen -y -f topo.json\n</code></pre> <p>By default, this command generates a ConfigMap file named <code>generated_topo_pod_1.yaml</code>, where <code>pod_1</code> is the pod ID specified in the input file.</p> <p>If you examine the generated file, you'll see that it contains the familiar topology file structure embedded within a ConfigMap resource.</p> <p>Because <code>edatopogen</code> produces the ConfigMap resource directly, you can apply it to the cluster using <code>kubectl</code>:</p> <pre><code>kubectl -n eda apply -f generated_topo_pod_1.yaml #(1)!\n</code></pre> <ol> <li>This command creates the ConfigMap with the topology file in the <code>eda</code> namespace. The <code>eda</code> namespace is a namespace where user resources are created.</li> </ol> <p>Next, run the <code>api-server-topo</code> tool in the Toolbox pod<sup>1</sup> to parse the topology ConfigMap and create the resources:</p> <pre><code>api-server-topo -n eda\n</code></pre> <ol> <li> <p>The <code>api-server-topo</code> CLI tool is available in the <code>eda-toolbox</code> pod.</p> <p>You can log in to the <code>eda-toolbox</code> pod using the following command executed from the playground repository:</p> <pre><code>make open-toolbox\n</code></pre> <p>Or using this command when running outside the playground repository:</p> <p><pre><code>kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- env \"TERM=xterm-256color\" bash -l\n</code></pre> \u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"user-guide/transactions/","title":"Transactions","text":""},{"location":"user-guide/transactions/#introduction","title":"Introduction","text":"<p>Transactions form the foundation of EDA's powerful revision control system and add sought-after reliability to infrastructure automation by applying the changes atomically, network-wide. Every action that leads to a config change in EDA - modifying a resource, installing an EDA application, upgrading a network operating system - is processed as a transaction.  </p> <p>At a very high-level, EDA transactions have three main steps:</p> <ol> <li>Generate config from abstractions</li> <li>Deploy config changes, network-wide</li> <li>Commit to Git for revision control</li> </ol> <p>In EDA, deploy and commit are inseparable. If the change is not deployable on any of the target node, the whole transaction is pronounced failed and the changes are reverted from all nodes. This means users can't commit changes that the network can't apply \u2014 every commit to Git is a point-in-time of the network's configuration history.<sup>1</sup> With a single command, you can roll back the entire network from the commit history. Your maintenance window back out just got a whole lot easier!</p> Details of the transaction steps <ol> <li>Generate config from abstractions<ul> <li>Run all configuration intent scripts which have a dependency on the resources in the transaction.<sup>2</sup></li> <li>Compile node configurations pieces from the intent scripts' outputs into full node configurations.</li> <li>Perform YANG schema validation on the full node configurations. If schema is invalid, transaction fails here.</li> </ul> </li> <li>Deploy config changes, network-wide<ul> <li>Push new configuration to all nodes with commit confirmation.</li> <li>If any node rejects the new config, transaction fails here and EDA performs a network-wide roll-back.</li> </ul> </li> <li>Commit to Git for revision control<ul> <li>Create a Git commit</li> <li>Push commit to remote Git server(s) for backup</li> </ul> </li> </ol>"},{"location":"user-guide/transactions/#whats-in-a-transaction-commit","title":"What's in a Transaction Commit?","text":"<p>Whenever you create/update/delete a resource in EDA, a number of scripts associated with this resource run. We call these scripts \"intents\".</p> <p>Intents have strict idempotency where every intent run with the same set of inputs will result in the same set of outputs. Always. Therefore EDA has no need to persistently store anything that can be derived or computed. EDA stores intent scripts, input resources, and pool allocations in Git - and that's it!<sup>3</sup></p> <p>Yes, that's right, EDA does not backup node configs - we simply don't need them for revision control and omitting those large repetitive files lets us scale the Git repo to very large networks.</p>"},{"location":"user-guide/transactions/#transaction-basket","title":"Transaction Basket","text":"<p>Multiple EDA resource changes can be applied together to fate-share a set of changes. The EDA UI uses a basket to represent this. When committing from the basket all resources are applied as a single transaction - if the transaction fails, none of the changes from the basket are committed.</p> <p>For REST API and Kubernetes users, the basket concept can be used via the Transaction API and the Transaction CRD, respectively.</p>"},{"location":"user-guide/transactions/#transaction-results","title":"Transaction Results","text":""},{"location":"user-guide/transactions/#summary","title":"Summary","text":"<p>EDA stores the result of a transaction for users to review. Here is some of the terminology you'll find in the results:</p> <ul> <li>Input Resources - Resources created, updated or deleted by the user.</li> <li>Intent Runs - Configuration scripts executed during the transaction.</li> <li>Output Resources - Resources derived from the intent run.</li> <li>Changed Resources - Input and Output resources that are changed, compared to the previous committed transaction.</li> <li>Nodes with Changes - Nodes which are impacted by this transaction. This includes node configuration changes, node version changes, or changes to the associated TopoNode resource in EDA.</li> </ul> <p>Error Types:</p> <ul> <li>Intent Errors - Errors returned by an intent script</li> <li>Node Config Errors - Error in YANG schema validation or errors returned by the node when pushing configuration</li> <li>General Errors - Errors related to the EDA environment</li> </ul>"},{"location":"user-guide/transactions/#diffs","title":"Diffs","text":"<p>Diff of all changed resources and changed node configurations in the transaction.</p>"},{"location":"user-guide/transactions/#transaction-topology","title":"Transaction Topology","text":"<p>Transaction Topology displays all input and output resources of a transaction and graphs the relationship between derived and parent resources.</p> <p>Changed resources are colored yellow in the topology, and if an intent error occurred during the transaction the related resource is colored red.</p> Transaction Topology Limitations <ol> <li> <p>Transaction Topology graphs the createUpdate relationships between resources. Read relationships are not graphed. For example: The Fabric intent reads from allocation pool resources. The link between the Fabric resource and the allocation pool resources is not displayed in the topology.</p> </li> <li> <p>Transaction Topology is not currently available for transaction results with more than 1000 resources.</p> </li> </ol>"},{"location":"user-guide/transactions/#detail-level","title":"Detail Level","text":"<p>For all transactions committed to Git, EDA can always display the input resources and their diffs. Data not in Git (e.g. failed transaction, dry-run transactions, output resources, node configuration diffs, etc.) are stored in-memory for a limited time. EDA uses the following rules for retaining detailed transaction results:</p> <ul> <li>Keep a guaranteed 25 transactions per user<sup>4</sup></li> <li>Keep diffs for a maximum 10k resources per user \u2014 details from the oldest transactions will be purged if this limit is exceeded</li> </ul> <p>Additionally, transactions from 'machine interfaces' do not contain detailed results. This includes resource changes via the <code>/apps</code> REST API endpoint and changes via Kubernetes.</p>"},{"location":"user-guide/transactions/#the-nodeconfig-resource","title":"The NodeConfig Resource","text":"<p>NodeConfig is a special resource in EDA that is not published to EDB or Kubernetes but you will often see in transaction results. These function as an internal configlet which intent scripts create to contribute specific sections of node configuration. EDA combines all the nodeConfig resources into a complete node configuration. This is why you'll see both 'NodeConfig' and 'Node Configuration' in the transaction diffs.</p>"},{"location":"user-guide/transactions/#dry-run","title":"Dry-Run","text":"<p>What if you want to review the configuration changes before pushing to the network? That's where dry-run comes in. Any transaction can be executed as a dry run. This performs all config generation and YANG schema validation, but does not push any changes to the network.</p>"},{"location":"user-guide/transactions/#revert-and-restore","title":"Revert and Restore","text":"<p>EDA exposes 'Revert' and 'Restore' actions for each committed transaction:</p> <ul> <li>Revert reverses the changes of a specific commit. Reverts will fail if reversed changes conflict with commits that occurred after it.</li> <li>Restore sets all EDA resources, apps, and allocations to exactly as they were at the specified commit. Restores can not have conflicts.</li> </ul> <p>Both actions are executed as a new transaction and committed with a new commit hash, i.e., the commit history always moves forward even if the transaction is a roll-back of changes.</p> <ol> <li> <p>\"But what if I change config outside EDA?\" Don't worry, EDA detects the deviation and commits it to the transaction log should the deviation be accepted or rejected.\u00a0\u21a9</p> </li> <li> <p>Configuration intent scripts use the latest commit and the transaction input to derive resource and pieces of node configuration. The term 'declarative abstraction' is often used to describe this process.\u00a0\u21a9</p> </li> <li> <p>Additional data is stored in Git (User settings, user created dashboards, KeyCloak DBs, etc.) but these are not relevant to transactions.\u00a0\u21a9</p> </li> <li> <p>If there are outstanding in-progress transactions, a user can temporarily have more than 25 transactions\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/using-the-clis/","title":"Using the CLIs","text":"<p>EDA exposes two north-bound APIs to its users - Kubernetes API and EDA API - and an in-cluster gRPC API. You used the Kubernetes API when you managed EDA resources using the <code>kubectl</code> CLI in the Getting Started guide. And you used the EDA's REST API when you, for example, opened the EDA UI in your browser.</p> <p>On top of the offered APIs we build CLI tools like <code>edactl</code> and <code>e9s</code> which come handy in certain scenarios where CLI access is preferred.</p> <p><code>edactl</code> provides a comprehensive suite of commands that allow users to create, query, update and delete resources within an EDA cluster, making it ideal for scripting and automation.</p> <p>On the other hand, <code>e9s</code> offers a dynamic, real-time terminal-based UI that simplifies the interaction with clusters by providing a high-level overview and quick navigation options for common tasks. While <code>edactl</code> demands precise command inputs, <code>e9s</code> excels in offering visual feedback and streamlined workflows, significantly reducing the complexity and time needed for cluster management tasks.</p> <p>In addition to EDA-specific CLIs, users get to benefit from the vast ecosystem of tools available in the Kubernetes ecosystem. We will cover some of such tools in this section as well.</p>"},{"location":"user-guide/using-the-clis/#edactl","title":"edactl","text":"<p><code>edactl</code> is your go-to tool for scripting, managing and automating pipelines with EDA. A swiss-knife for EDA users.</p> <p><code>edactl</code> is preinstalled in the <code>eda-toolbox</code> pod. You can either connect to the toolbox pod<sup>1</sup> and execute the utility directly from there, or you can setup a handy alias (for example in your <code>~/.zshenv</code>) to make it easily accessible.</p> Setting up <code>edactl</code> alias<pre><code>alias edactl='kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- edactl'\n</code></pre> <p>It offers a comprehensive suite of commands that enable users to interact seamlessly with an EDA cluster.</p> edactl commands<pre><code>Available Commands:\n  cluster      Show the cluster status\n  completion   Generate the autocompletion script for the specified shell\n  config       Interactions with EDACONFIG\n  edge-if-ping Ping from an edge interface\n  get          Displays one or many resources\n  git          Git related commands\n  help         Help about any command\n  intent       intent [config | state]\n  labels       Display the label key/values in use\n  namespace    Display active namespaces\n  node         Node related commands\n  platform     Platform related commands\n  query        Run an EQL query\n  sdk          Manipulate EDA sdk\n  sub          Subscribe to state updates\n  testman      testman related commands\n  transaction  List transaction results\n  workflow     Workflow related commands\n</code></pre> <p>For example, to query all interfaces with operational state <code>up</code> execute the following command while in the <code>eda-toolbox</code> pod:</p> <pre><code>edactl query '.namespace.node.srl.interface where (oper-state = \"up\")'\n</code></pre> <pre><code> Namespace Name    Node Name    Name           Admin State    Mtu    Loopback Mode    Ifindex     Oper State    Oper Down Reason    Last Change               Linecard    Forwarding Complex    Forwarding Mode    Vlan Tagging    Tpid         Description              Num Physical Channels\n eda               leaf1        ethernet-1/1   enable         9232   none             16382       up                                2024-12-13T10:11:38.554Z  1           0                     store-and-forward  false           TPID_0X8100\n eda               leaf1        ethernet-1/2   enable         9232   none             49150       up                                2024-12-13T10:11:38.606Z  1           0                     store-and-forward  false           TPID_0X8100\n eda               leaf1        ethernet-1/3   enable         9232   none             81918       up                                2024-12-13T10:11:38.674Z  1           0                     store-and-forward  true            TPID_0X8100\n</code></pre>"},{"location":"user-guide/using-the-clis/#e9s","title":"e9s","text":"<p><code>e9s</code> is the Terminal UI (TUI) for EDA and can help you interact with the platform similar to how you'd use the famous <code>k9s</code> for Kubernetes.</p> <p>It comes preinstalled in the <code>eda-toolbox</code> pod. You can either connect to the toolbox pod<sup>1</sup> and execute the utility directly from there, or you can setup a handy alias (for example in your <code>~/.zshenv</code>) to make it easily accessible.</p> e9s<pre><code>alias e9s='kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- sh -c \"TERM=xterm-256color e9s\"'\n</code></pre> <p>And behold the power of <code>e9s</code>!</p> <p></p> <p>Here is a quick demonstration on how to use the powerful EDA Query Language (EQL) to run queries in <code>e9s</code>:</p>"},{"location":"user-guide/using-the-clis/#kubectl","title":"kubectl","text":"<p><code>kubectl</code> is the CLI to reach for when interacting with Kubernetes. It is also downloaded as part of the playground setup and can be found in the <code>tools</code> directory of the playground repository. If you don't <code>kubectl</code> installed, you can copy the binary from the playground repo like so:</p> assuming your playground repo is in <code>~/nokia-eda/playground</code><pre><code>sudo cp $(realpath ~/nokia-eda/playground/tools/kubectl) /usr/local/bin/kubectl\n</code></pre>"},{"location":"user-guide/using-the-clis/#k9s","title":"k9s","text":"<p>k9s is a TUI for Kubernetes clusters that you can see in many of our demos. Once in a while you would want to inspect the state of your cluster in a more graphical way than just using <code>kubectl</code> - that is when <code>k9s</code> comes in handy.</p> <p>As with <code>kubectl</code> you can copy it from the playground repo:</p> assuming your playground repo is in <code>~/nokia-eda/playground</code><pre><code>sudo cp $(realpath ~/nokia-eda/playground/tools/k9s) /usr/local/bin/k9s\n</code></pre>"},{"location":"user-guide/using-the-clis/#lnav","title":"lnav","text":"<p>EDA is composed of many microservices, and it is often useful to have a log viewer to quickly inspect the logs distributed across the pods.</p> <p>The log aggregation that EDA uses is based on fluentbit/fluentd combination with the logs aggregated in the <code>eda-fluentd</code> deployment. To browse the logs you can use the lnav CLI you would find in this deployment.</p> <p>For convenience, you can set up an alias to quickly access the TUI logs viewer:</p> <pre><code>alias edalogs='kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=fluentd -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- sh -c \"TERM=xterm-256color lnav /var/log/eda/*/*/*.log\"'\n</code></pre>"},{"location":"user-guide/using-the-clis/#helm","title":"helm","text":"<p>Helm is one of the many package managers for Kubernetes. You might want to add it to your PATH to install additional apps and deployments on your cluster. For example, you may install the NetBox stack and test EDA&lt;-&gt;NetBox integration, all done in a single cluster.</p> <p>The <code>helm</code> CLI is downloaded by the playground installer, so you can fetch it and use it right away like so:</p> assuming your playground repo is in <code>~/nokia-eda/playground</code><pre><code>sudo cp $(realpath ~/nokia-eda/playground/tools/helm) /usr/local/bin/helm\n</code></pre> <ol> <li> <p>You can log in to the <code>eda-toolbox</code> pod using the following command executed from the playground repository:</p> <pre><code>make open-toolbox\n</code></pre> <p>Or using this command when running outside the playground repository:</p> <p><pre><code>kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- env \"TERM=xterm-256color\" bash -l\n</code></pre> \u21a9\u21a9</p> </li> </ol>"},{"location":"blog/author/rdodin/","title":"Roman Dodin","text":""},{"location":"blog/author/bwallis/","title":"Bruce Wallis","text":""}]}