{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"apps/app-store/","title":"EDA Store","text":""},{"location":"apps/app-store/#overview","title":"Overview","text":"<p>Almost everything in EDA is considered an Application (App), including all the Apps that were installed during the Getting Started - Install step. Apps extend the functionality of EDA by exposing custom resources to the EDA API and MicroPython code that will be executed by EDA whenever such a custom resource is manipulated either by a user or another App.</p> <p>The EDA Store is used to manage the Applications inside EDA. It can be accessed through the UI which provides 3 different views:</p> All Packages List The initial page when opening the EDA Store in the UI will show all the packages known to the EDA Store. Clicking the \"All Packages\" dropdown at the top allows the selection of \"My Packages\". Clicking an App from the list will open the App specific page. My Packages List This view shows all the installed Apps in the current EDA deployment. Clicking on an App from the list will open the App specific page. App Page After clicking on an App in either of the list views, a page will open with specific details from the App. It will show a set of details of the App, and if it has not been installed yet, it will show an install button. If the App has an update available (a new version), an update button will appear. In the future, more details about Apps will become available as the Overview, Documentation and License pages are added to Apps."},{"location":"apps/app-store/#resources","title":"Resources","text":"<p>The EDA Store relies on two different resources in the EDA environment:</p> <code>Catalog</code> A catalog is a git repository that contains the manifests of Apps. A manifest contains all the details of an App and will be discussed further in the Development section. Using the manifests of all the <code>Catalogs</code> registered in EDA, the EDA Store can build a list of all available Apps. <code>Registry</code> While a manifest of an App contains all the details of an App, the actual code and resources of an App are stored in an OCI compliant image. This image needs to be stored in a container registry. This registry must be known to the EDA deployment so the EDA Store can pull the image and use the data in the image to deploy the App. This information is given to EDA in the form of a <code>Registry</code> custom resource."},{"location":"apps/app-store/#installing-an-app","title":"Installing an App","text":"<p>To install an App, you can use the EDA Store UI, select the App from the list and click the \"Install\" button. In the background, this will create a <code>Workflow</code> custom resource in the EDA environment. The EDA Store backend takes this resource and takes the appropriate actions to read the information of the App from its manifest, and make sure the appropriate data is available to EDA, which can include the code of the App, custom resource definitions and more.</p> <p>You can also install an App using <code>kubectl</code> and giving it the correct <code>Workflow</code> custom resource. Here's an example to install the Cloud Connect App:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: connect-nokia\n  namespace: eda-system\nspec:\n  operation: install\n  autoProcessRequirements:\n    - strict\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v3.0.0\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: connect-nokia\n  namespace: eda-system\nspec:\n  operation: install\n  autoProcessRequirements:\n    - strict\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v3.0.0\n\nEOF\n</code></pre> <p>The status of the Workflow shows the progress of the installation. This <code>Workflow</code> resource initiates an app installer job. Once installed, a <code>Manifest</code> resource will be created and the Workflow is done (and the object may be deleted). To see the installed apps using <code>kubectl</code>, you can check their manifests:</p> <pre><code>kubectl get manifests -n eda-system\n</code></pre>"},{"location":"apps/app-store/#uninstalling-an-app","title":"Uninstalling an App","text":"<p>To uninstall an App, you can use the UI. Open the App page, and it will say the currently installed version and to the right, under the general information block, there is a link to \"Uninstall package\". This will remove the App.</p> <p>Alternatively, you can use <code>kubectl</code> commands to delete an app. Creating a new Workflow with a <code>delete</code> operation, will start uninstalling an application. Here's an example to delete the previously created Cloud Connect App.</p> Known Limitations <p>There is no validation yet when uninstalling apps, so make sure all your config is removed before uninstalling.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: delete-connect-nokia\n  namespace: eda-system\nspec:\n  operation: delete\n  autoProcessRequirements:\n    - strict\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v3.0.0\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: delete-connect-nokia\n  namespace: eda-system\nspec:\n  operation: delete\n  autoProcessRequirements:\n    - strict\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v3.0.0\n\nEOF\n</code></pre> <p>Note the difference between installing and uninstalling by the <code>operation</code> field. Changing an already existing Workflow by updating its operation field from <code>install</code> to <code>delete</code> will not trigger a new (un)install job. A new Workflow needs to be created instead.</p> Uninstalling apps with dependencies <p>Trying to delete an app that is required by another app will not be permitted to prevent the second app from malfunctioning. In this case, the EDA store might return an error message saying that the to-be-deleted app is not present. This is a known bug and a more meaningful error message is planned for an upcoming release.</p>"},{"location":"apps/app-store/#app-requirements","title":"App Requirements","text":"<p>App requirement (or app dependency) management plays an important part to make sure that the whole system after (un)installing apps still functions properly. In EDA, apps may expect some resources to exist that are provided by other applications. These need to be installed before (or at the same time as) the dependent app. Deletion of apps may also be blocked if it breaks the requirement of another app. The requirement of an app is defined in its manifest specification, which contains the app and a version constraint (e.g. <code>v3.0.*</code>, <code>&gt;=v3.0.0</code>). The EDA Store makes sure that all the app requirements stay valid at all times to prevent invalid app version configurations.</p> <p>When trying to install an app through the UI, the EDA Store will check if other apps needs to be installed or updated alongside it. You will then be prompted to approve that the EDA store needs to install or upgrade these additional applications.</p> Requirements show the full graph in a flat list <p>The requirements tab in the UI currently shows the full dependency graph in a flat list. So the list does not only include the apps that are required to install app <code>A</code>, but also the apps that require <code>A</code> themselves.</p> Requirement modes using CLI <p>Through the CLI, there is currently only one requirement mode that is the default on what the EDA store is allowed to do:</p> <p><code>strict</code>: The app installer only verifies that the resulting installed apps will be satisfied w.r.t. their requirements. If invalid, the installation will be aborted with an error message denoting what requirement is missing.</p> <p>Other modes are planned in future releases.</p> <p>To specify a mode, pass the <code>autoProcessRequirements</code> field to the workflow spec. See the app installation example for how this is filled in.</p>"},{"location":"apps/fabric/","title":"Fabric","text":"<p>The Fabric application streamlines the construction and deployment of data center fabrics, suitable for environments ranging from small, single-node edge configurations to large, complex multi-tier and multi-pod networks. It automates crucial network configurations such as IP address assignments, VLAN setups, and both underlay and overlay network protocols.</p> <p>Upon deployment, the Fabric application initiates several supporting applications including ISLs (Inter-Switch Links), DefaultRouters, DefaultInterfaces, and DefaultBGPPeers, among others. These applications, in turn, generate node configurations. The operational state of the Fabric is determined by the collective status of these underlying applications.</p>"},{"location":"apps/fabric/#deployment-models","title":"Deployment Models","text":"<p>The Fabric application supports highly flexible deployment models, enabling you to tailor the configuration of your data center fabric to suit different architectural needs. You can deploy a single instance of a Fabric resource to manage the entire data center, incorporating all network nodes, or you can opt to divide your data center into multiple, smaller Fabric instances.</p> <p>For example, you might deploy one Fabric instance to manage the superspine and borderleaf layers while deploying separate Fabric instances for each pod within the data center. This modular approach allows for more granular control.  This can be taken to the extreme where each layer of a datacenter fabric could be its own instance of a Fabric.  The choice is yours!</p> <p>The Fabric application facilitates interconnecting these Fabric instances through the fabricSelector property. This property enables different Fabric instances to work together seamlessly, ensuring that the network functions as a cohesive whole even when managed by multiple instances of the Fabric resource.</p> <p>The fabricSelector is a label selector that selects adjacent Fabrics based on their assigned labels and the criteria specified in the selector. The fabricSelector operates in a unidirectional manner, meaning only the upper layer of the fabric needs to select the downstream fabrics. For example, the instance of the Fabric representing the superspine layer would use a label selector to select the pod Fabrics; the pod Fabrics do not need nor should they to select the superspine layer.  Example found below.</p>"},{"location":"apps/fabric/#selecting-toponodes-topolinks-and-fabrics","title":"Selecting TopoNodes, TopoLinks and Fabrics","text":"<p>The Fabric application configures network nodes, their interswitch links, and the interconnections between different Fabric instances using a mechanism based on label selectors. These selectors identify specific TopoNodes, TopoLinks, and adjacent Fabric instances that correspond to node roles within a typical Clos network architecture\u2014such as Leaf, Spine, Super-spine, and Border-leaf. The role of a node and the interconnections between Fabric instances significantly influence the configuration parameters applied to them, which are determined by additional inputs from the Fabric application such as the selected underlay or overlay network protocols.</p>"},{"location":"apps/fabric/#how-label-selectors-work","title":"How Label Selectors Work","text":"<p>Label selectors are used to filter and select the key-value pairs assigned to TopoNodes, TopoLinks, and other Fabric instances based on specific criteria such as their role within the network. Once these elements are labeled, the Fabric application can automatically apply the necessary configurations.</p>"},{"location":"apps/fabric/#configuring-nodes-links-and-fabrics","title":"Configuring Nodes, Links, and Fabrics","text":"<ol> <li> <p>Initial Labeling:  If TopoNodes, TopoLinks, and adjacent Fabric instances are labeled before the creation of the Fabric instance, the application will automatically generate all necessary configurations for these components during the transaction associated with the addition of the Fabric instance.</p> </li> <li> <p>Post-Deployment Labeling: If new labels that match the Fabric's selection criteria are added to TopoNodes, TopoLinks, or adjacent Fabric instances after the Fabric instance has been deployed, these components will automatically be configured by the Fabric application during the transaction that handles the addition of the labels. This ensures that changes in network topology, roles, or Fabric interconnections are dynamically incorporated into the Fabric's configuration.</p> </li> </ol>"},{"location":"apps/fabric/#example-label-selectors","title":"Example Label Selectors","text":"<ul> <li>Leaf Node Selector: <code>eda.nokia.com/role=leaf</code></li> <li>Spine Node Selector: <code>eda.nokia.com/role=spine</code></li> <li>Fabric Selector: <code>eda.nokia.com/pod=pod1</code></li> </ul>"},{"location":"apps/fabric/#assigning-ip-addresses","title":"Assigning IP Addresses","text":"<p>IP addresses play a critical role in network configuration within the Fabric application. Here's how IP addressing is managed:</p>"},{"location":"apps/fabric/#systemloopback-interfaces","title":"System/Loopback Interfaces","text":"<ul> <li>IPv4 Assignment: IPv4 addresses must be assigned to the primary loopback interface (System or Lo0) of each node.</li> <li>IPv6 Assignment: Optionally, IPv6 addresses can also be configured on these interfaces.</li> </ul>"},{"location":"apps/fabric/#topolink-interfaces","title":"TopoLink Interfaces","text":"<ul> <li>The Fabric application requires the configuration of either IPv4, IPv6 addresses or the use of IPV6 unnumbered on the interfaces selected by the TopoLink label selector under the <code>InterSwitchLinks</code> property . This ensures that all connections within the network are appropriately addressed.</li> </ul>"},{"location":"apps/fabric/#ip-address-allocation-pools","title":"IP Address Allocation Pools","text":"<ul> <li>IP addresses can be automatically assigned from specified IP Address allocation pools. Separate pools are typically used for System interfaces and ISL (Inter-Switch Link) interfaces.</li> <li>Important: The allocation pool referenced for either set of interfaces must exist prior to the deployment of the Fabric application instance to ensure successful IP configuration.</li> </ul> <p>The <code>systemPoolIPV4</code> property must be provided.</p>"},{"location":"apps/fabric/#optional-ip-pools-and-autonomous-systems-per-role","title":"Optional IP Pools and Autonomous Systems per Role","text":"<p>The Fabric application allows for the optional specification of system IP pools and autonomous systems for different roles within the network fabric. These optional configurations can override the global settings.</p> <p>For each role (Leaf, Spine, Superspine, Borderleaf) the following properties may be configured:</p> <ul> <li>Autonomous System: The <code>asnPool</code> property allows for a specific ASN pool to be used for eBGP sessions, override the pools specified under the underlay protocol section.</li> <li>IP Pools: The <code>systemPoolIPV4</code> and <code>systemPoolIPV6</code> properties can be specified to dynamically allocate IP addresses for the System/ lo0 interfaces.</li> </ul>"},{"location":"apps/fabric/#selecting-an-underlay-protocol","title":"Selecting an Underlay Protocol","text":"<p>The Fabric application currently supports a single underlay protocol: eBGP. This section details how eBGP is implemented within the network fabric.</p>"},{"location":"apps/fabric/#ebgp-configuration","title":"eBGP Configuration","text":"<ul> <li>ISL Application: The Fabric app will emit instances of the ISL application to configure both the IP addressing and the BGP peering between nodes on each of the TopoLinks.</li> <li>Autonomous Systems: Like IP addresses, the autonomous systems used by the eBGP sessions are automatically allocated from the specified ASN pool (<code>asnPool</code>).</li> </ul>"},{"location":"apps/fabric/#routing-policies","title":"Routing Policies","text":"<ul> <li>Automatic Generation: If not explicitly specified, the Fabric will automatically generate the required <code>RoutingPolicies</code>. These policies are used in the eBGP peering sessions to ensure IP reachability across the fabric.  However, if RoutingPolicies are defined independently of the Fabric they can be used by specifying the <code>importPolicy</code> and <code>exportPolicy</code> properties.</li> </ul>"},{"location":"apps/fabric/#selecting-an-overlay-protocol","title":"Selecting an Overlay Protocol","text":"<p>The application supports the use of either eBGP or iBGP for transporting the EVPN AFI/SAFI, which are used for overlay services.</p>"},{"location":"apps/fabric/#ebgp-configuration_1","title":"eBGP Configuration","text":"<p>When eBGP is selected as the overlay protocol, it leverages existing eBGP sessions established by the underlay protocol. These sessions are extended to advertise the EVPN address family, in addition to the existing ipv4-unicast and ipv6-unicast families.  It should be noted that the import and export policies specified in the Underlay configuration will be used, any import or export policies specified in the overlay protocol will be ignored.</p>"},{"location":"apps/fabric/#ibgp-configuration","title":"iBGP Configuration","text":"<p>If iBGP is the preferred method for exchanging EVPN routes, additional properties must be configured within the Fabric application:</p> <ul> <li> <p>Autonomous System (<code>autonomousSystem</code>): Specifies the AS used for the establishment of the iBGP session.</p> </li> <li> <p>Route Reflector (RR) Configuration:</p> </li> <li>RR Client Node Selector (<code>rrClientNodeSelector</code>): This label selector identifies TopoNodes to be configured as iBGP RR clients. It also drives the configuration of the selected iBGP RR neighbors if being configured by the Fabric.  Typically, this would select leaf and border leaf nodes.<ul> <li>Example: <code>eda.nokia.com/role=leaf</code></li> </ul> </li> <li>RR IP Addresses (<code>rrIPAddresses</code>): If the Route Reflectors are not configured by the Fabric application, these IP addresses are used to configure the iBGP neighbors on the selected RR clients.</li> <li>RR Node Selector (<code>rrNodeSelector</code>): This label selector identifies TopoNodes to be configured as iBGP Route Reflectors. It also drives the configuration of the selected iBGP RR client neighbors, typically involving spines or border leafs.<ul> <li>Example: <code>eda.nokia.com/role=borderleaf</code></li> </ul> </li> </ul>"},{"location":"apps/fabric/#example-fabric-k8s-crs","title":"Example fabric K8S CRs","text":""},{"location":"apps/fabric/#simple-leaf-spine-fabric","title":"Simple Leaf / Spine Fabric","text":"<code>kubectl</code>YAML <pre><code>cat &lt;&lt; 'EOF' | tee my-fabric.yaml | kubectl apply -f -\napiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: myfabric-1\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n\nEOF\n</code></pre> <pre><code>apiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: myfabric-1\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n</code></pre>"},{"location":"apps/fabric/#verify-the-fabric","title":"Verify the Fabric","text":"<p>Verify the fabric operational state:</p> <pre><code>kubectl get fabrics\n\nNAME           LAST CHANGE   OPERATIONAL STATE\nsunnyvale-dc1   104m          up\n</code></pre>"},{"location":"apps/interfaces/","title":"Interfaces","text":"Description The interfaces application enables the configuration and management of network interfaces across your infrastructure, supporting various interface types including single interfaces, LAGs, and loopback interfaces. Supported OS SR Linux, SR OS Catalog nokia-eda/catalog Source Code coming soon <p>The Interfaces application provides two resources - Interface and Breakout.</p>"},{"location":"apps/interfaces/#interface","title":"Interface","text":"<p> TOPOLOGY \u2192 IInterface</p> <p>The Interface resource declaratively defines abstracted network interfaces for the range of supported network operating systems and supports three primary interface types:</p> <ul> <li>Standard Interface: Individual physical interfaces</li> <li>LAG (Link Aggregation Group): Bundled interfaces operating as a single logical link</li> <li>Loopback: Virtual interfaces for management and routing purposes</li> </ul>"},{"location":"apps/interfaces/#basic-configuration-fields","title":"Basic Configuration Fields","text":"<p>In the basic scenario of configuring a simple interface the following basic configuration fields are typically set:</p> <ul> <li>Type: An interface type - <code>standard</code>, <code>lag</code> or <code>loopback</code>.</li> <li>Members: A list of objects where each object is a reference to a node name and its associated physical interface name.     The interface name is provided in the normalized way, non alphanumerical characters are replaced with <code>-</code> (dash). For example, original interface name <code>ethernet-1/13</code> becomes <code>ethernet-1-13</code>.</li> <li>Enabled State: Interfaces are enabled by default but can be explicitly disabled</li> <li>Description: Optional text description of the interface</li> <li>MTU: Maximum Transmission Unit (range: 1450-9500)</li> </ul> <p>Add the metadata blob that includes the Interface resource Name, Namespace and Labels, and you get a valid EDA resource that you can apply, for example to your Try EDA cluster.</p> <p>When applied, the resource presented below will create a simple physical network interface configuration on the supported network OS with the user-provided values and the resource defaults.</p> YAML<code>kubectl</code> basic Interface resource definition<pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-ethernet-1-13\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: interface\n  description: \"Customer facing interface\"\n  enabled: true\n  mtu: 9000\n  members:\n    - node: leaf1\n      interface: ethernet-1-13\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-ethernet-1-13\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: interface\n  description: \"Customer facing interface\"\n  enabled: true\n  mtu: 9000\n  members:\n    - node: leaf1\n      interface: ethernet-1-13\n\nEOF\n</code></pre>"},{"location":"apps/interfaces/#interface-naming-and-normalization","title":"Interface Naming and Normalization","text":"<p>The Interface application employs a standardized, or normalized, format for interface names within its configurations. This approach ensures consistency when defining interfaces across diverse network operating systems (NOS). The system subsequently translates these normalized names into the specific format required by each target OS.</p> <p>A key aspect of EDA's interface modeling is the use of normalized interface names. Typically, an OS-native interface name like <code>ethernet-1/13</code> is represented as <code>ethernet-1-13</code> in EDA configurations by replacing non-alphanumeric characters (like <code>/</code>) with a dash (<code>-</code>). This normalized name is then used by the system to derive the OS-specific interface identifier.</p> <p>The following subsections detail how these normalized EDA interface names are translated for various supported operating systems, based on the underlying logic.</p>"},{"location":"apps/interfaces/#sr-linux","title":"SR Linux","text":"<ul> <li>Native interface name <code>ethernet-1/1</code> is normalized as <code>ethernet-1-1</code>.</li> <li>Breakout interfaces like <code>ethernet-1/1/1</code> become <code>ethernet-1-1-1</code>.</li> <li>Loopback interfaces such as <code>lo0</code> translate to <code>loopback-0</code>.</li> <li>LAG interfaces like <code>lag10</code> translate to <code>lag-10</code>.</li> </ul>"},{"location":"apps/interfaces/#sr-os","title":"SR OS","text":"<ul> <li>Native port identifier <code>1/1/1</code> translates to <code>ethernet-1-a-1</code> name, where \"a\" is the first MDA on a 1<sup>st</sup> line card.</li> <li>The system supports more complex mappings for different hardware configurations:<ul> <li>Port <code>2/2/1</code> translates to <code>ethernet-2-b-1</code> (representing linecard 2, MDA \"b\"<sup>2</sup>, port 1).</li> <li>Breakout (implicit MDA 1): <code>1/1/c1/1</code> translates to <code>ethernet-1-1-1</code>.</li> <li>Breakout (explicit \"a\" for MDA 1): <code>1/1/c2/1</code> translates to <code>ethernet-1-a-2-1</code> (where MDA \"a\" maps to 1, and \"2-1\" defines the port as <code>c2/1</code>).</li> <li>XIOM MDA: <code>1/x1/1/1</code> translates to <code>ethernet-1-1-a-1</code>.</li> </ul> </li> <li>Loopback interfaces like <code>lo0</code> become <code>loopback-0</code>.</li> <li>LAG interfaces retain names like <code>lag-10</code>.</li> </ul>"},{"location":"apps/interfaces/#ethernet-configuration","title":"Ethernet Configuration","text":"<p>The Interface application provides extensive Ethernet-specific configurations through the <code>ethernet</code> property, including:</p> <ul> <li>Speed: Interface speed (100G, 40G, 25G, 10G, 1G, etc.)</li> <li>Forward Error Correction (FEC): Various FEC modes (disabled, rs528, rs544, baser, rs108)</li> <li>Timers: Hold-up, hold-down, and reload delay timers</li> <li>Storm Control: Traffic rate limiting for broadcast, multicast, and unknown unicast</li> <li>L2CP Protocol Transparency: Configuration for tunneling various L2CP protocols</li> </ul>"},{"location":"apps/interfaces/#storm-control-configuration","title":"Storm Control Configuration","text":"<p>Storm control helps protect the network from traffic storms by setting rate limits:</p> YAML<code>kubectl</code> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: example-interface\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: interface\n  description: \"Customer facing interface with storm control enabled\"\n  enabled: true\n  mtu: 9000\n  ethernet:\n    stormControl:\n      enabled: true\n      units: kbps\n      broadcastRate: 1000000\n      multicastRate: 1000000\n      unknownUnicastRate: 1000000\n  members:\n    - node: leaf-1\n      interface: ethernet-1-1\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: example-interface\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: interface\n  description: \"Customer facing interface with storm control enabled\"\n  enabled: true\n  mtu: 9000\n  ethernet:\n    stormControl:\n      enabled: true\n      units: kbps\n      broadcastRate: 1000000\n      multicastRate: 1000000\n      unknownUnicastRate: 1000000\n  members:\n    - node: leaf-1\n      interface: ethernet-1-1\nEOF\n</code></pre>"},{"location":"apps/interfaces/#lag-configuration","title":"LAG Configuration","text":"<p>Link Aggregation Groups (LAGs) provide link redundancy and increased bandwidth. The Interface application supports both regular/local LAGs (with static and LACP-based configurations) as well as ESI-based<sup>1</sup> multihoming LAGs.</p> <p>The following set of Interface objects is relevant for the LAG interface configuration:</p> <ul> <li>Minimum Links: Minimum required number of active links in a LAG to be operational</li> <li>LACP Settings: Mode, interval, system priority, and admin key</li> <li>Multi-homing: ESI configuration for multi-chassis operation</li> </ul>"},{"location":"apps/interfaces/#example-lag-configuration","title":"Example LAG Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-simple-lag\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: lag\n  description: \"Customer facing lag\"\n  enabled: true\n  mtu: 9000\n  lag:\n    type: lacp\n    minLinks: 2\n    lacp:\n      mode: active\n      interval: fast\n      systemPriority: 32768\n  members:\n    - node: leaf1\n      interface: ethernet-1-14\n    - node: leaf1\n      interface: ethernet-1-15\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-simple-lag\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: lag\n  description: \"Customer facing lag\"\n  enabled: true\n  mtu: 9000\n  lag:\n    type: lacp\n    minLinks: 2\n    lacp:\n      mode: active\n      interval: fast\n      systemPriority: 32768\n  members:\n    - node: leaf1\n      interface: ethernet-1-14\n    - node: leaf1\n      interface: ethernet-1-15\n\nEOF\n</code></pre>"},{"location":"apps/interfaces/#multi-homing-support","title":"Multi-homing Support","text":"<p>The Interface application supports sophisticated multi-homing configurations for LAGs based on EVPN standard, enabling high availability and load balancing:</p> <ul> <li>Modes: all-active, single-active, or port-active</li> <li>ESI: Ethernet Segment Identifier configuration</li> <li>Active Node Preference: Preferred node selection for single-active scenarios</li> <li>Revertive Behavior: Controls failback behavior</li> </ul>"},{"location":"apps/interfaces/#multi-homing-configuration-example","title":"Multi-homing Configuration Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-leaf2-simple-mh-lag\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: lag\n  description: \"Customer facing multihoming lag\"\n  enabled: true\n  mtu: 9000\n  lag:\n    type: lacp\n    minLinks: 2\n    multihoming:\n      mode: all-active\n      preferredActiveNode: leaf1\n      revertive: true\n    lacp:\n      mode: active\n      interval: fast\n      systemPriority: 32768\n  members:\n    - node: leaf1\n      interface: ethernet-1-20\n    - node: leaf2\n      interface: ethernet-1-20\n</code></pre> <pre><code>cat &lt;&lt; 'EOF'  | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  name: leaf1-leaf2-simple-mh-lag\n  namespace: eda\n  labels:\n    eda.nokia.com/role: edge\nspec:\n  type: lag\n  description: \"Customer facing multihoming lag\"\n  enabled: true\n  mtu: 9000\n  lag:\n    type: lacp\n    minLinks: 2\n    multihoming:\n      mode: all-active\n      preferredActiveNode: leaf1\n      revertive: true\n    lacp:\n      mode: active\n      interval: fast\n      systemPriority: 32768\n  members:\n    - node: leaf1\n      interface: ethernet-1-20\n    - node: leaf2\n      interface: ethernet-1-20\n\nEOF\n</code></pre>"},{"location":"apps/interfaces/#operational-state","title":"Operational State","text":"<p>The Interface application maintains detailed operational state information, including:</p> <ul> <li>Administrative and operational status</li> <li>Interface speed</li> <li>Last state change timestamp</li> <li>Member status and neighbor discovery</li> <li>LAG-specific operational details</li> </ul> <p>You can verify the interface operational state using:</p> <pre><code>kubectl -A get interfaces\n</code></pre> <pre><code>NAME               ENABLED   OPERATIONAL STATE   SPEED   LAST CHANGE   AGE\ncustomer-facing    true      up                 100G    2m            10m\n</code></pre>"},{"location":"apps/interfaces/#breakout","title":"Breakout","text":"<p> TOPOLOGY \u2192 BBreakout</p> <p>The Breakout resource allows for the configuration of interface breakouts on specified Nodes. This resource specifies the Nodes, parent Interfaces, the number of breakout channels, and the speed of each channel.</p>"},{"location":"apps/interfaces/#configuration-fields","title":"Configuration Fields","text":"<ul> <li><code>node</code>: A list of references to TopoNodes where the parent interfaces are to be broken out.</li> <li><code>interface</code>: A list of normalized parent interface/port names to be broken out.</li> <li><code>channels</code>: (Required) The number of breakout channels to create (integer, min: 1, max: 8).</li> <li><code>speed</code>: (Required) The speed of each breakout channel. Supported speeds are: 800G, 400G, 200G, 100G, 50G, 40G, 25G, 10G.</li> <li><code>nodeSelector</code>: An alternative way to specify the TopoNode(s) where the parent interfaces are to be broken out.</li> </ul>"},{"location":"apps/interfaces/#example-breakout-configuration","title":"Example Breakout Configuration","text":"<p>This example demonstrates how to configure a breakout port.</p> YAML<code>kubectl</code> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Breakout\nmetadata:\n  name: breakout-example\n  namespace: default\nspec:\n  node:\n    - node-1 # Name of the TopoNode\n  interface:\n    - ethernet-1-1 # Name of the parent interface on node-1\n  channels: 4\n  speed: 100G\n</code></pre> <pre><code>cat &lt;&lt; 'EOF'  | kubectl apply -f -\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Breakout\nmetadata:\n  name: breakout-example\n  namespace: default\nspec:\n  node:\n    - node-1 # Name of the TopoNode\n  interface:\n    - ethernet-1-1 # Name of the parent interface on node-1\n  channels: 4\n  speed: 100G\nEOF\n</code></pre> <ol> <li> <p>A standards-based alternative to proprietary Multi-chassis LAGs.\u00a0\u21a9</p> </li> <li> <p>Letter \"b\" means 2<sup>nd</sup> MDA.\u00a0\u21a9</p> </li> </ol>"},{"location":"apps/kafka-exporter/","title":"Kafka Exporter","text":"Description Kafka Exporter publishes network data to a Kafka broker. Author Nokia Supported OS SR Linux, SR OS Catalog nokia-eda/catalog Language Go Source Code coming soon"},{"location":"apps/kafka-exporter/#installation","title":"Installation","text":"<p>The Kafka Exporter app can be installed using EDA Store or by running the <code>app-install</code> workflow with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: kafka-exporter-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: kafka.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: kafka-exporter-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: kafka.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n\nEOF\n</code></pre>"},{"location":"apps/kafka-exporter/#configuration","title":"Configuration","text":"<p>After installation, you can configure the Kafka Exporter using a <code>Producer</code> or a <code>ClusterProducer</code> Custom Resources (CR).</p> <p>The CR specifies the data to be exported, the Kafka broker settings and the messages delivery behavior.</p> <p>The <code>Producer</code> CR is namespace specific and is used to export data only from its own namespace. While the <code>ClusterProducer</code> CR is created in the EDA base namespace (<code>eda-system</code>) and allows to export data from any user namespace.</p>"},{"location":"apps/kafka-exporter/#what-to-export","title":"What to export","text":"<p>Define the data to be exported.</p> <ul> <li> <p>Export Paths: <code>.spec.exports[].path</code></p> <p>Specifies the paths in the state DB to export, e.g., <code>.namespace.node.srl.interface</code>.</p> <p>For a <code>Producer</code> CR the <code>.namespace</code> prefix can be omitted.</p> </li> <li> <p>Fields: <code>.spec.exports[].fields</code></p> <p>Lists the fields to include in the exported data. If not specified, all fields under the path are included.</p> </li> <li> <p>Where Query: <code>.spec.exports[].where</code></p> <p>A filter for the data, e.g., <code>oper-state = down</code>. Only matching data will be exported.</p> </li> </ul>"},{"location":"apps/kafka-exporter/#where-are-we-exporting-it","title":"Where are we exporting it","text":"<p>Specify the destination and security settings for the export</p> <ul> <li> <p>Broker Addresses: <code>.spec.brokers</code></p> <p>Comma-separated list of Kafka broker addresses to connect to, e.g., <code>broker1:9092,broker2:9092</code>.</p> </li> <li> <p>Security Settings:</p> <ul> <li> <p>SASL: <code>.spec.sasl</code></p> <ul> <li><code>user</code>: Kafka username.</li> <li><code>password</code>: Kafka password.</li> <li><code>mechanism</code>: Authentication mechanisms such as <code>plain</code>, <code>scram-sha-256</code>,<code>scram-sha-512</code> or <code>oauthbearer</code>.</li> <li><code>token-url</code>: The token URL when <code>mechanism</code> is <code>oauthbearer</code>.</li> </ul> </li> <li> <p>TLS: <code>.spec.tls</code></p> <p>Certificate-based authentication for secure communication. Includes:</p> <ul> <li><code>cert-file</code>: Path to the client certificate file.</li> <li><code>key-file</code>: Path to the client private key file.</li> <li><code>ca-file</code>: Path to the certificate authority file.</li> <li><code>skip-verify</code>: whether the producer should verify the broker's certificate</li> </ul> </li> </ul> </li> </ul>"},{"location":"apps/kafka-exporter/#how-are-we-doing-all-that","title":"How are we doing all that?","text":"<p>Set how often or when data is exported and what kind of acknowledgment is required.</p> <ul> <li> <p>Message Delivery Mode:</p> <ul> <li><code>.spec.sync-producer</code>: Use synchronous messaging (<code>true</code>) or asynchronous messaging (<code>false</code>).</li> <li><code>.spec.flush-frequency</code>: Defines how long messages can sit in the producer's buffer before being batch sent to the broker.</li> </ul> </li> <li> <p>Acknowledgment Level: <code>.spec.required-acks</code></p> <ul> <li><code>no-response</code>: No acknowledgment required.</li> <li><code>wait-for-local</code>: Acknowledged by the leader broker only.</li> <li><code>wait-for-all</code>: Acknowledged by all in-sync replicas.</li> </ul> </li> <li> <p>Compression Codec: <code>.spec.compression-codec</code></p> <ul> <li>Options: <code>none</code>, <code>gzip</code>, <code>snappy</code>, <code>zstd</code>, <code>lz4</code>.</li> </ul> </li> <li> <p>Retry and Timeout:</p> <ul> <li><code>.spec.max-retry</code>: Number of retries for failed message delivery (default: 3).</li> <li><code>.spec.timeout</code>: Timeout duration for producer operations (default: 10 seconds).</li> </ul> </li> <li> <p>Export Frequency: <code>.spec.exports[].period</code></p> <ul> <li>Interval for periodic exports (minimum: 10 seconds).</li> </ul> </li> <li> <p>Export Triggers: <code>.spec.exports[].mode</code></p> <ul> <li><code>on-change</code>: Export data when it changes.</li> <li><code>periodic</code>: Export data at regular intervals.</li> <li><code>periodic-on-change</code>: Combine both periodic and change-based exports.</li> </ul> </li> </ul>"},{"location":"apps/kafka-exporter/#usage-examples","title":"Usage Examples","text":""},{"location":"apps/kafka-exporter/#producer","title":"Producer","text":"YAML<code>kubectl</code> <pre><code>apiVersion: kafka.eda.nokia.com/v1alpha1\nkind: Producer\nmetadata:\n  name: kafka-producer\n  namespace: eda\nspec:\n  brokers: \"broker1:9092,broker2:9092\"\n  required-acks: wait-for-local\n  max-retry: 3\n  timeout: \"10s\"\n  compression-codec: gzip\n  exports:\n    - topic: \"interface-state\"\n      path: \".node.srl.interface\"\n      fields:\n        - admin-state\n        - oper-state\n      where: 'admin-state = \"enable\"'\n      period: \"60s\"\n      mode: periodic-on-change\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: kafka.eda.nokia.com/v1alpha1\nkind: Producer\nmetadata:\n  name: kafka-producer\n  namespace: eda\nspec:\n  brokers: \"broker1:9092,broker2:9092\"\n  required-acks: wait-for-local\n  max-retry: 3\n  timeout: \"10s\"\n  compression-codec: gzip\n  exports:\n    - topic: \"interface-state\"\n      path: \".node.srl.interface\"\n      fields:\n        - admin-state\n        - oper-state\n      where: 'admin-state = \"enable\"'\n      period: \"60s\"\n      mode: periodic-on-change\n\nEOF\n</code></pre>"},{"location":"apps/kafka-exporter/#clusterproducer","title":"ClusterProducer","text":"YAML<code>kubectl</code> <pre><code>apiVersion: kafka.eda.nokia.com/v1alpha1\nkind: ClusterProducer\nmetadata:\n  name: kafka-cluster-producer\n  namespace: eda-system\nspec:\n  brokers: \"broker1:9092,broker2:9092\"\n  required-acks: wait-for-local\n  max-retry: 3\n  timeout: \"10s\"\n  compression-codec: gzip\n  exports:\n    - topic: \"interface-state\"\n      path: \".namespace.node.srl.interface\"\n      fields:\n        - admin-state\n        - oper-state\n      where: 'admin-state = \"enable\"'\n      period: \"60s\"\n      mode: periodic-on-change\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: kafka.eda.nokia.com/v1alpha1\nkind: ClusterProducer\nmetadata:\n  name: kafka-cluster-producer\n  namespace: eda-system\nspec:\n  brokers: \"broker1:9092,broker2:9092\"\n  required-acks: wait-for-local\n  max-retry: 3\n  timeout: \"10s\"\n  compression-codec: gzip\n  exports:\n    - topic: \"interface-state\"\n      path: \".namespace.node.srl.interface\"\n      fields:\n        - admin-state\n        - oper-state\n      where: 'admin-state = \"enable\"'\n      period: \"60s\"\n      mode: periodic-on-change\n\nEOF\n</code></pre> <p>Also check out EDA Telemetry demo lab for Kafka exporter usage examples.</p>"},{"location":"apps/netbox/","title":"NetBox","text":"Description The EDA NetBox app integrates with NetBox to synchronize EDA resources with NetBox Supported OS N/A Catalog EDA built in apps Source Code coming soon"},{"location":"apps/netbox/#overview","title":"Overview","text":"<p>The NetBox app enables users to integrate/synchronize various resources between NetBox and EDA by providing the following resource types:</p> <ul> <li>Instance: Defines the target NetBox instance to interact with.</li> <li>Allocation: Specifies the type of EDA allocation to create based on the NetBox's <code>Prefixes</code>.</li> </ul> <p>Corresponding Instance and Allocation resources must be created in the same (non-<code>eda-system</code>) namespace.</p> <p>EDA continues to use its own allocation pools for IP addresses, indices and subnets, but the NetBox app will dynamically create the allocation pools based on the NetBox's <code>IPAM &gt; Prefixes</code> objects and post the allocated objects back to NetBox.</p> <p>This mode of operation allows the users to leverage NetBox's IPAM features and dynamically create the allocation pools in EDA. Check out the end-to-end example for more details.</p>"},{"location":"apps/netbox/#supported-objects","title":"Supported objects","text":"<p>In the current version of the NetBox app EDA's allocation pools are created based on the NetBox Prefix objects. Depending on the Prefix's Status mode, the allocation pools of certain type can be created.</p> Prefix Status Suitable EDA Allocation Pools Example usage in EDA Active IP Address (<code>IPAllocationPool</code>),IP Address + Mask (<code>IPInSubnetAllocationPool</code>) System IPManagement IP Container Subnet (<code>SubnetAllocationPool</code>) ISL subnet <p>More objects will be supported in the future.</p>"},{"location":"apps/netbox/#netbox-configuration","title":"NetBox Configuration","text":""},{"location":"apps/netbox/#create-a-webhook","title":"Create a Webhook","text":"<p>The Webhook in NetBox is triggered by the NetBox's Event Rule and allows NetBox to send updates to the EDA app.</p> <ul> <li>Name: Any meaningful identifier</li> <li> <p>URL: <code>https://${EDA_ADDR}:${EDA_PORT}/core/httpproxy/v1/netbox/webhook/${INSTANCE_NAMESPACE}/${INSTANCE_NAME}</code>       Replace the <code>${INSTANCE_NAMESPACE}</code> with the EDA namespace name you will use to create the NetBox Instance custom resource later. The <code>${INSTANCE_NAME}</code> should be the name of the NetBox Instance custom resource you will create in the Instance Customer Resource section.</p> <p>For example, if you want to create EDA-NetBox integration for the EDA Allocation pools in the <code>eda</code> namespace, and you will name your NetBox Instance CR simply <code>netbox</code>, then the URL will be:</p> <pre><code>https://youredaaddress.com:9443/core/httpproxy/v1/netbox/webhook/eda/netbox\n</code></pre> </li> <li> <p>Method: <code>POST</code></p> </li> <li>Secret: Choose a signature secret (plaintext string) that will be used to validate the webhook request. The matching Kubernetes secret with the same string will be created later in the Kubernetes Secrets section.</li> <li>SSL verification: Based on your setup either leave SSL verification enabled or disable it.</li> <li>Leave all other settings as default.</li> </ul>"},{"location":"apps/netbox/#create-an-event-rule","title":"Create an Event Rule","text":"<p>An event rule is used to trigger webhook based on the events happening in NetBox. You will find the Event Rules menu item under the Integrations section in NetBox.</p> <ul> <li>Name: Choose a relevant name</li> <li>Objects: Include IPAM\u00a0IPAddresses and IPAM\u00a0Prefixes</li> <li>Enabled: Yes</li> <li> <p>Event Types:</p> <ul> <li>Object created</li> <li>Object updated</li> <li>Object deleted</li> </ul> </li> <li> <p>Action:</p> <ul> <li>Type: Webhook</li> <li>Webhook: Select the one created above</li> </ul> </li> </ul>"},{"location":"apps/netbox/#generate-an-api-token","title":"Generate an API Token","text":"<p>Using the Admin \u2192 Authentication \u2192 API Tokens menu create a NetBox API token for the NetBox user that EDA app will use. Enable write permission for the API token.</p>"},{"location":"apps/netbox/#configure-user-permissions","title":"Configure User Permissions","text":"<p>In the Admin \u2192 Authentication \u2192 Permissions menu, grant the user you created the API token for the permissions to <code>create</code>, <code>update</code>, and <code>delete</code> for the following objects:</p> <ul> <li><code>IPAM &gt; IPAddress</code></li> <li><code>IPAM &gt; Prefix</code></li> <li><code>Extras &gt; Tag</code> (a.k.a <code>Customizations.Tags</code> in earlier versions)</li> <li><code>Extras &gt; Custom Field</code> (a.k.a <code>Customizations.CustomFields</code> in earlier versions)</li> </ul>"},{"location":"apps/netbox/#configure-global-vrf-setting","title":"Configure Global VRF Setting","text":"<p>Starting with NetBox 4.2.6, the <code>ENFORCE_GLOBAL_UNIQUE</code> setting has been flipped to <code>true</code>, this may have negative effect on EDA installations that use multiple topologies using the same IP addressing.</p> <p>As per the NetBox documentation, to relax this enforcement change the configuration setting of the global VRF via environment variable or in the <code>configuration.py</code> file.</p> <pre><code>ENFORCE_GLOBAL_UNIQUE=false\n</code></pre>"},{"location":"apps/netbox/#tags","title":"Tags","text":"<p>In case you plan to have more than one \"NetBox Prefix\" \u2192 \"EDA allocation pool\" mapping, you will need to create a tag in NetBox for each distinct allocation pool and assign it to the Prefix object in NetBox.</p> <p>In the EDA Allocation resource you then reference the tag name in the <code>tags</code> field and the allocation pool will be created based on the prefixes with that tag.</p>"},{"location":"apps/netbox/#kubernetes-secrets","title":"Kubernetes Secrets","text":"<p>The NetBox API Token and the Webhook secret must be created as Kubernetes Secrets in the same namespace where the EDA NetBox app will run (example: <code>eda</code>). The data for these secrets must be provided as base64 encoded strings.</p> <p>Secret for the webhook:</p> YAML<code>kubectl</code> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-webhook-signature\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded signature key that NetBox will use\n  signatureKey: ${NETBOX_WEBHOOK_SIGNATURE_KEY}\n</code></pre> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-webhook-signature\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded signature key that NetBox will use\n  signatureKey: ${NETBOX_WEBHOOK_SIGNATURE_KEY}\nEOF\n</code></pre> <p>Secret for the API Token:</p> YAML<code>kubectl</code> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-api-token\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded NetBox API token with IPAM permissions\n  apiToken: ${NETBOX_API_TOKEN}\n</code></pre> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-api-token\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded NetBox API token with IPAM permissions\n  apiToken: ${NETBOX_API_TOKEN}\nEOF\n</code></pre>"},{"location":"apps/netbox/#eda-configuration","title":"EDA Configuration","text":""},{"location":"apps/netbox/#installation","title":"Installation","text":"<p>Install the NetBox app from the EDA Store or with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: netbox-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: netbox.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v2.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: netbox-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: netbox.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v2.0.0\n\nEOF\n</code></pre>"},{"location":"apps/netbox/#instance-resource","title":"Instance Resource","text":"<p>Defines connection details to the NetBox instance from the EDA NetBox app:</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Instance\nmetadata:\n  name: netbox1\n  namespace: eda\nspec:\n  url: http://${NETBOX_ADDR}:${NETBOX_PORT}\n  # Name of a secret containing the base64-encoded API token\n  # under the `apiToken` key\n  apiToken: netbox-api-token\n  # Name of a secret containing the base64-encoded signature key\n  # under the `signatureKey` key\n  signatureKey: netbox-webhook-signature\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Instance\nmetadata:\n  name: netbox1\n  namespace: eda\nspec:\n  url: http://${NETBOX_ADDR}:${NETBOX_PORT}\n  # Name of a secret containing the base64-encoded API token\n  # under the `apiToken` key\n  apiToken: netbox-api-token\n  # Name of a secret containing the base64-encoded signature key\n  # under the `signatureKey` key\n  signatureKey: netbox-webhook-signature\nEOF\n</code></pre> <p>The NetBox Instance resource requires a user to provide names of the two Kubernetes secrets created in the same namespace where the Instance is deployed:</p> <ol> <li>The <code>apiToken</code> field references the secret containing the NetBox API Token.</li> <li>The <code>webhookSignatureSecret</code> field references the secret containing the Webhook signature secret.</li> </ol> <p>After creation, check the status of the Instance resource to verify successful connection.</p>"},{"location":"apps/netbox/#allocation-resource","title":"Allocation Resource","text":"<p>With Allocation resource a user specifies which NetBox Prefixes should create which EDA allocation pools.</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: netbox-isl-pool\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox  # &lt;-- Reference to the Instance resource\n  tags:\n    - eda-isl-pool  # &lt;-- Must match tags on NetBox prefixes\n  type: subnet      # &lt;-- One of: ip-address, subnet, ip-in-subnet\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: netbox-isl-pool\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox  # &lt;-- Reference to the Instance resource\n  tags:\n    - eda-isl-pool  # &lt;-- Must match tags on NetBox prefixes\n  type: subnet      # &lt;-- One of: ip-address, subnet, ip-in-subnet\nEOF\n</code></pre> <p>The name of the Allocation resource will drive the name of the EDA allocation pool.</p> <p>With tags a user selects which tagged Prefixes from NetBox would be \"mapped\" to this Allocation resource. Since NetBox prefixes don't have a unique name, the tags are used to identify the Prefixes.</p> <p>A single NetBox prefix object can be mapped to three different allocation pools in EDA depending on the type specified in the Allocation resource.</p> Type Resource Created Typical\u00a0Use <code>ip-address</code> <code>ipallocationpools.core.eda.nokia.com</code> IP Addresses\u00a0\u2192 System IPs <code>ip-in-subnet</code> <code>ipinsubnetallocationpools.core.eda.nokia.com</code> IP Addresses\u00a0+\u00a0Masks\u00a0\u2192 Management IP <code>subnet</code> <code>subnetallocationpools.core.eda.nokia.com</code> Subnets\u00a0\u2192 ISL\u00a0links <p>Consult with the Supported Objects section to see what status a NetBox prefix must have to be compatible with the desired allocation pool type.</p> <p>The status field of the Allocation resource is used to track the matching allocations. For example, consider the following status block in the Allocation resource:</p> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-systemip-v4\n  namespace: eda\n  labels: {}\n  annotations: {}\nspec:\n  enabled: true\n  instance: netbox\n  tags:\n    - eda-systemip-v4\n  type: ip-address\n  description: ''\n  subnetLength: null\nstatus:\n  matchedPrefixes:\n    - id: 3\n      prefix: 192.168.10.0/24\n      tags:\n        - eda-systemip-v4\n  lastEvent: ''\n  lastEventStatus: ''\n  lastEventTime: null\n</code></pre> <p>It indicates that the incoming via Webhook NetBox prefix <code>192.168.10.0/24</code> tagged with the <code>eda-systemip-v4</code> tag was recorded with the ID <code>3</code> for this Allocation resource.</p>"},{"location":"apps/netbox/#example","title":"Example","text":"<p>In this example, we will demonstrate how EDA/NetBox integration works by creating two Prefix objects in NetBox for System IPs and inter-switch link subnets that will be synchronized to EDA and result in two Allocation pools in EDA. The two pools will then be used to instantiate a Fabric in EDA and through that we will</p> <p>We will install a demo NetBox instance<sup>1</sup> in the same cluster that runs EDA using helm and the netbox chart v6.0.33:</p> <pre><code>helm install netbox-server oci://ghcr.io/netbox-community/netbox-chart/netbox \\\n    --create-namespace \\\n    --namespace=netbox \\\n    --set superuser.password=netbox \\\n    --set enforceGlobalUnique=false \\ #(1)!\n    --version 6.0.33 #(2)!\n</code></pre> <ol> <li><code>enforceGlobalUnique=false</code> allows configures the global VRF of NetBox to allow duplicate IP addresses. The duplicated IP addresses may be created by EDA when distinct topologies use the same IP addressing.</li> <li>We fix the chart version to ensure the reproducibility of the example, but there is no hard dependency on the chart version.</li> </ol> <p>The NetBox instance will take a few minutes to start, you can monitor the pods in the <code>netbox</code> namespace<sup>2</sup> and once all pods are up and running, expose the NetBox instance:</p> <pre><code>kubectl -n netbox port-forward svc/netbox-server 45123:80\n</code></pre> <p>You should now be able to login to the NetBox UI via <code>http://localhost:45123</code> using <code>admin:netbox</code> credentials.</p> <p>Then install the NetBox EDA app using one of the documented methods.</p> NetBox configuration Webhook <p>Go to Operations \u2192 Integrations \u2192 Webhook in NetBox UI and create a webhook with the following values:</p> <ul> <li>Name: <code>eda</code></li> <li> <p>URL: <code>https://${EDA_ADDR}:${EDA_PORT}/core/httpproxy/v1/netbox/webhook/eda/netbox</code>     Replace <code>${EDA_ADDR}</code> and <code>${EDA_PORT}</code> with the address and port of the EDA instance you use.</p> </li> <li> <p>Secret: <code>eda</code></p> </li> <li>SSL verification: disabled</li> </ul> Event Rule <p>Go to Operations \u2192 Integrations \u2192 Event Rules in NetBox UI and create an Event Rule that will trigger the Webhook with the following fields set:</p> <ul> <li>Name: <code>eda</code></li> <li>Object types:<ul> <li><code>IPAM &gt; IP Address</code></li> <li><code>IPAM &gt; Prefix</code></li> </ul> </li> <li>Enabled: checked</li> <li>Event types: <code>Object created</code> <code>Object deleted</code> <code>Object updated</code></li> <li>Action type: <code>Webhook</code></li> <li>Webhook: <code>eda</code> (the name of the webhook we created above)</li> </ul> API Token and Permissions <p>Normally you would generate a new API token for the user you want to use for API access, but since the demo instance of NetBox that we installed with the Helm chart already contains an API token for the <code>admin</code> user, we will just use it, instead of generating a new one.</p> Create secrets <p>Now we need to create the Kubernetes secrets for the generated API Token and the Webhook signature secret.</p> <p>The inputs to the secrets should be in base64 format, therefore the snippets below run the raw inputs through <code>base64</code> command to convert them to base64 format.</p> <p>We install the secrets in the <code>eda</code> namespace - the default namespace your EDA installation comes with. If you use another namespace, adjust the namespace name accordingly.</p> Token secretWebhook signature secretToken secret (regular installation) <p>The NetBox Helm chart used in this example creates a Kubernetes secret <code>netbox/netbox-server-superuser</code> which contains the API token for the <code>admin</code> user. We will use the existing token value as is:</p> <pre><code>NETBOX_API_TOKEN=$(kubectl -n netbox get secret netbox-server-superuser -o jsonpath='{.data.api_token}')\ncat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-api-token\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded NetBox API token with IPAM permissions\n  apiToken: ${NETBOX_API_TOKEN}\nEOF\n</code></pre> <pre><code>NETBOX_WEBHOOK_SIGNATURE_KEY=$(echo -n \"eda\" | base64)\ncat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-webhook-signature\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded signature key that NetBox will use\n  signatureKey: ${NETBOX_WEBHOOK_SIGNATURE_KEY}\nEOF\n</code></pre> <p>In case you are repeating this exercise without using NetBox Helm chart, or if you run a non-admin user, you will need to generate the API Token manually.</p> <pre><code>NETBOX_API_TOKEN=$(base64 &lt;&lt;&lt; \"yourTokenHere\")\ncat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Secret\nmetadata:\n  name: netbox-api-token\n  namespace: eda\ntype: Opaque\ndata:\n  # base64-encoded NetBox API token with IPAM permissions\n  apiToken: ${NETBOX_API_TOKEN}\nEOF\n</code></pre> Prefixes and Tags <p>As per the task of this example we need to create two prefixes in NetBox, one for the System IPs and one for the subnets used by our Fabric app to assign addresses on the point-to-point interswitch links.</p> <p>We will also create a tag for each of the prefixes, such that we can use the tags to identify each prefix in EDA's Allocation resource.</p> <p>Starting with the System IPs prefix, we first create a Tag using the Customization \u2192 Tags NetBox menu, we will name the tag simply <code>eda-systemip-v4</code>. Then create a prefix in IPAM \u2192 Prefixes NetBox menu and specify the <code>192.168.10.0/24</code> prefix with the Status=Active and assign the <code>eda-systemip-v4</code> tag to it.</p> <p>Next, we need to create a Prefix for our interswitch links. In EDA, the Fabric app uses the allocation pool of type \"subnet\" to then assign point-to-point addresses to each end of the interswitch link. This means, that the Prefix in NetBox would need to be created with the <code>Container</code> status, as this would indicate that the Prefix is a container for sub-prefixes. Exactly what we need.</p> <p>We create the <code>eda-isl-v6</code> tag first and then the Prefix <code>2005::/64</code> with the Status=Container and this tag assigned.</p> EDA configuration <p>Switching to EDA. Install the NetBox app if you haven't done already and proceed with creation of the NetBox Instance resource as per the documentation.</p> <p>We are using the names of the Kubernetes secrets we created a moment ago for the API Token and the Webhook signature key. And since we deployed the NetBox inside the same cluster, we know the DNS name of the service it uses.</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Instance\nmetadata:\n  name: netbox\n  namespace: eda\nspec:\n  url: http://netbox-server.netbox.svc.cluster.local\n  apiToken: netbox-api-token\n  signatureKey: netbox-webhook-signature\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Instance\nmetadata:\n  name: netbox\n  namespace: eda\nspec:\n  url: http://netbox-server.netbox.svc.cluster.local\n  apiToken: netbox-api-token\n  signatureKey: netbox-webhook-signature\nEOF\n</code></pre> <p>Shortly after submitting the instance resource, you should see EDA reporting the instance as reachable in the status field of the instance resource. Verify with:</p> <pre><code>kubectl get instance netbox -n eda \\\n-o custom-columns=\"URL:.spec.url,STATUS:.status.reachable\"\n</code></pre> <pre><code>URL                                             STATUS\nhttp://netbox-server.netbox.svc.cluster.local   true\n</code></pre> Allocations <p>Once the Instance resource is configured and the NetBox is reachable, you can proceed with creating the Allocation resources.</p> <p>As per our task, we need two Allocation Pools in EDA:</p> <ol> <li><code>IPAllocationPool</code> for the IPv4 addresses used as System IPs for our leaf and spines</li> <li><code>SubnetAllocationPool</code> for the subnets used for the interswitch links in our fabric.</li> </ol> <p>Instead of creating these pools manually, we will create two Allocation resources from the EDA NetBox app and let it create these pools for us based on the NetBox prefixes.</p> <p>Starting with the Allocation resource for the System IPs:</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-systemip-v4\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox\n  tags:\n    - eda-systemip-v4\n  type: ip-address\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-systemip-v4\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox\n  tags:\n    - eda-systemip-v4\n  type: ip-address\nEOF\n</code></pre> <p>The name of the Allocation resource (<code>nb-systemip-v4</code>) will drive the name of the EDA Allocation Pool name once NetBox app will get to create the pool based on the received webhook from the NetBox server.</p> <p>In the specification block of the Allocation resource we provide</p> <ul> <li>the name of the NetBox instance resource we just created</li> <li>the tags to match the received prefixes from the NetBox server and associate with this Allocation. Recall, that we created this tag in NetBox and added it to the Prefix we intend to use for the System IPs.</li> <li>the type of the allocation, which will drive the type of the EDA Allocation Pool. Since System IPs are plain IPv4 addresses, we choose <code>ip-address</code> type.</li> </ul> <p>Following the same approach, create the Allocation resource for the subnets used for the interswitch links:</p> YAML<code>kubectl</code> <pre><code>apiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-isl-v6\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox\n  subnetLength: 127\n  tags:\n    - eda-isl-v6\n  type: subnet\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: netbox.eda.nokia.com/v1alpha1\nkind: Allocation\nmetadata:\n  name: nb-isl-v6\n  namespace: eda\nspec:\n  enabled: true\n  instance: netbox\n  subnetLength: 127\n  tags:\n    - eda-isl-v6\n  type: subnet\nEOF\n</code></pre> <p>The difference between the two Allocation resources is the type of the allocation. Since subnets are CIDR blocks, we choose the <code>subnet</code> type and we also specify the <code>subnetLength</code> property to define the length of the subnet to allocate from the received prefix.</p> <p>Once you have the Allocation resources created, you should see the pools with the matching names created in EDA:</p> IP PoolSubnet Pool <pre><code>kubectl -n eda get ipallocationpool nb-systemip-v4\n</code></pre> <pre><code>NAME             AGE\nnb-systemip-v4   13h\n</code></pre> <pre><code>kubectl -n eda get subnetallocationpool nb-isl-v6\n</code></pre> <pre><code>NAME        AGE\nnb-isl-v6   13h\n</code></pre> Fabric <p>Next we create a fabric resource using the EDA Playground topology setup in this example. We reference the allocation pools our NetBox app created when it synced the prefixes:</p> YAML<code>kubectl</code> <pre><code>apiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: my-nb-ebgp-fabric\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    poolIPV6: nb-isl-v6\n  systemPoolIPV4: nb-systemip-v4\n  underlayProtocol:\n    bgp:\n      asnPool: asn-pool\n    protocol:\n      - EBGP\n  overlayProtocol:\n    protocol: EBGP\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: my-nb-ebgp-fabric\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    poolIPV6: nb-isl-v6\n  systemPoolIPV4: nb-systemip-v4\n  underlayProtocol:\n    bgp:\n      asnPool: asn-pool\n    protocol:\n      - EBGP\n  overlayProtocol:\n    protocol: EBGP\nEOF\n</code></pre> <p>The Fabric app will use the referenced pools and will try to allocated the pool resources in order to instantiate a fabric. In our example the System IP (v4) and Subnets (v6) will be allocated from the pools and the allocated resources will be populated back to the NetBox server to keep track of the allocated resources.</p> <p>From the Prefix we created for System IPs you will see the three allocated IPs populated back in NetBox server, one per each spine and leaf in our topology:</p> <p>In the same way, you will see interswitch subnets carved out from the <code>2005::/64</code> prefix, one per each link between leafs and spines:</p> Custom Fields <p>The NetBox app also creates some custom fields in NetBox model to backtrack the allocation of the resources. For example, if you select an allocated sub-prefix from the <code>2005::/64</code> prefix, you will see EDA custom fields that show the Allocation resource that created this allocation and the owner object that requested the allocation.</p> <p>The objects allocated by EDA will also have the <code>EDAManaged</code> tag assigned to them.</p> <ol> <li> <p>Based on NetBox Community v4.3.2-Docker-3.3.0 version and Helm chart v6.0.33.\u00a0\u21a9</p> </li> <li> <p>Or run a wait with:  </p> <p><pre><code>kubectl -n netbox wait --for=condition=available --timeout=300s \\\ndeployment/netbox-server\n</code></pre> \u21a9</p> </li> </ol>"},{"location":"apps/notifier/","title":"Notifier","text":"Description The Notifier app creates and delivers creates and delivers custom notifications from a variety of sources to multiple destinations. Author Nokia Supported OS SR Linux, SR OS Catalog nokia-eda/catalog Language Go Source Code coming soon"},{"location":"apps/notifier/#installation","title":"Installation","text":"<p>Notifier app can be installed using EDA Store or by running the app-installer workflow with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: notifier-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: notifier.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: notifier-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: notifier.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n\nEOF\n</code></pre>"},{"location":"apps/notifier/#configuration","title":"Configuration","text":"<p>After installing the app, you can configure your notification sources and destinations. You have the option to choose between two sources - Alarm or Query - and can send notifications to multiple destinations.</p> <p>Sources are defined using the Notifier or ClusterNotifier Custom Resources (CRs), while destinations<sup>1</sup> (referred to as Providers) are set up using the Provider or ClusterProvider CRs. You can mix and match sources, as well as send notifications to multiple destinations.</p> <p>The ClusterNotifier and ClusterProvider CRs are deployed in the eda-system namespace and provide system-wide notification capabilities across all EDA namespaces. In contrast, the regular Notifier and Provider CRs are namespace-scoped and can only generate notifications from alarms or queries within their own namespace.</p>"},{"location":"apps/notifier/#notification-source","title":"Notification source","text":""},{"location":"apps/notifier/#alarm","title":"Alarm","text":"<p>To configure the source of the notifications, you need to create a Notifier or ClusterNotifier CR. </p> <p>The example below shows a ClusterNotifier CR that genrates notifications based on any alarm across all namespaces and sends them to the referenced <code>discord</code> provider.</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterNotifier\nmetadata:\n  name: alarms-to-discord\n  namespace: eda-system\nspec:\n  description: \"Notifier for all alarms to Discord\"\n  enabled: true\n  sources:\n    alarms:\n      include:\n        - \"*\"\n  providers:\n    - discord\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterNotifier\nmetadata:\n  name: alarms-to-discord\n  namespace: eda-system\nspec:\n  description: \"Notifier for all alarms to Discord\"\n  enabled: true\n  sources:\n    alarms:\n      include:\n        - \"*\"\n  providers:\n    - discord\n\nEOF\n</code></pre> <p>You can filter which alarms trigger notifications by specifying their <code>type</code> in the include/exclude lists (for example, <code>InterfaceDown</code>, <code>TopoLinkDown</code>). For ClusterNotifier CRs, you can further refine the scope by specifying which namespaces to monitor.</p>"},{"location":"apps/notifier/#query","title":"Query","text":"<p>EQL queries can be used as a source for notifications. Users can specify the table, select relevant fields, and define conditions to trigger a notification. When the condition is met, a notification is generated and sent using the referenced providers.</p> <p>The notification format can be customized using two fields; <code>title</code> and <code>template</code>; both use Go templates.. These templates render based on a map that includes all selected fields and the keys returned by the table. The key names match the raw column names shown in the EDA UI query tool.</p> <p>For example, querying the table <code>.namespace.node.srl.interface</code> returns the keys:</p> <ul> <li><code>namespace.name</code></li> <li><code>namespace.node.name</code></li> <li><code>name</code> (this is the interface name)</li> <li>and any field that was explicitly requested under <code>fields</code>.</li> </ul> <p>The example below shows a ClusterNotifier CR that generates notifications whenever an interface operational state changes to <code>down</code> while its administrative state is <code>enable</code>.</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterNotifier\nmetadata:\n  name: interface-down-notifier\n  namespace: eda-system\nspec:\n  enabled: true\n  sources:\n    query:\n      table: .namespace.node.srl.interface\n      fields:\n        - admin-state\n        - oper-state\n        - .namespace.node.name\n      where: admin-state = \"enable\" and oper-state = \"down\"\n      title: Interface Down Alert\n      template: |\n        Namespace: {{ index . \"namespace.name\" }}.\n        Interface {{ index . \"name\"}} is DOWN on node {{ index . \"namespace.node.name\"}}.\n        (State admin/oper: {{ index . \"oper-state\" }}/{{ index . \"admin-state\"}})    \n  providers:\n    - discord\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterNotifier\nmetadata:\n  name: interface-down-notifier\n  namespace: eda-system\nspec:\n  enabled: true\n  sources:\n    query:\n      table: .namespace.node.srl.interface\n      fields:\n        - admin-state\n        - oper-state\n        - .namespace.node.name\n      where: admin-state = \"enable\" and oper-state = \"down\"\n      title: Interface Down Alert\n      template: |\n        Namespace: {{ index . \"namespace.name\" }}.\n        Interface {{ index . \"name\"}} is DOWN on node {{ index . \"namespace.node.name\"}}.\n        (State admin/oper: {{ index . \"oper-state\" }}/{{ index . \"admin-state\"}})    \n  providers:\n    - discord\n\nEOF\n</code></pre>"},{"location":"apps/notifier/#provider-reference","title":"Provider reference","text":"<p>The Notifier/ClusterNotifier CR references the notification destination(s) by name. In the examples above, the <code>discord</code> provider referenced in the ClusterNotifier CR is the name of the ClusterProvider CR that should exist in the <code>eda-system</code> namespace. When using namespace-scoped notifiers, both the Notifier and Provider CRs must be in the same namespace, for example <code>namespace: eda</code>.</p>"},{"location":"apps/notifier/#notification-destination","title":"Notification destination","text":"<p>Notifier supports multiple notification destinations (aka providers), and leverages the shoutrrr package to send notifications to the supported providers with a few provider using custom integrations. The full list of supported providers is available at the shouterrr docs.</p> <p>Notifier app knows which provider to use based on the <code>uri</code> field in the Provider or ClusterProvider CR.</p>"},{"location":"apps/notifier/#discord","title":"Discord","text":"<p>To send notifications to Discord a user needs to create a Discord webhook<sup>2</sup>. The webhook URL should look like this:</p> <pre><code>https://discord.com/api/webhooks/webhookid/token\n</code></pre> <p>Replace the <code>https://</code> scheme with <code>discord://</code></p> <pre><code>discord://discord.com/api/webhooks/webhookid/token\n</code></pre> <p>Now everything is ready for the ClusterProvider CR creation with the following configuration:</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: discord\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: discord://discord.com/api/webhooks/webhookid/token\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: discord\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: discord://discord.com/api/webhooks/webhookid/token\n\nEOF\n</code></pre> <p>The Discord username posting the notification can be customized using a query parameter <code>username</code> overwriting the default webhook bot name. For example : <code>discord://discord.com/api/webhooks/123456789/XXXXXXXXXXXXX?username=EDA</code></p> <p>The following example of a Discord notification shows two different TopoLink alarm states: a critical alarm when all members are down (red), and a major alarm when the link is in degraded state (green). Each notification includes detailed information about the resource, its state, and timing.</p> <p> </p> Discord alarm notifications"},{"location":"apps/notifier/#teams","title":"Teams","text":"<p>The <code>teams</code> provider allows users to send MS Teams notifications when events occur in the network or within EDA. The integration is done using Teams <code>Incoming Webhook Connector</code>, a guide can be found here<sup>3</sup>.</p> <p>Copy the generated webhook address and replace the <code>https://</code> scheme with <code>teams://</code> to configure the teams provider.</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: teams\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: teams://&lt;company&gt;.webhook.office.com/webhookb2/XXXXX\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: teams\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: teams://&lt;company&gt;.webhook.office.com/webhookb2/XXXXX\n\nEOF\n</code></pre> <p>The following example shows notifications from the EDA Notifier app to Teams that shows two consecutive messages: a TopoLinkDown alarm (critical severity, not cleared) indicating all members are down, followed by a TopoLinkDegraded alarm that has been cleared (major severity, cleared=true). Each notification provides structured information including namespace, resource details, severity level, and timestamp.</p> <p> </p> Teams alarm notifications"},{"location":"apps/notifier/#slack","title":"Slack","text":"<p>The <code>slack</code> provider allows users to send Slack notifications when events occur in the network or within EDA. The integration is done using Slack webhooks, you can find the guide here<sup>4</sup>.</p> <p>Copy the generated webhook address and replace the <code>https://</code> scheme with <code>slack://</code> to configure the slack provider.</p> <p>The Slack channel where the notification must be posted as well as the username posting it can optionally be customized using a query parameters <code>channel</code> and <code>username</code> overwriting the default webhook name and destination channel. For example : <code>slack://hooks.slack.com/services/XXXXX/YYYYYY/ZZZZZZ?username=EDA&amp;channel=alerts</code></p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: slack\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: slack://hooks.slack.com/services/ABC/DEF/GHI\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: slack\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: slack://hooks.slack.com/services/ABC/DEF/GHI\n\nEOF\n</code></pre> <p>The following example of a Slack notification shows two consecutive messages: a TopoLinkDown alarm (critical severity, red icon) indicating all members are down, followed by a TopoLinkDegraded alarm that has been cleared (major severity with green checkmark, cleared=true). Both messages provide detailed information including namespace, resource name, group, severity, and timestamp.</p> <p> </p> Slack alarm notifications"},{"location":"apps/notifier/#email","title":"Email","text":"<p>The <code>email</code> provider allows users to send notifications as emails when events occur in the network or within EDA. Notifier sends an email given an SMTP address and some additional parameters:</p> <p>The SMTP address must start with <code>smtp://</code>. If a username and password are required, they must be part of the URI authority field <code>smtp://$user:$password@host</code> Additional query parameters can be added to the URI:</p> <ul> <li><code>from</code>     : The sender email address</li> <li><code>to</code>       : The recipient email address</li> <li><code>startTLS</code> : <code>yes | no</code>, if set to <code>yes</code> the connection to the SMTP server must use TLS.</li> <li><code>useHTML</code>  : <code>yes | no</code>, if set to <code>yes</code> the email content type will be set to \"text/html; charset=UTF-8\" otherwise \"text/plain; charset=UTF-8\"</li> </ul> <p>Example <code>email</code> ClusterProvider CR:</p> YAMLApply with <code>kubectl</code> <pre><code>apiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: email\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: smtp://$user:$password@smtp.example.com?from=eda@nokia.com&amp;to=noc@customer.com&amp;startTLS=yes\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: notifiers.eda.nokia.com/v1\nkind: ClusterProvider\nmetadata:\n  name: email\n  namespace: eda-system\nspec:\n  enabled: true\n  uri: smtp://$user:$password@smtp.example.com?from=eda@nokia.com&amp;to=noc@customer.com&amp;startTLS=yes\n\nEOF\n</code></pre> <ol> <li> <p>The full list of supported destinations/providers is available here.\u00a0\u21a9</p> </li> <li> <p>Refer to the Discord docs for more information on how to create a Discord webhook.\u00a0\u21a9</p> </li> <li> <p>Teams incoming webhook integration.\u00a0\u21a9</p> </li> <li> <p>Slack webhooks guide \u21a9</p> </li> </ol>"},{"location":"apps/prometheus-exporter/","title":"Prometheus Exporter","text":"Description Prometheus Exporter exposes EDA and network metrics to be scraped by a Prometheus server. Author Nokia Supported OS SR Linux, SR OS Catalog nokia-eda/catalog Language Go Source Code coming soon"},{"location":"apps/prometheus-exporter/#installation","title":"Installation","text":"<p>The Prometheus exporter app can be installed using EDA Store or by running the <code>app-install</code> workflow with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: prom-exporter-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: prom.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: prom-exporter-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: prom.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v4.0.0\n\nEOF\n</code></pre>"},{"location":"apps/prometheus-exporter/#configuration","title":"Configuration","text":"<p>After installing the app you can configure the metrics you wish to be exported by defining an EDB path (also referred to as <code>jsPath</code>) and, optionally, a <code>fields</code> list and a <code>where</code> EQL statement. You can check what is returned by the path using the EDA Query UI or <code>edactl</code>.</p> <p>At every scrape request the app will retrieve the configured paths and fields and automatically generate the metric name, its labels and its value based on the path, fields and values received back from EDA.</p> <p>If your use case requires additional customizations, the app supports:</p> <ul> <li>Renaming metric names using regex and replacement patterns.</li> <li>Adding static or dynamic labels to metrics.</li> <li>Mapping non-numeric values to Prometheus-compatible numeric values.</li> </ul> <p>Scrape requests from Prometheus must be directed to the URL <code>https://EDA_API_ADDRESS/core/httpproxy/v1/prometheus-exporter/metrics</code>.</p>"},{"location":"apps/prometheus-exporter/#export-custom-resource","title":"Export Custom Resource","text":"<p>The app is configured using an <code>Export</code> Custom Resource (CR) from the <code>prom.eda.nokia.com</code> API group that groups a list of <code>exports</code> together.</p> <p>Each <code>export</code> definition includes:</p> <ul> <li>Path<sup>Required</sup>: The EDB path to export, e.g., <code>.namespace.node.srl.interface.statistics</code>.</li> <li>Fields: A list of fields to expose as part of the metric. If not defined all fields under the configured <code>path</code> are exposed.</li> <li>Where: A filter clause for querying, e.g., <code>oper-state = down</code> or <code>.interface.name != \"mgmt0\"</code>.</li> <li>Prefix: A prefix to prepend to all metrics exposed by this definition.</li> <li>Metric Name: Customization of metric names using regex and replacements.</li> <li>Labels: Static or dynamic labels to add to metrics.</li> <li>Mappings: Rules to map non-numeric values to numeric equivalents.</li> </ul> <p>Here is an example of a Prometheus exporter custom resource:</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: replaced-metrics\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      metricName:\n        regex: namespace_node_srl_(\\w+)_statistics_(\\w+)\n        replacement: \"${1}_${2}\"\n</code></pre>"},{"location":"apps/prometheus-exporter/#metric-customization","title":"Metric customization","text":"<p>The resulting Prometheus metrics are autogenerated based on the returned paths, fields and values. A metric is composed of the following parts:</p> <ul> <li>Name</li> <li>Labels</li> <li>Value</li> </ul>"},{"location":"apps/prometheus-exporter/#name","title":"Name","text":"<p>Metric names are derived from the provided jsPath and fields. For example:</p> <ul> <li>jsPath: <code>.namespace.node.srl.interface.statistics</code></li> <li>Field: <code>out-octets</code></li> </ul> <p>The resulting metric name will be generated by following this process:</p> <ol> <li> <p>Strip the leading <code>.</code> (period) from the jsPath.</p> </li> <li> <p>Remove all keys from the jsPath.</p> </li> <li> <p>Replace all <code>.</code> (period) with an <code>_</code> (underscore) in the jsPath</p> </li> <li> <p>Replace every <code>-</code> (hyphen) with <code>_</code> (underscore) in the jsPath and field name</p> </li> <li> <p>Join the resulting jsPath and field name with and <code>_</code> (underscore)</p> </li> </ol> <p>Example</p> <p>Given the path <code>.namespace.node.srl.interface.statistics</code> and field <code>out-octets</code>, the resulting metric name is: <code>namespace_node_srl_interface_statistics_out_octets</code>.</p>"},{"location":"apps/prometheus-exporter/#customization","title":"Customization","text":"<p>Metric names can be customized to suit user needs in a simple or advanced way.</p>"},{"location":"apps/prometheus-exporter/#simple","title":"Simple","text":"<p>Use the <code>prefix</code> field in the CR to add a prefix to all metric names.</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: prefixed-metrics\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      prefix: eda\n</code></pre> <p>The above configuration produces metrics starting with <code>eda_</code> prefix. For example, the metric <code>namespace_node_srl_interface_statistics_out_octets</code> becomes: <code>eda_namespace_node_srl_interface_statistics_out_octets</code>.</p>"},{"location":"apps/prometheus-exporter/#advanced","title":"Advanced","text":"<p>Use the <code>metricName</code> field to apply regex-based transformations which has two components:</p> <ul> <li>Regex: Defines the pattern to match in the metric name.</li> <li>Replacement: Defines how the matched pattern should be replaced.</li> </ul> <p>For example, if the metric name <code>namespace_node_srl_interface_statistics_out_octets</code> is too long, you can shorten it to <code>interface_out_octets</code>:</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: replaced-metrics\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      metricName:\n        regex: namespace_node_srl_(\\w+)_statistics_(\\w+)\n        replacement: \"${1}_${2}\"\n</code></pre>"},{"location":"apps/prometheus-exporter/#labels","title":"Labels","text":"<p>Labels add context and categorization to metrics. They are generated automatically from the jsPath keys and their values. For each key in the jsPath, a label name is a created using the path element name and the key name joined using an <code>_</code>.</p> <p>Example</p> <p>Given the jsPath: <code>.namespace{.name==\"eda\"}.node.srl{.name==\"dut1\"}.interface{.name==\"ethernet-1/1\"}.statistics</code></p> <p>The resulting labels would be: <code>namespace_name=\"eda\", node_name=\"dut1\", interface_name=\"ethernet-1/1\"</code></p> <p>In addition to <code>jsPath</code>-based labels, two types of additional labels can be defined:</p>"},{"location":"apps/prometheus-exporter/#static-labels","title":"Static Labels","text":"<p>Predefined name-value pairs that are the same for all metrics in an export. The CR in the example below will result in metrics with 2 additional labels <code>env=prod</code> and <code>region=us-west-1</code> added:</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: static-labels-metric\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      labels:\n        static:\n          - name: env\n            value: prod\n          - name: region\n            value: us-west-1\n</code></pre>"},{"location":"apps/prometheus-exporter/#dynamic-labels","title":"Dynamic Labels","text":"<p>Labels generated based on data from a specific <code>path</code> (EDB path/jsPath) and <code>field</code>, with optional regex transformations. Example:</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: dynamic-labels-metric\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n      labels:\n        dynamic:\n          - path: .namespace.node.srl.interface\n            field: description\n          - path: .namespace.node.srl.platform.chassis\n            field: type\n</code></pre> <p>The above example generates metrics based on the given path and adds 2 labels:</p> <ol> <li>the interface description for which the metric is exposed</li> <li>node's chassis type</li> </ol>"},{"location":"apps/prometheus-exporter/#values","title":"Values","text":"<p>Metric values are derived directly from the data at the specified <code>path</code> and <code>field</code>. If the raw value is not a numeric type that Prometheus can ingest, mappings are required to convert the value.</p> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: mapped-values-metric\n  namespace: eda-system\nspec:\n  exports:\n    - path: .namespace.node.srl.interface\n      fields:\n        - admin-state\n        - oper-state\n      mappings:\n        - source: \"up\"\n          destination: \"2\"\n        - source: \"down\"\n          destination: \"1\"\n        - source: \"enable\"\n          destination: \"2\"\n        - source: \"disable\"\n          destination: \"1\"\n</code></pre> <p>The above Export maps non-numeric values from the fields into numeric values that can be ingested by Prometheus. The mapping rules are:</p> <ul> <li>up \u2192 2</li> <li>down \u2192 1</li> <li>enable \u2192 2</li> <li>disable \u2192 1</li> </ul>"},{"location":"apps/prometheus-exporter/#metrics-grouping","title":"Metrics grouping","text":"<p>Metrics grouping in the Prometheus exporter allows for efficient organization and selective scraping of metrics by Prometheus. Here's how it works:</p> <p>By default, Prometheus scrapes all exported metrics from the endpoint: <code>https://EDA_API_ADDRESS/core/httpproxy/v1/prometheus-exporter/metrics</code> This endpoint aggregates metrics from all <code>Export</code> CRs defined in the system.</p>"},{"location":"apps/prometheus-exporter/#group-specific-metrics-scraping","title":"Group-Specific Metrics Scraping","text":"<p>To provide more control over which metrics are scraped, you can assign CRs to specific groups. When a <code>group</code> is specified in the CR, Prometheus can scrape only the metrics belonging to that group using a targeted endpoint: <code>https://EDA_API_ADDRESS/core/httpproxy/v1/prometheus-exporter/metrics/{group}</code></p> <p>Where <code>{group}</code> is the name of the group specified in the CR.</p> <p>Groups are defined in the <code>spec.group</code> field of an <code>Export</code> CR. For example:</p> YAML<code>kubectl</code> <pre><code>apiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: metrics-grouping\n  namespace: eda-system\nspec:\n  group: group1\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: prom.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: metrics-grouping\n  namespace: eda-system\nspec:\n  group: group1\n  exports:\n    - path: .namespace.node.srl.interface.statistics\n\nEOF\n</code></pre>"},{"location":"apps/prometheus-exporter/#use-cases-for-grouping","title":"Use Cases for Grouping","text":"<ol> <li> <p>Selective Scraping: If you want Prometheus to scrape only specific metrics (e.g., metrics related to networking or storage), you can group the relevant CRs and use the group-specific endpoint.</p> </li> <li> <p>Performance Optimization: By grouping metrics, you can reduce the load on the Prometheus server and the exporter by scraping only the necessary data.</p> </li> <li> <p>Access Control: Different teams or systems can be assigned specific groups, ensuring each team accesses its relevant metrics.</p> </li> </ol>"},{"location":"apps/prometheus-exporter/#usage-examples","title":"Usage Examples","text":"<p>Check out EDA Telemetry demo lab for Prometheus exporter usage examples.</p>"},{"location":"apps/protocols/","title":"Protocols","text":"Description The Protocols application manages BGP, static, and aggregate route resources to automatically generate routing configurations for network nodes in both default and custom VRFs. Supported OS SR Linux, SR OS Catalog nokia-eda/catalog / manifest Source Code coming soon <p>The Protocols application enables users to create and manage various routing protocols in EDA and contains resources that are split between Overlay and Default routing categories. These two categories define the deployment model for the resource.</p> <p>Resources from the Default Routing category will be used in the network element's default VRF, whereas resources listed under the Overlay Routing category designed to be associated with a custom, non-default VRF.</p> <p>The application provides the following components:</p> Resource TypesDashboards <p> DEFAULT ROUTING</p> <ul> <li>Default BGP Groups</li> <li>Default BGP Peers</li> <li>Default Static Routes</li> <li>Default Aggregate Routes</li> <li>Default Route Reflectors</li> <li>Default Route Reflector Clients</li> </ul> <p> OVERLAY ROUTING</p> <ul> <li>BGP Groups</li> <li>BGP Peers</li> <li>Static Routes</li> <li>Aggregate Routes</li> <li>Route Reflectors</li> <li>Route Reflector Clients</li> </ul> <p>Summary dashboards for the following resource types:</p> <ul> <li>Default BGP Peers</li> <li>Default BGP Groups</li> <li>Default Route Reflectors</li> <li>Default Route Reflector Clients</li> </ul>"},{"location":"apps/protocols/#border-gateway-protocol-bgp","title":"Border Gateway Protocol (BGP)","text":"<p>BGP configuration in the Protocols application supports both default VRF and custom VRF deployments, with comprehensive features for peer management, route reflection, and policy control.</p>"},{"location":"apps/protocols/#configuration-types","title":"Configuration Types","text":"<p>The application supports two primary BGP deployment models:</p> <ul> <li>Default BGP: Configuration in the default VRF using <code>DefaultBGPPeer</code> and <code>DefaultBGPGroup</code> custom resources (CRs).</li> <li>Custom VRF BGP: Configuration in custom IP-VRFs using <code>BGPPeer</code> and <code>BGPGroup</code> CRs.</li> </ul>"},{"location":"apps/protocols/#bgp-groups","title":"BGP Groups","text":"<p>BGP Groups enable centralized management of peer configurations, ensuring consistent policy application across multiple peers.</p> <p>Because a BGP group in the default VRF and custom VRF usually have different configuration options and represent different groups, two BGP groups resource types are offered - <code>DefaultBGPGroup</code> and <code>BGPGroup</code>.</p>"},{"location":"apps/protocols/#default-bgp-group-configuration","title":"Default BGP Group Configuration","text":"<p> DEFAULT ROUTING  \u2192 DGDefault BGP Group</p> YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultBGPGroup\nmetadata:\n  name: example-default-group\n  namespace: eda\nspec:\n  description: \"Default VRF BGP group\"\n  localAS:\n    autonomousSystem: 65001\n  timers:\n    holdTime: 90\n    keepAlive: 30\n  ipv4Unicast:\n    enabled: true\n    maxReceivedRoutes: 1000\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultBGPGroup\nmetadata:\n  name: example-default-group\n  namespace: eda\nspec:\n  description: \"Default VRF BGP group\"\n  localAS:\n    autonomousSystem: 65001\n  timers:\n    holdTime: 90\n    keepAlive: 30\n  ipv4Unicast:\n    enabled: true\n    maxReceivedRoutes: 1000\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-bgp-group-configuration","title":"Custom VRF BGP Group Configuration","text":"<p> OVERLAY ROUTING \u2192 BGBGP Group</p> YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: BGPGroup\nmetadata:\n  name: example-custom-group\n  namespace: eda\nspec:\n  description: \"Custom VRF BGP group\"\n  localAS:\n    autonomousSystem: 65002\n  timers:\n    holdTime: 90\n    keepAlive: 30\n  ipv4Unicast:\n    enabled: true\n    maxReceivedRoutes: 1000\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: BGPGroup\nmetadata:\n  name: example-custom-group\n  namespace: eda\nspec:\n  description: \"Custom VRF BGP group\"\n  localAS:\n    autonomousSystem: 65002\n  timers:\n    holdTime: 90\n    keepAlive: 30\n  ipv4Unicast:\n    enabled: true\n    maxReceivedRoutes: 1000\nEOF\n</code></pre>"},{"location":"apps/protocols/#bgp-peers","title":"BGP Peers","text":"<p>BGP peers represent individual BGP sessions and can inherit configurations from BGP groups. The Protocols application supports both explicit peer configuration and dynamic neighbor discovery.  Selecting an interface will bind the session to the Toponode on which the Interface is deployed.  The interface can be a DefaultInterface (interface in the default VRF) or a SystemInterface (primary loopback in the default VRF).</p>"},{"location":"apps/protocols/#default-bgp-peer-configuration","title":"Default BGP Peer Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultBGPPeer\nmetadata:\n  name: example-default-peer\n  namespace: eda\nspec:\n  description: \"Default VRF BGP peer\"\n  group: \"example-default-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  peerAS:\n    autonomousSystem: 65100\n  peerIP: \"192.168.1.1\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultBGPPeer\nmetadata:\n  name: example-default-peer\n  namespace: eda\nspec:\n  description: \"Default VRF BGP peer\"\n  group: \"example-default-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  peerAS:\n    autonomousSystem: 65100\n  peerIP: \"192.168.1.1\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-bgp-peer-configuration","title":"Custom VRF BGP Peer Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: BGPPeer\nmetadata:\n  name: example-custom-peer\n  namespace: eda\nspec:\n  description: \"Custom VRF BGP peer\"\n  group: \"example-custom-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  peerAS:\n    autonomousSystem: 65200\n  peerIP: \"192.168.2.1\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: BGPPeer\nmetadata:\n  name: example-custom-peer\n  namespace: eda\nspec:\n  description: \"Custom VRF BGP peer\"\n  group: \"example-custom-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  peerAS:\n    autonomousSystem: 65200\n  peerIP: \"192.168.2.1\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#address-family-support","title":"Address Family Support","text":"<p>The Protocols application provides comprehensive support for multiple BGP address families including, but not limited to:</p>"},{"location":"apps/protocols/#ipv4-unicast","title":"IPv4 Unicast","text":"<ul> <li>Enable/disable IPv4 unicast routing</li> <li>Support for IPv6 next-hops (RFC 5549)</li> <li>Configurable maximum route limits</li> <li>Next-hop self options</li> <li>Independent policy control</li> </ul>"},{"location":"apps/protocols/#ipv6-unicast","title":"IPv6 Unicast","text":"<ul> <li>Enable/disable IPv6 unicast routing</li> <li>Configurable maximum route limits</li> <li>Independent policy control</li> </ul>"},{"location":"apps/protocols/#l2vpn-evpn","title":"L2VPN EVPN","text":"<ul> <li>Enable/disable EVPN</li> <li>Support for IPv6 next-hops</li> <li>Configurable maximum route limits</li> <li>Integration with overlay services</li> </ul>"},{"location":"apps/protocols/#route-reflection","title":"Route Reflection","text":"<p>Route reflection enables scalable iBGP deployments by eliminating the need for a full mesh of iBGP sessions. The Protocols application supports route reflection in both default and custom VRFs.</p> <p>The router reflector resources can select the clients to connect to using a label selector. The label selector will select RouteReflectorClient or DefaultRouteReflectorClient resources; if the clients are not EDA resources, you may specify a list of client IPs to which the the route reflector will attempt to establish a session.</p>"},{"location":"apps/protocols/#configuration-types_1","title":"Configuration Types","text":"<ul> <li>Default VRF: Using <code>DefaultRouteReflector</code> and <code>DefaultRouteReflectorClient</code>.</li> <li>Custom VRF: Using <code>RouteReflector</code> and <code>RouteReflectorClient</code>.</li> </ul>"},{"location":"apps/protocols/#route-reflector-configuration","title":"Route Reflector Configuration","text":""},{"location":"apps/protocols/#default-vrf-example","title":"Default VRF Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultRouteReflector\nmetadata:\n  name: example-default-rr\n  namespace: eda\nspec:\n  description: \"Default VRF Route Reflector\"\n  clusterID: \"1.1.1.1\"\n  defaultBGPRRGroup: \"rr-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  clientSelector:\n    - \"role=leaf\"\n  clientIPs:\n    - \"192.168.1.1\"\n    - \"192.168.1.2\"\n  ipv4Unicast:\n    enabled: true\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultRouteReflector\nmetadata:\n  name: example-default-rr\n  namespace: eda\nspec:\n  description: \"Default VRF Route Reflector\"\n  clusterID: \"1.1.1.1\"\n  defaultBGPRRGroup: \"rr-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  clientSelector:\n    - \"role=leaf\"\n  clientIPs:\n    - \"192.168.1.1\"\n    - \"192.168.1.2\"\n  ipv4Unicast:\n    enabled: true\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-route-reflector-example","title":"Custom VRF Route Reflector Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: RouteReflector\nmetadata:\n  name: example-custom-rr\n  namespace: eda\nspec:\n  clusterID: \"2.2.2.2\"\n  bgpGroup: \"custom-rr-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  ipv4ClientSelector:\n    - \"role=customer-edge\"\n  ipv6ClientSelector:\n    - \"role=customer-edge\"\n  clientIPs:\n    - \"172.16.1.1\"\n    - \"172.16.1.2\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: RouteReflector\nmetadata:\n  name: example-custom-rr\n  namespace: eda\nspec:\n  clusterID: \"2.2.2.2\"\n  bgpGroup: \"custom-rr-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  ipv4ClientSelector:\n    - \"role=customer-edge\"\n  ipv6ClientSelector:\n    - \"role=customer-edge\"\n  clientIPs:\n    - \"172.16.1.1\"\n    - \"172.16.1.2\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#route-reflector-client-configuration","title":"Route Reflector Client Configuration","text":"<p>Route reflector clients establish sessions with route reflectors based on selectors or explicit IP addresses.  The label selector will select DefaultRouteReflector or RouteReflector resources, or a list of IP addresses can be provided which the router relctor client will try to establish a session to.</p>"},{"location":"apps/protocols/#default-vrf-client-example","title":"Default VRF Client Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultRouteReflectorClient\nmetadata:\n  name: example-default-rr-client\n  namespace: eda\nspec:\n  defaultBgpClientGroup: \"client-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  routeReflectorSelector:\n    - \"role=spine\"\n  routeReflectorIPs:\n    - \"192.168.0.1\"\n    - \"192.168.0.2\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultRouteReflectorClient\nmetadata:\n  name: example-default-rr-client\n  namespace: eda\nspec:\n  defaultBgpClientGroup: \"client-group\"\n  interface: \"system\"\n  interfaceKind: \"SYSTEMINTERFACE\"\n  routeReflectorSelector:\n    - \"role=spine\"\n  routeReflectorIPs:\n    - \"192.168.0.1\"\n    - \"192.168.0.2\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-client-example","title":"Custom VRF Client Example","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: RouteReflectorClient\nmetadata:\n  name: example-custom-rr-client\n  namespace: eda\nspec:\n  bgpGroup: \"custom-client-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  ipv4RouteReflectorSelector:\n    - \"role=provider-edge\"\n  ipv6RouteReflectorSelector:\n    - \"role=provider-edge\"\n  routeReflectorIPs:\n    - \"172.16.0.1\"\n    - \"172.16.0.2\"\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: RouteReflectorClient\nmetadata:\n  name: example-custom-rr-client\n  namespace: eda\nspec:\n  bgpGroup: \"custom-client-group\"\n  interface: \"customer-1\"\n  interfaceKind: \"ROUTEDINTERFACE\"\n  ipv4RouteReflectorSelector:\n    - \"role=provider-edge\"\n  ipv6RouteReflectorSelector:\n    - \"role=provider-edge\"\n  routeReflectorIPs:\n    - \"172.16.0.1\"\n    - \"172.16.0.2\"\nEOF\n</code></pre>"},{"location":"apps/protocols/#static-routes","title":"Static Routes","text":"<p>Static routes provide explicit path control for network traffic.</p>"},{"location":"apps/protocols/#configuration-types_2","title":"Configuration Types","text":"<p>The application supports two types of static route deployments:</p> <ul> <li>Default Static Routes: Configuration in the default VRF using a <code>DefaultStaticRoute</code> resource.</li> <li>Custom VRF Static Routes: Configuration in custom VRFs using a <code>StaticRoute</code> resource.</li> </ul>"},{"location":"apps/protocols/#default-vrf-static-route-configuration","title":"Default VRF Static Route Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultStaticRoute\nmetadata:\n  name: example-default-static\n  namespace: eda\nspec:\n  defaultRouter: \"default-router\"\n  prefixes:\n    - \"192.168.0.0/24\"\n    - \"172.16.0.0/24\"\n  preference: 5\n  nexthopGroup:\n    nexthops:\n      - ipPrefix: \"10.0.0.1\"\n      - ipPrefix: \"10.0.0.2\"\n    resolve: true\n    bfd:\n      enabled: true\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultStaticRoute\nmetadata:\n  name: example-default-static\n  namespace: eda\nspec:\n  defaultRouter: \"default-router\"\n  prefixes:\n    - \"192.168.0.0/24\"\n    - \"172.16.0.0/24\"\n  preference: 5\n  nexthopGroup:\n    nexthops:\n      - ipPrefix: \"10.0.0.1\"\n      - ipPrefix: \"10.0.0.2\"\n    resolve: true\n    bfd:\n      enabled: true\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-static-route-configuration","title":"Custom VRF Static Route Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: StaticRoute\nmetadata:\n  name: example-custom-static\n  namespace: eda\nspec:\n  router: \"customer-router\"\n  prefixes:\n    - \"192.168.1.0/24\"\n    - \"192.168.2.0/24\"\n  preference: 10\n  nodes:\n    - \"node1\"\n    - \"node2\"\n  nexthopGroup:\n    nexthops:\n      - ipPrefix: \"10.1.0.1\"\n        bfd:\n          enabled: true\n      - ipPrefix: \"10.1.0.2\"\n    resolve: true\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: StaticRoute\nmetadata:\n  name: example-custom-static\n  namespace: eda\nspec:\n  router: \"customer-router\"\n  prefixes:\n    - \"192.168.1.0/24\"\n    - \"192.168.2.0/24\"\n  preference: 10\n  nodes:\n    - \"node1\"\n    - \"node2\"\n  nexthopGroup:\n    nexthops:\n      - ipPrefix: \"10.1.0.1\"\n        bfd:\n          enabled: true\n      - ipPrefix: \"10.1.0.2\"\n    resolve: true\nEOF\n</code></pre>"},{"location":"apps/protocols/#route-aggregation","title":"Route Aggregation","text":"<p>Route aggregation enables efficient route summarization and management.</p>"},{"location":"apps/protocols/#configuration-types_3","title":"Configuration Types","text":"<p>The application supports two types of route aggregation:</p> <ul> <li>Default Aggregate Routes: Configuration in the default VRF using a <code>DefaultAggregateRoute</code> resource.</li> <li>Custom VRF Aggregate Routes: Configuration in custom VRFs using an <code>AggregateRoute</code> resource.</li> </ul>"},{"location":"apps/protocols/#default-vrf-aggregate-route-configuration","title":"Default VRF Aggregate Route Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultAggregateRoute\nmetadata:\n  name: example-default-aggregate\n  namespace: eda\nspec:\n  defaultRouter: \"default-router\"\n  prefixes:\n    - \"192.168.0.0/16\"\n    - \"172.16.0.0/12\"\n  aggregatorIP: \"10.0.0.1\"\n  aggregatorASN: 65001\n  summaryOnly: true\n  generateICMP: false\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: DefaultAggregateRoute\nmetadata:\n  name: example-default-aggregate\n  namespace: eda\nspec:\n  defaultRouter: \"default-router\"\n  prefixes:\n    - \"192.168.0.0/16\"\n    - \"172.16.0.0/12\"\n  aggregatorIP: \"10.0.0.1\"\n  aggregatorASN: 65001\n  summaryOnly: true\n  generateICMP: false\nEOF\n</code></pre>"},{"location":"apps/protocols/#custom-vrf-aggregate-route-configuration","title":"Custom VRF Aggregate Route Configuration","text":"YAML<code>kubectl</code> <pre><code>apiVersion: protocols.eda.nokia.com/v1alpha1\nkind: AggregateRoute\nmetadata:\n  name: example-custom-aggregate\n  namespace: eda\nspec:\n  router: \"customer-router\"\n  prefixes:\n    - \"192.168.1.0/24\"\n    - \"192.168.2.0/24\"\n  aggregatorIP: \"10.0.0.2\"\n  aggregatorASN: 65002\n  nodes:\n    - \"node1\"\n    - \"node2\"\n  summaryOnly: true\n  generateICMP: false\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: protocols.eda.nokia.com/v1alpha1\nkind: AggregateRoute\nmetadata:\n  name: example-custom-aggregate\n  namespace: eda\nspec:\n  router: \"customer-router\"\n  prefixes:\n    - \"192.168.1.0/24\"\n    - \"192.168.2.0/24\"\n  aggregatorIP: \"10.0.0.2\"\n  aggregatorASN: 65002\n  nodes:\n    - \"node1\"\n    - \"node2\"\n  summaryOnly: true\n  generateICMP: false\nEOF\n</code></pre>"},{"location":"apps/protocols/#operational-state-and-verification","title":"Operational State and Verification","text":""},{"location":"apps/protocols/#bgp-status","title":"BGP Status","text":"<pre><code># Check BGP peer status\nkubectl get bgppeers\nNAME         SESSION STATE   LAST CHANGE   ENABLED   OPERATIONAL STATE   PEER AS\nexample-peer Established    10m           true      up                  65100\n\n# Check BGP group status\nkubectl get bgpgroups\nNAME          LAST CHANGE   OPERATIONAL STATE\nexample-group 10m          up\n\n# Check route reflector status\nkubectl get routereflectors\nNAME    LAST CHANGE   OPERATIONAL STATE   NUM RR BGP PEERS   NUM RR BGP PEERS DOWN\nrr-1    10m          up                  4                  0\n</code></pre>"},{"location":"apps/protocols/#static-route-status","title":"Static Route Status","text":"<pre><code># Check static route status\nkubectl get staticroutes\nNAME          LAST CHANGE   OPERATIONAL STATE   HEALTH\ncustom-route  10m          up                  100\n</code></pre>"},{"location":"apps/protocols/#aggregate-route-status","title":"Aggregate Route Status","text":"<pre><code># Check aggregate route status\nkubectl get aggregateroutes\nNAME             LAST CHANGE   OPERATIONAL STATE   HEALTH\ncustomer-summary 10m          up                  100\n</code></pre>"},{"location":"apps/remote-write/","title":"Remote Write","text":"Description The Remote Write app exports metrics to servers adhering to Prometheus Remote-Write Specifications Author Nokia Supported OS N/A Catalog nokia-eda/catalog Source Code coming soon"},{"location":"apps/remote-write/#overview","title":"Overview","text":"<p>The Remote Write app enables exporting network and EDA metrics to remote Prometheus-compatible servers using the Remote-Write specification v1.0. The app provides resources to define the metrics to export and the destinations to send them to.</p> <p>Application components:</p> Resources <p> REMOTEWRITE</p> <ul> <li>Cluster Destinations</li> <li>Cluster Exporters</li> <li>Destinations</li> <li>Exporters</li> </ul>"},{"location":"apps/remote-write/#installation","title":"Installation","text":"<p>Notifier app can be installed using EDA Store or by running the app-installer workflow with <code>kubectl</code>:</p> YAML<code>kubectl</code> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: remote-write-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: remotewrite.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v2.0.0\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: remote-write-install\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: remotewrite.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        value: v2.0.0\n\nEOF\n</code></pre>"},{"location":"apps/remote-write/#getting-started","title":"Getting Started","text":"<p>After installing the app, you can configure:</p> <ul> <li>Export and ClusterExport: Define metrics to collect (with filtering, mapping, renaming, labels, etc.).</li> <li>Destination and ClusterDestination: Define remote write endpoints (with TLS, authentication, and buffering).</li> </ul>"},{"location":"apps/remote-write/#example-resources","title":"Example Resources","text":""},{"location":"apps/remote-write/#destination","title":"Destination","text":"<p>Defines a remote server to which metrics are written. Supports optional TLS, authentication, custom headers, retries, and timeouts.</p> YAML<code>kubectl</code> <pre><code>apiVersion: remotewrite.eda.nokia.com/v1alpha1\nkind: Destination\nmetadata:\n  name: dest1\n  namespace: eda\nspec:\n  url: 'http://prw.example.com:9090/api/v1/write'\n  writeOptions:\n    bufferSize: 100           # Number of metrics before sending\n    flushInterval: 60s        # Time interval for sending buffered data\n    maxRetries: 3             # Retry attempts on failure\n    timeout: 10s              # Client write timeout\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: remotewrite.eda.nokia.com/v1alpha1\nkind: Destination\nmetadata:\n  name: dest1\n  namespace: eda\nspec:\n  url: 'http://prw.example.com:9090/api/v1/write'\n  writeOptions:\n    bufferSize: 100           # Number of metrics before sending\n    flushInterval: 60s        # Time interval for sending buffered data\n    maxRetries: 3             # Retry attempts on failure\n    timeout: 10s              # Client write timeout\nEOF\n</code></pre>"},{"location":"apps/remote-write/#export-interfaces-statistics","title":"Export: Interfaces Statistics","text":"<p>Defines what metrics to export and to which destinations. Metrics are retrieved from the state DB at the given <code>path</code> and can include optional filtering, labeling, and transformation.</p> YAML<code>kubectl</code> <pre><code>apiVersion: remotewrite.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: interface-stats\n  namespace: eda\nspec:\n  exports:\n    - prefix: interfaces\n      path: .namespace.node.srl.interface.statistics # EQL path\n      interval: 30s                                  # Optional polling interval\n      mode: periodic                                 # periodic | on-change | periodic-on-change\n      fields: [\"in-octets\", \"out-octets\"]            # Optional subset of fields\n      labels:\n        static:\n          - name: region\n            value: us-west\n  destinations:\n    - name: dest1\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: remotewrite.eda.nokia.com/v1alpha1\nkind: Export\nmetadata:\n  name: interface-stats\n  namespace: eda\nspec:\n  exports:\n    - prefix: interfaces\n      path: .namespace.node.srl.interface.statistics # EQL path\n      interval: 30s                                  # Optional polling interval\n      mode: periodic                                 # periodic | on-change | periodic-on-change\n      fields: [\"in-octets\", \"out-octets\"]            # Optional subset of fields\n      labels:\n        static:\n          - name: region\n            value: us-west\n  destinations:\n    - name: dest1\n\nEOF\n</code></pre>"},{"location":"apps/remote-write/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"apps/remote-write/#destination-resource-options","title":"Destination Resource Options","text":"<ul> <li>authentication: <code>username</code>/<code>password</code> for basic auth.</li> <li>authorization: <code>type</code> (for example, Bearer) and token-based credentials.</li> <li>tls: Provide CA/cert/key file paths and <code>skipVerify</code> flag.</li> <li>writeOptions: Tune buffer size, flush interval, custom HTTP headers, retries, and timeouts.</li> <li> <p>metadata:</p> <ul> <li><code>include</code>: Whether to send metadata.</li> <li><code>interval</code>: Frequency of metadata updates.</li> <li><code>maxEntriesPerWrite</code>: Limit per request.</li> </ul> </li> </ul>"},{"location":"apps/remote-write/#export-resource-options","title":"Export Resource Options","text":"<ul> <li>path (required): State DB path to collect from.</li> <li>mode: <code>periodic</code>, <code>on-change</code>, or <code>periodic-on-change</code>.</li> <li>interval: Polling interval for metric collection.</li> <li>fields: Optional subset of fields to export.</li> <li>labels: Static and dynamic labels.</li> <li>mappings: Transform field values using regex and numeric replacements.</li> <li>metricName: Rename metrics using regex.</li> <li>resource: Use a CR as source; metric value is <code>1</code>, and CR labels are used as metric labels.</li> <li>where: Filtering condition (e.g., <code>admin-state = enable</code>).</li> </ul>"},{"location":"apps/virtualnetwork/","title":"Virtual Network (VNET)","text":"<p>The Virtual Network (<code>VNET</code>) application is a resource designed to group and manage network services together, typically deployed as overlay services. The VNET simplifies management by serving as a single input for a set of resources that support a common set of applications.</p>"},{"location":"apps/virtualnetwork/#core-components-of-vnet","title":"Core Components of VNET","text":"<p>The primary components that make up the VNET include:</p> <ul> <li> <p>BridgeDomain: Represents a Layer 2 broadcast domain. It is used in conjunction with VLAN and BridgeInterface resources, which attach sub-interfaces to this L2 broadcast domain.</p> </li> <li> <p>VLAN: Groups sub-interfaces together under a common VLAN ID. VLAN IDs can be automatically assigned from a pool or manually set by the user.  The VLAN uses a label selector to select the interfaces on which to provisioning the sub-interfaces.</p> </li> <li> <p>BridgeInterface: Allows operators to manually attach a sub-interface to a specific BridgeDomain.</p> </li> <li> <p>Router: Acts as a Layer 3 domain manager. It can connect multiple BridgeDomains through an <code>IRBInterface</code> or link directly to <code>RoutedInterfaces</code>.</p> </li> <li> <p>IRBInterface (Integrated Routing and Bridging Interface): Connects a BridgeDomain to a Router, facilitating communication between Layer 2 and Layer 3 networks.</p> </li> <li> <p>RoutedInterface: Represents a directly connected Layer 3 interface on a device that is attached to a Router.</p> </li> <li> <p>DHCPRelay: Enables DHCP relay functionality on sub-interfaces within the VNET, facilitating dynamic IP address allocation.</p> </li> </ul>"},{"location":"apps/virtualnetwork/#additional-capabilities","title":"Additional Capabilities","text":"<ul> <li>PE-CE BGP: The VNET also supports Provider Edge to Customer Edge (PE-CE) BGP.</li> <li>IP Filters: IPv4, IPv6 and MAC filters can also be used within the <code>VirtualNetwork</code>.</li> <li>DSCP and Dot1p classifiers: Attachment of DSCP and Dot1p classifiers are also supported.</li> </ul>"},{"location":"apps/virtualnetwork/#example-vnets","title":"Example VNETs","text":""},{"location":"apps/virtualnetwork/#layer-2-vnet","title":"Layer 2 VNET","text":"<code>kubectl</code>YAML <pre><code>cat &lt;&lt; 'EOF' | tee l2-vnet.yaml | kubectl apply -f -\napiVersion: services.eda.nokia.com/v1alpha1\nkind: VirtualNetwork\nmetadata:\n  name: vnet1\n  namespace: eda\nspec:\n  bridgeDomains:\n    - name: bd1\n      spec:\n        eviPool: evi-pool\n        l2proxyARPND:\n          dynamicLearning:\n            ageTime: 2000\n            enabled: true\n            sendRefresh: 2000\n          ipDuplication:\n            enabled: true\n            holdDownTime: 10\n            monitoringWindow: 10\n            numMoves: 4\n          proxyARP: true\n          proxyND: false\n          tableSize: 250\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  vlans:\n    - name: storage\n      spec:\n        bridgeDomain: bd1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=storage\n        vlanID: pool\n        vlanPool: vlan-pool\n    - name: compute\n      spec:\n        bridgeDomain: bd1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=compute\n        vlanID: pool\n        vlanPool: vlan-pool\n\nEOF\n</code></pre> <pre><code>apiVersion: services.eda.nokia.com/v1alpha1\nkind: VirtualNetwork\nmetadata:\n  name: vnet1\n  namespace: eda\nspec:\n  bridgeDomains:\n    - name: bd1\n      spec:\n        eviPool: evi-pool\n        l2proxyARPND:\n          dynamicLearning:\n            ageTime: 2000\n            enabled: true\n            sendRefresh: 2000\n          ipDuplication:\n            enabled: true\n            holdDownTime: 10\n            monitoringWindow: 10\n            numMoves: 4\n          proxyARP: true\n          proxyND: false\n          tableSize: 250\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  vlans:\n    - name: storage\n      spec:\n        bridgeDomain: bd1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=storage\n        vlanID: pool\n        vlanPool: vlan-pool\n    - name: compute\n      spec:\n        bridgeDomain: bd1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=compute\n        vlanID: pool\n        vlanPool: vlan-pool\n</code></pre>"},{"location":"apps/virtualnetwork/#layer-3-vnet","title":"Layer 3 VNET","text":"<code>kubectl</code>YAML <pre><code>cat &lt;&lt; 'EOF' | tee l3-vnet.yaml | kubectl apply -f -\n---\napiVersion: services.eda.nokia.com/v1alpha1\nkind: VirtualNetwork\nmetadata:\n  name: vnet2\n  namespace: eda\nspec:\n  bridgeDomains:\n    - name: app1\n      spec:\n        eviPool: evi-pool\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n    - name: app2\n      spec:\n        eviPool: evi-pool\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  irbInterfaces:\n    - name: irb1\n      spec:\n        arpTimeout: 14400\n        bfd:\n          desiredMinTransmitInt: 150002\n          detectionMultiplier: 4\n          enabled: true\n          minEchoReceiveInterval: 1000000\n          requiredMinReceive: 150000\n        bridgeDomain: app1\n        evpnRouteAdvertisementType:\n          arpDynamic: true\n          arpStatic: true\n          ndDynamic: false\n          ndStatic: false\n        hostRoutePopulate:\n          dynamic: true\n          evpn: true\n          static: false\n        ipAddresses:\n          - ipv4Address:\n              ipPrefix: 13.3.3.1/24\n              primary: true\n            ipv6Address:\n              ipPrefix: fc00:31::1/120\n              primary: true\n          - ipv4Address:\n              ipPrefix: 14.4.4.1/24\n              primary: false\n            ipv6Address:\n              ipPrefix: fc00:41::1/120\n              primary: false\n        ipMTU: 1500\n        l3ProxyARPND:\n          proxyARP: false\n          proxyND: false\n        learnUnsolicited: NONE\n        router: routetable1\n    - name: irb2\n      spec:\n        arpTimeout: 14400\n        bfd:\n          desiredMinTransmitInt: 150002\n          detectionMultiplier: 4\n          enabled: true\n          minEchoReceiveInterval: 1000000\n          requiredMinReceive: 150000\n        bridgeDomain: app2\n        evpnRouteAdvertisementType:\n          arpDynamic: true\n          arpStatic: true\n          ndDynamic: false\n          ndStatic: false\n        hostRoutePopulate:\n          dynamic: true\n          evpn: true\n          static: false\n        ipAddresses:\n          - ipv4Address:\n              ipPrefix: 15.3.3.1/24\n              primary: true\n            ipv6Address:\n              ipPrefix: fc00:51::1/120\n              primary: true\n          - ipv4Address:\n              ipPrefix: 16.4.4.1/24\n              primary: false\n            ipv6Address:\n              ipPrefix: fc00:61::1/120\n              primary: false\n        ipMTU: 1500\n        l3ProxyARPND:\n          proxyARP: false\n          proxyND: false\n        learnUnsolicited: NONE\n        router: routetable1\n  routers:\n    - name: routetable1\n      spec:\n        eviPool: evi-pool\n        routerID: 5.4.3.2\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  vlans:\n    - name: vlan1\n      spec:\n        bridgeDomain: app1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=storage\n        vlanID: pool\n        vlanPool: vlan-pool\n    - name: vlan2\n      spec:\n        bridgeDomain: app2\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=compute\n        vlanID: pool\n        vlanPool: vlan-pool\n\nEOF\n</code></pre> <pre><code>---\napiVersion: services.eda.nokia.com/v1alpha1\nkind: VirtualNetwork\nmetadata:\n  name: vnet2\n  namespace: eda\nspec:\n  bridgeDomains:\n    - name: app1\n      spec:\n        eviPool: evi-pool\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n    - name: app2\n      spec:\n        eviPool: evi-pool\n        macAging: 300\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  irbInterfaces:\n    - name: irb1\n      spec:\n        arpTimeout: 14400\n        bfd:\n          desiredMinTransmitInt: 150002\n          detectionMultiplier: 4\n          enabled: true\n          minEchoReceiveInterval: 1000000\n          requiredMinReceive: 150000\n        bridgeDomain: app1\n        evpnRouteAdvertisementType:\n          arpDynamic: true\n          arpStatic: true\n          ndDynamic: false\n          ndStatic: false\n        hostRoutePopulate:\n          dynamic: true\n          evpn: true\n          static: false\n        ipAddresses:\n          - ipv4Address:\n              ipPrefix: 13.3.3.1/24\n              primary: true\n            ipv6Address:\n              ipPrefix: fc00:31::1/120\n              primary: true\n          - ipv4Address:\n              ipPrefix: 14.4.4.1/24\n              primary: false\n            ipv6Address:\n              ipPrefix: fc00:41::1/120\n              primary: false\n        ipMTU: 1500\n        l3ProxyARPND:\n          proxyARP: false\n          proxyND: false\n        learnUnsolicited: NONE\n        router: routetable1\n    - name: irb2\n      spec:\n        arpTimeout: 14400\n        bfd:\n          desiredMinTransmitInt: 150002\n          detectionMultiplier: 4\n          enabled: true\n          minEchoReceiveInterval: 1000000\n          requiredMinReceive: 150000\n        bridgeDomain: app2\n        evpnRouteAdvertisementType:\n          arpDynamic: true\n          arpStatic: true\n          ndDynamic: false\n          ndStatic: false\n        hostRoutePopulate:\n          dynamic: true\n          evpn: true\n          static: false\n        ipAddresses:\n          - ipv4Address:\n              ipPrefix: 15.3.3.1/24\n              primary: true\n            ipv6Address:\n              ipPrefix: fc00:51::1/120\n              primary: true\n          - ipv4Address:\n              ipPrefix: 16.4.4.1/24\n              primary: false\n            ipv6Address:\n              ipPrefix: fc00:61::1/120\n              primary: false\n        ipMTU: 1500\n        l3ProxyARPND:\n          proxyARP: false\n          proxyND: false\n        learnUnsolicited: NONE\n        router: routetable1\n  routers:\n    - name: routetable1\n      spec:\n        eviPool: evi-pool\n        routerID: 5.4.3.2\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  vlans:\n    - name: vlan1\n      spec:\n        bridgeDomain: app1\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=storage\n        vlanID: pool\n        vlanPool: vlan-pool\n    - name: vlan2\n      spec:\n        bridgeDomain: app2\n        interfaceSelector:\n          - eda.nokia.com/edgeLinkType=compute\n        vlanID: pool\n        vlanPool: vlan-pool\n</code></pre>"},{"location":"apps/virtualnetwork/#verify-the-status-of-the-virtualnetwork","title":"Verify the status of the <code>VirtualNetwork</code>","text":"<p>Verify the fabric operational state:</p> <pre><code>kubectl -n eda get virtualnetwork\n\nNAME    OPERATIONALSTATE   LASTCHANGE\nvnet1   down               2024-04-30T21:26:36.000Z\nvnet2   degraded           2024-04-30T22:47:38.000Z\n</code></pre>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/subscribe/","title":"Subscribe To This Blog","text":"<p>If you want to get notified when a new post is published on this blog - consider subscribing via one of the following channels.</p>"},{"location":"blog/subscribe/#rss","title":"RSS","text":"<p>This blog publishes two RSS feeds:</p> <ul> <li><code>https://docs.eda.dev/feed_rss_created.xml</code> - feed is updated whenever a new post is created.</li> <li><code>https://docs.eda.dev/feed_rss_updated.xml</code> - feed is updated whenever a new post is created or updated.</li> </ul> <p>Depending on how thoroughly you want to monitor the blog choose between those two feeds.</p>"},{"location":"blog/subscribe/#email","title":"Email","text":"<p>You can get notifications in your mailbox by channeling the RSS feed using one of the RSS-to-Email services.</p> <p>A popular option is a free blogtrottr service, but if it doesn't suit you, there are alternatives like feedrabbit and IFTT.</p> <p>In blogtrottr, all you need to do is to enter <code>https://docs.eda.dev</code> in the site input field, type in your email and select the \"Realtime\" delivery option. Then select which feed you want to receive.</p>"},{"location":"blog/tags/","title":"Tags","text":""},{"location":"blog/tags/#tag:installation","title":"installation","text":"<ul> <li>            Try EDA Like a Pro          </li> </ul>"},{"location":"blog/tags/#tag:media","title":"media","text":"<ul> <li>            The beginning of an era EDA          </li> </ul>"},{"location":"blog/tags/#tag:nfd","title":"nfd","text":"<ul> <li>            The beginning of an era EDA          </li> </ul>"},{"location":"blog/tags/#tag:release","title":"release","text":"<ul> <li>            EDA 25.4          </li> </ul>"},{"location":"blog/the-beginning-of-an-era-eda/","title":"The beginning of an era EDA","text":"<p>Today marks a huge milestone. You may have heard us talking about \"EDA\" at several public events - now you get to experience it for yourself.</p> <p>It was a mere 24 months ago that we started the initial design for a next generation controller, which eventually adopted the codename EDA - Event Driven Automation.</p> <p>Our goals were lofty; intents without inflexibility, simplified consumption of streaming telemetry, multi vendor, multi domain, CI/CD, pipelines, all encompassing revision control, all built for the modern tooling era.</p> <p>Did we succeed? You get to be the judge!</p> <p></p>","tags":["media","nfd"]},{"location":"blog/the-beginning-of-an-era-eda/#eda","title":"EDA?","text":"<p>If you've never heard of EDA before there is no better place to start than checking out the NFD special dedicated to this next generation automation controller.</p> <p>Before diving into the technical details, we wanted to share a bit about our motivations. What problems we saw unsolved and how we saw EDA as a solution, and the world of declarative abstractions.</p> <p>What you will notice when reading through this engineering documentation portal is that we always try to put a demo behind the concepts we are describing. Our NFD appearance was not an exception - after explaining the design goals, drawing out the problem space and telling you how we think EDA is fit to solve them, we did a live demo of EDA in action.</p> <p>How to deploy the whole fabric config in a network-wide transaction over a fleet of devices using declarative abstractions? How declarative abstractions can be nested and composed? How leveraging modeled network management interfaces can guarantee safety and reliability when used in conjunction with a transaction model? This is all waiting for you in the next video:</p> <p>After covering the configuration aspects of EDA we switch to state. What exactly do we mean by saying that abstractions should not only be for configuration, but also for state? How having state and configuration together can help operations? What would it look like to have a query language for your whole network, both for config and state? And lastly, if you came for AI bits - this video is for you!</p>","tags":["media","nfd"]},{"location":"blog/the-beginning-of-an-era-eda/#try-eda","title":"Try EDA","text":"<p>The NFD videos are a great introduction to the concepts behind EDA, and it is highly likely we target the same problems you face with existing automation software. In that case, you would presumably willing to book an EDA demo... While booking a demo is absolutely possible, we are confident that you'll be able to recognize the value of EDA by running it in your own environment and on your own terms.</p> <p>And with that said. the team<sup>1</sup> is immensely proud to share EDA's first public release tagged with <code>24.12.1</code> version. This release is available for everyone to enjoy without a license and is available for download from the public GitHub container registry. No, really - no pay walls or registration walls.</p> <p> Try EDA </p> <p>We're excited to see the yet-unimagined ways you'll use the framework to solve interesting automation problems.</p>","tags":["media","nfd"]},{"location":"blog/the-beginning-of-an-era-eda/#community","title":"Community","text":"<p>EDA is a framework that allows users to create their own automation journey by creating custom abstractions, CI/CD workflows, composable UI dashboards, and applications that can be shared with the community. We wholeheartedly believe that the automation flourishes when it is open, collaborative, and accessible to everyone.</p> <p>As with SR Linux, we host our community Discord server and invite everyone to join us as we push the boundaries of what is possible with automation.</p> <p>  Join EDA Discord </p> <ol> <li> <p>From the EDA development, test, and product management teams.\u00a0\u21a9</p> </li> </ol>","tags":["media","nfd"]},{"location":"blog/try-eda-like-a-pro/","title":"Try EDA Like a Pro","text":"<p>Our tiny but mighty <code>make try-eda</code> command carries out the entire EDA Playground installation. It installs a Kubernetes cluster, deploys the EDA core apps, and creates the necessary playground components along with a simulated network topology. Automation greatness, one click away. Just like we love it.</p> <p>But as you build up your EDA experience, you may find yourself eager to step off the beaten path and start customizing your installation experience to your needs. In this blog post we share some new additions made to the Playground installation to make your Try EDA experience more enjoyable.</p>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#preferences-file","title":"Preferences file","text":"<p>Most likely you started your EDA journey by following our quickstart guide and deployed your playground environment like this:</p> <pre><code>make try-eda\n</code></pre> <p>Yes, this is all you need to get the ball rolling, but providing the variable values inline is not always convenient. Often you want to store the values in a configuration file.</p> <p>EDA's Playground config is powered by the make's preferences file and we ship the instance of it - <code>prefs.mk</code> - within the playground repo itself.</p> <p>The preferences file contains a selected set of the \"most wanted\" variables that you would want to tune for your playground installation. Things like the address you use to access the UI, the proxy settings, and kind cluster name.</p> <p>You can of course edit the provided <code>prefs.mk</code> file, but what I like to do is to create a new file within the <code>./private</code> directory where I can store my values without changing the original file. There are a few reasons for this:</p> <ol> <li>Keep the git repo clean, as the files in the <code>private</code> directory are not tracked by git.</li> <li>Doing <code>git pull</code> won't overwrite the changes I made to a copy of the <code>prefs.mk</code> file.</li> <li>I can create multiple preferences files for different installation scenarios.</li> </ol> <p>If you opt in using a custom preferences file you would need to set the <code>PLAYGROUND_PREFS_FILE</code> environment variable to point to the file you want to use.</p> Using a custom preferences file<pre><code>export PLAYGROUND_PREFS_FILE=\"private/kind-prefs.mk\" #(1)!\nmake try-eda\n</code></pre> <ol> <li>Both absolute and relative paths are supported.</li> </ol> Spice it up with direnv <p>A neat trick is to use direnv tool and create an <code>.envrc</code> file in your working directory that would set the <code>PLAYGROUND_PREFS_FILE</code> variable to point to the file you want to use.</p> <code>.envrc</code><pre><code>export PLAYGROUND_PREFS_FILE=\"private/kind-prefs.mk\"\n</code></pre>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#kpt-setters-file","title":"KPT Setters File","text":"<p>Alright, you noticed that the make preferences file contain only a handful of variables. But what if you want to customize the installation further?</p> <p>EDA uses the kpt to deploy and manage the configuration of its components. When browsing the nokia-eda/kpt repository you may notice the <code>kpt-set</code> comments in various kubernetes manifests:</p> snippet from <code>eda-kpt-base/engine-config/engineconfig.yaml</code><pre><code>apiVersion: core.eda.nokia.com/v1\nkind: EngineConfig\nmetadata:\n  name: engine-config # kpt-set: ${CLUSTER_MEMBER_NAME}\nspec:\n  # ...\n  llm:\n    apiKey: \"\" # kpt-set: ${LLM_API_KEY}\n    model: gpt-4o # kpt-set: ${LLM_MODEL}\n  simulate: true # kpt-set: ${SIMULATE}\n</code></pre> <p>These <code>kpt-set</code> comments are markers for the kpt tool that these values can set by Kpt using the <code>${VARIABLE_NAME}</code> syntax. How would you set the values of these variables you ask? Using the Kpt setters file.</p> <p>Kpt Setters Reference</p> <p>We maintain the reference of all available setters in our docs.</p> <p>The setters file allow you to specify the values for the setters that will be used when you install EDA Playground. For example, to set the PV claim volume size for the Git server deployment, you would create a yaml file like this:</p> <code>my-setters.yml</code><pre><code>apiVersion: v1\nkind: ConfigMap #(1)!\nmetadata:\n  name: my-setters\ndata:\n  GOGS_REPLICA_PV_CLAIM_SIZE: 10Gi #(2)!\n  # your other setters here\n</code></pre> <ol> <li>As you can see, the setters file is a ConfigMap resource, but it is not applied to your cluster, it is only used by the kpt tool to read the values from it.</li> <li>The setter's key must match the name of the setter variable in the manifest file.</li> </ol> <p>Now that you have your setters file with the necessary values, you should set the path to it in the preferences file:</p> <pre><code>KPT_SETTERS_FILE := private/my-setters.yml\n</code></pre> <p>And that's it! The kpt will read the values from the setters file and apply them to the manifests when you run the <code>make try-eda</code> command.</p>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#kind-config","title":"Kind Config","text":"<p>The default EDA Playground installation deploys the platform on a KinD cluster. And by default we deploy a default KinD cluster using a barebones cluster configuration.</p> <p>This works great for the most installation scenarios, but sometimes you need to customize the kind cluster configuration. For example, you may need to add extra bits of configuration to play with Ingress resources and expose additional ports for your cluster.</p> <p>We allow you to use your own kind configuration file by setting the <code>KIND_CONFIG_FILE</code> variable in the preferences file pointing to the desired config file. Here is an example of a custom kind config file that I use to setup ingress nginx with kind:</p> kind configpreferences file <code>private/kind-ingress-config.yml</code><pre><code>---\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnetworking:\n  ipFamily: dual\n  apiServerAddress: \"127.0.0.1\"\nnodes:\n  - role: control-plane\n    kubeadmConfigPatches:\n      - |\n        kind: InitConfiguration\n        nodeRegistration:\n          kubeletExtraArgs:\n            node-labels: \"ingress-ready=true\"\n    extraPortMappings:\n      - containerPort: 80\n        hostPort: 80\n        protocol: TCP\n      - containerPort: 443\n        hostPort: 443\n        protocol: TCP\n</code></pre> <pre><code>KIND_CONFIG_FILE := private/kind-ingress-config.yml\n</code></pre>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#llm-api-key","title":"LLM API Key","text":"<p>The Natural Language Query feature requires an OpenAI API key to be set in the EDA's Engine Config resource. You can provide the key directly in the preferences file using the <code>LLM_API_KEY</code> variable, but providing a \"secret\" in a file body is not the most secure way to do it.</p> <p>Instead, you can set the environment variable under the same key <code>LLM_API_KEY</code> in your <code>.profile</code>, <code>.zshenv</code>, <code>.bashrc</code>, <code>.zshrc</code>, or any other file that your shell reads on startup. Make tool will read the env variable under this key by default, so you may leave the variable unset in the preferences file.</p>","tags":["installation"]},{"location":"blog/try-eda-like-a-pro/#kind-api-server-address","title":"Kind API Server Address","text":"<p>When we deploy a Kind cluster for EDA Playground, the k8s API server address is kept at its default value of <code>127.0.0.1</code>. The localhost nature of the address results in the k8s API server being inaccessible from outside the machine you run the cluster on.</p> <p>We noticed that many users would like to spin up playground on a remote servers and access the k8s API server via a network. To support this use case, we added the <code>KIND_API_SERVER_ADDRESS</code> variable to the preferences file which allows you to set the non localhost IP address for the k8s API server. This effectively allows you to access the k8s API server from outside the machine you run the cluster on.</p>","tags":["installation"]},{"location":"blog/eda-254/","title":"EDA 25.4","text":"<p>It is that time again  The EDA product team are pleased to announce the release of EDA 25.4.1 </p> <p>The team have been hard at work; introducing our first non-SR Linux OS, a boatload of QoL UI improvements (bulk edits!), and a number of app extensions to cover additional use cases.</p> <p>To some numbers! In this release we delivered 152 GA features, 14 alpha features, and 90 beta features (I'll come back to this later).</p> <p>Our big themes for this release were DX (or Developer Experience) and productizing SR OS as a first class citizen.</p> <p>To look at DX first, with EDA 25.4 we are providing:</p> <ul> <li> <p>Extensions to <code>edactl</code> to support intent debuggability (under edactl intent debug).     This includes the ability to trigger instances of intents to run, with DEBUG toggled to allow more logging verbosity.</p> <p>It includes the ability to monitor execution of instances (including the immediate monitor + trigger). This massively improves intent debuggability, dumping any logs, subscriptions, inputs, and outputs your application received/emitted.</p> <p>For performance debugging, stats are provided for all execution of all intents, including number of executions and cumulative execution time.</p> </li> <li> <p>The new <code>edabuilder</code> tool.</p> <p>Purposefully built for developing applications on EDA (intent-based or otherwise). The initial focus of the tool is primarily to assist with the scaffolding/packaging/testing/publishing of an application, including its resources and intents. A new section of documentation dedicated to the above.</p> </li> </ul> <p>Now for Nokia SR OS - our first litmus test on our claims of supporting multiple operating systems. We are releasing this as beta in EDA 25.4.1, with the expectation that this graduates to GA in 25.8.1. The large number of beta features mentioned above relate to this.</p> <p>You are free to try EDA with SR OS in a lab environment, with most apps already providing support.</p> <p>There are minor gaps in app coverage for SR OS (upgrades are not supported for example), but you should find coverage for the common use cases we support SR Linux for, including:</p> <ul> <li>ZTP (including component configuration)</li> <li>Underlay via the Fabric resource and its dependencies.</li> <li>Overlay via the VirtualNetwork resource and its dependencies.</li> <li>The surrounding set of policies/profiles in filters, QoS, routing policies, and almost everything else.</li> <li>Queries with EQL, including natural language.     Use <code>sros:</code> as a prefix to force a query to only SR OS devices.</li> <li>Normalization of all state data, including overlays (CPU, memory, disk).</li> <li>Lots, lots more.</li> </ul> <p>This covers SR OS both as a DC GW (using option A), and as any of the roles used by SR Linux today - leaf, spine, superspine.</p> <p>Supported SR OS releases</p> <p>You must use SR OS 24.10R4 or above, or 25.3R2 or above.</p> <p>For now you must run SR OS nodes in containerlab, or interact with real hardware in your physical lab.</p> <p>Beyond these themes you'll find new overlays, extensions to our integrations with Prometheus, ServiceNow, PagerDuty, and NetBox, and enhancements in our integration with OpenStack.</p> <p>You'll also (if you're paying attention) notice huge speed improvements in transactions and general scale improvements at scale. We were already blazing fast here (deploying scaled fabrics in seconds) but we have managed to squeeze a measly 10x improvement in some intent apps, with most seeing somewhere in the 5-8x range.</p> <p>With that said, onwards!</p> <p>If you aren't there yet, join the EDA Discord server: https://eda.dev/discord.</p> <p>with  from the EDA product team</p>","tags":["release"]},{"location":"blog/150-minutes-of-eda/","title":"150 minutes of EDA","text":"<p>A week ago we gathered for the 20<sup>th</sup> time with our partners and customers to share our vision for the future of networking. The sunny Tarragona hosted our SReXperts EMEA 2025 and it was a blast. Many after-event social media postings<sup>1</sup><sup>2</sup><sup>3</sup> can give you a taste of the event.</p> <p>It was also the first time we hosted the EDA hackathon for the lucky hundred participants who were there with us on the first day to learn about the product and later solve some challenges we carefully outlined on the https://hack.srexperts.net website.</p> <p>It was great to see so many people getting engaged and excited about the possibilities EDA brings to the industry and getting the most out of the practical exercises.</p> <p>Yet, we understand that not everyone could make it to the event, and that's why we've decided to share the theoretical part of the hackathon with the community, as we believe in the power of knowledge sharing and collaboration.</p> <p>When introducing EDA to the community, we wanted to cut it close to the wire and mix the slides with real demos. In fact, we had eight demos flawlessly executed from the stage as we were introducing the concepts to the audience.</p> <p>Once I landed from Tarragona, I started to slice the single stream into topics, and this resulted in seven parts, each with a clear message and scope. We hope you enjoy the content and find it useful, as we had a lot of fun preparing it.</p> <p>Don't forget to join our Discord if you want to connect with us and learn more.</p>"},{"location":"blog/150-minutes-of-eda/#building-on-k8s-and-try-eda","title":"Building on K8s and \"Try EDA\"","text":"<p>Nokia EDA uses Kubernetes not only as a universal deployment platform that enables high availability and horizontal scaling, but also brings the Kubernetes Resource Model concepts to networking to ensure declarative configuration of resources.</p> <p>In Part 1 we explore the benefits of using Kubernetes as a platform for infrastructure and network automation and explain how to make use of the \"Try EDA\" installation that brings the full-fledged EDA setup with a Digital Twin and a small DC pod on the side.</p>"},{"location":"blog/150-minutes-of-eda/#declarative-abstractions-labels-and-allocation-pools","title":"Declarative Abstractions, Labels, and Allocation Pools","text":"<p>The networking industry has pretty much converged on the benefits that abstractions bring to the table. Instead of exposing dozens of nerd knobs, we tend to create business-critical and user-friendly abstractions. Couple the abstracted input with declarative principles and you get a modern and simple network management solution. But simple is hard.</p> <p>In Part 2 we present the core concepts of EDA, starting with Declarative Abstractions. All EDA resources (Interface, BGP Peer, Static Route, etc.) are declarative and abstract. This concept underpins the simplicity and multivendor design principles we strive to offer to users.</p> <p>Next, we introduce the two ways a user can select and reference resources in EDA - by name or labels. The label-based selection plays a key role in automation at scale, where the mapping is done implicitly by dereferencing objects with a given label set.</p> <p>At the end of this part we talk about Allocation Pools, a concept that allows users to reliably manage resources such as indices, IP addresses, ASNs and so on.</p>"},{"location":"blog/150-minutes-of-eda/#building-an-evpn-vxlan-fabric","title":"Building an EVPN VXLAN Fabric","text":"<p>The concepts introduced in Part 2 https://youtu.be/a7j_xKz7XhI enable EDA users to declaratively build and manage complex networks by offering simple and abstracted input.</p> <p>Take an EVPN VXLAN fabric, for instance. To build an EVPN VXLAN fabric one needs to sort out things like underlay addressing, BGP peer configuration, ASN assignments, ACL policy creation, overlay protocol setup and many other adjacent tasks.</p> <p>A perfect task for an abstracted intent, don't you think? This is exactly our plan for this part where we build a fabric across our topology by providing the bare minimum configuration input, and the system takes care of the rest.</p>"},{"location":"blog/150-minutes-of-eda/#network-wide-transactions-and-deviations","title":"Network-wide Transactions and Deviations","text":"<p>With great power comes great responsibility. Performing automation at scale without having reliability built-in is a recipe for a massive outage. With Nokia EDA you get best-in-class network-wide transaction support where a configuration change undergoes a set of checks:</p> <ul> <li>syntax check</li> <li>schema validation</li> <li>dependency check</li> <li>node-based check</li> </ul> <p>And if any of the checks fail, the whole transaction reverts to ensure that you don't have partially rolled out configuration. Worry-free configuration push on Friday is closer than you might think.</p>"},{"location":"blog/150-minutes-of-eda/#network-state-and-query-language","title":"Network State and Query Language","text":"<p>In the DIY world of network automation we have a peculiar split - we perform configuration management with one set of tools (terraform, ansible, scrapli, napalm) and we deal with the network state using a completely different set of tools (zabbix, grafana, librenms).</p> <p>This severance does not do justice for operations, though, asking the NOC teams to correlate raw state metrics with the deployed services. How do you know if your service for a particular tenant is running?</p> <p>Things are different in the EDA realm where any given resource submitted to EDA has a corresponding state reported for it. If you configured the Fabric in part 3, you know that even this composite abstraction has a state associated with it. Knowing the health score of your Fabric gives you clear visibility into its performance and reduces the complexity in day 2+ operations.</p> <p>Besides having the state of the resources, we bring you the real-time, distributed and network-wide query language that runs across all your network with blazing fast performance. Do you want to find that rogue MAC in your DC fabric? You can, even with natural language support.</p> <p>Operations are often neglected in DIY solutions, and we are set to change that.</p>"},{"location":"blog/150-minutes-of-eda/#building-virtual-networks","title":"Building Virtual Networks","text":"<p>As we start with datacenter automation, one of the prime-time automation activities is creating overlay networks on top of the EVPN VXLAN fabric.</p> <p>Again, building on top of declarative abstraction principles, we offer you a range of resources to help achieve your goal. Do you need a layer 2 network? Take the Bridge Domain resource. Want to create a layer 3 network? Use the Router resource. Combine the two with the IRB Interface resource and you get a distributed L\u2154 network.</p> <p>On top of that you can create Routed Interfaces and set up BGP Peers on them to break out from your datacenter and achieve external connectivity.</p> <p>The reusability of abstracted components in EDA makes it easy to mix and match and build tailored network designs without compromising the declarative principles.</p>"},{"location":"blog/150-minutes-of-eda/#automation-and-extensibility","title":"Automation and Extensibility","text":"<p>Not API-first, but API-only. EDA lives and breathes APIs and we hope you will appreciate our strong focus on automation. Everything you can do via EDA UI is possible to achieve with any REST API client, as EDA UI is just a client of the API.</p> <p>But API alone is not enough to ensure you get the best out of the platform. EDA, like Kubernetes, is a platform to build upon, and we can't wait to see what you will build on it. To support you in this endeavor we offer developer experience tools like EDABuilder to help you build and package EDA apps.</p> <p>Oh yes, apps - everything in EDA is an app and you can fork, edit an existing one or build your own app. Abstracting the provided abstractions? Possible.</p> <p>To ensure your applications can be discovered and managed we implemented the EDA Store - a component that discovers applications from catalogs. You can publish your apps to your own catalog and make EDA watch it and discover apps from it. Lots of options to offer you full flexibility in how you create, host and distribute EDA apps.</p> <ol> <li> <p>https://www.linkedin.com/feed/update/urn:li:activity:7337432794446393344/ \u21a9</p> </li> <li> <p>https://www.linkedin.com/posts/vach-kompella-75846_nokia-srexperts-evpn-activity-7241886104923037696-T8IJ \u21a9</p> </li> <li> <p>https://www.linkedin.com/posts/rdodin_autocon3-srexperts2025-containerlab-activity-7336793194862411778-QhtC \u21a9</p> </li> </ol>"},{"location":"connect/audit/","title":"Audit","text":""},{"location":"connect/audit/#overview","title":"Overview","text":"<p>The EDA Cloud Connect plugins are listening to or directly interacting with the cloud platforms they manage. Sometimes this connection can be broken temporarily or be out of sync. To automatically fix these out of sync events, you can run an audit on the plugin.</p> <p>An audit can be launched through the UI by navigating to System Administration&gt;Connect&gt;Audit. </p> <p>As an alternative, you can also create an <code>Audit</code> resource in the Kubernetes cluster of EDA with the following content:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectAudit\nmetadata:\n  name: test-audit\n  namespace: eda\nspec:\n  connectPluginName: &lt;name of the plugin&gt;\n  scope: PLUGIN\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectAudit\nmetadata:\n  name: test-audit\n  namespace: eda\nspec:\n  connectPluginName: &lt;name of the plugin&gt;\n  scope: PLUGIN\n\nEOF\n</code></pre>"},{"location":"connect/audit/#audit-result","title":"Audit Result","text":"<p>An audit runs out-of-band inside the plugin (that is, VMWare or OpenShift plugin). You can follow this process using the .status.state field, which will progress from Scheduled to InProgress to Finished. Once the audit is finished, the spec.finished field will be true.</p> <p>An example output is given below: <pre><code>status:\n  endTime: \"2024-12-16T13:37:56Z\"\n  enqueueTime: \"2024-12-16T13:37:56Z\"\n  outcome: Success\n  results:\n  - auditType: ConnectPluginAudit\n    foundDiscrepancies:\n    - connectResourceKind: BridgeDomain\n      connectResourceName: 4030b313-60c5-4256-8135-57833913ce67\n      outcome: Success\n      pluginResourceKind: vlan on Distributed Virtual Portgroup\n      type: Missing\n    - connectResourceKind: Vlan\n      connectResourceName: 33b01228-b522-434c-b099-26ff69ec57c4\n      outcome: Success\n      pluginResourceKind: vlan on Distributed Virtual Portgroup\n      type: Dangling\n    - connectResourceKind: Vlan\n      connectResourceName: 0c7f00d6-5d0a-469f-85a7-6733e457df8c\n      outcome: Success\n      pluginResourceKind: vlan on Distributed Virtual Portgroup\n      type: Missing\n    outcome: Success\n    state: Finished\n  state: Finished\n  totalNumberOfDiscrepancies: 3\n  totalNumberOfSuccessfulDiscrepancies: 3\n</code></pre></p> <p>The status of an audit consists of one or more results, each one referencing a different part of the audit. In case of a PLUGIN audit, the only stage is the plugin auditing against EDA, so typically there will be only one result. The result has an AuditType field to indicate the stage of the audit, as well as an outcome field. The outcome is Success if the audit was able to correct any discrepancies found.</p> <p>If there are any discrepancies found, they are listed in the foundDiscrepancies list, detailing what resources where involved and what the taken action is. Dangling resources are resources left in EDA that are not available in the plugin environment, while missing resources are the opposite. Misconfigured resources are available in both environments, but have one or more misconfigured fields.</p> <p>Finally, a count is provided of the totalNumberOfDiscrepancies as well as successfully and failed fixes.</p>"},{"location":"connect/cloud-connect-installation/","title":"Cloud Connect Core Installation","text":"<p>This guide provides detailed instructions for installing the EDA Cloud Connect Core application.</p>"},{"location":"connect/cloud-connect-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>EDA cluster is up and running</li> <li>Access to the EDA Store UI or Kubernetes API</li> <li>All Connect Core dependencies are satisfied (automatically resolved when installing through the UI)</li> </ul>"},{"location":"connect/cloud-connect-installation/#installation-using-eda-store-ui","title":"Installation Using EDA Store UI","text":"<p>Cloud Connect is an application in the EDA app ecosystem. The easiest way to install it is through the EDA Store UI:</p> <ol> <li>Navigate to the EDA Store in the EDA UI</li> <li>Locate the Cloud Connect Core application</li> <li>Click Install</li> <li>Configure the installation options (see Plugin Configuration Options)</li> <li>Complete the installation</li> </ol> <p>Dependencies are automatically resolved when installing through the UI.</p>"},{"location":"connect/cloud-connect-installation/#installation-using-kubernetes-api","title":"Installation Using Kubernetes API","text":"<p>If you prefer installing the Connect Core using the Kubernetes API, you can do so by creating the following Workflow resource:</p> Connect Core dependencies <p>When installing through the UI, dependencies are automatically resolved; this is not the case through the API. Make sure all dependencies of the Connect Core app are installed before executing the below kubectl command.</p> <p>When the dependencies are not satisfied, an error like the following will be added to the status of the AppInstaller object:</p> <p><code>app requirements validation failed: connect.eda.nokia.com requires interfaces.eda.nokia.com, but interfaces.eda.nokia.com is not present</code></p> YAML Resource<code>kubectl apply</code> command\" <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: connect-nokia\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v5.0.0\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: connect-nokia\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: connect.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v5.0.0\n\nEOF\n</code></pre>"},{"location":"connect/cloud-connect-installation/#plugin-configuration-options","title":"Plugin Configuration Options","text":"<p>When installing Cloud Connect via the EDA UI, users are prompted to configure the application using the following options. These settings control resource limits and behavior of the Connect controllers:</p> Configuration Option Description Default Value Interface Controller GraceTimer (<code>interfaceControllerGraceTimer</code>) The grace period (in seconds) used by the Interface Controller before acting on missing LLDP data. <code>10</code> Interface Controller Pod CPU Limit (<code>interfaceControllerCpuLimit</code>) CPU limit for the connect-interface-controller pod. <code>1</code> Interface Controller Pod Memory Limit (<code>interfaceControllerMemoryLimit</code>) Memory limit for the connect-interface-controller pod. <code>2Gi</code> Plugin Controller Pod CPU Limit (<code>pluginControllerCpuLimit</code>) CPU limit for the connect-plugin-controller pod. <code>500m</code> Plugin Controller Pod Memory Limit (<code>pluginControllerMemoryLimit</code>) Memory limit for the connect-plugin-controller pod. <code>128Mi</code> <p>These options can be adjusted during installation to meet specific performance or resource requirements.</p> Settings are an advanced use case <p>These settings are intended for advanced users. Misconfiguration can lead to system instability or failure. Proceed with caution and ensure changes are validated in a test environment before applying them to production.</p>"},{"location":"connect/cloud-connect-installation/#next-steps","title":"Next Steps","text":"<p>After installing the Cloud Connect Core, you can proceed to install and configure one or more of the cloud platform plugins.</p>"},{"location":"connect/cloud-connect/","title":"Cloud Connect","text":""},{"location":"connect/cloud-connect/#overview","title":"Overview","text":"<p>The EDA Cloud Connect solution (or \"Connect\") acts as a bridge between EDA and different cloud environments like Red Hat OpenShift, VMware vSphere,  OpenStack and Nutanix.</p> <p>Connect is aware of the different processes and workloads running on the servers that make up the cloud environment, while at the same time being aware of the fabric as configured on EDA itself.</p> <p>This dual awareness enables Connect to configure the fabric dynamically based on workloads coming and going on the cloud platform. It does this by inspecting the cloud itself and learning the compute server, network interface and VLAN on which a specific workload is scheduled. By also learning the topology based on the LLDP information arriving in the fabric switches, it connects those two information sources.</p>"},{"location":"connect/cloud-connect/#components","title":"Components","text":"<p>The Connect solution is built around a central service, called the Cloud Connect Core, and plugins for each supported cloud environment.</p> <p>The Connect Core is responsible for managing the plugins and the relationship between <code>ConnectInterfaces</code> (compute interfaces) and EDA <code>Interfaces</code>  (fabric interfaces or edge-links). It keeps track of the LLDP information of EDA <code>Interfaces</code> and correlates that back to the <code>ConnectInterfaces</code>  created by plugins to identify the different physical interfaces of the computes of a cloud environment.</p> <p>Connect plugins are responsible for tracking the state of compute nodes, their physical interfaces, the virtual networks created in the cloud environment and their correlation to the physical network interfaces. As applications create networks and virtual machines or containers, the plugins will inform Connect Core of the changes needed to the fabric. Plugins will also create or manage EDA <code>BridgeDomains</code> and <code>VLANs</code> to make sure the  correct sub-interfaces are created for the application connectivity.</p>"},{"location":"connect/cloud-connect/#plugins-overview","title":"Plugins Overview","text":"<p>Connect plugins are the pluggable components that connect the Connect Core service to a specific cloud environment.  Connect comes with four Nokia supported plugins:</p> <ul> <li>Connect Nutanix plugin</li> <li>Connect OpenShift plugin</li> <li>Connect OpenStack plugin</li> <li>Connect VMware &amp; NSX plugin</li> </ul>"},{"location":"connect/cloud-connect/#feature-overview","title":"Feature Overview","text":"<p>Connect supports the following features:</p> <ul> <li>Creating Layer 2 EVPN overlay services on EDA.</li> <li>Using pre-existing <code>Interfaces</code> including LAGs in the fabric.</li> <li>Automatically discovering the cloud compute resources and connectivity to the fabric using LLDP.</li> <li>Automatically resolving inconsistent states between Connect and the fabric by performing an audit between Connect and EDA.</li> <li>Using the cloud management's standard network management tools to manage the fabric transparently (CMS Managed).</li> <li>Using EVPN services that are managed by EDA. This is the case in which an operator provisions a service in EDA before making them available in the   compute environment for use. This allows for more advanced use cases than the compute environment might support natively (EDA Managed).</li> </ul>"},{"location":"connect/cloud-connect/#installation","title":"Installation","text":"<p>For detailed installation instructions, see the Cloud Connect Core Installation Guide.</p>"},{"location":"connect/cloud-connect/#resources","title":"Resources","text":"<p>Connect uses a pluggable architecture. The Cloud Connect core installation is a collection of controllers responsible for bridging the hypervisor world with the fabric world. It is the plugin that is responsible for introspecting the cloud environment.</p> <p>The following Custom Resources are involved:</p> <code>ConnectPlugin</code> The logical representation of the plugin, created for each plugin automatically when the plugin starts with valid credentials. <code>ConnectPluginActionable</code> An actionable is an action to be taken by the <code>ConnectPlugin</code>. It is used by the Core to tell the plugin to do something (for example: initiate an audit). <code>ConnectPluginHeartbeat</code> The <code>ConnectPlugin</code> will continuously send heartbeats to the Cloud Connect service to report its status and alarms. <code>ConnectInterface</code> The logical representation of a hypervisor NIC and/or LAG. The labels on the <code>ConnectInterface</code> are used to label the EDA interface (leaf interface) correctly so that the correct subinterfaces are created."},{"location":"connect/cloud-connect/#plugins","title":"Plugins","text":"<p>Plugins are a core component of the Event Driven Automation (EDA) Connect environment. In the Connect environment, a plugin represents the component that communicates with the external cloud services. The following plugins are supported by EDA, and are further documented in their respective sections:</p> <ul> <li>Nutanix Connect plugin</li> <li>OpenStack Connect plugin</li> <li>OpenShift Connect plugin</li> <li>VMware vSphere plugin</li> <li>VMware NSX plugin</li> </ul> <p>Plugins are automatically registered within the Connect service when they are deployed. Each is stored in the database with the following main properties:</p> <code>Name</code> A unique name based on the plugin type and compute environment it is connected to. <code>Plugin Type</code> The type of plugin, for example, VMware or OpenShift. <code>Heartbeat Interval</code> The interval, in seconds, between heartbeats that the plugin intends to use. <code>Supported Actions</code> The different actions a plugin can support. These are actions the Core can request the plugin to do. For example, to trigger an audit."},{"location":"connect/cloud-connect/#heartbeats","title":"Heartbeats","text":"<p>When plugins register with the Connect core service, they can indicate that they support heartbeats. When a plugin supports heartbeats, the plugin is expected to send a heartbeat to the Connect core service at an interval of the configured value (or more frequently). If the Connect core does not receive a heartbeat from the plugin after two intervals, it raises an alarm in EDA to indicate that there could be an issue with the plugin.</p>"},{"location":"connect/cloud-connect/#connect-interfaces","title":"Connect Interfaces","text":"<p><code>ConnectInterfaces</code> are managed by the plugins and represent the network interfaces of a compute node. When a plugin notices a new compute or new network interface on a compute node, it will create a <code>ConnectInterface</code> in EDA for Connect Core to monitor.</p> <p>Connect Core uses the information from the <code>ConnectInterface</code> to determine the matching EDA <code>Interface</code>. This is the interface on a leaf managed by EDA to which the interface on the compute node is connected with potentially multiple interfaces, in case of a LAG or bond.</p> <p>The plugin will label these <code>ConnectInterfaces</code> to indicate that Connect Core needs to make sure the matching leaf interfaces have a subinterface created in the corresponding overlay service or <code>BridgeDomain</code>.</p> <p>This way, only those subinterfaces that are truly necessary are configured in the fabric. This limits configuration bloat and possible security risks.</p>"},{"location":"connect/cloud-connect/#namespace-support","title":"Namespace Support","text":"<p>The EDA Connect service supports multiple namespaces. Each plugin is namespaced and can only access resources within its namespace.</p> <p>This also means that a compute cluster can only belong to a single namespace, and cannot span multiple namespaces. This is to be expected, as compute clusters belong to a single fabric, and a fabric is part of a single namespace.</p>"},{"location":"connect/cloud-connect/#connect-ui","title":"Connect UI","text":"<p>The Connect UI can be found as part of the System Administrator section of the EDA UI, and allows for inspection of the different resources owned and managed by Connect. This Connect UI follows the same design as the regular EDA UI, where the left menu for Connect opens and displays the different resources available.</p> Do not edit resources manually, as this could interfere with the behavior of the plugins. <p>If you have made changes manually, an audit will revert them. Changes should be made through the Cloud orchestration platform. When trying to perform changes through the UI a lock will be displayed, indicating  that the resource is managed by Connect.</p>"},{"location":"connect/cloud-connect/#connect-integration-modes","title":"Connect Integration Modes","text":"<p>Integration modes define how plugins create resources in EDA for use by the applications in the compute environments.</p> <p>Connect supports two integration modes:</p> CMS-managed mode Networking concepts of the CMS (Cloud Management System) are used to create new services in EDA. EDA-managed mode Network services are created in EDA and the networking concepts in the CMS are linked or associated with these pre-existing services. <p>Each of these modes can be used by the plugins. For the plugins provided by Nokia, both modes are supported, and you can combine them and switch between them as needed. For instance, you can use one integration mode for one application, while using the other for another application.</p>"},{"location":"connect/cloud-connect/#cms-managed-integration-mode","title":"CMS-Managed Integration Mode","text":"<p>In the Cloud Management mode, Connect creates a <code>BridgeDomain</code> resource for each subnet that is created in the Cloud Management System (CMS). In this mode, the changes in the CMS are transparently reflected into EDA. The administrator of the CMS does not require any knowledge about how to use EDA.</p>"},{"location":"connect/cloud-connect/#eda-managed-integration-mode","title":"EDA-Managed Integration Mode","text":"<p>For more advanced use cases, a more complex EVPN service (or set of services) may be needed. This can include features of these services that are supported by EDA, but not natively by the CMS. Examples are configuring complex routing or QoS policies, or using BGP PE/CE for route advertisement from the application into the network service.</p> <p>In such cases, Nokia recommends using the EDA-managed integration mode, which instructs Connect to associate the subnets in the CMS with existing BridgeDomains in EDA, instead of creating new resources in EDA based on the cloud management networking.</p> <p>In this mode, an administrator, or orchestration engine, with knowledge of EDA first creates the necessary resources in EDA directly. You can create more complex configurations than the cloud management system itself would be able to do. When creating the networking constructs in the Cloud Management system, you provide a set of unique identifiers referring to those pre-created <code>BridgeDomain</code> constructs. This way, the Connect plugin and Connect service know not to create their own resources, but to use the pre-created items.</p> <code>VLAN</code> management <p>In EDA-managed mode, Connect will still create the necessary <code>VLAN</code> resources in EDA as needed, based on the VLANs used in the CMS.</p>"},{"location":"connect/cloud-connect/#lldp","title":"LLDP","text":"<p>To bridge EDA with the cloud environment, Cloud Connect uses LLDP extensively. The LLDP information is collected at the fabric level and streamed to EDA. There is also support for reversing that LLDP relationship, by having the computes collect the LLDP information.</p> <ul> <li>Nutanix Plugin: LLDP collected at fabric level</li> <li>OpenStack Plugin: LLDP collected at fabric level</li> <li>OpenShift Plugin: LLDP collected at hypervisor level</li> <li>VMware plugin: LLDP collected at fabric level</li> </ul> <p>When LLDP is collected at the fabric level, it is advised to disable in-hardware LLDP to prevent those LLDP messages from interfering with the ones that the host operating system is sending out.<sup>1</sup><sup>2</sup></p>"},{"location":"connect/cloud-connect/#lldp-gracetimer","title":"LLDP gracetimer","text":"<p>To prevent unnecessary fabric reconfiguration due to temporary LLDP data loss, a grace period is applied when LLDP information is collected at the fabric level. During this grace period, Connect Core will not reconfigure the fabric, allowing time for LLDP data to recover. The grace period is not applicable when LLDP data is collected at the hypervisor level. The gracetimer can be configured when installing Connect using the <code>interfaceControllerGraceTimer</code> setting; the default is 10 seconds.</p>"},{"location":"connect/cloud-connect/#support-matrix","title":"Support Matrix","text":"<p>In the table below you can find the qualified matrix for the Cloud Connect service.</p>"},{"location":"connect/cloud-connect/#2512","title":"25.12","text":"Component Release Supported Versions (Cloud Type) EDA Core Version OpenShift 5.0.x OpenShift 4.16, 4.18, 4.20 v4.0.0 (EDA release 25.12.x) VMware vCenter v5.0.x VMware vCenter 8.X v4.0.0 (EDA release 25.12.x) VMware NSX v5.0.x VMware NSX 4.2.X v4.0.0 (EDA release 25.12.x) Nutanix Prism Central v0.0.x (Beta) Nutanix Prism Central 7.3.X v4.0.0 (EDA release 25.12.x) <ol> <li> <p>Instructions on how to disable in-hardware LLDP for Mellanox cards can be found here: https://forums.developer.nvidia.com/t/need-help-disabling-hardware-lldp-c5x-ex/294083 \u21a9</p> </li> <li> <p>Instructions on how to disable in-hardware LLDP in VMware ESXI environments: https://knowledge.broadcom.com/external/article/344761/enabling-and-disabling-native-drivers-in.html \u21a9</p> </li> </ol>"},{"location":"connect/kubernetes-plugin-helm-installation/","title":"Kubernetes Plugin Helm Installation","text":"<p>This guide provides step-by-step instructions for installing the EDA Connect Kubernetes plugin using Helm charts.</p> <p>Warning</p> <p>Before proceeding with this installation method, ensure you have completed all the prerequisites and preparation steps described in the Kubernetes Plugin Installation guide.</p>"},{"location":"connect/kubernetes-plugin-helm-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>All prerequisites from the Kubernetes Plugin Installation guide must be met</li> <li>EDA Kubernetes preparation steps (Service Account and Token) must be completed</li> <li>Helm 3.x installed on your system</li> </ul>"},{"location":"connect/kubernetes-plugin-helm-installation/#installation-steps","title":"Installation Steps","text":""},{"location":"connect/kubernetes-plugin-helm-installation/#step-1-fetch-the-eda-connect-openshift-plugin-helm-charts","title":"Step 1: Fetch the EDA Connect OpenShift Plugin Helm Charts","text":"<p>There are two ways to get the Helm charts to deploy the EDA Connect OpenShift plugin:</p> <ol> <li> <p>Using the EDA Playground (if you used it to install EDA):</p> <pre><code>make download-connect-k8s-helm-charts\n</code></pre> </li> <li> <p>Downloading the release tarball and unpacking it:</p> <pre><code>curl -sLO https://github.com/nokia-eda/connect-k8s-helm-charts/archive/refs/tags/5.0.0.tar.gz\ntar zxf 5.0.0.tar.gz \n</code></pre> </li> </ol>"},{"location":"connect/kubernetes-plugin-helm-installation/#step-2-create-a-namespace-for-the-openshift-plugin","title":"Step 2: Create a Namespace for the OpenShift Plugin","text":"<p>The OpenShift Plugin uses its own namespace to separate it from other resources in the OpenShift cluster:</p> <pre><code>kubectl create namespace eda-connect-k8s-controller\n</code></pre>"},{"location":"connect/kubernetes-plugin-helm-installation/#step-3-configure-a-pull-secret-for-the-controller-image","title":"Step 3: Configure a Pull Secret for the Controller Image","text":"<p>If the EDA Connect OpenShift Plugin Controller image is hosted in a registry that requires authentication, create a Kubernetes secret for OpenShift to pull the image:</p> <pre><code>export PULL_TOKEN=&lt;PULL_TOKEN&gt;\nkubectl create secret docker-registry eda-k8s-image-secret \\\n  --docker-server=ghcr.io/nokia-eda/eda-connect-k8s-controller \\\n  --docker-username=nokia-eda-bot \\\n  --docker-password=${PULL_TOKEN} \\\n  -n eda-connect-k8s-controller\n</code></pre> Getting the pull token <p>The pull token can be retrieved from your EDA deployment. See the Get the Pull Token section in the main installation guide for detailed instructions.</p>"},{"location":"connect/kubernetes-plugin-helm-installation/#step-4-set-up-the-helm-values","title":"Step 4: Set Up the Helm Values","text":"<p>Create a <code>helm-values.yaml</code> file with the following content and update the fields as appropriate:</p> <pre><code>controllerEnvConfig:\n  connectpluginname: eda-openshift-controller-plugin\n  heartbeat: \"10\"\n  namespace: &lt;eda-fabric-namespace&gt; # The namespace in EDA containing the fabric and resources, this will different from the eda-system namespace.\n  skiptlsverify: False\n  loglevel: info\n  tlscertificatedata: &lt;EDA K8s certificate data can be extracted from kubeconfig from cluster `certificate-authority-data`&gt;\n  tlsenabled: True\ncontrollerEnvSecret:\n  connectHost: https://&lt;EDA-k8s-cluster-ip or hostname&gt;:&lt;port&gt; # (Caution - Do not use EDA API values, use EDA k8s API values)\n  connectPassword: &lt;Secret long-lived token of the service account created before&gt;\n  connectUsername: &lt;Name of the service account based on which secret token was created&gt;\n</code></pre>"},{"location":"connect/kubernetes-plugin-helm-installation/#helm-values-reference","title":"Helm Values Reference","text":"<p>The possible Helm Values are:</p> <code>connectpluginname</code> A name for the plugin. Make sure this is a unique name within your EDA environment. <p>Plugin Name Requirements</p> <p>The plugin name must comply with the regex check of <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code> and can only contain alphanumerical characters and <code>.</code>, <code>_</code> and <code>-</code>. It must start with an alphanumerical character, and have a length of 63 characters or fewer.</p> <code>heartbeat</code> The interval in seconds at which the plugin should send heartbeats. Values between 10-30 are recommended. _<code>namespace</code> A name of a namespace in EDA containing the fabric and resources. EDA Namespace <p>The EDA Namespace is the namespace in EDA where the fabric is configured. This is different from the <code>eda-system</code> namespace used for EDA system components.</p> <code>skiptlsverify</code> Can be enabled to disable server TLS certificate verification when connecting to the EDA Kubernetes cluster (not recommended for production). <code>tlscertificatedata</code> When certificate validation is enabled, this property can contain the certificate information of the EDA Kubernetes cluster, similar to what a kubeconfig would contain. This is only needed if certificate validation is enabled and if the EDA Kubernetes certificate has not been signed by a trusted authority. <code>tlsenabled</code> Should always be true to make sure TLS is used to secure the communication with the EDA Kubernetes cluster. <code>connectHost</code> The URL to reach the EDA Kubernetes cluster API. <code>connectPassword</code> The long-lived token created in the Create a Service Account Token section. <code>connectUsername</code> The service account name for the account created in the Create a Service Account section."},{"location":"connect/kubernetes-plugin-helm-installation/#step-5-deploy-the-plugin","title":"Step 5: Deploy the Plugin","text":"<p>Deploy the EDA Connect OpenShift Plugin using Helm:</p> <pre><code>helm install eda-k8s connect-k8s-helm-charts/ \\\n  -n eda-connect-k8s-controller \\\n  -f helm-values.yaml \\\n  --set controller.imagePullSecretName=eda-k8s-image-secret\n</code></pre>"},{"location":"connect/kubernetes-plugin-helm-installation/#post-installation-verification","title":"Post-Installation Verification","text":"<p>After deployment, verify the installation was successful using the steps described in the Post-Installation Verification section of the main installation guide.</p>"},{"location":"connect/kubernetes-plugin-installation/","title":"Kubernetes Plugin Installation","text":"<p>This guide provides an overview and prerequisites for installing the EDA Connect Kubernetes plugin on OpenShift clusters.</p>"},{"location":"connect/kubernetes-plugin-installation/#installation-methods","title":"Installation Methods","text":"<p>The EDA Connect Kubernetes plugin can be installed using two different methods:</p> <ul> <li>Helm-based Installation: Traditional installation using Helm charts</li> <li>OLM-based Installation: Installation using Red Hat Operator Lifecycle Manager (OLM)</li> </ul> <p>Make sure to first follow the preparation steps outlined in this guide before proceeding with either installation method.</p>"},{"location":"connect/kubernetes-plugin-installation/#prerequisites","title":"Prerequisites","text":"Other Kubernetes Distributions than OpenShift <p>type: warning</p> <p>This guide focuses on installing the EDA Connect Kubernetes plugin on OpenShift clusters. While it may be possible to adapt these instructions for other Kubernetes distributions, such as vanilla Kubernetes or other managed services, please note that these environments are not officially supported. Users attempting to deploy the plugin on unsupported Kubernetes distributions do so at their own risk and may encounter issues that are not covered in this documentation.</p> <p>Make sure to review the Prerequisites section carefully, as some components mentioned may not be available or may require different installation steps.</p> <p>Before installing or deploying the Kubernetes plugin components, ensure that:</p> <ul> <li>The Cloud Connect Core application is properly installed in the EDA cluster (see Cloud Connect Installation)</li> <li>The OpenShift cluster is up and running</li> <li>NMState Operator   and Multus are installed on the OpenShift cluster</li> <li>You have access to the controller container image: <code>ghcr.io/nokia-eda/eda-connect-k8s-controller:5.0.0</code></li> <li>NMState Operator is configured to listen for LLDP TLVs on interfaces connected to leaf switches</li> </ul>"},{"location":"connect/kubernetes-plugin-installation/#configure-nmstate-for-lldp","title":"Configure NMState for LLDP","text":"<p>Create the following resource in your OpenShift cluster, including all interfaces connected to leaf switches managed by EDA:</p> <pre><code>apiVersion: nmstate.io/v1\nkind: NodeNetworkConfigurationPolicy\nmetadata:\n  name: enable-receive-lldp\nspec:\n  desiredState:\n    interfaces:\n      - name: &lt;interface-name&gt;\n        lldp:\n          enabled: true\n</code></pre>"},{"location":"connect/kubernetes-plugin-installation/#eda-kubernetes-preparation","title":"EDA Kubernetes Preparation","text":"<p>Both installation methods require the same preparation steps on the EDA Kubernetes cluster.</p>"},{"location":"connect/kubernetes-plugin-installation/#create-a-service-account","title":"Create a Service Account","text":"<p>The EDA Connect OpenShift plugin uses a <code>ServiceAccount</code> in the EDA Kubernetes cluster to create the necessary resources in the EDA cluster for the integration to work properly.</p> <p>To create a service account in the EDA Kubernetes cluster, use the following resource.</p> Service Account namespace <p>This service account must be created in the <code>eda-system</code> namespace. Make sure to adapt the namespace when using a customized namespace for EDA.</p> YAML Resource<code>kubectl apply</code> command <pre><code>---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: k8s-controller-plugin\n  namespace: eda-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: k8s-controller-plugin\nsubjects:\n- kind: ServiceAccount\n  name: k8s-controller-plugin\n  namespace: eda-system\nroleRef:\n  kind: ClusterRole\n  # This cluster role is installed by the connect-core app.\n  name: eda-connect-plugin-cluster-role\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: k8s-controller-plugin\n  namespace: eda-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: k8s-controller-plugin\nsubjects:\n- kind: ServiceAccount\n  name: k8s-controller-plugin\n  namespace: eda-system\nroleRef:\n  kind: ClusterRole\n  # This cluster role is installed by the connect-core app.\n  name: eda-connect-plugin-cluster-role\n  apiGroup: rbac.authorization.k8s.io\n\nEOF\n</code></pre>"},{"location":"connect/kubernetes-plugin-installation/#create-a-service-account-token","title":"Create a Service Account Token","text":"<p>From the above Service Account, you need to create a Service Account Token that can be used by the plugin to connect to the EDA Kubernetes cluster. This can be done with the below manifest, which should be applied on the EDA Kubernetes cluster.</p> YAML Resource<code>kubectl apply</code> command <pre><code>---\napiVersion: v1\nkind: Secret\ntype: kubernetes.io/service-account-token\nmetadata:\n  name: k8s-controller-plugin\n  namespace: eda-system\n  annotations:\n    kubernetes.io/service-account.name: k8s-controller-plugin\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\n---\napiVersion: v1\nkind: Secret\ntype: kubernetes.io/service-account-token\nmetadata:\n  name: k8s-controller-plugin\n  namespace: eda-system\n  annotations:\n    kubernetes.io/service-account.name: k8s-controller-plugin\n\nEOF\n</code></pre> <p>After creating the Service Account Token, retrieve the actual token using the following command from the <code>eda-system</code> namespace:</p> <pre><code>kubectl get secrets/k8s-controller-plugin -n eda-system --template={{.data.token}} | base64 --decode\n</code></pre> <p>This token will be needed during plugin deployment.</p>"},{"location":"connect/kubernetes-plugin-installation/#get-the-pull-token","title":"Get the Pull Token","text":"<p>The EDA Connect OpenShift Plugin images are hosted on ghcr.io requiring authentication, you will need a pull token.</p> Getting the pull token <p>The easiest way to get the token/password for the pull secret is extract it from your EDA deployment and look for the <code>appstore-eda-apps-registry-image-pull</code> secret. By grabbing the content of that secret and using <code>base64</code> to decode the <code>dockerconfigjson</code>, you can find the password in the resulting JSON file.</p> <p>The following command shows how to get the token/password (make sure to have the KUBECONFIG for the EDA cluster loaded, not the OpenShift config):</p> <pre><code>kubectl get secret appstore-eda-apps-registry-image-pull -n eda-system -o json | jq -r '.data.\".dockerconfigjson\"' | base64 -d | jq -r '.auths.\"ghcr.io\".password'\n</code></pre>"},{"location":"connect/kubernetes-plugin-installation/#configuration-parameters","title":"Configuration Parameters","text":"<p>Both installation methods require similar configuration parameters. The exact parameter names may vary slightly between methods, but the following information is needed:</p> Plugin Name A unique name for the plugin within your EDA environment. <p>Plugin Name Requirements</p> <p>The plugin name must comply with the regex check of <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code> and can only contain alphanumerical characters and <code>.</code>, <code>_</code> and <code>-</code>. It must start with an alphanumerical character, and have a length of 63 characters or fewer.</p> Heartbeat Interval The interval in seconds at which the plugin should send heartbeats. Values between 10-30 seconds are recommended. EDA Namespace The namespace in EDA containing the fabric and resources. EDA Namespace <p>type: warning The EDA Namespace is the namespace in EDA where the fabric is configured. This is different from the <code>eda-system</code> namespace used for EDA system components.</p> TLS Configuration <ul> <li>TLS Enabled: Should always be true to secure communication with the EDA Kubernetes cluster</li> <li>Skip TLS Verify: Can be enabled to disable server TLS certificate verification (not recommended for production)</li> <li>TLS Certificate Data: Certificate information of the EDA Kubernetes cluster (only needed if certificate validation is enabled and the certificate is not signed by a trusted authority)</li> </ul> EDA Connect Credentials <ul> <li>Connect Host: The URL to reach the EDA Kubernetes cluster API</li> <li>Connect Username: The service account name created in the Create a Service Account section</li> <li>Connect Password: The long-lived token created in the Create a Service Account Token section</li> </ul>"},{"location":"connect/kubernetes-plugin-installation/#post-installation-verification","title":"Post-Installation Verification","text":"<p>After completing either installation method, verify the deployment was successful.</p>"},{"location":"connect/kubernetes-plugin-installation/#verify-the-controller-is-running-in-openshift","title":"Verify the Controller is Running in OpenShift","text":"<p>Check if the controller pod is running in the OpenShift cluster:</p> <pre><code>kubectl get pods -n eda-connect-k8s-controller\n</code></pre> Controller namespace <p>If you used OLM installation, the namespace may be different. Use the namespace where you installed the EDA OpenShift Operator.</p> <p>The expected output:</p> <pre><code>NAME                                            READY   STATUS    RESTARTS   AGE\nconnect-k8s-controller-manager-c8d4875bc-bpzrx  2/2     Running   0          66m\n</code></pre>"},{"location":"connect/kubernetes-plugin-installation/#verify-plugin-registration-in-eda","title":"Verify Plugin Registration in EDA","text":"<p>On the EDA Kubernetes environment, verify the plugin has been registered:</p> <pre><code>kubectl get connectplugins -n &lt;plugin-namespace&gt;\n</code></pre> <p>Expected output:</p> <pre><code>NAME                                   PROVIDED NAME           PLUGIN TYPE   AGE\n470e9af1-b85b-439b-b81a-ab71a7166bb0   k8s-controller-plugin   KUBERNETES    2h\n</code></pre>"},{"location":"connect/kubernetes-plugin-installation/#next-steps","title":"Next Steps","text":"<p>After successful installation and verification, proceed to:</p> <ul> <li>Create Network Attachment Definitions (NADs) in Kubernetes</li> <li>Configure Connect Network Definitions (CNDs) if needed</li> <li>Review the Kubernetes Plugin documentation for usage and operational modes</li> </ul>"},{"location":"connect/kubernetes-plugin-olm-installation/","title":"Kubernetes Plugin OLM Installation","text":"<p>This guide provides step-by-step instructions for installing the EDA Connect Kubernetes plugin using Red Hat Operator Lifecycle Manager (OLM).</p> <p>Warning</p> <p>Before proceeding with this installation method, ensure you have completed all the prerequisites and preparation steps described in the Kubernetes Plugin Installation guide.</p>"},{"location":"connect/kubernetes-plugin-olm-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>All prerequisites from the Kubernetes Plugin Installation guide must be met</li> <li>EDA Kubernetes preparation steps (Service Account and Token) must be completed</li> <li>OLM enabled on your OpenShift cluster</li> <li>Access to the OpenShift cluster console</li> </ul>"},{"location":"connect/kubernetes-plugin-olm-installation/#installation-steps","title":"Installation Steps","text":""},{"location":"connect/kubernetes-plugin-olm-installation/#step-1-install-the-eda-openshift-operator-through-olm","title":"Step 1: Install the EDA OpenShift Operator through OLM","text":"<p>Install the operator using the OpenShift console:</p> <ol> <li> <p>Log in to your OpenShift cluster console.</p> </li> <li> <p>From the main menu, navigate to Operators \u2192 OperatorHub.</p> </li> </ol> OperatorHub navigation <p></p> <ol> <li> <p>Type <code>eda-openshift-operator</code> in the All Items - Filter by keyword filter/search box.    </p> </li> <li> <p>Select the EDA OpenShift Operator tile when it displays. The EDA OpenShift Operator page displays.</p> </li> <li> <p>Click Install.    </p> </li> <li> <p>Enter the namespace where the OLM should install the EDA OpenShift Operator on the OpenShift cluster. The default namespace is    <code>eda-connect-k8s-controller</code>.    </p> </li> <li> <p>Scroll down and click Install.</p> </li> </ol>"},{"location":"connect/kubernetes-plugin-olm-installation/#step-2-configure-a-pull-secret-for-the-controller-image","title":"Step 2: Configure a Pull Secret for the Controller Image","text":"<p>If the EDA Connect OpenShift Plugin Controller image is hosted in a registry that requires authentication, create a Kubernetes secret for OpenShift to pull the image:</p> <pre><code>export PULL_TOKEN=&lt;PULL_TOKEN&gt;\nkubectl create secret docker-registry eda-k8s-image-secret \\\n  --docker-server=ghcr.io/nokia-eda/eda-connect-k8s-controller \\\n  --docker-username=nokia-eda-bot \\\n  --docker-password=${PULL_TOKEN} \\\n  -n eda-connect-k8s-controller\n</code></pre> Getting the pull token <p>The pull token can be retrieved from your EDA deployment. See the Get the Pull Token section in the main installation guide for detailed instructions.</p>"},{"location":"connect/kubernetes-plugin-olm-installation/#step-3-create-controller-container-environment-secret","title":"Step 3: Create Controller Container Environment Secret","text":"<p>Create a <code>openshift-eda-connect-k8s-controller-env-secret.yaml</code> file with the following content and update the fields as appropriate:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: eda-connect-k8s-controller-env-secret # Do not change the name of this Secret\n  namespace: &lt;eda-connect-k8s&gt; # Refers to the namespace where the OLM operator was installed\ndata:\n  CONNECT_HOST: https://&lt;EDA-k8s-cluster-ip or hostname&gt;:&lt;port&gt; # (Caution - Do not use EDA API values, use EDA k8s API values)\n  CONNECT_PASSWORD: &lt;Secret long-lived token of the service account created before&gt;\n  CONNECT_USERNAME: &lt;Name of the service account based on which secret token was created&gt;\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: eda-connect-k8s-controller-env-secret # Do not change the name of this Secret\n  namespace: &lt;eda-connect-k8s&gt; # Refers to the namespace where the OLM operator was installed\ndata:\n  CONNECT_HOST: https://&lt;EDA-k8s-cluster-ip or hostname&gt;:&lt;port&gt; # (Caution - Do not use EDA API values, use EDA k8s API values)\n  CONNECT_PASSWORD: &lt;Secret long-lived token of the service account created before&gt;\n  CONNECT_USERNAME: &lt;Name of the service account based on which secret token was created&gt;\n\nEOF\n</code></pre>"},{"location":"connect/kubernetes-plugin-olm-installation/#configuration-parameters","title":"Configuration Parameters","text":"<p>The environment secret requires the following configuration values:</p> <code>CONNECT_HOST</code> The URL to reach the EDA Kubernetes cluster API. <code>CONNECT_USERNAME</code> The service account name created in the Create a Service Account section. <code>CONNECT_PASSWORD</code> The long-lived token created in the Create a Service Account Token section."},{"location":"connect/kubernetes-plugin-olm-installation/#step-4-create-eda-connect-k8s-controller-config","title":"Step 4: Create EDA Connect K8s Controller Config","text":"<p>Create a <code>eda-connect-k8s-controller-config-cr.yaml</code> file with the following content and update the fields as appropriate:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: config.eda.nokia.com/v1\nkind: ConnectControllerConfig\nmetadata:\n  labels:\n    app.kubernetes.io/name: operator\n  name: connectcontrollerconfig\n  namespace: &lt;eda-connect-k8s&gt; # Refers to the namespace where the OLM operator was installed\nspec:\n  connectPluginName: k8s-controller-plugin\n  controllerImagePullSecret: eda-k8s-image-secret # Refers to the controller container image registry secret to be used\n  heartBeat: \"10\"\n  logLevel: info\n  edaNamespace: &lt;eda-fabric-namespace&gt; # The namespace in EDA containing the fabric and resources, this will different from the eda-system namespace.\n  skipTLSVerify: False\n  tlsCertificateData:\n  tlsEnabled: True\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: config.eda.nokia.com/v1\nkind: ConnectControllerConfig\nmetadata:\n  labels:\n    app.kubernetes.io/name: operator\n  name: connectcontrollerconfig\n  namespace: &lt;eda-connect-k8s&gt; # Refers to the namespace where the OLM operator was installed\nspec:\n  connectPluginName: k8s-controller-plugin\n  controllerImagePullSecret: eda-k8s-image-secret # Refers to the controller container image registry secret to be used\n  heartBeat: \"10\"\n  logLevel: info\n  edaNamespace: &lt;eda-fabric-namespace&gt; # The namespace in EDA containing the fabric and resources, this will different from the eda-system namespace.\n  skipTLSVerify: False\n  tlsCertificateData:\n  tlsEnabled: True\n\nEOF\n</code></pre>"},{"location":"connect/kubernetes-plugin-olm-installation/#configuration-parameters_1","title":"Configuration Parameters","text":"<p>The controller config requires the following values:</p> <code>connectPluginName</code> A unique name for the plugin within your EDA environment. <p>Plugin Name Requirements</p> <p>The plugin name must comply with the regex check of <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code> and can only contain alphanumerical characters and <code>.</code>, <code>_</code> and <code>-</code>. It must start with an alphanumerical character, and have a length of 63 characters or fewer.</p> <code>heartBeat</code> The interval in seconds at which the plugin should send heartbeats. Values between 10-30 are recommended. <code>edaNamespace</code> The namespace in EDA containing the fabric and resources (different from the <code>eda-system</code> namespace). EDA Namespace <p>The EDA Namespace is the namespace in EDA where the fabric is configured. This is different from the <code>eda-system</code> namespace used for EDA system components.</p> <code>skipTLSVerify</code> Can be enabled to disable server TLS certificate verification when connecting to the EDA Kubernetes cluster (not recommended for production). <code>tlsCertificateData</code> When certificate validation is enabled, this property can contain the certificate information of the EDA Kubernetes cluster. This is only needed if certificate validation is enabled and if the EDA Kubernetes certificate has not been signed by a trusted authority. <code>tlsEnabled</code> Should always be true to ensure TLS is used to secure the communication with the EDA Kubernetes cluster."},{"location":"connect/kubernetes-plugin-olm-installation/#post-installation-verification","title":"Post-Installation Verification","text":"<p>After deployment, verify the installation was successful using the steps described in the Post-Installation Verification section of the main installation guide.</p> <p>Controller namespace</p> <p>When verifying the controller pod, use the namespace where you installed the EDA OpenShift Operator instead of <code>eda-connect-k8s-controller</code>.</p>"},{"location":"connect/kubernetes-plugin/","title":"Kubernetes Plugin","text":""},{"location":"connect/kubernetes-plugin/#overview","title":"Overview","text":"<p>EDA Cloud Connect integrates with Kubernetes and in particular the OpenShift flavor to provide fabric-level application networks for  Kubernetes pods and services. The Connect integration leverages the Kubernetes Multus CNI solution to support managing the fabric directly from Kubernetes and make the fabric dynamically respond to the networking needs of the application.</p> <p>It provides the following advantages and capabilities:</p> <ul> <li>Direct integration into the network management workflow of Kubernetes</li> <li>Use of the common CNIs used by Enterprise applications and CNFs like IPVLAN and SR-IOV</li> <li>Automatic provisioning of the fabric based on where the application pods need the connectivity</li> <li>Support for advanced workflows</li> <li>Different operational modes:<ul> <li>Kubernetes-managed operational mode</li> <li>EDA-managed operational mode</li> </ul> </li> <li>Different association modes<ul> <li>Network Attachment Definition Transparent operational mode (Kubernetes-managed only)</li> <li>Connect Network Definition operational mode (Kubernetes-managed and EDA-managed)</li> <li>Network Attachment Definition Annotation operational mode (EDA-managed only)</li> </ul> </li> <li>Optimally configure subinterfaces to minimize configuration and security footprint of network services</li> <li>LAG/LACP interfaces</li> <li>VLAN Trunking</li> <li>Audits</li> </ul>"},{"location":"connect/kubernetes-plugin/#supported-secondary-cni","title":"Supported secondary CNI","text":"<ul> <li>MACVLAN</li> <li>IPVLAN</li> <li>SR-IOV</li> <li>Dynamic SR-IOV</li> </ul> What about the primary CNI? <p>The traffic of the primary CNI such as flannel or calico is typically vxlan or geneve encapsulated and is not configured as such in EDA or the fabric. The underlay network used to transport this traffic is typically managed outside of EDA Connect.</p>"},{"location":"connect/kubernetes-plugin/#supported-versions","title":"Supported Versions","text":"<ul> <li>Red Hat OpenShift 4.16</li> <li>Red Hat OpenShift 4.18</li> <li>Red Hat OpenShift 4.20</li> </ul> Other Kubernetes flavors <p>While the Kubernetes plugin is primarily tested on Red Hat OpenShift, it will also work on other Kubernetes flavors, as long as they provide the required prerequisites. See the Installation Guide for more details.</p> Running Kubernetes in VMs <p>The Kubernetes plugin is designed to work with Kubernetes clusters running on bare-metal nodes. When running the Kubernetes cluster inside VMs, the fabric can be orchestrated by EDA Connect through the hypervisor plugin (e.g., VMware vSphere, VMware NSX, OpenStack or the Nutanix Prism  Central plugin).</p>"},{"location":"connect/kubernetes-plugin/#architecture","title":"Architecture","text":"<p>The Kubernetes plugin consists of a controller which will monitor the following resources in Kubernetes:</p> <ul> <li>The physical NIC configuration and correlation to <code>NetworkAttachmentDefinitions</code> through the NMState Operator.</li> <li><code>NetworkAttachmentDefinitions</code> and their master interfaces.</li> <li><code>ConnectNetworkDefinitions</code> for the configuration of Layer 2 and Layer 3 services configuration.</li> </ul> Where does the plugin run? <p>The Kubernetes plugin controller runs as a pod in the Kubernetes cluster, not in the EDA k8s cluster. It connects to the EDA cluster to create and manage the required EDA resources based on the Kubernetes configuration.</p>"},{"location":"connect/kubernetes-plugin/#installation","title":"Installation","text":"<p>For detailed deployment instructions, see the Kubernetes Plugin Installation Guide. </p>"},{"location":"connect/kubernetes-plugin/#features","title":"Features","text":"<p>The Kubernetes plugin supports two operational modes for the <code>NADs</code>: CMS-managed mode and EDA-managed mode. Next to that it also supports three ways of associating <code>NetworkAttachmentDefinitions</code> to EDA <code>BridgeDomains</code>: Transparent association, Annotation based association, and <code>ConnectNetworkDefinition</code> association.</p>"},{"location":"connect/kubernetes-plugin/#operational-modes","title":"Operational Modes","text":"Kubernetes-Managed Mode Also referred to as Connect Managed. When using this mode, the plugin will create resources in EDA purely based on the configuration in Kubernetes. Depending on the association mode used, this can be pure layer 2 or involve routers on the fabric level. EDA-Managed Mode In EDA-managed mode, resources are first created in EDA and later on linked in Kubernetes. This allows for more advanced configuration of the application networks."},{"location":"connect/kubernetes-plugin/#association-modes","title":"Association Modes","text":"<p>The Kubernetes plugin supports the following association modes between <code>NetworkAttachmentDefinitions</code> in Kubernetes and <code>BridgeDomains</code> in EDA:</p> Transparent association This association does not require any information from EDA in Kubernetes. For every unique master interface defined in <code>NADs</code> in the Kubernetes cluster, the plugin will create a unique <code>BridgeDomain</code> resource. This association only supports Kubernetes-managed mode. Annotation based association In this association, annotations are added to the <code>NAD</code> that reference an existing EDA <code>BridgeDomain</code>. This association only supports EDA-managed mode. <code>ConnectNetworkDefinition</code> association The <code>ConnectNetworkDefinition</code> is a Custom Resource Definition that gets added to the Kubernetes Cluster and is used to describe the relationship between the different services and <code>NetworkAttachmentDefinitions</code>, and how the services relate to each other. This association supports both Kubernetes-managed and EDA-managed modes. By using this association mode, operators can define more complicated relationships between NADs without having to configure them on EDA, although EDA-managed mode is also supported. This mode is the most advanced and flexible."},{"location":"connect/kubernetes-plugin/#using-the-transparent-association-mode","title":"Using the Transparent Association Mode","text":"<p>To use the Transparent association mode, create network attachment definitions (NADs) in Kubernetes without any EDA Connect annotations or any reference to the NAD in a Connect Network Definition (CND).</p> <p>By doing so, the plugin creates a new EDA <code>BridgeDomain</code> for each NAD with a unique master (+VLAN) interface. If a NAD is created for which a NAD with the same master interface and VLAN already exists, it is associated with the existing <code>BridgeDomain</code>.</p> <p>When you remove the NAD, the EDA bridge domain is also removed.</p>"},{"location":"connect/kubernetes-plugin/#using-the-nad-annotation-association-mode","title":"Using the NAD Annotation Association Mode","text":"<p>The NAD Annotation operational mode only works for the EDA-managed operational mode because it relies on an annotation on the NAD that identifies the pre-existing EDA BridgeDomain resource to which the NAD needs to be associated with.</p> <p>To use this operational mode, when creating or updating a NAD, add the following annotation to it:</p> <pre><code>connect.eda.nokia.com/bridgedomain: &lt;eda-bridge-domain-name&gt; \n</code></pre> <p>In case of VLAN trunking, a more complex annotation needs to be used for each vlan in play, for example:</p> <pre><code>connect.eda.nokia.com/bridgedomain: &lt;eda-bridge-domain-name&gt;:&lt;vlan-id&gt;, &lt;eda-bridge-domain-name-2&gt;:&lt;vlan-id&gt; \n</code></pre>"},{"location":"connect/kubernetes-plugin/#using-the-connect-network-definition-operational-mode","title":"Using the Connect Network Definition Operational Mode","text":"<p>Connect Network Definition (CND) is a custom resource definition (CRD) that is added to the Kubernetes cluster on deployment of the plugin.</p> <p>A CND contains a design of all the network services and configuration an application may need. It can be used to define EDA <code>Routers</code> and EDA <code>BridgeDomain</code> resources. For each <code>BridgeDomain</code>, it is possible to associate one or more NADs with it. By doing so, the plugin knows how to connect applications into different network services.</p> <p>In some deployment use cases, <code>preProvisionHostGroupSelector</code> can be used to pre-provision connect interface for a NAD interface on a set of selected hosts, regardless of whether they are consumed by any pod. This will consume more resources on the fabric side, but can be useful in some scenarios where pods are scheduled dynamically on different nodes and need to have immediate connectivity without waiting for the fabric to be provisioned.</p> Limitations of <code>preProvisionHostGroupSelector</code> <p>Please note that this attribute is only applicable to <code>IPVLAN</code> and <code>MACVLAN</code> type of <code>NetworkAttachmentDefinitions</code></p> <p>You can use the CMS-managed integration mode, the EDA-managed integration mode, or a combination of both.</p> <p>Multiple CNDs can exist, for instance one per application.</p> <p>The below section details a couple of examples of CND usage.</p> Example 1: Multiple <code>NADs</code> in One <code>BridgeDomain</code> Example 2: Multiple <code>NADs</code> in One <code>BridgeDomain</code> with VLAN Trunking <p>The following is a sample configuration of the CND usage to be able to have multiple <code>NetworkAttachmentDefinitions</code> be residing in a single subnet, and have them use trunk VLAN's:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd2\nspec:\n  subnets:\n    - name: \"trunked-subnet1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1-untagged\n          trunkVlans:\n            - 10\n        - name: sriov-ns1/sriov-nad1-untagged\n          trunkVlans:\n            - 20\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd2\nspec:\n  subnets:\n    - name: \"trunked-subnet1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1-untagged\n          trunkVlans:\n            - 10\n        - name: sriov-ns1/sriov-nad1-untagged\n          trunkVlans:\n            - 20\nEOF\n</code></pre> Example 3: Using EDA-managed mode with CND <p>The following is a sample configuration of the CND usage to be able to have multiple <code>NetworkAttachmentDefinitions</code> be part of a single <code>BridgeDomain</code> that was pre-created in EDA:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd3\nspec:\n  subnets:\n    - name: \"eda-managed-subnet1\"\n      linkedBridgeDomain: eda_bridgedomain_1\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: sriov-ns1/sriov-nad1\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd3\nspec:\n  subnets:\n    - name: \"eda-managed-subnet1\"\n      linkedBridgeDomain: eda_bridgedomain_1\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: sriov-ns1/sriov-nad1\nEOF\n</code></pre> Example 4: Using preProvisionHostGroupSelector to pre-provision connect interface with the label selector <p>To be able to consume this attribute in CND, ensure that the Kubernetes nodes are labelled correctly and the same value is used in the CND.</p> <p>Example of the labelling a node is as following:</p> <pre><code>kubectl label nodes node-1 connect.eda.nokia.com/hostGroup=net-group-1\nkubectl label nodes node-2 connect.eda.nokia.com/hostGroup=net-group-2\n</code></pre> <p>The following is a sample configuration of the CND usage to be able to pre-configure connect interface</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd4\nspec:\n  subnets:\n    - name: \"subnet-1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n          preProvisionHostGroupSelector: 'net-group-1'\n        - name: macvlan-ns1/macvlan-nad1\n          preProvisionHostGroupSelector: 'net-group-2'\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd4\nspec:\n  subnets:\n    - name: \"subnet-1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n          preProvisionHostGroupSelector: 'net-group-1'\n        - name: macvlan-ns1/macvlan-nad1\n          preProvisionHostGroupSelector: 'net-group-2'\n\nEOF\n</code></pre> Example 5: Multiple <code>NADs</code> in One <code>BridgeDomain</code> associated to a <code>Router</code> <p>The following is a sample configuration of the CND usage to be able to have multiple <code>NetworkAttachmentDefinitions</code> be residing in a single subnet, associated with a router:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd-router\nspec:\n  routers:\n    - name: router-1\n  subnets:\n    - name: \"subnet1\"\n      router: router-1\n      ipv4Addresses:\n        - ipPrefix: 192.168.6.0/24\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: ipvlan-ns1/ipvlan-nad2\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd-router\nspec:\n  routers:\n    - name: router-1\n  subnets:\n    - name: \"subnet1\"\n      router: router-1\n      ipv4Addresses:\n        - ipPrefix: 192.168.6.0/24\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: ipvlan-ns1/ipvlan-nad2\n\nEOF\n</code></pre>"},{"location":"connect/kubernetes-plugin/#example-1","title":"Example 1:","text":"<p>The following is a sample configuration of the CND usage to be able to have multiple <code>NetworkAttachmentDefinitions</code> be residing in a single subnet, when they belong to different master interface. This is an example of Kubernetes Managed Mode.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd1\nspec:\n  subnets:\n    - name: \"subnet1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: ipvlan-ns1/ipvlan-nad2\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: connect.eda.nokia.com/v1\nkind: ConnectNetworkDefinition\nmetadata:\n  name: cnd1\nspec:\n  subnets:\n    - name: \"subnet1\"\n      networkAttachmentDefinitions:\n        - name: ipvlan-ns1/ipvlan-nad1\n        - name: ipvlan-ns1/ipvlan-nad2\nEOF\n</code></pre>"},{"location":"connect/kubernetes-plugin/#troubleshooting","title":"Troubleshooting","text":""},{"location":"connect/kubernetes-plugin/#the-controller-plugin-is-not-running","title":"The controller plugin is not running","text":"<p>Verify the following items:</p> <ul> <li>Incorrect Service Account Token configuration.</li> <li>Check connectivity between controller pod in Kubernetes and EDA cluster.</li> <li>Ensure the heartbeat interval is a non-negative integer.</li> <li>Plugin name must comply with this regex check <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code>. It may only contain alphanumerical characters   and '.', '_', '-' (dot, underscore, and, dash) and must start and end with an alphanumerical character.</li> </ul>"},{"location":"connect/kubernetes-plugin/#nothing-is-created-in-eda","title":"Nothing is created in EDA","text":"<p>Verify the following items:</p> <ul> <li>Check if the plugin controller is able to access the <code>NMstate</code> API and <code>NetworkAttachmentDefinition</code> API on the Kubernetes cluster.</li> <li>Check the plugin can reach EDA cluster correctly.</li> </ul>"},{"location":"connect/kubernetes-plugin/#the-plugin-is-not-configuring-the-correct-state","title":"The plugin is not configuring the correct state","text":"<ul> <li>Inspect the EDA resources, like <code>VLAN</code>, <code>BridgeDomain</code> and <code>ConnectInterface</code>.</li> <li>Check the logs of the plugin pod.</li> </ul>"},{"location":"connect/nutanix-plugin-installation/","title":"Nutanix Prism Central Plugin Installation","text":"<p>Technical Preview</p> <p>The Nutanix Prism Central Plugin is currently only available as beta version for technical preview purposes. It can be used for demo, POC or lab purposes.</p> <p>The following features are not included in the technical preview:</p> <ul> <li>SR-IOV support</li> <li>NIC Offloading</li> <li>Audit</li> <li>Alarms</li> <li>Heartbeats</li> </ul> <p>This guide provides detailed instructions for installing the EDA Connect Nutanix Prism Central plugin.</p>"},{"location":"connect/nutanix-plugin-installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing or deploying the Nutanix plugin components, ensure that:</p> <ul> <li>The Cloud Connect Core application is properly installed in the cluster (see Cloud Connect Installation)</li> <li>Nutanix Prism Central is installed and accessible</li> <li>You have read-only access credentials to Nutanix Prism Central</li> <li>LLDP is enabled on all Nutanix AHV hypervisors</li> <li>Downlink Interfaces in EDA are created</li> </ul>"},{"location":"connect/nutanix-plugin-installation/#installation-steps","title":"Installation Steps","text":"<p>To deploy the Nutanix Prism Central plugin, complete the following tasks:</p> <ol> <li>Deploy the plugin EDA app</li> <li>Deploy the plugin instance</li> </ol>"},{"location":"connect/nutanix-plugin-installation/#step-1-nutanix-prism-central-plugin-app-deployment","title":"Step 1: Nutanix Prism Central Plugin App Deployment","text":"<p>The Nutanix plugin app is an application in the EDA app ecosystem. It can be easily installed using the EDA Store UI.</p>"},{"location":"connect/nutanix-plugin-installation/#installation-using-eda-store-ui","title":"Installation Using EDA Store UI","text":"<ol> <li>Navigate to the EDA Store in the EDA UI</li> <li>Locate the Nutanix Prism Central Plugin App</li> <li>Click Install</li> <li>Complete the installation</li> </ol>"},{"location":"connect/nutanix-plugin-installation/#installation-using-kubernetes-api","title":"Installation Using Kubernetes API","text":"<p>If you prefer installing the plugin using the Kubernetes API, you can do so by creating the following Workflow resource:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: nutanix-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: nutanix.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v0.0.1-beta\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: nutanix-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: nutanix.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v0.0.1-beta\n\nEOF\n</code></pre>"},{"location":"connect/nutanix-plugin-installation/#step-2-nutanix-prism-central-plugin-deployment","title":"Step 2: Nutanix Prism Central Plugin Deployment","text":""},{"location":"connect/nutanix-plugin-installation/#create-a-secret-for-prism-central-credentials","title":"Create a Secret for Prism Central Credentials","text":"<p>Before creating a <code>NutanixPluginInstance</code>, create a Kubernetes <code>Secret</code> with the Prism Central credentials:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-nutanix-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata:\n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n</code></pre> <pre><code>echo -n myUsernameOrPassword | base64\nkubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-nutanix-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata:\n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n\n\nEOF\n</code></pre> Base64 encoding <p>Use the following command to base64 encode your username and password:</p> <pre><code>echo -n myUsernameOrPassword | base64\n</code></pre> <p>mandatory label</p> <p>The secrets used by the EDA plugins must have the <code>eda.nokia.com/backup: \"true\"</code> label.</p>"},{"location":"connect/nutanix-plugin-installation/#create-the-nutanix-plugin-instance","title":"Create the Nutanix Plugin Instance","text":"<p>As the Nutanix plugins are managed through the operator, you can use the EDA UI to create a new <code>NutanixPluginInstance</code> resource under the System Administration &gt; Connect &gt; Nutanix Plugins menu item.</p> <p>As an alternative, you can also create the same <code>NutanixPluginInstance</code> using the following custom resource example. Make sure to replace the specified values with their relevant content.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: nutanix.eda.nokia.com/v1\nkind: NutanixPluginInstance\nmetadata:\n  name: my-nutanix-plugin # A unique name for the plugin resource\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  heartbeatInterval: 30\n  prismCentralHost: example-host # The IP address or FQDN of the Prism Central\n  prismCentralTlsVerify: true # To verify TLS of the Prism Central\n  prismCentralCertificate: \"\" # If the Prism Central certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-nutanix-creds # Credentials are hosted in a separate Secret\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: nutanix.eda.nokia.com/v1\nkind: NutanixPluginInstance\nmetadata:\n  name: my-nutanix-plugin # A unique name for the plugin resource\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  heartbeatInterval: 30\n  prismCentralHost: example-host # The IP address or FQDN of the Prism Central\n  prismCentralTlsVerify: true # To verify TLS of the Prism Central\n  prismCentralCertificate: \"\" # If the Prism Central certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-nutanix-creds # Credentials are hosted in a separate Secret\n\n\nEOF\n</code></pre>"},{"location":"connect/nutanix-plugin-installation/#configuration-parameters","title":"Configuration Parameters","text":"<p>The <code>NutanixPluginInstance</code> resource supports the following fields:</p> Field Description Required <code>name</code> Name of the plugin instance in EDA. Yes <code>pluginNamespace</code> The namespace in the EDA deployment holding the fabric associated with this plugin. Yes <code>prismCentralHost</code> URL of the Prism Central instance (e.g <code>https://prismcentral.mydomain.com:9440</code>). Yes <code>authSecretRef</code> Name of the Kubernetes Secret containing Prism Central credentials Yes <code>heartbeatInterval</code> Interval in seconds for plugin heartbeat to EDA (default: 30s). No <code>prismCentralTlsVerify</code> Whether to verify the TLS certificate of Prism Central (default: true). No <code>prismCentralCertificate</code> PEM encoded certificate for Prism Central if self-signed (default: empty). No"},{"location":"connect/nutanix-plugin-installation/#post-installation-verification","title":"Post-Installation Verification","text":"<p>After deploying the plugin instance, verify that it is running:</p> <pre><code>kubectl get pods -n eda-system | grep nutanix\n</code></pre> <p>Check that the plugin has registered with Connect:</p> <pre><code>kubectl get connectplugins -n &lt;plugin-namespace&gt;\n</code></pre> <p>You should see your Nutanix plugin listed with status information.</p> <p>Verify that the <code>connect.eda.nokia.com</code> category has been created in Prism Central with the standard values (<code>EDA Managed</code> and <code>EDA Ignored</code>).</p>"},{"location":"connect/nutanix-plugin-installation/#next-steps","title":"Next Steps","text":"<p>After installation, proceed to:</p> <ul> <li>Configure VLAN subnets in Prism Central</li> <li>Set up categories for EDA-managed mode (if required)</li> <li>Review the Nutanix Prism Central Plugin documentation for usage and operational modes</li> </ul>"},{"location":"connect/nutanix-plugin/","title":"Nutanix Prism Central Plugin","text":"<p>Technical Preview</p> <p>The Nutanix Prism Central Plugin is currently only available as beta version for technical preview purposes. It can be used for demo, POC or lab purposes.</p> <p>The following features are not included in the technical preview:</p> <ul> <li>SR-IOV support</li> <li>NIC Offloading</li> <li>Audit</li> <li>Alarms</li> <li>Heartbeats</li> </ul>"},{"location":"connect/nutanix-plugin/#overview","title":"Overview","text":"<p>The Nutanix Prism Central plugin integrates Nokia EDA with Nutanix Prism Central, enabling automated network provisioning and management for Nutanix environments. It supports both VLAN Basic and Advanced Networking subnets, and provides seamless connectivity between Nutanix-managed workloads and the EDA fabric.</p> <p>Key capabilities include:</p> <ul> <li>Direct integration with Nutanix Prism Central through its v4 rest API</li> <li>Automatic provisioning of the fabric based on Nutanix virtual switch and subnet configuration</li> <li>Support for VLAN Basic and Advanced Networking subnets</li> <li>Support for VPC breakout subnets (VLAN-based)</li> <li>Basic workflows managed completely through Prism Central (Prism Managed Mode)</li> <li>Advanced workflows managed through EDA (EDA Managed Mode)</li> <li>Interconnectivity between different cloud environments through EDA</li> </ul>"},{"location":"connect/nutanix-plugin/#supported-versions","title":"Supported Versions","text":"<ul> <li>Nutanix Prism Central 7.3</li> </ul>"},{"location":"connect/nutanix-plugin/#architecture","title":"Architecture","text":"<p>The Nutanix Prism Central plugin consists of two components:</p> Nutanix Prism Central Plugin App Manages the lifecycle of Nutanix plugin instances in EDA using a custom resource definition (CRD). Nutanix Prism Central Plugin <p>Connects to Prism Central, monitors configuration changes, and synchronizes state with EDA. The plugin listens for events on:</p> <ul> <li>Virtual switches</li> <li>Subnets (VLAN Basic and VLAN Advanced)</li> <li>Host NIC to virtual switch associations</li> <li>Categories (for EDA-managed mode)</li> </ul>"},{"location":"connect/nutanix-plugin/#installation","title":"Installation","text":"<p>For detailed deployment instructions, see the Nutanix Prism Central Plugin Installation Guide.</p>"},{"location":"connect/nutanix-plugin/#features","title":"Features","text":""},{"location":"connect/nutanix-plugin/#limitations","title":"Limitations","text":"<ul> <li>VM NICs in Trunked mode are not supported</li> <li>Audit functionality is not supported in the technical preview</li> <li>Heartbeats are not supported in the technical preview</li> <li>SR-IOV and NIC offloading are not supported in the technical preview</li> </ul>"},{"location":"connect/nutanix-plugin/#operational-modes","title":"Operational Modes","text":"<p>The plugin supports two operational modes for managing VLAN subnets, selectable on a per-subnet basis:</p> Prism Central-Managed Mode This is the default mode. Each VLAN subnet in Prism Central results in a unique <code>BridgeDomain</code> in EDA. The VLAN in Prism Central determines the <code>VLANs</code> managed for the <code>BridgeDomain</code>. If multiple subnets use the same VLAN on the same virtual switch, only a single <code>BridgeDomain</code> will be provisioned. The <code>BridgeDomain</code> is not routable through the fabric in this mode.  If routing is required, EDA managed mode can be used, or external routing can be provisioned in the subnet. EDA-Managed Mode Subnets can be associated with an existing EDA <code>BridgeDomain</code> by attaching the <code>connect.eda.nokia.com</code> category with key <code>EDA Managed</code> to the subnet in Prism Central. The name of the subnet must match the name of the EDA <code>BridgeDomain</code>. <p>Alternatively, subnets can be excluded from EDA management by attaching the <code>connect.eda.nokia.com</code> category with key <code>EDA Ignored</code>. An example use case for this is the initial infrastructure network hosting the CVM and Prism Central VMs.</p>"},{"location":"connect/nutanix-plugin/#using-eda-managed-mode","title":"Using EDA-Managed Mode","text":"<p>The plugin automatically creates the <code>connect.eda.nokia.com</code> category in Prism Central on startup if it does not exist. It also ensures that the two standard values, <code>EDA Managed</code> and <code>EDA Ignored</code>, are present for this category.</p> <p>To use EDA-managed mode:</p> <ol> <li>Create a <code>BridgeDomain</code> in EDA with the desired settings. This can be a <code>BridgeDomain</code> in a <code>VirtualNetwork</code> as well as a standalone <code>BridgeDomain</code>.</li> <li>In Prism Central, attach the <code>connect.eda.nokia.com</code> category to the subnet and set its value to <code>EDA Managed</code>. The name of the subnet must match    the name of the EDA <code>BridgeDomain</code>.</li> </ol> BridgeDomain not found <p>If the referenced <code>BridgeDomain</code> does not exist in EDA, the plugin raises an alarm and no connectivity can be provided for the subnet. If the BridgeDomain is created later, the plugin will automatically reconcile and establish connectivity.</p> Multiple values for connect.eda.nokia.com Category <p>If multiple values for the <code>connect.eda.nokia.com</code> category are associated with a single subnet, EDA-Ignored will get precedence.</p> Category configuration in Prism Central <p>Categories can be assigned to subnets in Prism Central via the UI or API. An example configuration using the UI is shown below: </p> <p>You can switch between EDA-managed and Prism-managed mode at any time.</p> Switching between EDA-managed and Prism-managed mode <p>When switching between the two available modes, connectivity will be temporarily disrupted while the plugin reconfigures the resources in EDA.</p>"},{"location":"connect/nutanix-plugin/#vpc-overlay-subnets","title":"VPC Overlay Subnets","text":"<p>Subnets created in a VPC are overlay (Geneve-based) and are not visible to the EDA fabric. Only breakout subnets (VLAN-based) can be managed by EDA.</p>"},{"location":"connect/nutanix-plugin/#virtual-switch-modes","title":"Virtual Switch Modes","text":"<p>A Nutanix virtual switch can operate in several modes:</p> <ul> <li>Active-Backup: Each uplink is represented as a separate <code>ConnectInterface</code>.</li> <li>Active-Active with MAC pinning: A single <code>ConnectInterface</code> is created for all uplinks, mapped to a static LAG interface in EDA.</li> <li>Active-Active with LACP: A single <code>ConnectInterface</code> is created for all uplinks, mapped to an LACP interface in EDA.</li> </ul> <p>The plugin provisions the correct <code>ConnectInterface</code> objects based on the virtual switch mode. The corresponding Interface objects in EDA must be created before installing the plugin.</p> Unsupported virtual switch modes in the technical preview <p>In the technical preview, only the Active-Backup mode is supported. Active-Active modes with MAC pinning or LACP are not supported.</p>"},{"location":"connect/nutanix-plugin/#event-monitoring","title":"Event Monitoring","text":"<p>The plugin subscribes to events in Prism Central and configures EDA resources accordingly:</p> Event Trigger Custom Resource Purpose VLAN Subnet events <code>BridgeDomain</code> Each VLAN subnet results in a unique <code>BridgeDomain</code> (Prism Central mode) VLAN Subnet events <code>VLAN</code> Each VLAN subnet creates a <code>VLAN</code> resource for attachment to the BD Host NIC virtual switch uplink events <code>ConnectInterface</code> Each host NIC uplink creates a <code>ConnectInterface</code>"},{"location":"connect/nutanix-plugin/#audit","title":"Audit","text":"<p>The plugin performs an audit on startup and when requested by the operator to ensure synchronization between Prism Central and EDA. Any discrepancies are resolved automatically. See also the audit documentation.</p>"},{"location":"connect/nutanix-plugin/#startup","title":"Startup","text":"<ul> <li>The plugin instance has registered itself with Connect using the provided <code>metadata.name</code> as the <code>ConnectPlugin</code> <code>metadata.name</code>.</li> <li>The plugin checks connectivity with Prism Central and validates the provided credentials.</li> <li>The plugin performs an audit to synchronize initial state between Prism Central and EDA.</li> <li>The plugin creates the <code>connect.eda.nokia.com</code> category in Prism Central if it does not exist.</li> </ul> Wrong credentials <p>If the provided credentials are invalid, the plugin raises an alarm and will not retry any calls to Prism Central. In the technical preview, the authSecretRef has to be corrected and the Deployment has to be restarted manually.</p>"},{"location":"connect/nutanix-plugin/#troubleshooting","title":"Troubleshooting","text":""},{"location":"connect/nutanix-plugin/#the-plugin-is-not-running","title":"The plugin is not running","text":"<ul> <li>Check plugin alarms in EDA.</li> <li>Verify connectivity from the EDA cluster to Prism Central.</li> <li>Check credentials in the Kubernetes Secret.</li> <li>Check the plugin pod logs in the <code>eda-system</code> namespace in Kubernetes.</li> </ul>"},{"location":"connect/nutanix-plugin/#the-plugin-is-not-creating-resources-in-eda","title":"The plugin is not creating resources in EDA","text":"<ul> <li>Check plugin alarms in EDA.</li> <li>Verify connectivity from the EDA cluster to Prism Central.</li> <li>Check the plugin pod logs in the <code>eda-system</code> namespace in Kubernetes.</li> <li>Check the staleness state of the plugin object in EDA.</li> </ul>"},{"location":"connect/nutanix-plugin/#the-plugin-is-not-configuring-the-correct-state","title":"The plugin is not configuring the correct state","text":"<ul> <li>Check plugin alarms in EDA.</li> <li>Verify uplink configuration for vswitches in Prism Central.</li> <li>VLAN ranges are not supported on subnets.</li> <li>Inspect EDA resources (<code>VLAN</code>, <code>BridgeDomain</code>, <code>ConnectInterface</code>).</li> <li>Check the plugin pod logs.</li> </ul>"},{"location":"connect/openstack-plugin-installation/","title":"OpenStack Plugin Installation","text":"<p>This guide provides an overview and prerequisites for installing the EDA Connect OpenStack plugin on Red Hat OpenStack Platform (RHOSP) clusters.</p>"},{"location":"connect/openstack-plugin-installation/#installation-methods","title":"Installation Methods","text":"<p>The EDA Connect OpenStack plugin can be installed using the below method:</p> <ul> <li>RHOSP 17.1 Director Installation: Automated installation using Red Hat OpenStack Platform Director (   TripleO)</li> </ul> Non-RHOSP OpenStack Distributions <p>This guide focuses on installing the EDA Connect OpenStack plugin on Red Hat OpenStack Platform 17.1. While it may be possible to adapt these instructions for other OpenStack distributions, such as vanilla OpenStack or other managed services, these environments are not officially supported. Users attempting to deploy the plugin on unsupported OpenStack distributions do so at their own risk and may encounter issues that are not covered in this documentation.</p> <p>Make sure to first follow the preparation steps outlined in this guide before proceeding with either installation method.</p>"},{"location":"connect/openstack-plugin-installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing or deploying the OpenStack plugin components, ensure that:</p> <ul> <li>The Cloud Connect Core application is properly installed in the EDA cluster (see Cloud Connect Installation)</li> <li>You have administrative access to both the EDA Kubernetes cluster and the OpenStack environment</li> <li>The fabric is provisioned and operational in EDA</li> <li>You have access to the Nokia EDA Connect OpenStack plugin container images from <code>registry.connect.redhat.com/nokia-ni</code></li> </ul>"},{"location":"connect/openstack-plugin-installation/#eda-kubernetes-preparation","title":"EDA Kubernetes Preparation","text":"<p>All installation methods require the same preparation steps on the EDA Kubernetes cluster.</p>"},{"location":"connect/openstack-plugin-installation/#create-a-service-account","title":"Create a Service Account","text":"<p>The EDA Connect OpenStack plugin uses a <code>ServiceAccount</code> in the EDA Kubernetes cluster to create the necessary resources in the EDA cluster for the integration to work properly.</p> <p>To create a service account in the EDA Kubernetes cluster, use the following resource.</p> Service Account namespace <p>This service account must be created in the <code>eda-system</code> namespace. Make sure to adapt the namespace when using a customized namespace for EDA.</p> YAML Resource<code>kubectl apply</code> command <pre><code>---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: openstack-plugin\n  namespace: eda-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: openstack-plugin\nsubjects:\n- kind: ServiceAccount\n  name: openstack-plugin\n  namespace: eda-system\nroleRef:\n  kind: ClusterRole\n  # This cluster role is assumed to be already installed by connect app.\n  name: eda-connect-plugin-cluster-role\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: openstack-plugin\n  namespace: eda-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: openstack-plugin\nsubjects:\n- kind: ServiceAccount\n  name: openstack-plugin\n  namespace: eda-system\nroleRef:\n  kind: ClusterRole\n  # This cluster role is assumed to be already installed by connect app.\n  name: eda-connect-plugin-cluster-role\n  apiGroup: rbac.authorization.k8s.io\n\nEOF\n</code></pre>"},{"location":"connect/openstack-plugin-installation/#create-a-service-account-token","title":"Create a Service Account Token","text":"<p>From the above Service Account, you need to create a Service Account Token that can be used by the plugin to connect to the EDA Kubernetes cluster. This can be done with the below manifest, which should be applied on the EDA Kubernetes cluster.</p> YAML Resource<code>kubectl apply</code> command <pre><code>---\napiVersion: v1\nkind: Secret\ntype: kubernetes.io/service-account-token\nmetadata:\n  name: openstack-plugin\n  namespace: eda-system\n  annotations:\n    kubernetes.io/service-account.name: openstack-plugin\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\n---\napiVersion: v1\nkind: Secret\ntype: kubernetes.io/service-account-token\nmetadata:\n  name: openstack-plugin\n  namespace: eda-system\n  annotations:\n    kubernetes.io/service-account.name: openstack-plugin\n\nEOF\n</code></pre> <p>After creating the Service Account Token, retrieve the actual token and CA certificate using the following commands from the <code>eda-system</code> namespace:</p> <p>Retrieve the bearer token:</p> <pre><code>kubectl get secrets/openstack-plugin -n eda-system --template={{.data.token}} | base64 --decode\n</code></pre> <p>Retrieve the CA certificate (if EDA uses a self-signed certificate):</p> <pre><code>kubectl get secrets/openstack-plugin -n eda-system -o 'template={{index .data \"ca.crt\"}}' | base64 --decode\n</code></pre> <p>These values will be needed during plugin deployment.</p> Service Account naming <p>When using the OpenStack plugin in production, it is advised to create a service account per plugin instance. This way tokens can be revoked on a per-plugin basis. If deploying multiple OpenStack clouds, create separate service accounts for each deployment.</p>"},{"location":"connect/openstack-plugin-installation/#post-installation-verification","title":"Post-Installation Verification","text":"<p>After completing either installation method, verify the deployment was successful.</p>"},{"location":"connect/openstack-plugin-installation/#verify-plugin-registration-in-eda","title":"Verify Plugin Registration in EDA","text":"<p>On the EDA Kubernetes cluster, verify the plugin has been registered:</p> <pre><code>kubectl get connectplugins -n &lt;eda-namespace&gt;\n</code></pre> <p>The expected output should show your OpenStack plugin with status <code>Ready</code>:</p> <pre><code>NAME               STATUS   AGE\nopenstack-plugin   Ready    5m\n</code></pre>"},{"location":"connect/openstack-plugin-installation/#verify-the-openstack-plugin-is-active-in-openstack","title":"Verify the OpenStack Plugin is Active in OpenStack","text":"<p>From the OpenStack undercloud or a system with access to the overcloud controllers, check the Neutron server logs to verify the EDA Connect OpenStack plugin loaded successfully:</p> <pre><code>sudo podman exec -it neutron_api grep -i \"eda_connect\" /var/log/neutron/server.log\n</code></pre> <p>You should see log entries indicating the OpenStack plugin initialized successfully and established communication with the EDA cluster.</p>"},{"location":"connect/openstack-plugin-installation/#verify-topology-discovery","title":"Verify Topology Discovery","text":"<p>Ensure LLDP is functioning properly and the OpenStack plugin can discover the network topology:</p> <pre><code>openstack eda interface mapping list\n</code></pre> <p>This command should display the discovered mappings between physical networks (physnets) and compute node interfaces.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/","title":"OpenStack Plugin RHOSP 17.1 Installation","text":"<p>This guide provides step-by-step instructions for installing the EDA Connect OpenStack plugin on Red Hat OpenStack Platform (RHOSP) 17.1 using the OpenStack Director (TripleO).</p> <p>Warning</p> <p>Before proceeding with this installation method, ensure you have completed all the prerequisites and preparation steps described in the OpenStack Plugin Installation guide.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>All prerequisites from the OpenStack Plugin Installation guide must be met</li> <li>EDA Kubernetes preparation steps (Service Account and Token) must be completed</li> <li>Red Hat OpenStack Platform Director (undercloud) is installed and operational</li> <li>Refer to   the Red Hat OpenStack Platform Director Installation Guide   for details on setting up the undercloud and overcloud</li> </ul>"},{"location":"connect/openstack-plugin-rhosp-installation/#overview","title":"Overview","text":"<p>The installation process involves the following main steps:</p> <ol> <li>Prepare custom container images that include the Nokia EDA Connect plugin</li> <li>Configure Neutron with the EDA Connect mechanism driver</li> <li>Deploy or update the overcloud with the EDA Connect integration</li> <li>Configure LLDP on all compute and controller nodes for topology discovery</li> </ol>"},{"location":"connect/openstack-plugin-rhosp-installation/#installation-steps","title":"Installation Steps","text":""},{"location":"connect/openstack-plugin-rhosp-installation/#step-1-get-container-registry-credentials","title":"Step 1: Get Container Registry Credentials","text":"<p>The EDA Connect OpenStack Plugin images are hosted on <code>registry.connect.redhat.com/nokia-ni</code> requiring authentication. You will need credentials to pull the Nokia-published container images for:</p> <ul> <li><code>neutron-server</code></li> <li><code>neutron-openvswitch-agent</code></li> </ul> Getting the container registry credentials <p>Contact your Red Hat representative to obtain the credentials for accessing the Nokia container images in the Red Hat Container Catalog.</p> <p>The credentials will be in the format of a username (or service key) and password that need to be configured in the <code>ContainerImageRegistryCredentials</code> section during OpenStack deployment.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#step-2-prepare-container-images","title":"Step 2: Prepare Container Images","text":"<p>The Nokia EDA Connect OpenStack plugin provides customized container images for <code>neutron-server</code> and <code>neutron-openvswitch-agent</code> that include the ML2 mechanism driver.</p> <p>Create a container preparation parameters file to use the Nokia-published images:</p> YAML ResourceExample file <pre><code>parameter_defaults:\n  ContainerImagePrepare:\n    - push_destination: true\n      set:\n        ceph_alertmanager_image: ose-prometheus-alertmanager\n        ceph_alertmanager_namespace: registry.redhat.io/openshift4\n        ceph_alertmanager_tag: v4.12\n        ceph_grafana_image: rhceph-6-dashboard-rhel9\n        ceph_grafana_namespace: registry.redhat.io/rhceph\n        ceph_grafana_tag: latest\n        ceph_image: rhceph-6-rhel9\n        ceph_namespace: registry.redhat.io/rhceph\n        ceph_node_exporter_image: ose-prometheus-node-exporter\n        ceph_node_exporter_namespace: registry.redhat.io/openshift4\n        ceph_node_exporter_tag: v4.12\n        ceph_prometheus_image: ose-prometheus\n        ceph_prometheus_namespace: registry.redhat.io/openshift4\n        ceph_prometheus_tag: v4.12\n        ceph_tag: latest\n        name_prefix: openstack-\n        name_suffix: ''\n        namespace: registry.redhat.io/rhosp-rhel9\n        neutron_driver: ovn\n        rhel_containers: False\n        tag: 17.1\n      excludes:\n        - neutron-server\n        - neutron-openvswitch-agent\n    - push_destination: true\n      set:\n        name_prefix: rhosp17-1-openstack-\n        name_suffix: ''\n        namespace: registry.connect.redhat.com/nokia-ni\n        neutron_driver: null\n        rhel_containers: false\n        tag: '17.1'\n      includes:\n        - neutron-server\n        - neutron-openvswitch-agent\n      tag_from_label: '{version}-{release}'\n  ContainerImageRegistryLogin: true\n  ContainerImageRegistryCredentials:\n    registry.connect.redhat.com:\n      &lt;USERNAME&gt;|&lt;SERVICE_KEY&gt;: \"&lt;PASSWORD&gt;\"\n</code></pre> <p>Create the file at <code>/home/stack/templates/container-prepare-parameters.yaml</code> and update the credentials section with your Nokia-provided credentials:</p> <pre><code>cat &gt; /home/stack/templates/container-prepare-parameters.yaml &lt;&lt;'EOF'\nparameter_defaults:\n  ContainerImagePrepare:\n    - push_destination: true\n      set:\n        ceph_alertmanager_image: ose-prometheus-alertmanager\n        ceph_alertmanager_namespace: registry.redhat.io/openshift4\n        ceph_alertmanager_tag: v4.12\n        ceph_grafana_image: rhceph-6-dashboard-rhel9\n        ceph_grafana_namespace: registry.redhat.io/rhceph\n        ceph_grafana_tag: latest\n        ceph_image: rhceph-6-rhel9\n        ceph_namespace: registry.redhat.io/rhceph\n        ceph_node_exporter_image: ose-prometheus-node-exporter\n        ceph_node_exporter_namespace: registry.redhat.io/openshift4\n        ceph_node_exporter_tag: v4.12\n        ceph_prometheus_image: ose-prometheus\n        ceph_prometheus_namespace: registry.redhat.io/openshift4\n        ceph_prometheus_tag: v4.12\n        ceph_tag: latest\n        name_prefix: openstack-\n        name_suffix: ''\n        namespace: registry.redhat.io/rhosp-rhel9\n        neutron_driver: ovn\n        rhel_containers: False\n        tag: 17.1\n      excludes:\n        - neutron-server\n        - neutron-openvswitch-agent\n    - push_destination: true\n      set:\n        name_prefix: rhosp17-1-openstack-\n        name_suffix: ''\n        namespace: registry.connect.redhat.com/nokia-ni\n        neutron_driver: null\n        rhel_containers: false\n        tag: '17.1'\n      includes:\n        - neutron-server\n        - neutron-openvswitch-agent\n      tag_from_label: '{version}-{release}'\n  ContainerImageRegistryLogin: true\n  ContainerImageRegistryCredentials:\n    registry.connect.redhat.com:\n      &lt;USERNAME&gt;|&lt;SERVICE_KEY&gt;: \"&lt;PASSWORD&gt;\"\n\n\nEOF\n</code></pre> <p>Default values of the container preparation parameters file</p> <p>The values provided here are only examples. The example is based on the default RHOSP 17.1 template. If you have a customized deployment, ensure to adjust the values accordingly. </p> Container Registry Credentials <p>Replace <code>&lt;USERNAME&gt;|&lt;SERVICE_KEY&gt;</code> and <code>&lt;PASSWORD&gt;</code> with the credentials provided by Red Hat for accessing the container registry. See the Get Container Registry Credentials section for more information.</p> <p>Run the container image prepare command to generate the image list:</p> <pre><code>openstack tripleo container image prepare \\\n    -e /home/stack/templates/container-prepare-parameters.yaml \\\n    --output-env-file /home/stack/templates/overcloud-images.yaml\n</code></pre>"},{"location":"connect/openstack-plugin-rhosp-installation/#step-3-configure-eda-ca-certificate-if-required","title":"Step 3: Configure EDA CA Certificate (If required)","text":"<p>If your EDA Kubernetes cluster uses a self-signed certificate, you must inject the certificate authority into the overcloud image.</p> <p>Create a file at <code>/home/stack/templates/inject-trust-anchor.yaml</code>:</p> YAML ResourceExample file <pre><code>parameter_defaults:\n  # Map containing the CA certs and information needed for deploying them.\n  # Type: json\n  CAMap:\n    eda.crt:\n      content: |\n        -----BEGIN CERTIFICATE-----\n        &lt;EDA_CA_CERTIFICATE_CONTENT&gt;\n        -----END CERTIFICATE-----\n</code></pre> <pre><code>cat &gt; /home/stack/templates/inject-trust-anchor.yaml &lt;&lt;EOF\nparameter_defaults:\n  # Map containing the CA certs and information needed for deploying them.\n  # Type: json\n  CAMap:\n    eda.crt:\n      content: |\n        -----BEGIN CERTIFICATE-----\n        &lt;EDA_CA_CERTIFICATE_CONTENT&gt;\n        -----END CERTIFICATE-----\n\n\nEOF\n</code></pre> <p>Replace <code>&lt;EDA_CA_CERTIFICATE_CONTENT&gt;</code> with the CA certificate content obtained earlier using:</p> <pre><code>kubectl get secrets/openstack-plugin -n eda-system -o 'template={{index .data \"ca.crt\"}}' | base64 --decode\n</code></pre> Official CA certificates <p>If the EDA Kubernetes cluster uses certificates signed by a well-known certificate authority that is already trusted by the overcloud nodes, you can skip this step and omit the <code>ca_cert_path</code> parameter from the Neutron configuration.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#step-4-configure-neutron-for-eda-connect","title":"Step 4: Configure Neutron for EDA Connect","text":"<p>Create an environment file at <code>/home/stack/templates/neutron-eda-connect-config.yaml</code> with the EDA Connect plugin configuration:</p> YAML ResourceExample file <pre><code>parameter_defaults:\n  ControllerExtraConfig:\n    neutron::config::plugin_ml2_config:\n      DEFAULT/nic_mapping_provisioning:\n        value: 'True'\n      ml2_eda_connect/plugin_name:\n        value: '&lt;OPENSTACK_PLUGIN_NAME&gt;'\n      ml2_eda_connect/api_host:\n        value: 'https://api.eda.example.com:6443'\n      ml2_eda_connect/api_namespace:\n        value: 'default'\n      ml2_eda_connect/api_token:\n        value: '&lt;SERVICE_ACCOUNT_TOKEN&gt;'\n      ml2_eda_connect/ca_cert_path:\n        value: '/etc/pki/ca-trust/source/anchors/eda.crt.pem'\n  NeutronFirewallDriver: openvswitch\n  NeutronOVSFirewallDriver: openvswitch\n  NeutronServicePlugins: router,segments,trunk,qos,network_segment_range,port_forwarding,conntrack_helper,nic_mapping,log\n  NeutronTypeDrivers: vxlan,vlan,flat,gre\n  NeutronNetworkType: vlan,vxlan\n  NeutronMechanismDrivers: eda_connect,openvswitch,sriovnicswitch,l2population\n  NeutronAgentExtensions: nic-mapping,qos\n  NeutronPluginExtensions: eda_network,qos,port_security,tag_ports_during_bulk_creation,dns_domain_keywords\n</code></pre> <pre><code>cat &gt; /home/stack/templates/neutron-eda-connect-config.yaml &lt;&lt;'EOF'\nparameter_defaults:\n  ControllerExtraConfig:\n    neutron::config::plugin_ml2_config:\n      DEFAULT/nic_mapping_provisioning:\n        value: 'True'\n      ml2_eda_connect/plugin_name:\n        value: '&lt;OPENSTACK_PLUGIN_NAME&gt;'\n      ml2_eda_connect/api_host:\n        value: 'https://api.eda.example.com:6443'\n      ml2_eda_connect/api_namespace:\n        value: 'default'\n      ml2_eda_connect/api_token:\n        value: '&lt;SERVICE_ACCOUNT_TOKEN&gt;'\n      ml2_eda_connect/ca_cert_path:\n        value: '/etc/pki/ca-trust/source/anchors/eda.crt.pem'\n  NeutronFirewallDriver: openvswitch\n  NeutronOVSFirewallDriver: openvswitch\n  NeutronServicePlugins: router,segments,trunk,qos,network_segment_range,port_forwarding,conntrack_helper,nic_mapping,log\n  NeutronTypeDrivers: vxlan,vlan,flat,gre\n  NeutronNetworkType: vlan,vxlan\n  NeutronMechanismDrivers: eda_connect,openvswitch,sriovnicswitch,l2population\n  NeutronAgentExtensions: nic-mapping,qos\n  NeutronPluginExtensions: eda_network,qos,port_security,tag_ports_during_bulk_creation,dns_domain_keywords\n\n\nEOF\n</code></pre> <p>Update the following parameters in the file:</p> <code>ml2_eda_connect/plugin_name</code> A unique name for this OpenStack deployment within EDA (e.g., <code>openstack-plugin</code> or <code>rhosp-prod</code>) <p>Plugin Name Requirements</p> <p>The plugin name must comply with the regex check of <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code> and can only contain alphanumerical characters and <code>.</code>, <code>_</code> and <code>-</code>. It must start with an alphanumerical character, and have a length of 63 characters or fewer.</p> <code>ml2_eda_connect/api_host</code> The API endpoint of the EDA Kubernetes cluster (e.g., <code>https://api.eda.example.com:6443</code>) <code>ml2_eda_connect/api_namespace</code> The namespace in EDA where the fabric is configured (e.g., <code>default</code> or your custom namespace) <code>ml2_eda_connect/api_token</code> The bearer token obtained from the service account token secret in the Create a Service Account Token section <code>ml2_eda_connect/ca_cert_path</code> Path to the CA certificate file (use <code>/etc/pki/ca-trust/source/anchors/eda.crt.pem</code> if injecting the certificate, or omit if using a trusted CA) Additional Configuration Parameters explained <ul> <li>NIC Mapping Provisioning: Enables the automatic discovery of the physical NIC to Neutron network topology</li> <li>Mechanism Drivers: The <code>eda_connect</code> driver must be listed to enable fabric orchestration</li> <li>Service Plugins: The <code>nic_mapping</code> plugin is required for topology discovery</li> <li>Plugin Extensions: The <code>eda_network</code> extension enables EDA-managed networking features</li> </ul> <p>Example values</p> <p>The values provided here are only examples. The example is based on the default RHOSP 17.1 template. If you have a customized deployment, ensure to adjust the values accordingly.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#step-5-configure-nic-bonding-optional","title":"Step 5: Configure NIC Bonding (Optional)","text":"<p>If your deployment uses bonded interfaces for high availability or increased bandwidth, configure the appropriate bond type in your NIC configuration templates.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#linux-bonds-for-virtio-and-sr-iov","title":"Linux Bonds (for VIRTIO and SR-IOV)","text":"<p>For active-backup mode Linux bonds an example configuration is as follows:</p> <pre><code>- type: linux_bond\n  name: bond1\n  bonding_options: \"mode=active-backup miimon=100\"\n  use_dhcp: false\n  mtu: 9000\n  members:\n    - type: interface\n      name: nic2\n      primary: true\n      mtu: 9000\n    - type: interface\n      name: nic3\n      mtu: 9000\n</code></pre> <p>Supported bonding modes:</p> <ul> <li><code>mode=active-backup</code>: Active/standby failover</li> <li><code>mode=802.3ad</code>: LACP-based link aggregation</li> </ul> <p>Note</p> <p>For active-backup mode, no LAG configuration is required in EDA. For 802.3ad mode, configure a LAG with LACP settings in the EDA <code>Interfaces</code>.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#ovs-dpdk-bonds","title":"OVS DPDK Bonds","text":"<p>For balance-tcp mode with LACP an example is as follows:</p> <pre><code>- type: ovs_dpdk_bond\n  name: bond1\n  mtu: 9000\n  ovs_options: \"bond_mode=balance-tcp lacp=active other-config:lacp-fallback-ab=true other_config:lacp-time=fast\"\n  members:\n    - type: ovs_dpdk_port\n      name: ens3f0np0\n      driver: mlx5_core\n      members:\n        - type: interface\n          name: ens3f0np0\n    - type: ovs_dpdk_port\n      name: ens3f1np1\n      driver: mlx5_core\n      members:\n        - type: interface\n          name: ens3f1np1\n</code></pre> <p>Supported bonding modes:</p> <ul> <li><code>bond_mode=active-backup</code>: Active/standby failover</li> <li><code>bond_mode=balance-tcp</code> with <code>lacp=active</code>: LACP-based load balancing</li> </ul> <p>Note</p> <p>For balance-tcp mode with LACP, configure a LAG with LACP settings in the EDA <code>Interfaces</code>.</p> <p>Example Bond Configuration</p> <p>Make sure to adapt the above examples to your specific deployment and bonding requirements.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#step-6-deploy-or-update-the-overcloud","title":"Step 6: Deploy or Update the Overcloud","text":"<p>Add the environment files created above to your <code>openstack overcloud deploy</code> command:</p> <pre><code>openstack overcloud deploy \\\n    --log-file overcloud_deployment.log \\\n    --templates /usr/share/openstack-tripleo-heat-templates/ \\\n    --stack overcloud \\\n    -n /home/stack/templates/network_data.yaml \\\n    -r /home/stack/templates/roles_data.yaml \\\n    -e /home/stack/templates/overcloud-baremetal-deployed.yaml \\\n    -e /home/stack/templates/overcloud-networks-deployed.yaml \\\n    -e /home/stack/templates/overcloud-vip-deployed.yaml \\\n    -e /home/stack/templates/overcloud-images.yaml \\\n    -e /home/stack/templates/neutron-eda-connect-config.yaml \\\n    -e /home/stack/templates/inject-trust-anchor.yaml\n</code></pre> Environment file order <p>The order of environment files matters. Ensure that:</p> <ol> <li><code>overcloud-images.yaml</code> is included to use the Nokia container images</li> <li><code>neutron-eda-connect-config.yaml</code> comes after any base Neutron configuration</li> <li><code>inject-trust-anchor.yaml</code> is included if using self-signed certificates</li> </ol> Updating an existing deployment <p>If updating an existing overcloud deployment, you can use the <code>openstack overcloud update</code> command instead. Make sure to include all the environment files from the original deployment plus the new EDA Connect configuration files.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#step-7-configure-lldp-on-overcloud-nodes","title":"Step 7: Configure LLDP on Overcloud Nodes","text":"<p>After the overcloud deployment completes, LLDP must be enabled on all data plane interfaces of the controllers and computes for topology discovery.</p> <p>Create an Ansible playbook file at <code>/home/stack/post-overcloud-lldp.yaml</code>:</p> YAML ResourceExample file <pre><code>---\n- hosts: neutron_ovs_agent,neutron_ovs_dpdk_agent\n  gather_facts: no\n  become: true\n  tasks:\n    - name: Make sure the lldpd package is installed\n      package:\n        name:\n          - lldpd\n        state: present\n    - name: Make sure lldpd service is enabled/running\n      service:\n        name: lldpd\n        state: started\n        enabled: yes\n    - name: Configure portID TLV value\n      command: lldpcli configure lldp portidsubtype ifname\n    - name: Configure lldpd interface pattern\n      command: lldpcli configure system interface pattern {{ nic_pattern | default('em*,en*,p*,!en*v*,!p*v*') }}\n</code></pre> <pre><code>cat &gt; /home/stack/post-overcloud-lldp.yaml &lt;&lt;'EOF'\n---\n- hosts: neutron_ovs_agent,neutron_ovs_dpdk_agent\n  gather_facts: no\n  become: true\n  tasks:\n    - name: Make sure the lldpd package is installed\n      package:\n        name:\n          - lldpd\n        state: present\n    - name: Make sure lldpd service is enabled/running\n      service:\n        name: lldpd\n        state: started\n        enabled: yes\n    - name: Configure portID TLV value\n      command: lldpcli configure lldp portidsubtype ifname\n    - name: Configure lldpd interface pattern\n      command: lldpcli configure system interface pattern {{ nic_pattern | default('em*,en*,p*,!en*v*,!p*v*') }}\n\n\nEOF\n</code></pre> <p>Run the playbook against the overcloud inventory:</p> <pre><code>ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook -v \\\n    -i ~/overcloud-deploy/overcloud/config-download/overcloud/tripleo-ansible-inventory.yaml \\\n    /home/stack/post-overcloud-lldp.yaml\n</code></pre> LLDP package requirements <p>The playbook depends on the availability of the <code>lldpd</code> package on overcloud nodes. Overcloud nodes must be registered to Red Hat Subscription Manager (RHSM) to install the package. Alternatively, you can modify the overcloud image to include the <code>lldpd</code> package before deployment.</p> Customizing interface patterns <p>The default interface pattern <code>em*,en*,p*,!en*v*,!p*v*</code> matches most physical interfaces while excluding virtual interfaces. You can override this by passing the <code>nic_pattern</code> variable to the playbook:</p> <pre><code>ansible-playbook -v -i &lt;inventory&gt; post-overcloud-lldp.yaml -e \"nic_pattern='ens*,eno*'\"\n</code></pre>"},{"location":"connect/openstack-plugin-rhosp-installation/#post-installation-configuration","title":"Post-Installation Configuration","text":""},{"location":"connect/openstack-plugin-rhosp-installation/#verify-lldp-is-functioning","title":"Verify LLDP is Functioning","text":"<p>On one of the overcloud compute or controller nodes, verify LLDP is transmitting and receiving:</p> <pre><code>sudo lldpcli show neighbors\n</code></pre> <p>You should see the connected fabric switches listed as neighbors.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#verify-topology-discovery","title":"Verify Topology Discovery","text":"<p>From the undercloud or a system with OpenStack client access, verify the NIC mapping has been discovered:</p> <pre><code>openstack eda interface mapping list\n</code></pre> <p>This should display the discovered mappings between physical networks and compute node interfaces.</p>"},{"location":"connect/openstack-plugin-rhosp-installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"connect/openstack-plugin-rhosp-installation/#neutron-server-fails-to-start","title":"Neutron Server Fails to Start","text":"<p>If the Neutron server container fails to start, check the logs:</p> <pre><code>sudo podman logs neutron_api\n</code></pre> <p>Common issues:</p> <ul> <li>Invalid API token: Verify the token is correct and not expired</li> <li>Cannot reach EDA API: Check network connectivity and the API host URL</li> <li>Certificate validation errors: Ensure the CA certificate is correctly injected</li> </ul>"},{"location":"connect/openstack-plugin-rhosp-installation/#lldp-not-discovering-topology","title":"LLDP Not Discovering Topology","text":"<p>If topology discovery is not working:</p> <ol> <li> <p>Verify LLDP is running on overcloud nodes:    <pre><code>sudo systemctl status lldpd\n</code></pre></p> </li> <li> <p>Check LLDP is configured with the correct interface pattern:    <pre><code>sudo lldpcli show configuration\n</code></pre></p> </li> <li> <p>Verify the fabric switches have LLDP enabled on the interfaces connected to OpenStack nodes</p> </li> </ol>"},{"location":"connect/openstack-plugin-rhosp-installation/#networks-not-creating-bridgedomains-in-eda","title":"Networks Not Creating BridgeDomains in EDA","text":"<p>If OpenStack networks are not creating corresponding BridgeDomains in EDA:</p> <ol> <li> <p>Check the Neutron controller logs for errors:</p> </li> <li> <p>Verify the ConnectPlugin is registered and healthy in EDA:    <pre><code>kubectl get connectplugins -n &lt;eda-namespace&gt; -o yaml\n</code></pre></p> </li> <li> <p>Ensure the network is created with <code>provider-network-type vlan</code> (the plugin only manages VLAN networks)</p> </li> </ol>"},{"location":"connect/openstack-plugin-rhosp-installation/#updating-the-bearer-token-after-installation","title":"Updating the Bearer Token After Installation","text":"<p>If you need to update the bearer token after installation:</p> <ol> <li>Update the configuration file on all controller nodes at <code>/var/lib/config-data/puppet-generated/neutron/etc/neutron/plugins/ml2/ml2_conf.ini</code>:</li> </ol> <pre><code>[ml2_eda_connect]\napi_token = &lt;new_api_token&gt;\n</code></pre> <ol> <li>Restart the Neutron server container on all controllers</li> </ol>"},{"location":"connect/openstack-plugin/","title":"OpenStack Plugin","text":""},{"location":"connect/openstack-plugin/#overview","title":"Overview","text":"<p>EDA Cloud Connect integrates with OpenStack to provide fabric level application networks for OpenStack virtual machines. The EDA Cloud Connect integration leverages the OpenStack Neutron architecture to support managing the fabric directly from OpenStack and make the fabric dynamically respond to the networking needs of the application.</p> <p>It provides the following advantages and capabilities:</p> <ul> <li>Direct integration into the network management workflow of OpenStack.</li> <li>The use of the common ML2 plugins used by enterprise applications and VNFs like OVS, OVS-DPDK and SR-IOV.</li> <li>Support for multiple operational modes, (See also Operational Modes.</li> <li>OpenStack-managed: Automatic provisioning of the fabric based on where the virtual machines need the connectivity.</li> <li>EDA-managed: Support advanced workflows directly through EDA, including for VNF use cases with features like QoS, ACLs, and BGP PE-CE.</li> <li>Interconnectivity between different cloud environments, allowing for flexible network configurations.</li> </ul>"},{"location":"connect/openstack-plugin/#supported-versions","title":"Supported Versions","text":"<ul> <li>Red Hat OpenStack Platform (RHOSP) 17.1</li> </ul>"},{"location":"connect/openstack-plugin/#architecture","title":"Architecture","text":"<p>The OpenStack Plugin deploys some components into the OpenStack environment to allow the management of the SR Linux based fabric through OpenStack. Below is an overview of these components:</p>"},{"location":"connect/openstack-plugin/#the-connect-ml2-mechanism-driver","title":"The Connect ML2 mechanism driver","text":"<p>The Connect ML2 mechanism driver plugin is the heart of the integration between OpenStack and EDA. This plugin integrates with OpenStack Neutron and reacts to the creation of Networks, Network Segments and VM ports.</p> <p>Whenever a network segment is created in OpenStack Neutron, a matching <code>BridgeDomain</code> and <code>VLAN</code> is created in EDA.</p> <p>When a VM port is created inside a Neutron Subnet and the VM is started on an OpenStack compute node, the OpenStack plugin learns on which compute node the VM is deployed and through the internal topology ensures the necessary <code>ConnectInterfaces</code> are configured in EDA.</p> <p>The internal topology is learned from the L2 Agent extension which stores the Neutron Network to physical interfaces mapping in the Neutron database. This is then provided to the Connect service and together with the LLDP information of the fabric, the Connect service knows which downlinks in the fabrics need to be configured.</p>"},{"location":"connect/openstack-plugin/#the-connect-l2-agent-extension","title":"The Connect L2 Agent Extension","text":"<p>The Connect L2 Agent Extensions extend the already existing L2 Agent that is present on every OpenStack compute. These extensions are responsible for mapping the relation between the physical NICs and the different networking constructs setup for the Neutron networks.</p>"},{"location":"connect/openstack-plugin/#installation","title":"Installation","text":"<p>For detailed deployment instructions, see the OpenStack Plugin Installation Guide.</p>"},{"location":"connect/openstack-plugin/#features","title":"Features","text":""},{"location":"connect/openstack-plugin/#operational-modes","title":"Operational Modes","text":"<p>The plugin supports two operational modes for managing networking, selectable on a per-network basis:</p>"},{"location":"connect/openstack-plugin/#openstack-managed-networks","title":"OpenStack managed networks","text":"<p>In OpenStack managed mode, all networking is defined in OpenStack. The standard API commands for creating networks and subnets remain valid.</p> <p>For each VLAN segment created in OpenStack, a corresponding <code>BridgeDomain</code> will be created in EDA.</p> default network type <p>Neutron defines the default network type for tenant networks. If you want non-administrators to create their own networks that are offloaded to the EDA fabric, the network type must be set to 'vlan'. However, if only administrators need this capability, then the network type can be left to its default, since administrators can specify the network type as part of network creation.</p> <p>In Openstack managed mode only layer 2 <code>BridgeDomains</code> are defined in EDA. Layer 3 connectivity such as routing and floating ips  is however supported through the usual OpenStack routing implementation. These layer 3 capabilities are then not supported by the fabric, but purely software defined.</p>"},{"location":"connect/openstack-plugin/#eda-managed-networks","title":"EDA managed networks","text":"<p>In addition to the OpenStack managed networking model, Connect supports networking managed by EDA itself. In this case, <code>VNET</code> or <code>BridgeDomain</code> resources are created first in EDA directly, and then are consumed in OpenStack.</p> <p>To support EDA managed networking, a proprietary extension has been added to Network: <code>eda_bridge_domain</code>. This refers to the <code>Name</code> of a <code>BridgeDomain</code> you want to link the network to.</p>"},{"location":"connect/openstack-plugin/#using-the-eda-managed-operational-mode","title":"Using the EDA Managed operational mode","text":"<p>Step 1 - Using the EDA rest API, the Kubernetes interface or the UI: Create a VNET with BridgeDomain or a standalone BridgeDomain.</p> <p>Step 2 - Obtain the name of the resources.</p> EDA managed networking and namespaces <p>The Connect OpenStack plugin can only see resources in its own namespace, cross namespace referencing is not supported.</p> <p>Step 3 - Create OpenStack resources.</p> <p>An example workflow is included below:</p> <ul> <li>In OpenStack create the consuming network, linking it to the pre-created entity.   <code>openstack network create --eda-bridge-domain xyz os-network-1</code></li> </ul> Granularity at the network segment level <p>Since BridgeDomains are actually mapped at the network segment level, you can also specify --eda-bridge-domain when creating a network segment.</p> <p><code>openstack network segment create --network os-network-1 --network-type vlan --eda-bridge-domain xyz os-network-segment-1</code></p> <ul> <li> <p>Create a subnet within this network using the standard API syntax. For example:   <code>openstack subnet create --network os-network-1 --subnet-range 10.10.1.0/24 os-subnet-1</code></p> </li> <li> <p>Create a Neutron port and Nova server within this network and subnet also uses standard APIs.</p> </li> </ul> <p>The OpenStack plugin will handle the creation of <code>VLAN</code> and <code>ConnectInterface</code> resources as in the OpenStack managed use case. However, the <code>BridgeDomain</code> will be fully owned by the operator.</p>"},{"location":"connect/openstack-plugin/#virtualization-and-network-types","title":"Virtualization and network types","text":"<p>The EDA Connect OpenStack plugin supports the following segmentation types:</p> <ul> <li>VLAN: The plugin orchestrates on VLAN neutron networks, programming the EDA Cloud Connect service for fabric-offloaded forwarding.</li> <li>VXLAN and GRE: The plugin will not orchestrate on VXLAN or GRE neutron networks, but it is designed to be tolerant to other Neutron ML2 mechanism   drivers.</li> </ul> VXLAN and GRE management <p>When utilising another ML2 mechanism driver to provision these networks, make sure to create the relevant <code>VNET</code> or <code>BridgeDomain</code> and <code>VLAN</code> resources in EDA, as the plugin will not automatically take care of those. Typically, these will utilise the <code>untagged</code> VLAN to communicate between the nodes.</p> <p>The OpenStack plugin also supports the following virtualization types:</p> <ul> <li>VIRTIO</li> <li>SR-IOV</li> <li>DPDK</li> </ul>"},{"location":"connect/openstack-plugin/#bonding","title":"Bonding","text":"<p>The OpenStack plugin supports the following OpenStack supported bonding models:</p> <ul> <li>Active/Backup linuxbonds with:<ul> <li>VIRTIO</li> <li>SR-IOV</li> </ul> </li> </ul> <p>When an Active/Backup bond is used on the compute mode, the corresponding <code>Interfaces</code> should not be configured as LAGs in EDA.  Each physical interface in the bond should be represented as a separate <code>Interface</code> in EDA.</p> <ul> <li>Active/Active LACP OVS bonds with:<ul> <li>VIRTIO</li> <li>SR-IOV</li> <li>DPDK</li> </ul> </li> </ul> Active/Active VIRTIO/SR-IOV support <p>Active/Active for VIRTIO and SR-IOV ports is supported by the OpenStack plugin, but might not be in your deployment model.</p> <p>When an Active/Active bond is used on the compute node, a corresponding LAG <code>Interface</code> must be configured in EDA. All physical interfaces should be added to a single <code>Interface</code>.</p>"},{"location":"connect/openstack-plugin/#trunking","title":"Trunking","text":"<p>The network trunk service allows multiple networks to be connected to an instance using a single virtual NIC (vNIC). Multiple networks can be presented to an instance by connecting it to a single port.</p> <p>For details about the configuration and operation of the network trunk service, see https://docs.openstack.org/neutron/wallaby/admin/config-trunking.html.</p> <p>Trunking is supported for VRTIO, DPDK and SR-IOV.</p> <ul> <li>For vnic_type=normal ports (VIRTIO/DPDK), trunking is supported through an upstream openvswitch trunk driver.</li> <li>For vnic_type=direct ports (SR-IOV), trunking is supported by the EDA Connect trunk driver.</li> </ul> Trunks with SR-IOV ports <p>Using trunks with SR-IOV has some limitations with regard to the upstream OVS trunk model:</p> <ul> <li>Both parent ports of the trunk and all subports must be created with vnic_type 'direct'.</li> <li>To avoid the need for QinQ on switches, trunks for the SR-IOV instance must be created with parent port belonging to a flat network (untagged).</li> <li>If multiple projects within a deployment must be able to use trunks, the Neutron network above must be created as shared (using the --share   attribute).</li> <li>When adding subports to a trunk, their segmentation-type must be specified as VLAN and their segmentation-id must be equal to a segmentation-id of   the Neutron network that the subport belongs to.</li> </ul>"},{"location":"connect/openstack-plugin/#network-vlan-segmentation-and-vlan-segregation","title":"Network VLAN segmentation and VLAN segregation","text":"<p>The OpenStack plugin only acts on VLAN Neutron networks. To use VLAN networking, configure <code>provider_network_type = vlan</code>.</p> <p>Some OpenStack deployments apply an interconnected bridge model on the OpenStack controller nodes to support multi-physnet host interfaces and be more economical on the physical NIC's usage. As a result, when VLAN networks with overlapping segmentation IDs across physnets are applied, care must be taken that no overlapping segmentation IDs are wired on a host interface. Such a configuration would not be supported by the SR Linux fabric (or any other fabric).</p> <p>A typical case for this to arise would be if DHCP is enabled on the subnets created on segmentation-ID overlapping networks, as the Neutron DHCP agent on the OpenStack controller nodes would effectively end up in the described conflicting state. This can be avoided by disabling DHCP on the subnets, that is, defining the subnet with dhcp_enable = False. Even when DHCP is not effectively consumed by any VNF deployed in the related networks, the conflict would still occur when DHCP is enabled on the subnets.</p> <p>If the deployment use cases demand this wiring (for example, some of the deployed VNFs rely on DHCP), the system's VLAN ranges must be segregated per physical network in the neutron/ML2 configuration.</p>"},{"location":"connect/openstack-plugin/#edge-topology-introspection","title":"Edge Topology Introspection","text":""},{"location":"connect/openstack-plugin/#automated-edge-topology-introspection","title":"Automated Edge Topology Introspection","text":"<p>When the nic-mapping agent extension is enabled, it will persist the physnet &lt;-&gt; compute,interface relation in the Neutron database so it can wire Neutron ports properly in the Fabric.</p> <p>The known interface mappings can be consulted using the CLI command <code>openstack eda interface mapping list</code>.</p>"},{"location":"connect/openstack-plugin/#lldp-provisioning","title":"LLDP Provisioning","text":"<p>LLDP must be enabled on all data plane interfaces of the controllers and computes for topology discovery. See the Installation Guide for details on configuring LLDP.</p>"},{"location":"connect/openstack-plugin/#audit","title":"Audit","text":"<p>On Highly Available (HA) Openstack deployments, if multiple audit requests are created concurrently, they might be processed concurrently by different Neutron instances. This can lead to a situation when multiple processing instances compete to correct the same discrepancy, yielding unpredictable results. It is recommended to ensure no Audit exist in Connect in <code>InProgress</code> state prior to creating a new Audit request.</p>"},{"location":"connect/troubleshooting/","title":"Troubleshooting Cloud Connect","text":""},{"location":"connect/troubleshooting/#cloud-connect-custom-resources","title":"Cloud Connect Custom Resources","text":"<p>Connect will introduce and expose four new CRDs in EDA and the EDA Kubernetes environment:</p> <ul> <li><code>ConnectPlugin</code> - The logical representation of a plugin, created and managed by a running plugin.</li> <li><code>ConnectPluginActionable</code> - An actionable is an action that a plugin must take. This can be created by the Connect Core itself or by a user who   wants to trigger the action.</li> <li><code>ConnectPluginHeartbeat</code> - A plugin sends heartbeats at a well-defined interval, and by doing so, updates this resources linked to its   <code>ConnectPlugin</code>. When a plugin does not send heartbeats for a while (three times the expected interval), an alarm will be raised by the Core.</li> <li><code>ConnectInterface</code> - The logical representation of a physical interface of a bare metal compute. The labels on the <code>ConnectInterface</code> are used to   label the matching EDA <code>Interface</code>, so that they can be used as sub-interface label selectors for EDA <code>BridgeDomains</code>.</li> </ul>"},{"location":"connect/troubleshooting/#problem-missing-connectplugin-for-deployed-plugin","title":"Problem: Missing <code>ConnectPlugin</code> for deployed plugin","text":"<p>This problem is only applicable for plugins that are deployed outside the EDA Kubernetes cluster, for example, the OpenShift or OpenStack plugin. This indicates a connection problem from the plugin towards the EDA Kubernetes cluster. Verify the following information:</p> <ul> <li>Check the plugin logs for error messages.</li> <li>Verify the plugin's configuration, especially the Kubernetes information (location/URL, certificates, user certificates, and so forth).</li> </ul>"},{"location":"connect/troubleshooting/#problem-application-connectivity","title":"Problem: Application connectivity","text":"<p>An application missing connectivity can have multiple causes; here are some of the most common:</p> <ul> <li>Check whether there are any alarms reported in EDA.</li> <li>Check whether there are any transaction results in FAILED state. You can check this with <code>kubectl get transactions -A</code> or   <code>edactl transaction kubernetes-pending</code></li> <li>Check whether the bridge domain and VLAN are up, and the VLAN is showing the expected number of UP subinterfaces</li> <li>Check the <code>ConnectInterface</code> corresponding to the hypervisor NIC where you expect to see traffic.<ul> <li>If no <code>ConnectInterface</code> can be found, check the plugin. It is responsible for creating the <code>ConnectInterface</code>.</li> <li>If a <code>ConnectInterface</code> can be found, check the status.<ul> <li>If it is '', the connect-interface-controller is not online.</li> <li>If it is 'Disconnected', it cannot find an interface to label.</li> </ul> </li> </ul> </li> <li>Check the interface corresponding to the NIC on the SRL that is connected to the relevant hypervisor.<ul> <li>If it is not found: the operator has to create the \"downlink\" interfaces</li> <li>If it is found: check the status<ul> <li>If no members with the LLDP information are found, check the LLDP process on the hypervisor and on the SRL node</li> </ul> </li> </ul> </li> </ul>"},{"location":"connect/vmware-nsx-installation/","title":"VMware NSX Plugin Installation","text":"<p>This guide provides detailed instructions for installing the EDA Connect VMware NSX plugin.</p>"},{"location":"connect/vmware-nsx-installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing or deploying the VMware NSX plugin components, ensure that:</p> <ul> <li>The Cloud Connect Core application is properly installed in the cluster (see Cloud Connect Installation)</li> <li>VMware vSphere Plugin is deployed for each vCenter managed by NSX (see VMware vSphere Plugin Installation)</li> <li>You have read-only access credentials to the VMware NSX environment</li> </ul>"},{"location":"connect/vmware-nsx-installation/#installation-steps","title":"Installation Steps","text":"<p>To deploy the VMware NSX plugin, complete the following tasks:</p> <ol> <li>Deploy the plugin app</li> <li>Deploy the plugin instance</li> </ol>"},{"location":"connect/vmware-nsx-installation/#step-1-connect-vmware-nsx-plugin-app-deployment","title":"Step 1: Connect VMware NSX Plugin App Deployment","text":"<p>The VMware NSX plugin app is an application in the EDA app ecosystem. It can be easily installed using the EDA Store UI.</p>"},{"location":"connect/vmware-nsx-installation/#installation-using-eda-store-ui","title":"Installation Using EDA Store UI","text":"<ol> <li>Navigate to the EDA Store in the EDA UI</li> <li>Locate the VMware NSX Plugin App</li> <li>Click Install</li> <li>Complete the installation</li> </ol>"},{"location":"connect/vmware-nsx-installation/#installation-using-kubernetes-api","title":"Installation Using Kubernetes API","text":"<p>If you prefer installing the plugin using the Kubernetes API, you can do so by creating the following Workflow resource:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: nsx-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: nsx.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v5.0.0\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: nsx-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: nsx.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v5.0.0\n\nEOF\n</code></pre>"},{"location":"connect/vmware-nsx-installation/#step-2-connect-vmware-nsx-plugin-deployment","title":"Step 2: Connect VMware NSX Plugin Deployment","text":""},{"location":"connect/vmware-nsx-installation/#create-a-secret-for-nsx-credentials","title":"Create a Secret for NSX Credentials","text":"<p>A prerequisite for creating a <code>NsxPluginInstance</code> resource is a <code>Secret</code> resource with username and password fields that contain the account information for an account that can connect to the VMware NSX environment and has read-only access to the cluster so that it can monitor the necessary resources.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-vmware-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata: \n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-vmware-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata: \n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n\nEOF\n</code></pre> Base64 encoding <p>Use the following command to base64 encode your username and password:</p> <pre><code>echo -n myUsernameOrPassword | base64\n</code></pre> <p>mandatory label</p> <p>The secrets used by the EDA plugins must have the <code>eda.nokia.com/backup: \"true\"</code> label.</p>"},{"location":"connect/vmware-nsx-installation/#create-the-nsx-plugin-instance","title":"Create the NSX Plugin Instance","text":"<p>As the VMware NSX plugins are managed through the operator, you can use the EDA UI to create a new <code>NsxPluginInstance</code> resource under the System Administration &gt; Connect &gt; NSX Plugins menu item.</p> <p>As an alternative, you can also create the same <code>NsxPluginInstance</code> using the following custom resource example. Make sure to replace the specified values with their relevant content.</p> vCenterFQDN <p>The vCenterFQDN field has to correspond to the \"FQDN or IP Address\" field when creating the compute manager in NSX. </p> <p>Note</p> <p>A VMware NSX instance can manage multiple VMware vCenter servers. This is reflected by referencing the vCenters and the corresponding Connect VMware vCenter plugins in the <code>NsxPluginInstance</code>.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: vmware.eda.nokia.com/v1\nkind: NsxPluginInstance\nmetadata:\n  name: my-nsx-plugin-instance # A unique name for the plugin resource (can be the same as the spec.name, or different)\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  externalId: example-external-id # A unique Identifier for the plugin (can be same as the name)\n  heartbeatInterval: 30\n  name: example-NSX # A unique name for the plugin\n  nsxManagementIP: exampleHost # The IP address of the NSX Server\n  nsxPollInterval: 2 # The plugin will poll NSX for changes every x seconds\n  nsxTlsVerify: false # To verify TLS of the NSX server\n  nsxCertificate: \"\" # If the NSX certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-nsx-creds # Credentials are hosted in a separate Secret\n  vCenters:\n    - vCenterFQDN: x.y.z # FQDN or IP of the Vcenter as defined in NSX\n      vmwarePluginID: example-VMWARE # Name of the Vcenter Plugin\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: vmware.eda.nokia.com/v1\nkind: NsxPluginInstance\nmetadata:\n  name: my-nsx-plugin-instance # A unique name for the plugin resource (can be the same as the spec.name, or different)\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  externalId: example-external-id # A unique Identifier for the plugin (can be same as the name)\n  heartbeatInterval: 30\n  name: example-NSX # A unique name for the plugin\n  nsxManagementIP: exampleHost # The IP address of the NSX Server\n  nsxPollInterval: 2 # The plugin will poll NSX for changes every x seconds\n  nsxTlsVerify: false # To verify TLS of the NSX server\n  nsxCertificate: \"\" # If the NSX certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-nsx-creds # Credentials are hosted in a separate Secret\n  vCenters:\n    - vCenterFQDN: x.y.z # FQDN or IP of the Vcenter as defined in NSX\n      vmwarePluginID: example-VMWARE # Name of the Vcenter Plugin\n\nEOF\n</code></pre> <p>Name and External ID constraints</p> <p>The plugin name and external ID must comply with the regex check of <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code> and can only contain alphanumerical characters and <code>.</code>, <code>_</code> and <code>-</code>. It must start with an alphanumerical character, and have a length of 63 characters or fewer.</p>"},{"location":"connect/vmware-nsx-installation/#post-installation-verification","title":"Post-Installation Verification","text":"<p>After deploying the plugin instance, verify that it is running:</p> <pre><code>kubectl get pods -n eda-system | grep nsx\n</code></pre> <p>Check that the plugin has registered with Connect:</p> <pre><code>kubectl get connectplugins -n &lt;plugin-namespace&gt;\n</code></pre> <p>You should see your NSX plugin listed with status information.</p>"},{"location":"connect/vmware-nsx-installation/#configuration-parameters","title":"Configuration Parameters","text":"<p>The <code>NsxPluginInstance</code> resource supports the following key parameters:</p> Parameter Description Required <code>name</code> Unique name for the plugin instance Yes <code>namespace</code> EDA namespace containing the fabric Yes <code>externalID</code> Unique identifier for the NSX environment Yes <code>nsxManagementIP</code> FQDN or IP address of the NSX Manager (eg. nsx.example.com). Note that no URI scheme should be provided. Yes <code>authSecretRef</code> Reference to the Kubernetes Secret with credentials Yes <code>heartbeatInterval</code> Interval in seconds for heartbeat updates No (default: 30) <code>nsxTlsVerify</code> Whether to verify the TLS certificate of NSX (default: true). No <code>nsxCertificate</code> PEM encoded certificate for NSX if self-signed (default: empty). No <code>nsxPollInterval</code> Interval in seconds for polling NSX for changes (default: 2). No (default: 60) <code>vCenters</code> List of vCenter references with FQDN and plugin names Yes"},{"location":"connect/vmware-nsx-installation/#next-steps","title":"Next Steps","text":"<p>After installation, proceed to:</p> <ul> <li>Configure VLAN or overlay segments in NSX</li> <li>Set up NSX tags for EDA-managed mode (if required)</li> <li>Review the VMware NSX Plugin documentation for usage and operational modes</li> </ul>"},{"location":"connect/vmware-nsx/","title":"VMware NSX Plugin","text":""},{"location":"connect/vmware-nsx/#overview","title":"Overview","text":"<p>The NSX plugin enables automated fabric configuration for VMware NSX environments, supporting both Overlay and VLAN segments. It integrates with EDA Connect to dynamically manage bridge domains and VLANs based on NSX segment definitions.</p> <p>NSX provides advanced networking capabilities such as:</p> <ul> <li>L2/L3 overlays using VXLAN or Geneve</li> <li>VLAN-based connectivity</li> <li>Tier-0 routers for overlay-to-underlay breakout</li> <li>Micro-segmentation, load balancing, and VPN services</li> </ul> <p>This plugin focuses on automating fabric configuration for overlay and VLAN segments:</p> <ul> <li>Automatic provisioning of the fabric based on the configured NSX VLAN segments.</li> <li>Automatic provisioning of the fabric based on NSX Host Transport Node and Host Switch Profile. The plugin will facilitate the communication between the hypervisors on these overlay segments. EDA will not be involved in the actual overlay traffic in this case.</li> <li>Automatic provisioning of the fabric based on NSX Edge Node Transport VLANs.</li> <li>CMS-managed and EDA-managed integration modes (See also Operational Modes)</li> </ul>"},{"location":"connect/vmware-nsx/#supported-versions","title":"Supported Versions","text":"<ul> <li>VMware NSX 4.2</li> </ul>"},{"location":"connect/vmware-nsx/#architecture","title":"Architecture","text":"<p>The VMware NSX plugin consists of two components:</p> VMware NSX Plugin App This app runs in EDA and manages the lifecycle of the VMware NSX plugins. It does so in the standard app model where a custom resource is used to manage the VMware NSX plugins. VMware NSX Plugin The plugin itself, which is responsible for connecting and monitoring the VMware NSX environment for changes."},{"location":"connect/vmware-nsx/#installation","title":"Installation","text":"<p>For detailed deployment instructions, see the VMware NSX Plugin Installation Guide.</p>"},{"location":"connect/vmware-nsx/#features","title":"Features","text":""},{"location":"connect/vmware-nsx/#vcenter-support","title":"vCenter Support","text":"<p>While NSX is used for defining overlay networking, vCenter is still used to configure the compute hosts and VMs. The NSX plugin has a dependency on one or more VMware vCenter plugins for the creation of the ConnectInterface objects in EDA.</p>"},{"location":"connect/vmware-nsx/#supported-network-scenarios","title":"Supported network scenarios","text":""},{"location":"connect/vmware-nsx/#host-transport-nodes-and-overlay-segments","title":"Host Transport Nodes and Overlay Segments","text":"<p>Overlay segments in NSX are L2 networks encapsulated in L3 using VXLAN or Geneve. The encapsulated traffic is VLAN-tagged and transported via uplinks defined in NSX configurations.</p> <p>The NSX plugin will create a <code>BridgeDomain</code> and a <code>VLAN</code> resource based on the Transport VLAN defined on the Host Transport Node in NSX. EDA and the Fabric will not be involved in the overlay traffic itself; the plugin will only facilitate communication between the hypervisors on these overlay segments.</p>"},{"location":"connect/vmware-nsx/#vlan-segments","title":"VLAN Segments","text":"<p>In NSX, it is also still possible to create VLAN segments. When a VLAN segment is linked in a Host Transport Node, the NSX plugin will create the appropriate <code>BridgeDomain</code> and <code>VLAN</code> resources in EDA.</p> Constraints when using VLAN Segments <p>When linked to Edge nodes, VLAN segments are not configured by the NSX plugin. VLAN segments can only be linked to Host Transport Nodes.</p>"},{"location":"connect/vmware-nsx/#edge-node","title":"Edge Node","text":"<p>In NSX Edge Nodes provide services at the edge of the network, such as routing between NSX logical networks and external physical networks. The plugin automatically provisions the transport network for the Edge Nodes when it is defined in NSX.</p> <p>The uplinks of the Edge nodes are virtual rather than physical. To map these to the physical uplinks of the host, the plugin copies the uplink mapping from the Host Transport Node to the Edge Transport Node.</p> <p>The NSX plugin will create a <code>BridgeDomain</code> and a <code>VLAN</code> resource based on the Transport VLAN defined on the uplink profile and transport zone of the Edge Node in NSX. The VLAN is allocated only when a transport zone of type \"overlay\" is also set, since any overlay network requires a transport zone.</p> Constraints when using Edge Nodes <p>The following constraints are imposed on Edge Node transport networks:</p> <ul> <li>The Edge Node can only have a transport network on a switch that has a default uplink teaming for its parent host.</li> <li>The Edge Node cannot have its transport network traffic go through a different NIC/Uplink than its parent host.</li> <li>The Edge Node cannot exclude itself from a Host Switch that its host is participating on. In the example above, this means it is not possible to create the VLAN for one of the switches and not the other.</li> </ul> Host Transport Node to Edge Node connectivity <p>Most scenarios require connectivity between Host Transport Nodes and Edge Nodes. The easiest way to achieve this is by using EDA-managed <code>BridgeDomains</code>. Either with a single <code>BridgeDomain</code> for both Host Transport Nodes and Edge Nodes or by using multiple <code>BridgeDomains</code> interconnected through a <code>VirtualNetwork</code>. When using a single <code>BridgeDomain</code> make sure the IPAM configuration places both Host Transport Nodes and Edge Nodes in the same subnet.</p>"},{"location":"connect/vmware-nsx/#operational-modes","title":"Operational Modes","text":"<p>The plugin supports the following operational modes:</p> NSX Managed Mode Also referred to as Connect Managed. When using this mode, the plugin will create a unique <code>BridgeDomain</code> for each VLAN segment and to facilitate overlay segment communication between the hypervisors. EDA Managed Mode <p>EDA managed BridgeDomains are supported for both VLAN and overlay networks. To specify an EDA managed BridgeDomain, use an NSX tag with:</p> <p>Scope (key): <code>ConnectBridgeDomain</code></p> <p>Tag (value): The BridgeDomain name</p> <ul> <li>For VLAN networks: Place the tag on the VLAN segment.</li> <li>For overlay networks: Place the tag on the overlay transport zone.</li> <li>For Edge Node transport VLANs: Place the tag on the Edge Node overlay transport zone.</li> </ul> <p>A VLAN is uniquely defined by its hostSwitchID, vlanTag, and edaBridgeDomain (the tag value). Two segments with the same VLAN tag but different BridgeDomain tags will result in two Connect VLANs.</p>"},{"location":"connect/vmware-nsx/#heartbeat","title":"Heartbeat","text":"<p>The plugin implements a heartbeat mechanism, polling Connect at a regular interval (configured by <code>heartbeatInterval</code>). This ensures the plugin's health and timely processing of actionable events from Connect.</p>"},{"location":"connect/vmware-nsx/#operator-initiated-audit","title":"Operator Initiated Audit","text":"<p>In addition to the startup audit, users can initiate an audit manually. The audit object contains the status and results, including any discrepancies found between NSX and Connect.</p>"},{"location":"connect/vmware-nsx/#startup","title":"Startup","text":"<p>When the plugin is started, the following actions are taken by the plugin:</p> <ul> <li>The plugin registers itself with Connect, based on the provided <code>externalID</code>. If a matching <code>ConnectPlugin</code> pre-exists, it is reused.</li> <li>The plugin performs an audit: Any Connect-related state that was programmed in NSX while the plugin was not running is synchronized with   Connect.</li> </ul>"},{"location":"connect/vmware-nsx/#alarms","title":"Alarms","text":"<p>Alarms will notify users of issues such as:</p> <ul> <li>Incorrect NSX credentials</li> <li>Bad certificate</li> <li>No connectivity to NSX</li> <li>EDA BridgeDomain missing for EDA managed resources</li> <li>Misconfigured resources (e.g., invalid uplink name)</li> </ul> Required plugin or vCenter missing <p>When the NSX plugin detects that a required vCenter plugin is missing, it will not raise an alarm in the current release.  Make sure that for all vCenters configured in NSX a corresponding vCenter plugin is installed and running in EDA.</p>"},{"location":"connect/vmware-nsx/#troubleshooting","title":"Troubleshooting","text":""},{"location":"connect/vmware-nsx/#the-plugin-is-not-running","title":"The plugin is not running","text":"<p>If an incorrect NSX hostname or IP is configured in the <code>NsxPluginInstance</code> resource, the plugin will raise an alarm and retry the connection indefinitely. In case the credentials are incorrect, the plugin will also raise an alarm and retry indefinitely.</p> <ul> <li>Check the raised NSX plugin alarms as well as any connect VMware plugin alarms.</li> <li>Check that the 'NSXPluginInstance' matches the compute manager's server IP or FQDN field and the corresponding VMware plugin name field.</li> <li>Check the connectivity from the EDA cluster to NSX.</li> <li>Verify the credentials for NSX. Make sure to check the base64 encoding of the Secret.</li> <li>Check the logs of the plugin pod.</li> </ul>"},{"location":"connect/vmware-nsx/#the-plugin-is-not-creating-any-resources-in-eda","title":"The plugin is not creating any resources in EDA","text":"<ul> <li>Check the raised plugin alarms.</li> <li>Check the connectivity from the EDA cluster to NSX.</li> <li>Check the logs of the plugin pod.</li> <li>Check the plugin staleness state field and verify that heartbeats are being updated.</li> <li>Check the <code>NSXPluginInstance</code> resource and verify that it has valid values.</li> <li>Make sure the LLDP settings are correctly configured on all distributed vSwitches.</li> <li>Try to sync state by launching an Audit (see Operator Initiated Audit).</li> </ul>"},{"location":"connect/vmware-nsx/#the-plugin-is-configuring-an-incorrect-state-in-eda","title":"The plugin is configuring an incorrect state in EDA","text":"<ul> <li>Check the raised NSX and VMware plugin alarms.</li> <li>Check the logs of the plugin pod.</li> <li>Make sure the LLDP settings are correctly configured on all distributed vSwitches.</li> <li>Try to sync state by launching an Audit (see Operator Initiated Audit).</li> <li>Inspect the EDA resources, like <code>VLANs</code> and <code>BridgeDomains</code>.</li> <li>Verify the required vCenter plugins are configured correctly.</li> </ul>"},{"location":"connect/vmware-plugin-installation/","title":"VMware vSphere Plugin Installation","text":"<p>This guide provides detailed instructions for installing the EDA Connect VMware vSphere plugin.</p>"},{"location":"connect/vmware-plugin-installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing or deploying the VMware vSphere plugin components, ensure that:</p> <ul> <li>The Cloud Connect Core application is properly installed in the cluster (see Cloud Connect Installation)</li> <li>You have read-only access credentials to the VMware vCenter environment</li> </ul>"},{"location":"connect/vmware-plugin-installation/#installation-steps","title":"Installation Steps","text":"<p>To deploy the VMware vSphere plugin, complete the following tasks:</p> <ol> <li>Deploy the plugin EDA app</li> <li>Deploy the plugin instance</li> </ol>"},{"location":"connect/vmware-plugin-installation/#step-1-connect-vmware-vsphere-plugin-app-deployment","title":"Step 1: Connect VMware vSphere Plugin App Deployment","text":"<p>The VMware vSphere plugin app is an application in the EDA app ecosystem. It can be easily installed using the EDA Store UI.</p>"},{"location":"connect/vmware-plugin-installation/#installation-using-eda-store-ui","title":"Installation Using EDA Store UI","text":"<ol> <li>Navigate to the EDA Store in the EDA UI</li> <li>Locate the VMware vSphere Plugin App</li> <li>Click Install</li> <li>Complete the installation</li> </ol>"},{"location":"connect/vmware-plugin-installation/#installation-using-kubernetes-api","title":"Installation Using Kubernetes API","text":"<p>If you prefer installing the plugin using the Kubernetes API, you can do so by creating the following Workflow resource:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: vmware-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: vmware.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v5.0.0\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: vmware-plugin\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: vmware.eda.nokia.com\n      catalog: eda-catalog-builtin-apps\n      version:\n        type: semver\n        value: v5.0.0\n\nEOF\n</code></pre>"},{"location":"connect/vmware-plugin-installation/#step-2-connect-vmware-vsphere-plugin-deployment","title":"Step 2: Connect VMware vSphere Plugin Deployment","text":""},{"location":"connect/vmware-plugin-installation/#create-a-secret-for-vmware-credentials","title":"Create a Secret for VMware Credentials","text":"<p>A prerequisite for creating a <code>vmwarePluginInstance</code> resource is a <code>Secret</code> resource with username and password fields that contain the account information for an account that can connect to the VMware vCenter environment and has read-only access to the cluster so that it can monitor the necessary resources.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-vmware-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata: \n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: my-vmware-creds\n  namespace: eda-system\n  labels:\n    \"eda.nokia.com/backup\": \"true\"\ndata: \n  username: YWRtaW4K # base64 encoded\n  password: YWRtaW4K # base64 encoded\n\nEOF\n</code></pre> Base64 encoding <p>Use the following command to base64 encode your username and password:</p> <pre><code>echo -n myUsernameOrPassword | base64\n</code></pre> <p>mandatory label</p> <p>The secrets used by the EDA plugins must have the <code>eda.nokia.com/backup: \"true\"</code> label.</p>"},{"location":"connect/vmware-plugin-installation/#create-the-vmware-plugin-instance","title":"Create the VMware Plugin Instance","text":"<p>As the VMware vSphere plugins are managed through the operator, you can use the EDA UI to create a new <code>VmwarePluginInstance</code> resource under the * System Administration &gt; Connect &gt; VMware Plugins* menu item.</p> <p>As an alternative, you can also create the same <code>VmwarePluginInstance</code> using the following custom resource example. Make sure to replace the specified values with their relevant content.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: vmware.eda.nokia.com/v1\nkind: VmwarePluginInstance\nmetadata:\n  name: my-vmware-plugin-instance # A unique name for the plugin resource (can be the same as the spec.name, or different)\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  externalId: example-external-id # A unique Identifier for the plugin (can be same as the name)\n  heartbeatInterval: 30\n  name: example-vSphere # A unique name for the plugin\n  vcsaHost: example-host # The IP address of the vCenter Server\n  vcsaTlsVerify: true # To verify TLS of the VCSA\n  vcsaCertificate: \"\" # If the VCSA certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-vmware-creds # Credentials are hosted in a separate Secret\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: vmware.eda.nokia.com/v1\nkind: VmwarePluginInstance\nmetadata:\n  name: my-vmware-plugin-instance # A unique name for the plugin resource (can be the same as the spec.name, or different)\n  namespace: eda-system # The system namespace.\nspec:\n  pluginNamespace: eda # The namespace in the EDA deployment holding the fabric associated with this plugin\n  externalId: example-external-id # A unique Identifier for the plugin (can be same as the name)\n  heartbeatInterval: 30\n  name: example-vSphere # A unique name for the plugin\n  vcsaHost: example-host # The IP address of the vCenter Server\n  vcsaTlsVerify: true # To verify TLS of the VCSA\n  vcsaCertificate: \"\" # If the VCSA certificate is self signed, add it here to be able to verify from the plugin\n  authSecretRef: my-vmware-creds # Credentials are hosted in a separate Secret\n\nEOF\n</code></pre> <p>Name and External ID constraints</p> <p>The plugin name and external ID must comply with the regex check of <code>'([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]'</code> and can only contain alphanumerical characters and <code>.</code>, <code>_</code> and <code>-</code>. It must start with an alphanumerical character, and have a length of 63 characters or fewer.</p>"},{"location":"connect/vmware-plugin-installation/#configuration-parameters","title":"Configuration Parameters","text":"<p>The <code>VmwarePluginInstance</code> resource supports the following key parameters:</p> Field Description Required <code>name</code> Name of the plugin instance in EDA. Yes <code>externalID</code> Unique identifier of the Plugin. Yes <code>pluginNamespace</code> The namespace in the EDA deployment holding the fabric associated with this plugin. Yes <code>vcsaHost</code> URL of the VCSA (e.g <code>vcenter.mydomain.com</code>). Note that no URI scheme should be provided. Yes <code>authSecretRef</code> Name of the Kubernetes Secret containing VCSA credentials Yes <code>heartbeatInterval</code> Interval in seconds for plugin heartbeat to EDA (default: 30s). No <code>vcsaTlsVerify</code> Whether to verify the TLS certificate of VCSA (default: true). No <code>VCSACertificate</code> PEM encoded certificate for VCSA if self-signed (default: empty). No"},{"location":"connect/vmware-plugin-installation/#post-installation-verification","title":"Post-Installation Verification","text":"<p>After deploying the plugin, verify that it is running:</p> <pre><code>kubectl get pods -n eda-system | grep vmware\n</code></pre> <p>Check that the plugin has registered with Connect:</p> <pre><code>kubectl get connectplugins -n &lt;plugin-namespace&gt;\n</code></pre> <p>You should see your VMware plugin listed with status information.</p>"},{"location":"connect/vmware-plugin-installation/#next-steps","title":"Next Steps","text":"<p>After installation, proceed to:</p> <ul> <li>Configure distributed Port Groups in vCenter</li> <li>Set up Custom Attributes for EDA-managed mode (if required)</li> <li>Make sure LLDP is enabled on the distributed vSwitch (at least advertise in Discovery protocol settings)</li> <li>Review the VMware vSphere Plugin documentation for usage and operational modes</li> </ul>"},{"location":"connect/vmware-plugin/","title":"VMware vSphere Plugin","text":""},{"location":"connect/vmware-plugin/#overview","title":"Overview","text":"<p>The VMware vSphere plugin leverages the VMware vSphere distributed vSwitch architecture to support managing the fabric directly from VMware vCenter and make the fabric respond to the networking needs of the environment.</p> <p>It provides the following capabilities:</p> <ul> <li>Direct integration into the network management workflow of VMware vCenter.</li> <li>The use of the common distributed vSwitches and port groups for both regular virtual machine NICs as well as SR-IOV use cases.</li> <li>Support for both untagged and single vlan port groups.</li> <li>Automatic provisioning of the fabric based on where the virtual machines need the connectivity.</li> <li>Support advanced workflows through EDA, including for VNF use cases with features like QoS, ACLs, and BGP PE-CE (EDA Managed)</li> <li>Interconnectivity between different cloud environments, allowing for flexible network configurations.</li> <li>LAG/LACP interfaces</li> <li>Audits</li> </ul>"},{"location":"connect/vmware-plugin/#supported-versions","title":"Supported Versions","text":"<ul> <li>VMware vSphere 8</li> </ul>"},{"location":"connect/vmware-plugin/#architecture","title":"Architecture","text":"<p>The VMware vSphere plugin consists of two components:</p> VMware vSphere Plugin App This app runs in EDA and manages the lifecycle of the VMware vSphere plugins. It does so in the standard app model where a custom resource is used to manage the VMware vSphere plugins. VMware vSphere Plugin <p>The plugin itself, which is responsible for connecting and monitoring the VMware vCenter environment for changes. The plugin will listen to the events of the following objects:</p> <ul> <li>Distributed vSwitch (dvS)</li> <li>Distributed Port Groups (dvPG)</li> <li>Host to dvS associations</li> <li>Custom attributes</li> </ul>"},{"location":"connect/vmware-plugin/#installation","title":"Installation","text":"<p>For detailed deployment instructions, see the VMware vSphere Plugin Installation Guide.</p>"},{"location":"connect/vmware-plugin/#features","title":"Features","text":""},{"location":"connect/vmware-plugin/#limitations","title":"Limitations","text":"<ul> <li>VM Nics in Trunked mode are not supported</li> </ul>"},{"location":"connect/vmware-plugin/#operational-modes","title":"Operational Modes","text":"<p>The plugin supports the following operational modes; these modes can be used simultaneously:</p> VMware-Managed Mode Also referred to as Connect Managed. When using this mode, the plugin will create a unique <code>BridgeDomain</code> and <code>VLAN</code> resource for each VLAN  tagged dvPG in the VMware vCenter environment. EDA-Managed Mode In EDA-managed mode, a dvPG is given a special custom attribute that refers to an existing EDA <code>BridgeDomain</code> resource. When the plugin detects  this custom attribute, and it refers to an existing <code>BridgeDomain</code> resource in EDA, it will not create a new <code>BridgeDomain</code> but instead will  associate the dvPG with the existing one. This allows for more advanced configuration of the application networks."},{"location":"connect/vmware-plugin/#using-eda-managed-mode","title":"Using EDA-Managed Mode","text":"<p>To use the EDA-managed mode follow these steps:</p> <ol> <li>Create a <code>BridgeDomain</code> in EDA with the desired settings</li> <li>When creating a distributed Port Group in vCenter, configure a Custom Attribute called <code>ConnectBridgeDomain</code> and set its value to the name of the EDA    <code>BridgeDomain</code>.</li> </ol> <p>Case Sensitivity</p> <p>Both the key of the Custom Attribute and the value are case-sensitive</p> Global vs Distributed Port Group type of Custom Attribute <p>Make sure to create a Custom Attribute of type Distributed Port Group on the Port Group. </p> <p>You can configure multiple dvPGs with the same <code>BridgeDomain</code>.</p> <p>You can switch between EDA-managed and VMware-managed mode at any time. You can switch back to VMware-managed mode by setting the <code>ConnectBridgeDomain</code> Custom Attribute to <code>none</code>, or by deleting the Custom Attribute entirely.</p> Switching between EDA-managed and VMware-managed mode <p>When switching between the two available modes, connectivity will be temporarily disrupted while the plugin reconfigures the resources in EDA.</p>"},{"location":"connect/vmware-plugin/#event-monitoring","title":"Event Monitoring","text":"<p>A plugin will connect to a VMware vCenter environment and subscribe to VMware events. The plugin will configure Connect and EDA based on the events it receives:</p> Event Trigger Custom Resource Purpose VLAN-tagged distributed PortGroup events <code>BridgeDomain</code> In VMware-managed mode, each dvPG will result in its own unique <code>BridgeDomain</code>. VLAN-tagged distributed PortGroup events <code>VLAN</code> Each dvPG with a specific VLAN tag will have an EDA <code>VLAN</code> resource so it can be attached to the <code>BridgeDomain</code>. Host NIC distributed Switch Uplink events <code>ConnectInterface</code> Each host NIC that gets added as an uplink to a dvS will trigger the creation of a <code>ConnectInterface</code>, which is mapped by Connect Core to an EDA <code>Interface</code>. <p>Naming limitations</p> <p>The uplink names must comply with the regex check of <code>^[a-zA-Z0-9][a-zA-Z0-9._-]*[a-zA-Z0-9]$</code>. It can only contain alpha-numerical characters and <code></code>(space), <code>.</code>, <code>_</code>, and <code>-</code>. It must also have a length of 30 characters or fewer.</p>"},{"location":"connect/vmware-plugin/#startup","title":"Startup","text":"<p>When the plugin is started, the following actions are taken by the plugin:</p> <ul> <li>The plugin registers itself with Connect, based on the provided <code>externalID</code>. If a matching <code>ConnectPlugin</code> pre-exists, it is reused.</li> <li>The plugin performs an audit: Any Connect-related state that was programmed in vCenter while the plugin was not running is synchronized with   Connect.</li> </ul> Plugin externalID is immutable <p>Note that the <code>externalID</code> of the plugin instance is immutable once created. If you do change it a second plugin instance will be created instead.     To recover from this situation, delete the incorrectly created <code>ConnectPlugin</code>, <code>BridgeDomain</code>, <code>VLAN</code> and <code>ConnectInterface</code> resources.</p>"},{"location":"connect/vmware-plugin/#heartbeat","title":"Heartbeat","text":"<p>The plugin implements a heartbeat mechanism, polling Connect at a regular interval (configured by <code>heartbeatInterval</code>). This ensures the plugin's health and timely processing of actionable events from Connect.</p>"},{"location":"connect/vmware-plugin/#operator-initiated-audit","title":"Operator Initiated Audit","text":"<p>In addition to the startup audit, users can initiate an audit manually. The audit object contains the status and results, including any discrepancies found between NSX and Connect.</p>"},{"location":"connect/vmware-plugin/#lldp","title":"LLDP","text":"<p>Cloud Connect uses LLDP to discover which VMware hypervisors are running on which switches in EDA. Make sure you enable at least \"advertise\" LLDP in the Discovery protocol settings of the distributed vSwitch.</p>"},{"location":"connect/vmware-plugin/#troubleshooting","title":"Troubleshooting","text":""},{"location":"connect/vmware-plugin/#the-plugin-is-not-running","title":"The plugin is not running","text":"<p>If an incorrect vCenter hostname or IP is configured in the <code>VmwarePluginInstance</code> resource, the plugin will try to connect for 3 minutes and crash and restart if it fails to connect. In case the credentials are incorrect, the plugin will crash and restart immediately.</p> <ul> <li>Check the raised plugin alarms.</li> <li>Check the connectivity from the EDA cluster to vCenter.</li> <li>Verify the credentials for vCenter. Make sure to check the base64 encoding of the Secret.</li> <li>Check the logs of the plugin pod.</li> </ul>"},{"location":"connect/vmware-plugin/#the-plugin-is-not-creating-any-resources-in-eda","title":"The plugin is not creating any resources in EDA","text":"<ul> <li>Check the raised plugin alarms.</li> <li>Check the connectivity from the EDA cluster to vCenter.</li> <li>Check the logs of the plugin pod.</li> <li>Check the Plugin staleness state field and verify heartbeats are being updated.</li> <li>Try an operator-initiated audit and check the audit results.</li> </ul>"},{"location":"connect/vmware-plugin/#the-plugin-is-not-configuring-the-correct-state","title":"The plugin is not configuring the correct state","text":"<ul> <li>Check the raised plugin alarms.</li> <li>Verify the Uplinks for the dvPG in vCenter are configured as active or standby. If there are no active or standby Uplinks configured, the plugin   will not associate any <code>ConnectInterface</code> with the <code>VLAN</code>.</li> <li>Uplink names can only contain alpha-numerical characters and <code>.</code>, <code>_</code>, <code>-</code> and must have a length of 30 characters or less.</li> <li>VLAN ranges are not supported on dvPGs.</li> <li>Inspect the EDA resources, like <code>VLAN</code>, <code>BridgeDomain</code> and <code>ConnectInterface</code>.</li> <li>Check the logs of the plugin pod.</li> <li>Make sure the LLDP settings are correctly configured on all distributed vSwitches.</li> </ul>"},{"location":"development/custom-catalog/","title":"Add a Custom EDA Store Catalog","text":""},{"location":"development/custom-catalog/#overview","title":"Overview","text":"<p>An App Catalog is a structured git repository that contains all the necessary information EDA Store needs to install an app. The <code>Manifest</code>  is the most important one. But the app can also contain other app metadata information for the UI, like a README, or a license (see the manifest <code>appInfo</code>  specification field). The catalog of built-in apps that is delivered along with EDA can be found here.</p>"},{"location":"development/custom-catalog/#catalog-structure","title":"Catalog Structure","text":"<p>The structure of a catalog is as follows:</p> <pre><code>vendors/\n    &lt;vendor-1-name&gt;\n        apps/\n            &lt;app-1-name&gt;/\n                manifest.yaml\n                README.md\n                LICENSE\n                ... # Other useful files, which can be referenced in the manifest and used in the UI.\n            &lt;app-2-name&gt;/\n                ...\n    &lt;vendor-2-name&gt;/\n        apps/\n            ...\n    ...\n</code></pre> <p>The manifest of an App must be called <code>manifest.yaml</code> and be placed in <code>vendors/&lt;vendor-name&gt;/apps/&lt;app-name&gt;/manifest.yaml</code> in the git repository.</p>"},{"location":"development/custom-catalog/#app-versioning","title":"App Versioning","text":"<p>Apps will have multiple versions. To version the Apps in the Catalog, git tags are used. A structured git tag will be seen as an installable App (with a certain version) for the EDA Store, which can then be installed from the UI.</p> <p>Any tag in the form of <code>vendors/&lt;vendor-name&gt;/apps/&lt;app-name&gt;/&lt;version&gt;</code> will be registered as an installable App by the EDA Store.</p> <p>The version field should conform to Semantic Versioning 2.0, prefixed with a \"v\". For example: v0.1, v0.1.0-alpha.</p>"},{"location":"development/custom-catalog/#adding-a-catalog-to-the-eda-store","title":"Adding a Catalog to the EDA Store","text":""},{"location":"development/custom-catalog/#creating-a-credentials-secret","title":"Creating a Credentials Secret","text":"<p>If the Catalog-hosting Git repository requires authentication, you must create a Kubernetes secret that contains the credentials to connect to the Catalog git repository over HTTPS. This can be done using the following resource where you replace the data with the correct <code>base64</code> encoded values.</p> <p>mandatory label</p> <p>The secrets used by the app catalog or app registry must have the <code>eda.nokia.com/backup: \"true\"</code> label for the EDA Store to pick them up.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: your-creds # A unique secret name\n  labels:\n    eda.nokia.com/backup: \"true\"\ndata:\n  username: &lt;base64(username)&gt; # Base64 encoded username\n  password: &lt;base64(password or token)&gt; # Base64 encoded password/token\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: your-creds # A unique secret name\n  labels:\n    eda.nokia.com/backup: \"true\"\ndata:\n  username: &lt;base64(username)&gt; # Base64 encoded username\n  password: &lt;base64(password or token)&gt; # Base64 encoded password/token\n\nEOF\n</code></pre>"},{"location":"development/custom-catalog/#creating-the-catalog","title":"Creating the Catalog","text":"<p>You can create your own Catalog using the following resource. This uses the above created secret as <code>authSecretRef</code>.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: your-catalog # name of your catalog\nspec:\n  title: Your Awesome Catalog # UI name of your catalog, optional\n  remoteURL: https://&lt;your-catalog&gt;.git # link to your git repository.\n  authSecretRef: your-creds # reference to valid credentials for the git repository\n  skipTLSVerify: {true|false}\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: your-catalog # name of your catalog\nspec:\n  title: Your Awesome Catalog # UI name of your catalog, optional\n  remoteURL: https://&lt;your-catalog&gt;.git # link to your git repository.\n  authSecretRef: your-creds # reference to valid credentials for the git repository\n  skipTLSVerify: {true|false}\nEOF\n</code></pre>"},{"location":"development/custom-registry/","title":"Add a Custom EDA Store Registry","text":""},{"location":"development/custom-registry/#overview","title":"Overview","text":"<p>An EDA Store Registry is a container registry that contains OCI compliant images of an App. It is where you will upload your full App content and code as a single OCI image.</p> <p>The <code>manifest.spec.image</code> field will point to the specific App image with a specific tag for each version.</p>"},{"location":"development/custom-registry/#adding-a-registry-to-the-eda-store","title":"Adding a Registry to the EDA Store","text":""},{"location":"development/custom-registry/#creating-a-credentials-secret","title":"Creating a Credentials Secret","text":"<p>If the registry hosting your App OCI image requires authentication, you must create a Kubernetes secret that contains the credentials to connect to the Registry git repository over HTTPS. This can be done using the following resource where you replace the data with the correct <code>base64</code> encoded values.</p> <p>mandatory label</p> <p>The secrets used by the app catalog or app registry must have the <code>eda.nokia.com/backup: \"true\"</code> label for the EDA Store to pick them up.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: your-creds # A unique secret name\n  labels:\n    eda.nokia.com/backup: \"true\"\ndata:\n  username: &lt;base64(username)&gt; # Base64 encoded username\n  password: &lt;base64(password or token)&gt; # Base64 encoded password/token\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Secret\ntype: Opaque\nmetadata:\n  name: your-creds # A unique secret name\n  labels:\n    eda.nokia.com/backup: \"true\"\ndata:\n  username: &lt;base64(username)&gt; # Base64 encoded username\n  password: &lt;base64(password or token)&gt; # Base64 encoded password/token\n\nEOF\n</code></pre> <p>Make sure to give the secret a different name than the Catalog Credentials secret</p>"},{"location":"development/custom-registry/#creating-the-registry","title":"Creating the Registry","text":"<p>You can create your own Registry using the following resource. This uses the above created secret as <code>authSecretRef</code>.</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: Registry\nmetadata:\n  name: your-registry # name of your registry\nspec:\n  remoteURL: &lt;url-to-your-registry.com&gt; # link to your registry\n  authSecretRef: your-registry-creds # reference to valid credentials for your registry\n  skipTLSVerify: {true|false}\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: appstore.eda.nokia.com/v1\nkind: Registry\nmetadata:\n  name: your-registry # name of your registry\nspec:\n  remoteURL: &lt;url-to-your-registry.com&gt; # link to your registry\n  authSecretRef: your-registry-creds # reference to valid credentials for your registry\n  skipTLSVerify: {true|false}\nEOF\n</code></pre>"},{"location":"development/custom-registry/#mirroring-a-registry-to-the-eda-store","title":"Mirroring a Registry to the EDA Store","text":"<p>If it is not possible to use a registry that is referenced in the manifests of a certain catalog, you can mirror that registry to a local registry and then update the Registry resource in the EDA Kubernetes cluster and update the <code>mirrorUrl</code> to point to the mirror hostname.</p> <p>Only the hostname/FQDN will be replaced, image repositories and tags are assumed to be the same when using a mirror.</p>"},{"location":"development/custom-registry/#limitations","title":"Limitations","text":""},{"location":"development/custom-registry/#using-artifactory-container-registry-with-apps-using-embedded-container-images","title":"Using Artifactory container registry with Apps using embedded container images","text":"<p>Artifactory currently doesn't support OCI compliant images with embedded container images. If you are creating an advanced App that uses its own container image, you can not use Artifactory as a registry. An alternative could be to host your own Harbor registry.</p> <p>Regular MicroPython Apps do not have this limitation, for these Artifactory will work fine.</p>"},{"location":"development/ansible/","title":"Ansible Collections for Nokia EDA","text":"<p> https://ansible.eda.dev \u00b7  Nokia EDA Collection in Galaxy</p> <p>Ansible is an open-source automation platform that allows you to automate tasks across a wide range of IT environments. It uses a simple, human-readable language to describe automation tasks, making it accessible to both developers and operations teams. In order to extend the platform and meet specific needs and target environments, Ansible allows users to create custom modules and plugins that are packaged as Ansible collections and hosted at Ansible Galaxy.</p> <p>Nokia provides a set of Ansible collections specifically designed for the Event Driven Automation (EDA) platform that allow users to automate interactions with the EDA platform and manage the resources under its management.</p> <p>Go to https://ansible.eda.dev for a complete reference and examples.</p>"},{"location":"development/api/","title":"API","text":""},{"location":"development/api/#overview","title":"Overview","text":"<p>EDA includes an HTTP REST API to support software integration. By using the REST API, you can write your own software that can configure any feature of the EDA.</p>"},{"location":"development/api/#general-concepts","title":"General Concepts","text":"<p>The EDA API is following a very similar model as the Kubernetes Resource Model. Every custom resource that gets added through the installation of an App, will be available through the EDA API in a similar way as custom resources in Kubernetes are available through the Kubernetes API.</p> <p>There are two major components to the EDA API, and a few internal components:</p> Core API The Core API is used to manage a few core concepts of EDA, like getting and posting <code>Transactions</code>, executing EQL <code>Queries</code> and getting <code>NodeConfigs</code> for specific nodes. Apps API <p>The Apps API is where every App installed into EDA, exposes its custom resources. That includes all the default installed Apps.</p> <p>EDA API vs Kubernetes API &amp; <code>kubectl</code></p> <p>In the current EDA model, both the EDA API and Kubernetes API (or <code>kubectl</code>) can be used to manage certain resources. However, be aware that anything that has been internally generated within EDA might not be fully visible to the Kubernetes environment and only available over the EDA API.</p> OpenAPI API This API provides access to OpenAPIv3 Specifications for the Core and Apps API. HTTPProxy API The EDA API server acts as a transparent passthrough proxy for certain services, like Keycloak for authentication and other internal services. This is handled by the HTTPProxy API. <p>Do not change or manipulate any of the HTTPProxy API settings as this can break your EDA deployment.</p>"},{"location":"development/api/#synchronous-vs-asynchronous","title":"Synchronous vs Asynchronous","text":"<p>All the API requests are handled as synchronous API requests. To make asynchronous API requests use the <code>Transaction</code> API.</p>"},{"location":"development/api/#authentication","title":"Authentication","text":"<p>For authentication and authorization, EDA uses Keycloak as its backend. Keycloak is a proven and secure solution for Identity and Access management. EDA uses Keycloak through the OpenID Connect protocol where the authentication flow to obtain the OAuth 2.0 token is different for browser-based and non-browser-based clients:</p> <ol> <li>For browser-based clients, the user is redirected to Keycloak for authentication and then send back with the necessary tokens for the API to authenticate and verify the user as a legitimate user. This is referred to as the Standard Flow (Authorization Code Grant in the OAuth2 specifications RFC 6749 4.1).</li> <li>For non-browser API clients, such as CLI applications, scripts, etc., the Direct Access Grant flow (Resource Owner Password Credentials Grant in the OAuth2 specifications RFC 6749 4.5) is used to obtain the authentication token. In this case the API client directly authenticates with Keycloak using client_secret and provides the Authorization Server with Resource Owner credentials (EDA username credentials). The Authorization Server (Keycloak) provides the client with the token that is used for further API calls to the EDA API. The API client is also responsible for refreshing or renewing their token.</li> </ol> <p>The non-browser API clients authenticate against the Kecloak authorization server by providing the following parameters in the request:</p> <ul> <li><code>client_id</code>: Must be set to <code>eda</code></li> <li><code>grant_type</code>: Must be set to <code>password</code></li> <li><code>scope</code>: Must be set to <code>openid</code></li> <li><code>username</code>: The username for the user that needs to authenticate</li> <li><code>password</code>: The password for the user that needs to authenticate</li> <li><code>client_secret</code>: The Keycloak client secret for client ID <code>eda</code></li> </ul> <p>Some of the hardcoded settings might change in the future</p>"},{"location":"development/api/#getting-the-client_secret","title":"Getting the <code>client_secret</code>","text":"<p>Every EDA deployment gets a unique client secret token generated during installtion. An EDA system administrator is responsible for retrieving the client secret and providing it to the application/scripts/clients that intent to interact with the EDA API server. The secret can be retrieved using Keycloak UI and Keycloak API. Below you will find different methods to obtain the client secret:</p> UIShell scriptAnsible module <ul> <li>Navigate to <code>https://{EDA_URL}/core/httpproxy/v1/keycloak</code> in your browser.</li> <li>Log in with the Keycloak administrator username and password (default is <code>admin:admin</code> and can be changed).</li> <li>From the Keycloak drop-down list on the upper left, select Event Driven Automation (eda).</li> <li>Select Clients from the menu on the left.</li> <li>Select eda in the client table.</li> <li>Select Credentials in the tab bar on the top.</li> <li>Copy the Client Secret.</li> </ul> <p>The above steps are shown in the video:</p> <p>During the development cycle a user might want to fetch the client secret in the automated way, without resorting to the UI. The shell script below fetches the client secret using the variables defined at the top of the file:</p> <p>Note, the script requires <code>curl</code> and <code>jq</code> to be installed in your environment.</p> Shell Script <pre><code>#!/bin/bash\n\nexport EDA_API_URL=\"${EDA_API_URL:-https://myinstance.eda.rocks:9443}\"\nexport KC_KEYCLOAK_URL=\"${EDA_API_URL}/core/httpproxy/v1/keycloak/\"\nexport KC_REALM=\"master\"\nexport KC_CLIENT_ID=\"admin-cli\"\nexport KC_USERNAME=\"${KC_USERNAME:-admin}\"\nexport KC_PASSWORD=\"${KC_PASSWORD:-admin}\"\nexport EDA_REALM=\"eda\"\nexport API_CLIENT_ID=\"eda\"\n\n# Get access token\nKC_ADMIN_ACCESS_TOKEN=$(curl -sk \\\n  -X POST \"$KC_KEYCLOAK_URL/realms/$KC_REALM/protocol/openid-connect/token\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"grant_type=password\" \\\n  -d \"client_id=$KC_CLIENT_ID\" \\\n  -d \"username=$KC_USERNAME\" \\\n  -d \"password=$KC_PASSWORD\" \\\n  | jq -r '.access_token')\n\nif [ -z \"$KC_ADMIN_ACCESS_TOKEN\" ]; then\n  echo \"Failed to obtain keycloak admin token\"\n  exit 1\nfi\n\n\n# Fetch all clients in the 'eda-realm'\nKC_CLIENTS=$(curl -sk \\\n  -X GET \"$KC_KEYCLOAK_URL/admin/realms/$EDA_REALM/clients\" \\\n  -H \"Authorization: Bearer $KC_ADMIN_ACCESS_TOKEN\" \\\n  -H \"Content-Type: application/json\")\n\n# Get the `eda` client's ID\nEDA_CLIENT_ID=$(echo \"$KC_CLIENTS\" | jq -r \".[] | select(.clientId==\\\"${API_CLIENT_ID}\\\") | .id\")\n\nif [ -z \"$EDA_CLIENT_ID\" ]; then\n  echo \"Client 'eda' not found in realm 'eda-realm'\"\n  exit 1\nfi\n\n# Fetch the client secret\nEDA_CLIENT_SECRET=$(curl -sk \\\n  -X GET \"$KC_KEYCLOAK_URL/admin/realms/$EDA_REALM/clients/$EDA_CLIENT_ID/client-secret\" \\\n  -H \"Authorization: Bearer $KC_ADMIN_ACCESS_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  | jq -r '.value')\n\nif [ -z \"$EDA_CLIENT_SECRET\" ]; then\n  echo \"Failed to fetch client secret\"\n  exit 1\nfi\n\necho \"$EDA_CLIENT_SECRET\"\n</code></pre> <p>If you have this script saved as a file, you can call it like this:</p> <pre><code>EDA_API_URL=https://eda.netdevops.me:9443 /tmp/clientsecret.sh\nk9NeZZK4LT6hHypzgy3djteFITEkUUaR\n</code></pre> <p>With overriding the top level parameters using the env variables.</p> <p>In case you're using Ansible collections for Nokia EDA, you can fetch the client secret using the Utils collection and the <code>get_client_secret</code> module.</p>"},{"location":"development/api/#getting-the-access-token","title":"Getting the Access Token","text":"<p>With the client secret obtained from the previous step, an API client can now request an access token from Keycloak. Below you will find different ways of getting the token:</p> curlAnsible <p>An example of using <code>curl</code> to authenticate and get an access token for the EDA API. Make sure to use your own EDA URL and Keycloak client secret.</p> <pre><code>curl -s https://${EDA_API_URL}/core/httpproxy/v1/keycloak/realms/eda/protocol/openid-connect/token \\\n  -H 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'client_id=eda' \\\n  --data-urlencode 'grant_type=password' \\\n  --data-urlencode 'scope=openid' \\\n  --data-urlencode 'username=${EDA_USERNAME}' \\\n  --data-urlencode 'password=${EDA_PASSWORD}' \\\n  --data-urlencode 'client_secret=${EDA_CLIENT_SECRET}'\n</code></pre> Example output parsed using <code>jq</code> <pre><code>curl -s https://${EDA_API_URL}/core/httpproxy/v1/keycloak/realms/eda/protocol/openid-connect/token \\\n  -H 'Content-Type: application/x-www-form-urlencoded' \\\n  --data-urlencode 'client_id=eda' \\\n  --data-urlencode 'grant_type=password' \\\n  --data-urlencode 'scope=openid' \\\n  --data-urlencode 'username=admin' \\\n  --data-urlencode 'password=admin' \\\n  --data-urlencode 'client_secret=9eGhwdAaox8bQ5DnfuUHuQTbOxhJxUwg' | jq -S\n{\n  \"access_token\": \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJBTHBheFhxanhaYmY5Vy1Pb3JpVnoxSUNTUV9SLUNrc05jZzVGRGFadUI0In0.eyJleHAiOjE3MzM5OTMyNDcsImlhdCI6MTczMzk5Mjk0NywianRpIjoiZjExZTdmM2UtMzFkNi00NTQ0LWE3MDUtMjA2Mzg0ZTYyYmNiIiwiaXNzIjoiaHR0cHM6Ly9wbG0tc2Itazgubm92YWxvY2FsOjk0NDMvY29yZS9odHRwcHJveHkvdjEva2V5Y2xvYWsvcmVhbG1zL2VkYSIsInN1YiI6ImYyYTc1MDM1LTU2YTUtNGJhMC1iZTliLTUzZTEzNTEyNTliZSIsInR5cCI6IkJlYXJlciIsImF6cCI6ImVkYSIsInNpZCI6ImYyZTU1YjQ2LWRiN2YtNGIwMi05ZTIwLTc2YTc2YWE0MDYwMSIsImFjciI6IjEiLCJhbGxvd2VkLW9yaWdpbnMiOlsiLyoiXSwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbImVkYXJvbGVfc3lzdGVtLWFkbWluaXN0cmF0b3IiLCJhZG1pbiJdfSwic2NvcGUiOiJvcGVuaWQgcHJvZmlsZSBlbWFpbCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwibmFtZSI6IkVEQSBhZG1pbiB1c2VyIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiYWRtaW4iLCJnaXZlbl9uYW1lIjoiRURBIiwiZmFtaWx5X25hbWUiOiJhZG1pbiB1c2VyIn0.ZH2vO1sbxm4tke2bE1fUdUbkCtHYo3bFUZpr0J46GL0lGpyIf0LkxOnosatjpLCQl7-CpExhZCv11SmUM6W6c4DoX6d90PKeC-t-GoSKshAxGIh7njtFt1_dYAf1NgF4EGOQMPINj-_n4igjU22Ef7aU8c05m-QkbIPykYFJ0BefqG_H8A1QzNvntADrEfrpHAudGFxB1Ei5FpBxIRfqX40B7_9brzWMlrRRXeWA9i-JVe-6JXQxTTqRKAF9sWGllTA-vbcl-MZ1WsGcC8yS-KQ9nyTrqkwT4Sh06Z7s8IpqBNPEcVJ8p_X65bblGoRKrXMSD0zEXM2zTsJRGd6JVA\",\n  \"expires_in\": 300,\n  \"id_token\": \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJBTHBheFhxanhaYmY5Vy1Pb3JpVnoxSUNTUV9SLUNrc05jZzVGRGFadUI0In0.eyJleHAiOjE3MzM5OTMyNDcsImlhdCI6MTczMzk5Mjk0NywianRpIjoiODM0MGVlMWQtOThkNC00ZmQ5LThhOTQtNTIwNTQ5YWJlMjE3IiwiaXNzIjoiaHR0cHM6Ly9wbG0tc2Itazgubm92YWxvY2FsOjk0NDMvY29yZS9odHRwcHJveHkvdjEva2V5Y2xvYWsvcmVhbG1zL2VkYSIsImF1ZCI6ImVkYSIsInN1YiI6ImYyYTc1MDM1LTU2YTUtNGJhMC1iZTliLTUzZTEzNTEyNTliZSIsInR5cCI6IklEIiwiYXpwIjoiZWRhIiwic2lkIjoiZjJlNTViNDYtZGI3Zi00YjAyLTllMjAtNzZhNzZhYTQwNjAxIiwiYXRfaGFzaCI6IlNJRUREbWdpb2xneXpPT2lqQ3ZHRWciLCJhY3IiOiIxIiwiZW1haWxfdmVyaWZpZWQiOmZhbHNlLCJuYW1lIjoiRURBIGFkbWluIHVzZXIiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJhZG1pbiIsImdpdmVuX25hbWUiOiJFREEiLCJmYW1pbHlfbmFtZSI6ImFkbWluIHVzZXIifQ.a9946wNL4_UCfi9LmysRz6wiZG3Zgt84Vz6pa5HfxRcQj5tvFsoBVNCSWd07OzxAS_QuPsMESl9WM4WalUW4Ib6XyNEPENvJsQE8mRWSm-x1R0d1lqrGSaiOJzKX5XUNgZ1u7PRbG-jtlcY-Iaq3Ei7sfOWVmXz8mKOyGteRCa9MSrbD4oFe52DTPNV4EwHIbkI8hUuO9dvgu3MdX6OdLSU9FApDAQjrMo7dqF9_E5SfGvnIPWcAiPD2QyuTP6ZF2SBDEX0OIqn7LNiyyeg4t6RylCakgi31zi_cTY3SfeMhmc9_X4SOj0XbmqZYM7o_mCFxbXTjeSVLcJv4zvuMHg\",\n  \"not-before-policy\": 0,\n  \"refresh_expires_in\": 1800,\n  \"refresh_token\": \"eyJhbGciOiJIUzUxMiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI1NDRjYThkOC0yN2JkLTRlYTAtOGY2Ny1jOTkzYjExMDAwZDYifQ.eyJleHAiOjE3MzM5OTQ3NDcsImlhdCI6MTczMzk5Mjk0NywianRpIjoiZmE2OGQwYWEtNTcyOS00ZjhiLWE5OWUtNDQyNmY3ZWEwNzg5IiwiaXNzIjoiaHR0cHM6Ly9wbG0tc2Itazgubm92YWxvY2FsOjk0NDMvY29yZS9odHRwcHJveHkvdjEva2V5Y2xvYWsvcmVhbG1zL2VkYSIsImF1ZCI6Imh0dHBzOi8vcGxtLXNiLWs4Lm5vdmFsb2NhbDo5NDQzL2NvcmUvaHR0cHByb3h5L3YxL2tleWNsb2FrL3JlYWxtcy9lZGEiLCJzdWIiOiJmMmE3NTAzNS01NmE1LTRiYTAtYmU5Yi01M2UxMzUxMjU5YmUiLCJ0eXAiOiJSZWZyZXNoIiwiYXpwIjoiZWRhIiwic2lkIjoiZjJlNTViNDYtZGI3Zi00YjAyLTllMjAtNzZhNzZhYTQwNjAxIiwic2NvcGUiOiJvcGVuaWQgcm9sZXMgd2ViLW9yaWdpbnMgYWNyIGJhc2ljIHByb2ZpbGUgZW1haWwifQ.SQeRoXLXA61l8AozNH2iaOYR0lJVMYWTtbAEYKY4lREYYesAAMNRVk5wcLR1oKJrFzCFRnhMmIEZysQ7D_DDcw\",\n  \"scope\": \"openid profile email\",\n  \"session_state\": \"f2e55b46-db7f-4b02-9e20-76a76aa40601\",\n  \"token_type\": \"Bearer\"\n}\n</code></pre> <p>In case you're using Ansible collections for Nokia EDA, you can fetch the client secret using the Utils collection and the <code>get_token</code> module.</p>"},{"location":"development/api/#openapi-specifications","title":"OpenAPI Specifications","text":"<p>Detailed information about all of the individual API endpoints and their parameters is available in the OpenAPI (v3) format. You can download OpenAPIv3 JSON files either from your EDA installation or from the community-supported eda-labs/openapi repository.</p>"},{"location":"development/api/#api-documentation-in-the-eda-ui","title":"API documentation in the EDA UI","text":"<p>If you have EDA already installed<sup>1</sup> you can find OpenAPI documentation and download specifications for both EDA Core as well as for every application you have installed in your cluster. To access the API Documentation, use the  icon in the top right corner and select API Documentation menu item:</p> <p>The API Documentation UI can be used to explore the API specification as well as to download the OpenAPI Specification JSON files. To download the specification file for a selected application, use the  icon in the top right corner.</p> <p>You can then use these files within your own tools that can work with the standard OpenAPI specifications.</p> <p>The API documentation web view does not only provide a reference to the available APIs and endpoints, but also allows you to run the requests for all available endpoints. For example, the video below shows how to run a <code>GET</code> request to list configured users in the EDA platform by using the Core API.</p> <p>The request runner in the API documentation web view takes care of the authentication flow on your behalf. You can start running API requests right away.</p>"},{"location":"development/api/#eda-openapi-repository","title":"EDA OpenAPI Repository","text":"<p>If you don't have EDA installed, but still want to browse the OpenAPI specification for the EDA core and its default apps, you can use the community-supported eda-labs/openapi repository.</p> <p>This repo uses tags to indicate which EDA software release these OpenAPI spec files were extracted from.</p>"},{"location":"development/api/#listing-openapi-specifications","title":"Listing OpenAPI Specifications","text":"<p>For EDA Core and each installed EDA App the API server maintains the API Specification file that can be listed and fetched via the <code>openapi</code> endpoint.</p> <p>To list the available API Specifications and their relevant URLs, first authenticate the client and then you can execute the following <code>curl</code> command to get the list of APIs and OpenAPI Specification URLs per API.</p> <pre><code>curl -s https://${EDA_URL}/openapi/v3 \\\n  -H 'Authorization: Bearer ${TOKEN}' \\\n  -H 'Content-Type: application/json'\n</code></pre> Example output parsed using <code>jq</code> <pre><code>$ curl -s https://${EDA_URL}/openapi/v3 \\\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJuNnV4VXVyODdyaHNYUEt6dHNlT1Qxc1lERVI5MVVlMXBzWnhhaEdQX19rIn0.eyJleHAiOjE3MTQ2MDMwNjAsImlhdCI6MTcxNDYwMjc2MCwianRpIjoiYzdiZjU3NGUtY2ZkNi00Nzk3LTk2NzItMWI5Y2E5YTg2NzQ2IiwiaXNzIjoiaHR0cDovL2hlbGl4Lm5va2lhLmRlbGxhZXJ0LmRldjo5MjAwL2NvcmUvaHR0cHByb3h5L3YxL2tleWNsb2FrL3JlYWxtcy9lZGEiLCJzdWIiOiJmMmE3NTAzNS01NmE1LTRiYTAtYmU5Yi01M2UxMzUxMjU5YmUiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJlZGEiLCJzZXNzaW9uX3N0YXRlIjoiMTFkZjU2OWEtNTZhYi00NmMyLWJkOTItNTJkYTg1YzM4NzA4IiwiYWNyIjoiMSIsImFsbG93ZWQtb3JpZ2lucyI6WyIvKiJdLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsiYWRtaW4iXX0sInNjb3BlIjoib3BlbmlkIHByb2ZpbGUgZW1haWwiLCJzaWQiOiIxMWRmNTY5YS01NmFiLTQ2YzItYmQ5Mi01MmRhODVjMzg3MDgiLCJlbWFpbF92ZXJpZmllZCI6ZmFsc2UsInByZWZlcnJlZF91c2VybmFtZSI6ImFkbWluIiwiZ2l2ZW5fbmFtZSI6IiIsImZhbWlseV9uYW1lIjoiIn0.bfTVRxe8KaVAqxjjDKIOJI6UGtJtpKc4W58ouvM1ILAVTiUtaWONT9xGIWDsUaEOzWQTlg-fjYWD3SmAMwPMo11wXafQkL7hTItj6Gs0DalwvmarXGetaVc7rVQhG5p3kvTQ0rNYqjE2bU763ml173kPXNKWUl7VXArCVK6uZ0azBDDX5uzlFBd5QEBtn1pH_-rATheCpvnkjC3s2WfJhDULfkix63N5MQWwhOajAKRe5mXTWLv9W9d_nwDsrHipPBtvAvG65I7s6tqjFH_M--PQPXifsl73v0hTnIHzC9ujpcGxkxctK9DvpwADF7TmuKVjbFHZqxp3FT7HxaK6Zg' \\\n  -H 'Content-Type: application/json' | jq -S\n{\n    \"paths\": {\n        \"/apps/aaa.eda.nokia.com/v1alpha1\": {\n            \"x-eda-nokia-com\": {\n                \"serverRelativeURL\": \"/openapi/v3/apps/aaa.eda.nokia.com/v1alpha1\",\n                \"title\": \"AAA Application APIs\"\n            },\n            \"serverRelativeURL\": \"/openapi/v3/apps/aaa.eda.nokia.com/v1alpha1\",\n            \"title\": \"AAA Application APIs\"\n        },\n        \"/apps/aifabrics.eda.nokia.com/v1alpha1\": {\n            \"x-eda-nokia-com\": {\n                \"serverRelativeURL\": \"/openapi/v3/apps/aifabrics.eda.nokia.com/v1alpha1\",\n                \"title\": \"AIFabrics Application APIs\"\n            },\n            \"serverRelativeURL\": \"/openapi/v3/apps/aifabrics.eda.nokia.com/v1alpha1\",\n            \"title\": \"AIFabrics Application APIs\"\n        },\n        \"/apps/appstore.eda.nokia.com/v1\": {\n            \"x-eda-nokia-com\": {\n                \"serverRelativeURL\": \"/openapi/v3/apps/appstore.eda.nokia.com/v1\",\n                \"title\": \"App Store Application APIs\"\n            },\n            \"serverRelativeURL\": \"/openapi/v3/apps/appstore.eda.nokia.com/v1\",\n            \"title\": \"App Store Application APIs\"\n        },\n        // snipped\n    }\n}\n</code></pre>"},{"location":"development/api/#fetching-the-api-specifications","title":"Fetching the API Specifications","text":"<p>For each of the App/version and the Core, the <code>serverRelativeURL</code> is the full URI to the API specifications for that specific App/version. You can use that to fetch the full OpenAPIv3 Specifications for the resources used and exposed by that specific App and version. Below is an example for the <code>connect</code> App. With an authenticated client you can execute the following <code>curl</code> command to fetch the OpenAPIv3 specification of the <code>connect.eda.nokia.com/v1alpha1</code> app.</p> <pre><code>curl -s http://${EDA_HOST}/openapi/v3/apps/connect.eda.nokia.com/v1alpha1 \\\n  -H 'Authorization: Bearer ${TOKEN}' \\\n  -H 'Content-Type: application/json'\n</code></pre> <ol> <li> <p>Try EDA installation is a perfect fit for experimenting with the API.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/","title":"Developing apps on EDA","text":"<p>EDA is all about extensibility, and the packaging of this extensibility is referred to as an \"app\".</p> <p>For a refresher on what an app is, check out apps.</p> <p>With base configuration your EDA cluster points to an app catalog supplied by Nokia. This gives you access to official Nokia-supported applications, including upgrades via the EDA store. If you're anything like us you have your own opinions about how you'd like to solve your automation problems! This is where building your own app comes in.</p> <p>Apps in general let you:</p> <ul> <li>Template inputs to resources within your cluster.     Have strong opinions about how your users interact with resources - set defaults, enforce constraints, and provide a consistent user experience.</li> <li>Define your own inputs, and the execution logic that should run in response to those inputs.     Generate configuration for targets, respond to telemetry events, trigger workflows, and much, much more.</li> <li>Generate alarms, normalize telemetry data.</li> <li>Define your own dashboards and other UI visualizations.</li> <li>Define your own workflows - one-shot operations that you'd like to expose to your users.</li> </ul> <p>An application may consist of one or more of these components, or none of them!</p>"},{"location":"development/apps/#why-build-on-eda","title":"Why build on EDA?","text":"<p>You've likely used other infrastructure automation tools before, and you may be wondering why you should build on EDA. Here are a few reasons:</p> <ul> <li>EDA operates on a deterministic, declarative, abstracted, and event-driven model.     This means that you can define the state you want your infrastructure to be in, and EDA will take care of making sure it gets there. No more handling deltas or worrying about order of operations. This massively simplifies application logic - given a certain input what would you like the output to be?</li> <li>Built for all your state streaming needs.     Simply define the set of things you'd like to monitor, and what you'd like to have happen on any updates. EDA takes care of subscriptions, and event triggers for you, providing a generic means to raise alarms, publish status of infrastructure, and normalize telemetry data.</li> <li>EDA is built on top of Kubernetes, which means you get all the benefits of Kubernetes - scalability, reliability, and a rich ecosystem of tools.</li> <li>And all of this comes with the multivendor capabilities.</li> </ul>"},{"location":"development/apps/#development-workflow","title":"Development workflow","text":"<p>In its simplest form, an app builders workflow consists of the following steps:</p> <ul> <li>Define the resources you want to handle - the abstractions or inputs you expect your users to provide.</li> <li>Define the logic you need - the scripts (or sometimes referred to as intents) that will run in response to changes in those resources. These scripts are written in Python<sup>1</sup>.</li> <li>Define the relationships between the above - what logic is triggered by what resources.</li> </ul> <p>In its more advanced form you may:</p> <ul> <li>Write Kubernetes-controller style apps, which are a bit more complex, but also more powerful.     This effectively lets you build and package your own Kubernetes controllers, which can be used to manage any Kubernetes resource, or any EDA resource.</li> <li>Define any views required - the dashboards that will display the state of your resources, or any other information you want to expose or visualize.</li> <li>Define the workflows you need - the one-shot operations that you want your users to be able to perform. Think ping, upgrade, verify, etc.</li> </ul>"},{"location":"development/apps/#next-steps","title":"Next steps","text":"<p> Setup the dev environment</p> <ol> <li> <p>MicroPython to be precise. The considerably faster cold startup times and lower memory footprint make it ideal for the event-driven nature of EDA.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/build-publish/","title":"Build and Publish","text":"<p>We take pride in EDA's extensibility through applications, and one of the key aspects of this extensibility is the ease of build, publish, share and install workflows. EDA uses standard, well-known and established toolchains for this purpose:</p> <ul> <li>OCI image as a packaging format for the application</li> <li>Container registry as a storage for the application images</li> <li>Git for catalog and application discovery and sharing</li> </ul> <p>From the distribution point of view, EDA app consists of two distinct artifacts that are coupled together:</p> <ol> <li>An app manifest file that describes the app components, including the URL/tag of the app image</li> <li>An OCI image that contains the app components</li> </ol> <p>This structure can be visualized as:</p> <p>In this chapter we will cover the process of building and publishing an application.</p>"},{"location":"development/apps/build-publish/#building-an-oci-app-image","title":"Building an OCI App Image","text":"<p>We refer to the process of packaging the application artifacts into an OCI image format as \"building\" the image. But building the image alone won't make the app installable, as the image needs to be hosted in an OCI container registry that is reachable from your EDA cluster. As these two steps are tightly coupled, we have a single command in the <code>edabuilder</code> CLI that takes care of both operations at once - <code>edabuilder build-push</code>.</p> <p>Since most container registries require authentication, we first need to login to the registry. The <code>edabuilder</code> has a <code>login registry</code> subcommand that takes in two arguments - username and password. For example, to login to a free ghcr.io registry, you would use the following command:</p> <pre><code>edabuilder login registry -u &lt;username&gt; -p &lt;password&gt; ghcr.io #(1)!\n</code></pre> <ol> <li> <p>If you're using GitHub CLI, then instead of providing the token as a password, you can make use of the <code>gh</code> CLI tool and perform the following:</p> <p>Add <code>write:packages</code> scope to your token:</p> <pre><code>gh auth login -s 'write:packages'\n</code></pre> <p>And then use the token as:</p> <pre><code>edabuilder login registry -u hellt -p $(gh auth token) ghcr.io\n</code></pre> </li> </ol> <p>With the authentication step out of the way, we need to make sure that the application manifest has the correct container image URL and tag set. When <code>edabuilder</code> scaffolds an application it sets the image name in the app's manifest. If you have followed the quickstart guide, your <code>banners</code> app manifest file will contain the following:</p> banners/manifest.yaml<pre><code>apiVersion: core.eda.nokia.com/v1\nkind: Manifest\nmetadata:\n  name: banners\nspec:\n  # omitted for brevity\n  group: banners.eda.local\n  image: change.me/banners:v0.0.0\n</code></pre> <p>As an app owner, you set the image value to an image URI that points to the registry where you want the image to be published in the app manifest file<sup>1</sup>. As we are using ghcr.io for this example, we could set the image value to e.g.:</p> <pre><code>- image: change.me/banners:v0.0.0\n+ image: ghcr.io/eda-labs/banners:v2.1.0\n</code></pre> <p>Now, <code>edabuilder build-push</code> has everything it needs - an image URI and the credentials for the container registry the image points to. Simply point the command towards your manifest and its build context, like so:</p> run from the project's directory<pre><code>edabuilder build-push --app manifest=banners/manifest.yaml #(1)!\n</code></pre> <ol> <li>Note that the <code>banners</code> directory in the <code>--app manifest=banners/...</code> argument is the directory containing the application manifest. If you named your app differently you will have to change this value accordingly.</li> </ol> <p>A successful <code>build-push</code> action ends by prompting you with \"Successfully pushed OCI Image\". Your app image should now show up in the registry. If you intend to have your image accessible without authentication, make your image public using the interface of your registry provider.</p>"},{"location":"development/apps/build-publish/#publishing-an-app","title":"Publishing an App","text":"<p>The second pillar of an app is its manifest file, which we still need to publish to a catalog of our choice.</p> <p>The first thing you need to ensure is that you have a git repository created that you intend to use as an App Catalog for your EDA applications. In this example, we will be using our eda-labs/catalog repository that we use for our community-oriented applications.</p> <p>Start off by logging into the Git provider of your choice to make sure you are authorized to push the manifest to the repository:</p> <pre><code>edabuilder login git -u hellt -p $(gh auth token) https://github.com/eda-labs/catalog #(1)!\n</code></pre> <ol> <li>Change the user, password and repository URL to the appropriate values for your repository.</li> </ol> <p>After a successful login we can publish our application manifest to the repository:</p> <pre><code>edabuilder publish https://github.com/eda-labs/catalog \\\n--app manifest=banners/manifest.yaml\n</code></pre> <p>A successful publish of the manifest should result in the following output:</p> <pre><code>Publishing to branch 'main'\nNo app version given, using the manifest image tag as app version: \nStaging `banners` at version `v2.1.0`\nSuccessfully published Apps\n</code></pre> <p>Now you should see the application manifest published in your Git repository following the <code>vendors/&lt;vendor-name&gt;/apps/&lt;app-name&gt;</code> path:</p> <p></p> <p>The app version will be matching the version from the image tag found in the manifest, unless the version is provided inline with the <code>--app</code> argument.</p> <p>To republish an app, i.e. override an existing version, add <code>--force</code> flag to the command.</p>"},{"location":"development/apps/build-publish/#configuring-eda-store-with-your-publishing-authority","title":"Configuring EDA Store with your publishing authority","text":"<p>Just uploading the OCI image and the manifest to a catalog won't make your application available in the EDA Store. You need to make the store aware of any new OCI registries and/or catalogs. The procedure for adding a registry to the EDA store can be found here, the procedure for catalogs can be found here.</p> <p>In our example we are using ghcr.io. If you've deployed EDA through the Playground, this registry is already registered with the EDA store, so nothing needs to be done.  </p> <p>We do need to apply a catalog CR, though. Here is the Catalog CR that adds a catalog named \"eda-labs\" and references the Git repo we pushed our manifest to in the previous step:</p> Catalog CRApply command <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: eda-labs\nspec:\n  remoteType: git\n  remoteURL: https://github.com/eda-labs/catalog\n  skipTLSVerify: false\n  title: EDA Labs Catalog\n  # auth secret is not required, as our Catalog repo is public\n  # authSecretRef: ''\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: eda-labs\nspec:\n  remoteType: git\n  remoteURL: https://github.com/eda-labs/catalog\n  skipTLSVerify: false\n  title: EDA Labs Catalog\n  # auth secret is not required, as our Catalog repo is public\n  # authSecretRef: ''\nEOF\n</code></pre> <p>Once added, the EDA Store will start parsing the referenced Git repo and display them as available applications in the EDA Store.</p> <p>Since our repo is public, we did not utilize the <code>authSecretRef</code> reference; if your Git repo is private, you would need to create a Secret and reference it.</p>"},{"location":"development/apps/build-publish/#local-development","title":"Local development","text":"<p>The three sections above describe what you need to do when you're ready to publish an app. It's a bit of manual work, and having to do this over and over again while your app is still under development is cumbersome. That is where <code>edabuilder deploy</code> comes in. This command is designed to help you iterate on your app in a frictionless manner during development. Under the hood, it makes use of the concepts described above, but <code>edabuilder</code> juggles around some of the URIs in order to use an intermediary development catalog and registry inside of your EDA cluster.</p> <p>Concretely, when you want to try out a new version of your code, simply travel down to your app directory (the one containing the <code>manifest.yaml</code>), and execute</p> <pre><code>edabuilder deploy #(1)!\n</code></pre> <ol> <li>This command also has support for the <code>--app</code> flag, so technically you don't have to travel down to the app directory.</li> </ol> <p>This does the following:</p> <ol> <li>create a development catalog repository in the git server in your EDA cluster</li> <li>create a secret and Catalog CR for the dev catalog to configure the EDA Store</li> <li>create a simple<sup>2</sup> development registry (Deployment, Service, and Secret and Registry CR to configure the EDA Store)</li> <li><code>edabuilder generate</code> to keep all of your Python models, CRDs, etc. up-to-date</li> <li>rewrite the manifest AppImage URI (in memory) to point to the development registry, then <code>edabuilder build-push</code></li> <li><code>edabuilder publish</code> to the development catalog</li> <li>apply an app install Workflow to (re)install the app and wait for the installation result</li> </ol> <p>When you run <code>edabuilder deploy</code> for the first time, step 3 could take a while if the registry image needs to be pulled.</p>"},{"location":"development/apps/build-publish/#bring-your-own-catalogregistry","title":"Bring your own catalog/registry","text":"<p>The <code>edabuilder deploy</code> command is customisable through a configuration file, located at <code>~/.config/edabuilder/config.yaml</code><sup>3</sup>. It allows you to provide multiple custom OCI registries and/or application catalogs (Git repositories) by specifying the URL of the corresponding component and to select the current one to use for the <code>edabuilder deploy</code> command.</p> <p>Consult with the  deploy targets section of the <code>edabuilder</code> CLI documentation for more information on how to use this configuration file.</p> <ol> <li> <p>When creating your app development project through <code>edabuilder init</code>, you can use the <code>-r | --registry</code> option to specify your production registry. If you do so, the PROJECT file will store the registry and it will automatically be included in the image URI of any newly created apps' manifests.\u00a0\u21a9</p> </li> <li> <p>A basic CNCF Distribution Registry image is used here.\u00a0\u21a9</p> </li> <li> <p>You can provide a custom location for this file by setting the <code>EDABUILDER_CONFIG</code> environment variable.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/components/","title":"Application Components","text":"<p>Each application in EDA is its own directory in the EDA project repository<sup>1</sup>. Taking the quickstart app as a starting point, a project contains the <code>banners</code> directory that has the following structure.</p> contents of the banners app directory<pre><code>.\n\u251c\u2500\u2500 api\n\u251c\u2500\u2500 crds\n\u251c\u2500\u2500 docs\n\u251c\u2500\u2500 examples\n\u251c\u2500\u2500 intents\n\u251c\u2500\u2500 openapiv3\n\u251c\u2500\u2500 test\n\u251c\u2500\u2500 ui\n\u251c\u2500\u2500 workflows\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 go.sum\n\u2514\u2500\u2500 manifest.yaml\n</code></pre>"},{"location":"development/apps/components/#application-api","title":"Application API","text":"<p>To define application APIs, edabuilder uses the same pattern as kubebuilder, i.e. the API is defined by the Go files in the <code>api</code> directory.</p> <p>Based on the source API types defined in <code>.go</code> files, the <code>edabuilder generate</code> creates the following components:</p> <ul> <li>Python models equivalent to your API structs defined in Go; stored in <code>api/pysrc</code> directory.</li> <li>Custom Resource Definitions (CRDs) in <code>crds</code> directory.</li> <li>OpenAPI schema files, which describe extensions to the schema of both Kubernetes and EDA and is located in <code>openapiv3</code> directory.</li> </ul> <p>The <code>generate</code> command can be run separately, but many subcommands (like <code>deploy</code> and <code>release</code>) start off by running <code>edabuilder generate</code> to make sure your app state is always up-to-date.</p>"},{"location":"development/apps/components/#intents","title":"Intents","text":"<p>Intents (aka Scripts), are executable Python code that is triggered by the changes made to the respective resources. These scripts are used to implement the logic of the application for non-Kubernetes-controller apps.</p> <p>Intents are what most developers will write when building new applications on EDA or extending the existing apps provided by Nokia.</p> <p>Check the Banner application walkthrough to see what makes up a simple intent-based application.</p>"},{"location":"development/apps/components/#dashboards","title":"Dashboards","text":"<p>The developers can create and bundle custom UI dashboards, adding observability and monitoring capabilities for their apps. The dashboards are defined using JSON files and can be found in the <code>ui</code> directory of the app.</p>"},{"location":"development/apps/components/#workflows","title":"Workflows","text":"<p>Workflows are the \"run to completion\" applications that can be triggered by the resources, users or API clients. Workflows are typically used to implement the logic of the application for one-shot operations - things like upgrades, network pings, route information collection or other operations that are not perpetually ongoing.</p> <p>Workflows are typically written in Go, but can be written in any language for which EDA Development Kit (EDK) support is available.</p>"},{"location":"development/apps/components/#documentation","title":"Documentation","text":"<p>Each application contains its own documentation in the <code>docs</code> directory. The documentation is written in Markdown and includes the overview of the application, its components, license info, usage examples and documentation for each resource defined by the application.</p>"},{"location":"development/apps/components/#manifest","title":"Manifest","text":"<p>The <code>manifest.yaml</code> file defines every aspect of the application packaging, including the application metadata, its components, dependencies, and other relevant information. EDA Store uses this manifest file to understand how to install, deploy and manage the application within an EDA platform.</p> <p>Whenever a user adds a new application component with the <code>edabuilder</code> CLI, the manifest file is automatically updated to include the new components, therefore users typically should not need to edit this file too often manually.</p>"},{"location":"development/apps/components/#other-resources","title":"Other resources","text":"<p>Some applications may include more specialized components, but these are less common and the majority of applications will consist of the components described above.</p> <ol> <li> <p>The layout of the project is covered in the Project Layout section.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/edabuilder/","title":"EDABuilder","text":"<p><code>edabuilder</code> is a standalone CLI tool for performing EDA Store operations such as building and publishing EDA apps or scaffolding the boilerplate code for new apps. The download instructions are mentioned in Environment setup page.</p> <p><code>edabuilder</code> has the following capabilities:</p> <ul> <li><code>init</code>: initialise a directory as a project that will hold multiple apps.</li> <li><code>create app</code>: scaffold the boilerplate for a new application.</li> <li><code>create resource</code>: create a new API resource. These resources are the inputs and outputs of your app, i.e. the main way to interact with your app.</li> <li><code>create intent</code>: scaffold boilerplate code for a new config/state intent for one of your API resources, if you hadn't done so already at the time of creating the resource.</li> <li><code>create version</code>: create a new API version.</li> <li><code>build-push</code>: package an app and host it in a registry<sup>1</sup>.</li> <li><code>publish</code>: publish your app to a catalog<sup>1</sup>.</li> <li><code>generate</code>: based on your API resources, defined in the Go files under <code>api/</code>, generate equivalent python models to be used as an SDK in your intents, CRDs, OpenAPI specs, and keep your manifest up-to-date.</li> <li><code>generate appsettings</code>: Scaffold a new <code>settings</code> directory, which you can further customise to provide documentation for your app's settings.</li> <li><code>generate appsettings-openapi</code>: Generate an OpenAPI spec based on the settings struct in your <code>settings</code> directory.</li> <li><code>deploy</code>: build, publish and install your application in your EDA cluster, allowing you to test it immediately and iteratively, during development<sup>1</sup>.</li> </ul> <p>Working directories</p> <p><code>edabuilder</code> will run using the current working directory as context. You should run project related commands from the root of your project (<code>edabuilder init</code> for example), and application related commands from the root of your applications (<code>edabuilder create</code> for example).</p>"},{"location":"development/apps/edabuilder/#initialising-a-project","title":"Initialising a project","text":"<p>When you run <code>edabuilder init [&lt;project-name&gt;]</code>, either the current directory or a new one, named <code>project-name</code>, will be initialised for app development. This entails populating a couple of directories (<code>common/</code>, <code>test/</code>, <code>utils/</code>) with common libraries to be imported in the app scripts you will be writing, as well as creating a PROJECT file that keeps track of some project-wide parameters, such as the publishing authority of your apps, your production registry, etc. These parameters can all be passed via arguments to the command. To see the available options, run <code>edabuilder init -h</code>.</p>"},{"location":"development/apps/edabuilder/#creating-an-app","title":"Creating an app","text":"<p>Running <code>edabuilder create app &lt;app-name&gt;</code> from the root of your project will net you a new directory containing a scaffolded structure for an app with a couple of subdirectories created in it. They all have self-explanatory, categorised, names that suggest where to put app files. Additionally, a <code>manifest.yaml</code> file is created. The <code>edabuilder</code> tool will maintain parts of this manifest along the way. More on that in the other sections.</p>"},{"location":"development/apps/edabuilder/#creating-a-resource","title":"Creating a resource","text":"<p>As stated earlier, resources are the main way to interact with your app. Run <code>edabuilder create resource MyCoolKind</code> to scaffold a barebones resource: the \"API definition\" is the Go file located at <code>api/&lt;apiversion&gt;/mycoolkind_types.go</code>.</p> <p>From this file, the equivalent python models are generated at <code>api/&lt;apiversion&gt;/pysrc/mycoolkind.py</code>, as well as a CRD under <code>crds/</code> and the OpenAPI spec under <code>openapiv3/</code>. Your manifest is automatically kept up-to-date with this change, meaning this new <code>pysrc</code> and the CRD are ready to be packaged in your app already.</p>"},{"location":"development/apps/edabuilder/#creating-an-intent","title":"Creating an intent","text":"<p>In and of itself, a resource consisting of only a CRD is not very useful. You likely intend to trigger some code when an instance of your resource is created, updated, or deleted. We call the scripts containing the code for these trigger events \"intents\".</p> <p>Two types of intents exist: config intents and state intents. The config intent is really meant for direct interaction: A user creates a resource with some desired parameters, and the intent code is subsequently triggered, performing some action in the cluster. A resource bundled with a config intent is called a \"config resource\".</p> <p>The state intent will in most cases be more of a watcher: Based on some observed state of the cluster, the code e.g. performs some translations or exports some metrics. A resource bundled with a state intent is called a \"state resource\".</p> <p>Since intents and resources are such tightly coupled concepts, intent code of either type can be scaffolded at the time of creating a resource, with the <code>--scaffold-config</code> or <code>--scaffold-state</code> options. If you forgot to scaffold the intent boilerplate at resource creation time, you can add it after the fact by using the <code>edabuilder create intent</code> subcommand.</p> <p>After creating an intent (or creating a resource with one of the intent scaffolding options for that matter), your manifest is kept up-to-date with the appropriate scripts and trigger events.</p>"},{"location":"development/apps/edabuilder/#creating-a-version","title":"Creating a Version","text":"<p>Through <code>edabuilder create version</code> you can create a new API version, e.g. when you are introducing backwards compatibility breaking changes over the lifetime of your app. Here you have the option to carry over API resources from a previous version. If you choose to do so, a boilerplate migration script will be scaffolded per resource that is present in your old API version. The API version in the manifest specification is automatically updated to the new version, and conversion scripts are tracked in the manifest as well.</p>"},{"location":"development/apps/edabuilder/#generating-your-app","title":"Generating your app","text":"<p><code>edabuilder generate</code> is an idempotent command designed to keep any generated code in your app up-to-date. It uses your API resources as input to generate a python SDK under <code>api/&lt;apiversion&gt;/pysrc</code>, CRDs and OpenAPI. It also ensures your manifest is up-to-date.</p> <p>Many of the other subcommands use <code>generate</code> under the hood, so it's likely you won't have to run it explicitly very often.</p>"},{"location":"development/apps/edabuilder/#adding-app-settings","title":"Adding App Settings","text":"<p>There are two <code>edabuilder</code> commands which allow you to provide install-time settings for your application. For instance, if your app includes a resource, (e.g. a k8s deployment) for which you want the user to be able to specify configurable parameters like CPU limit, etc.</p> <p>The first command, <code>edabuilder generate appsettings</code>, will evaluate all CRs that are linked in your app's Manifest and look for settings annotations. A setting is annotated with <code># app-set: ${&lt;setting name&gt;}</code>. To continue the example of a CPU limit set for a Deployment resource, the Deployment CR linked in the Manifest would look something like:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-controller\nspec:\n  # omitted for brevity\n  containers:\n    - image: ghcr.io/your-container-image-uri\n      resources:\n        limits:\n          cpu: \"4\" # app-set: ${controllerCpuLimit}\n</code></pre> <p>Where the setting JSON name is <code>controllerCpuLimit</code> and its default value is <code>\"4\"</code>. After gathering all the settings you have annotated in your app CRs, <code>edabuilder</code> will collect these in a single Go struct that becomes the source of truth for your settings' OpenAPI specification. This struct, <code>AppSettingsSpec</code>, is located at <code>&lt;app-root&gt;/settings/appsettings_types.go</code>. For the CPU limit example above, this is the resulting struct:</p> <pre><code>// AppSettingsSpec defines the desired state of AppSettings.\ntype AppSettingsSpec struct {\n    // Document the 'ControllerCpuLimit' setting here, so it shows up nicely in your generated OpenAPI spec.\n    // +kubebuilder:default=\"4\"\n    // +eda:ui:title=\"ControllerCpuLimit\"\n    ControllerCpuLimit string `json:\"controllerCpuLimit,omitempty\"`\n}\n</code></pre> <p>You should manually review and edit this struct to make sure the documentation comments and field types are correct before continuing. Given that a single structure defines the app settings means that the settings' names should be unique across all CRs of your app.</p> <p>Iterating on settings</p> <p>The <code>generate appsettings</code> command is strictly meant for the initial scaffolding of the application' settings structure. Rerunning this command (which requires the <code>-f</code> flag) is a destructive operation, in the sense that it will revert all manual changes you may have done in <code>AppSettingsSpec</code>.</p> <p>If you have already scaffolded the settings and made updates to the <code>AppSettingsSpec</code> struct and would like to add a new setting, then simply add a field to the struct for your new setting and do not rerun the <code>generate appsettings</code> command.</p> <p>Once you're done documenting your app settings, you can finalise your app settings for the EDA Store with the second command, <code>edabuilder generate appsettings-openapi</code>. It will generate an OpenAPI spec under <code>&lt;app-root&gt;/appsettings-openapi/</code>. Your Manifest will be updated automatically to include this file.</p> <p>Your app is now ready to be installed by the EDA Store with install-time settings.</p> <p>Installing with a non-default value of a setting</p> <p>App settings can be provided directly in the AppInstaller workflow or at the app install time in the EDA UI.</p> <p>To provide a custom value for a setting in the workflow, add the <code>&lt;setting-name&gt;: &lt;custom-value&gt;</code> key-value pair to the list entry of the appropriate app in the Workflow's <code>spec.input.apps[*].appSettings</code> map. Here is an example Workflow to install some app with a custom value for the <code>controllerCpuLimit</code> setting:</p> Install Workflow <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: AppInstaller\nmetadata:\n  name: app-install-workflow-with-settings\n  namespace: eda-system\nspec:\n  operation: install\n  apps:\n    - appId: &lt;your-app-with-cpu-limit-setting&gt;\n      catalog: &lt;your catalog&gt;\n      version:\n        value: v0.0.0\n      appSettings:\n        controllerCpuLimit: \"8\"\n</code></pre>"},{"location":"development/apps/edabuilder/#configuring-deploy-targets","title":"Configuring deploy targets","text":"<p>The <code>edabuilder deploy</code> command is customisable through a configuration file located at <code>~/.config/edabuilder/config.yaml</code><sup>2</sup>. It allows a user to provide the so called deploy targets - the custom OCI registry and application catalog pairs that a user can select from when deploying an app. The configuration file is structured as follows:</p> <pre><code># a map of named deploy targets\ndeploy-targets:\n  internal-target: # first deploy target\n    # Is authentication required to read from both registry and catalog?\n    # When set to false or omitted, indicates that the registry/catalog are public\n    read-authentication: false\n    registry:\n      # URL of your registry, i.e. [&lt;scheme&gt;]&lt;fqdn&gt;[:port]\n      url: corporateregistry.internal\n      # Whether to skip TLS verification for the registry [default: false]\n      skip-tls-verify: true\n    catalog:\n      # URL of your catalog repo, i.e. [&lt;scheme&gt;]&lt;fqdn&gt;[:port]/&lt;repository&gt;.git\n      url: https://gitlab.mycorp.internal/dev/eda-apps.git\n      skip-tls-verify: true\n\n  external-target: # second deploy target\n    registry:\n       url: ghcr.io\n    catalog:\n      url: https://github.com/someorg/eda-apps.git\n\n# the name of the currently active deploy target\n# in-cluster is a special value that indicates the in-cluster deploy target\ncurrent-deploy-target: in-cluster\n</code></pre> <p>The deployment targets are defined in the <code>config.yaml</code> file in the edabuilder config directory using the following top level keys:</p> <ul> <li><code>deploy-targets</code> - a YAML object that is a map of deploy target configurations.</li> <li><code>current-deploy-target</code> - a string value that matches one of the configured deploy-target names. Defaults to in-cluster which is a reserved name for a deploy target being the EDA cluster itself, with the dev registry and dev catalog deployed in it.</li> </ul>"},{"location":"development/apps/edabuilder/#in-cluster-deploy-target","title":"<code>in-cluster</code> deploy target","text":"<p>The default deploy target is the <code>in-cluster</code> target, which is a reserved name for the OCI registry and Catalog deployed by <code>edabuilder</code> in the EDA cluster itself. The <code>edabuilder deploy</code> command will use this target by default if no other target is specified.</p>"},{"location":"development/apps/edabuilder/#current-deploy-target","title":"Current deploy target","text":"<p>After you have added the desired deploy targets to the <code>config.yaml</code> file, you can set the current deploy target by running either by specifying its name in the configuration file, or using the CLI command:</p> <pre><code>edabuilder deploy use-target &lt;target-name&gt;\n</code></pre> <p>To reset the current deploy target to the default <code>in-cluster</code> target, you can run:</p> <pre><code>edabuilder deploy reset-target\n</code></pre>"},{"location":"development/apps/edabuilder/#read-authentication","title":"Read authentication","text":"<p>Both the catalog and registry may require authentication for cloning or fetching. Private Git repositories and private registries always require authentication. This means that, for the app store to pull the corresponding artifacts, a secret containing the necessary authentication or token data must be provided.</p> <p>However, when using public registries and catalogs, users do not need to provide authentication data for read operations.</p> <p>To provide this flexibility, the <code>read-authentication</code> boolean setting is available at the deploy-target level.</p> <ul> <li>When set to <code>false</code> (or when not present), both the catalog and registry are considered public, and reads can be performed without authentication.</li> <li>When set to <code>true</code>, authentication is required to read from the registry and catalog. In this case, during the <code>deploy</code> command, a prompt will appear asking if you want <code>edabuilder</code> to configure the associated secrets using authentication data previously provided via the <code>edabuilder login registry</code> or <code>edabuilder login catalog</code> commands (stored in <code>~/.config/edabuilder/auth.json</code><sup>3</sup>).</li> </ul> <p>If you choose \"Yes,\" the matching authentication data is provisioned as a Kubernetes secret and referenced in the corresponding catalog or registry. If you select \"No,\" no secrets are configured, and a prompt will inform you that these secrets should be created manually.</p> <ol> <li> <p>For more information on packaging, publishing and iteratively deploying apps, refer to Build and Publish \u21a9\u21a9\u21a9</p> </li> <li> <p>You can provide a custom location for this file by setting the <code>EDABUILDER_CONFIG</code> environment variable.\u00a0\u21a9</p> </li> <li> <p>You can provide a custom location for this file by setting the <code>EDABUILDER_AUTH_CONFIG</code> environment variable.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/project-layout/","title":"Project Layout","text":"<p>If you followed the quickstart and initialized a new EDA project with the <code>banners</code> application in it, your top level project directory would look like this:</p> <pre><code>.\n\u251c\u2500\u2500 banners # dir\n\u251c\u2500\u2500 common  # dir\n\u251c\u2500\u2500 test    # dir\n\u251c\u2500\u2500 utils   # dir\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .envrc\n\u251c\u2500\u2500 PROJECT\n\u251c\u2500\u2500 go.work\n\u251c\u2500\u2500 go.work.sum\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 ruff.toml\n</code></pre> <p>Let's cover the purpose of each directory in more detail.</p>"},{"location":"development/apps/project-layout/#application","title":"Application","text":"<p>The <code>banners</code> directory contains the <code>banners</code> application files that <code>edabuilder</code> created for us when we executed <code>edabuilder create app banners</code>. The contents of this app directory is covered in the App Components section.</p>"},{"location":"development/apps/project-layout/#common","title":"Common","text":"<p>The <code>common</code> directory contains the common python functions and constants that apps can use. It is auto-generated by <code>edabuilder</code> and typically should not be modified manually.</p>"},{"location":"development/apps/project-layout/#test","title":"Test","text":"<p>The <code>test</code> directory contains python packages that enable application unit testing. The app testing documentation is a work in progress.</p>"},{"location":"development/apps/project-layout/#utils","title":"Utils","text":"<p>In the <code>utils</code> directory you will find shared utility functions that simplify some operations on EDA objects.</p>"},{"location":"development/apps/project-layout/#project","title":"Project","text":"<p>The <code>PROJECT</code> file contains the global config a project was initialized with. For example, if you are reading this after the quickstart, your project file should look similar to this:</p> <pre><code>builderVersion: v25.12.1\ndomain: eda.local\nname: example\nregistry: change.me\nvendor: community\n</code></pre> <p>The <code>builderVersion</code> contains the EDA release version that is used by this particular version of the <code>edabuilder</code> tool.</p> <p>The rest of the fields are self explanatory and can be provided as CLI arguments during the project instantiation.</p>"},{"location":"development/apps/project-layout/#go-workspace","title":"Go workspace","text":"<p>The <code>go.work</code> file defines the Go Workspace configuration and includes (via <code>uses</code> statement) all apps created in the project. Since the project may contain more than one app, the workspace makes it possible to develop multiple apps in parallel without modifying each apps's Go module file.</p> <p>Most users will never need to modify the workspace file, and edabuilder will add new apps to the workspace automatically.</p>"},{"location":"development/apps/project-layout/#python-project","title":"Python project","text":"<p>You will find the <code>pyproject.toml</code> and <code>ruff.toml</code> files in the root of your project. The <code>pyproject.toml</code> file contains the Python project metadata and the <code>ruff.toml</code> file contains the Python linting rules.</p> <p>Since most EDA applications are written in Python<sup>1</sup><sup>2</sup> as an application developer you would want to initialize a virtual environment for your EDA app project to ensure that you get code autocompletion and basic linting in place.</p> <p>You may use any virtual environment tool of your choice, and in the quickstart we used <code>uv</code> to init the virtual environment by running <code>uv sync</code> while being in the project directory.</p>"},{"location":"development/apps/project-layout/#environment","title":"Environment","text":"<p>A couple of environment files - <code>.envrc</code> and <code>.env</code> - contain environment variables that should help your editor to resolve the local python packages and select the local <code>.venv</code> as an acting python environment.</p>"},{"location":"development/apps/project-layout/#git-ignore","title":"Git ignore","text":"<p>And finally, you will find a <code>.gitignore</code> file that contains a list of files and directories that should be ignored by Git.</p> <ol> <li> <p>Technically, with MicroPython runtime.\u00a0\u21a9</p> </li> <li> <p>There are two different classes of EDA apps - intent apps that are written in Python, and Controller-based apps, that can be written in any language.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/quick-start/","title":"Quick Start","text":"<p>An application in EDA can contain many things and do way more than just generating node configurations from the abstracted input. But, still, the most common thing you're going to want an app for is to generate some configuration for a target, and potentially publishing some state relating to that configuration and/or target.</p> <p>To fast track this common case an example demonstrating how to build an app is baked into the <code>edabuilder</code> CLI tool. In this quickstart we'll use the baked in example of an app that configures the login banner on a device and walk you through the steps required to build the app from scratch, iterate on it during the development cycle, and then publish it to a custom Catalog so you can share it with others.</p> <p>Without further ado, let's get started by going into a directory where we want to create our project.</p> <ol> <li> <p>Create a new project</p> <p>We begin with initializing a new project that will contain our demo application that will configure the login banner on a device.</p> <p>To create a project, supply the application vendor<sup>1</sup> and the project name as an argument to the <code>edabuilder init</code> command:</p> <pre><code>edabuilder init --vendor community example &amp;&amp; cd example\n</code></pre> <p>You find yourself in the <code>example</code> directory that we just initialized with some top-level project files and directories scaffolded out for you.</p> </li> <li> <p>Create a Python virtual environment</p> <p>Now is a good time to create a Python virtual environment that we will use to get autocompletion, code formatting and linting for our application code.</p> <p>If you have <code>uv</code> installed like was suggested in the setting the dev environment section, you can just run:</p> <pre><code>uv sync\n</code></pre> <p>You are free to use any other means to create a venv.</p> </li> <li> <p>Create an app</p> <p>From the <code>./example</code> project directory, we proceed with creating a directory that will contain our EDA application.</p> <p>An important thing to note is that an application in EDA is a group that contains one or more of the following resources:</p> <ul> <li>config and/or state intents that declaratively describe the desired configuration and state of a target.</li> <li>operational workflows associated with this app</li> <li>dashboards</li> </ul> <p>Let's call our application - <code>banners</code> - since we will scaffold an app that provisions a login banner on the network devices.</p> <pre><code>edabuilder create app banners #(1)!\n</code></pre> <ol> <li> <p>Warning</p> <p>If your application name is more than one word, the name must be in a kebab-case format.</p> <p>In this example, the app name is simply <code>banners</code>, but if you wanted to name it \"my banners\", then you should've named it <code>my-banners</code>.</p> </li> </ol> <p>This step should generate the <code>banners</code> directory where you will find the scaffolded layout of the application with no particular logic implemented yet.</p> </li> <li> <p>Create a resource</p> <p>At this stage, you would start defining the API of your app, typing code for your configuration and state intents, crafting alarms and creating the workflows and dashboards. But for the sake of this quickstart, we need something quick and easy; you will get to building real apps later once you've got the hang of it.</p> <p>We have baked in the example <code>Banner</code> resource inside the <code>edabuilder</code> CLI tool to demonstrate the app building workflow using a real example, without typing any code.</p> <p>custom resources, resources, and intents</p> <p>We often use the terms \"intent\" and \"custom resource\" or \"resource\" interchangeably. They all mean the same thing: a declarative definition of the EDA resource which can be, for example, a configuration or state object or a workflow<sup>2</sup>.</p> <p>With the <code>edabuilder create --app banners resource Banner</code> command, we will create the Banner resource in the <code>banners</code> app directory, and when used with the <code>-d | --scaffold-demo</code> flag, we tell edabuilder to output the demo scaffolding for the configuration and state scripts for the Banner resource.</p> <pre><code>edabuilder create --app banners resource Banner -d #(1)!\n</code></pre> <ol> <li> <p>Warning</p> <p>The resource name must be in a CamelCase format.</p> </li> </ol> <p>As a result of this command, you will find</p> <ul> <li>the API specification for the Banner and BannerState custom resources created in the <code>banners/api/v1alpha1</code> directory<sup>3</sup></li> <li>scaffolded configuration and state resources (aka intents) with the corresponding scripts in the <code>intents/banner</code> and <code>intents/bannerstate</code> directories. Without the demo <code>-d</code> flag the resources are created without the scripts, as the developers add them manually.</li> </ul> <p>We leave the app logic implementation details for a later deep dive. All we need to know for now, that an application that is capable of configuring banner message on the supported Network OSes has been scaffolded and we can deploy it onto the EDA cluster to see it in action.</p> </li> <li> <p>Deploy the app</p> <p>During the app development you would want to quickly test the changes you made to the app by deploying it to EDA cluster. Edabuilder comes with a one-shot command to do just that:</p> <pre><code>edabuilder deploy --app banners\n</code></pre> <p>The <code>deploy</code> command will package app components in an OCI container image, push it to the container registry deployed for you in the EDA cluster and install the app.</p> <p><code>deploy</code> command requirements</p> <p>The <code>kubectl</code> should be using the context that points to the EDA cluster for the operation to succeed.</p> </li> <li> <p>Try the app</p> <p>After deploying the development version of the app directly to the EDA cluster, you can try it out by creating an instance of the <code>Banner</code> resource via any of the EDA interfaces. Here are two of them:</p> EDA UIKubernetes API/kubectl <p>In the EDA UI you should see a new group menu named Banner appear in the list of the resources:</p> <p></p> <p>Selecting the Banner menu will take you to the list of instances of the <code>Banner</code> resource, where you can create a new instance of the resource and commit this transaction.</p> <p>To leverage the Kubernetes API one can create a custom resource in the YAML format like shown below:</p> <p>Resource:</p> <pre><code>apiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: demo-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf1\n  loginBanner: Hello EDA!\n</code></pre> <p>Apply:</p> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: demo-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf1\n  loginBanner: Hello EDA!\n\nEOF\n</code></pre> <p>Regardless of the interface you choose, the result of your actions should be a new instance of the <code>Banner</code> resource in the EDA cluster and the appropriate login banner configured on the targets matching your selection.</p> </li> </ol>"},{"location":"development/apps/quick-start/#what-just-happened","title":"What just happened?","text":"<p>Quite a lot! Here's a breakdown of what you just did:</p> <ol> <li>You initialized a new project.</li> <li>You created a new app.</li> <li>You created a new resource - Banner - with the generated scripts for the Banner and BannerState intents.</li> <li>You generated code-generated artifacts (OpenAPI schemas, CRDs, etc.) for your app.</li> <li>You deployed your app to your EDA cluster.</li> <li>You created an instance of your new resource via Kubernetes API or EDA UI.</li> <li>And observed the results of your app in action by logging into the SR Linux CLI and seeing a new login banner in effect.</li> </ol>"},{"location":"development/apps/quick-start/#where-to-from-here","title":"Where to from here?","text":"<p>First, get to know the project layout and the role of each directory and files they contain in the Project Layout section.</p> <p>Next, dive into the application components to learn what makes up an EDA app in the Components section.</p> <p>After that, you are ready to learn how the demo Banner app works. How it selects the nodes, generates the config snippets, creates resources in EDA cluster and so on. This is covered in the Banner script deep dive section.</p> <ol> <li> <p>A vendor is the publishing authority of your app. It can be an arbitrary string, but typically it matches your company name, personal name or a community name.\u00a0\u21a9</p> </li> <li> <p>The actual runtime used in EDA to run those scripts is MicroPython, but we will dive into these details in a later sections.\u00a0\u21a9</p> </li> <li> <p>In the <code>banner_api_types.go</code> and <code>bannerstate_api_types.go</code> files accordingly. The path is provided from the root of the project's repository.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/setup-env/","title":"Setting up the dev environment","text":"<p>Before you start building an app, you'll need to prepare the development environment. This guide assumes you have EDA installed already and if you don't, you can quickly spin one up by following the Try EDA guide.</p> <p>Your primary tools when developing an app:</p> <ul> <li><code>edabuilder</code> for scaffolding, building, and publishing your app.</li> <li><code>go</code> sdk for authoring the API of your custom resources.</li> <li><code>python</code> runtime for getting syntax highlighting and IDE support when writing intents optional.</li> <li><code>kubectl</code> for creating resources.</li> <li><code>edactl</code> for verifying installation workflows and debugging.</li> </ul> <p>These tools are available for all major OSes and architectures, so you can develop on your preferred platform, no matter where you are.</p> <code>edabuilder</code><code>go</code><code>python</code><code>kubectl</code><code>edactl</code> <p><code>edabuilder</code> is a CLI tool that helps to scaffold a new EDA app, build the container for it and then publish the application to the catalog. The CLI can be downloaded from the GitHub repository as well as from the <code>eda-toolbox</code><sup>1</sup> Pod.</p> Download from GitHubDownload from eda-toolbox <p>Download the latest <code>edabuilder</code> binary from the GitHub repository directly, or leverage the downloader script that comes with the EDA Playground:</p> Run in the EDA Playground repository<pre><code>make download-edabuilder\n</code></pre> <p>This will download the <code>edabuilder</code> binary to the <code>./tools</code> directory in the EDA Playground repository. For convenience, you can move the binary somewhere to your <code>$PATH</code>.</p> <p>If you're developing on a linux/amd64 machine, you can get the <code>edabuilder</code> binary from the <code>eda-toolbox</code> Pod:</p> <pre><code>TOOLBOX_POD=$(kubectl get -n eda-system pod -l eda.nokia.com/app=eda-toolbox \\\n  -o jsonpath='{.items[0].metadata.name}')\nkubectl -n eda-system \\\ncp ${TOOLBOX_POD}:/eda/tools/edabuilder /usr/local/bin/edabuilder\nsudo chmod +x /usr/local/bin/edabuilder\n</code></pre> <p>We will define the API of our declarative apps exactly like in Kubernetes - by crafting the Go files that extend the API of the EDA core. For this, we need a Go SDK.</p> <p>Install Go SDK by following the upstream installation instructions.</p> <p>Note</p> <p>The minimum required Go version is <code>1.24.0</code>.</p> <p>While being optional, we recommend installing the Python runtime and initialize a virtual environment for development.</p> <p>If you already have a Python environment dialed in, you can skip this step, but if not, then the easiest way to get Python on your dev machine is by installing uv - a modern multiplatform Python distribution and package manager.</p> <p><code>kubectl</code> is the Kubernetes command-line tool. During development, you may find it easier to create resources with it, rather than venturing into the EDA UI.</p> <p>If you have completed the Try EDA step, then kubectl has already been downloaded for you and you can just copy it out to a permanent location in your <code>$PATH</code>.</p> <p><code>edactl</code> will help you query the EDA cluster and debug your application. You don't even need to download it directly, you can use an alias to run it from within the EDA cluster as explained in the CLI Tools guide.</p> <p>And now with these tools in your toolchest, you've got everything you need to start building your first app! Choose your preferred path, would you want to put the code to the compiler right away or want to beef up your knowledge on the matter?</p> <ul> <li> <p> Quick start</p> <p>Prefer to dive into a hands on example?</p> <p> Create your first app</p> </li> <li> <p> More reading?</p> <p>Thirsting for knowledge?</p> <p> Learn what makes up an app</p> </li> </ul> <ol> <li> <p><code>eda-toolbox</code> pod is by default deployed in the <code>eda-system</code> namespace.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/scripts/","title":"Script Apps a.k.a. Intents","text":"<p>Script applications (also often referred to as intents) are EDA applications powered by Python scripts that are executed as a result of some external event. The simplest event is a user creating or modifying a resource in EDA that triggers a script app to be executed as a reaction to this event.</p> <p>For example, when a user creates an instance of a <code>Banner</code> resource via any of the EDA interfaces, the script application associated with the <code>Banner</code> resource is triggered to execute its logic - in this case, to configure a banner message on a network device.</p> <p>There exists three types of scripts:</p> <ul> <li><code>config</code></li> <li><code>state</code></li> <li><code>conversion</code></li> </ul> <p>Among these, <code>config</code> and <code>state</code> are the most common.</p> <p><code>config</code> scripts<sup>1</sup> are triggered when a resource is created, updated or deleted, and typically result in transactions to targets describing intended configuration.</p> <p><code>state</code> scripts<sup>2</sup> are responsible for alarm generation, subscription and normalization of telemetry data, and publishing updates to the <code>status</code> field of resources, or the creation of state-only resources.</p> <p><code>conversion</code> scripts are run when a resource is converted from one version to another, i.e. only during upgrades and resource version translation.</p> <ul> <li> <p> App Example</p> <p>Practical walkthrough of a simple script app.</p> <p> Banner application walkthrough</p> </li> <li> <p> More reading?</p> <p>Learn more about the Config and State scripts.</p> <p> Config scripts</p> </li> </ul> <ol> <li> <p>Execute inside EDA Config Engine.\u00a0\u21a9</p> </li> <li> <p>Execute inside EDA State Engine.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/scripts/banner-script/","title":"Banner Script Walkthrough","text":"<p>To better understand how script apps work, we invite you to walk through the demo Banner application that is bundled with EDABuilder CLI and was part of the app development quickstart guide.</p> <p>The Banner app has a very simple purpose: to provision a login banner on the supported targets by submitting an abstracted input. This is the task of the configuration component of the app. The state script of the Banner app simply lists the nodes that the Banner has been provisioned to.</p> <p>The simple scope of the app allows us to focus on the generic app development, rather than going into the weeds of the implementation logic.</p> <p>We are starting this walkthrough assuming you left off at the end of the quickstart guide, with the app named \"banners\" has been scaffolded with the Banner resource in it.</p>"},{"location":"development/apps/scripts/banner-script/#api","title":"API","text":"<p>Recall, that the \"banners\" application we created is meant to be a grouping for resources that make up the banners app. Each resource is an abstracted intent that is characterized by a set of inputs (spec) and outputs (status).</p> <p>During the scaffolding process we added the Banner resource to the \"banners\" application. This Banner resource is our abstracted intent that should be able to provision a login banner message on a list of target nodes based on the node selector.</p> <p>The starting point of the app development is defining the API surface of the resource to match the intent of the app. Application's API is defined in <code>.go</code> files following the kubebuilder pattern that is familiar to most K8s app developers.</p> <p>Let's have a look how <code>edabuilder</code> scaffolded the Banner resource API:</p> executed from the root of the example repo<pre><code>tree -L 2 banners/api\n</code></pre> <pre><code>banners/api\n\u2514\u2500\u2500 v1alpha1\n    \u251c\u2500\u2500 bannerstate_types.go\n    \u251c\u2500\u2500 banner_types.go\n    \u251c\u2500\u2500 groupversion_info.go\n    \u251c\u2500\u2500 pysrc\n    \u2514\u2500\u2500 zz_generated.deepcopy.go\n</code></pre> <p>We are focusing on the <code>banner_types.go</code> and <code>bannerstate_types.go</code> files, which defines the API surface of the Banner and BannerState resources.</p> <p>Banner and BannerState?</p> <p>Why the two resources you may ask? When in the quickstart we scaffolded the Banner resource and provided the <code>-d</code> flag to it, we got two types of resource:</p> <ol> <li><code>Banner</code> - the configuration type that defines the abstracted input for the configuration intent.</li> <li><code>BannerState</code> - the state type that defines the abstracted input for the state intent.</li> </ol> <p>These two resources are the two sides of the same coin. One is responsible for configuring the target based on the input, and the other one is responsible for gathering the state of the intent, generating alarms and populating the resource's status field with the relevant data.</p>"},{"location":"development/apps/scripts/banner-script/#configuration","title":"Configuration","text":"<p>Open up the <code>banner_types.go</code> file and you will see the following code:</p> <pre><code>// BannerSpec defines the desired state of Banner\ntype BannerSpec struct {\n    // List of nodes on which to configure the banners.\n    Nodes []string `json:\"nodes,omitempty\"`\n\n    // Labe selector to select nodes on which to configure the banners.\n    NodeSelector []string `json:\"nodeSelector,omitempty\"`\n\n    // This is the login banner displayed before a user has logged into the Node.\n    LoginBanner string `json:\"loginBanner,omitempty\"`\n}\n\n// BannerStatus defines the observed state of Banner\ntype BannerStatus struct {\n    // +eda:ui:title=\"Nodes\"\n    // List of nodes this banner has been applied to\n    Nodes []string `json:\"nodes,omitempty\"`\n}\n</code></pre> <p>The two Go types <code>BannerSpec</code> and <code>BannerStatus</code> define the specification and the status fields that our <code>Banner</code> resource should have. The fields in these two structure effectively describe the API surface of the Banner resource:</p> <pre><code>// Banner is the Schema for the banners API\ntype Banner struct {\n    metav1.TypeMeta   `json:\",inline\"` //(1)!\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec   BannerSpec   `json:\"spec,omitempty\"`\n    Status BannerStatus `json:\"status,omitempty\"`\n}\n</code></pre> <ol> <li><code>TypeMeta</code> and <code>ObjectMeta</code> fields are common to every k8s resource and implement the fields like <code>apiVersion</code>, <code>kind</code>, <code>namespace</code>, <code>labels</code> and so on.</li> </ol> What's with extra comments? <p>Did you notice the extra comments all around the types and type fields? These are annotations:</p> <pre><code>type BannerSpec struct {\n // +kubebuilder:validation:Optional\n // +eda:ui:columnspan=2\n // +eda:ui:orderpriority=100\n // +eda:ui:autocomplete=`{\"group\":\"core.eda.nokia.com\", \"version\":\"v1\", \"resource\":\"toponodes\"}`\n // +eda:ui:title=\"Nodes\"\n // List of nodes on which to configure the banners.\n Nodes []string `json:\"nodes,omitempty\"`\n</code></pre> <p>These are important parts of the API as with annotations we define validation rules, UI behavior and other aspects of the application. The annotations are covered in their own documentation section.</p> <p>Looking again at the <code>BannerSpec</code> type, we can clearly see what the app is supposed to do:</p> <ol> <li>The <code>Nodes</code> field is a list of string values that will accept target node names to which the login banner should apply.</li> <li>The <code>NodeSelector</code> is a list of string values where each element is a valid label selector. With this field we extend our Banner API to not only work on exact target node names, but on a dynamic set of nodes based on their labels.</li> <li>And the last element of the spec is the <code>LoginBanner</code> string - simply a message that will be displayed at login time.</li> </ol> <p>The <code>BannerStatus</code> is rather simple, both in implementation and the desired behavior:</p> <pre><code>// BannerStatus defines the observed state of Banner\ntype BannerStatus struct {\n    // List of nodes this banner has been applied to\n    Nodes []string `json:\"nodes,omitempty\"`\n}\n</code></pre> <p>With the above we say that the Banner's status container will only have one field - <code>Nodes</code> - that is a list of node names this banner has been applied to.</p> <p>Combining the spec, status and the common metadata fields, our API can be used with a resource defined in YAML format like this:</p> <pre><code>apiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: example-banner\n  namespace: eda\nspec:\n  nodeSelector:\n    - eda.nokia.com/role=leaf\n  loginBanner: Hello EDA!\n</code></pre>"},{"location":"development/apps/scripts/banner-script/#state","title":"State","text":"<p>Besides the <code>Banner</code> resource, we have the <code>BannerState</code> resource that serves a trigger to the state script of our app. The concept of the configuration and state scripts being triggered by the Banner and BannerState resources respectively is a core concept of the EDA framework that might be new to you.</p> <p>The reason the state script is triggered by its own resource is based on the high scalability aspect and the separation of concerns between the configuration and state scripts.</p> <p>In case of the <code>BannerState</code> resource, the API is very simple - it only has a single <code>Nodes</code> field. This field defines a list of node names this banner has been applied to.</p> <pre><code>// BannerStateSpec defines the desired state of BannerState\ntype BannerStateSpec struct {\n    // List of TopoNodes this login banner has been applied to\n    Nodes []string `json:\"nodes,omitempty\"`\n}\n\n// BannerStateStatus defines the observed state of BannerState\ntype BannerStateStatus struct {\n}\n\n// BannerState is the Schema for the bannerstates API\ntype BannerState struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec   BannerStateSpec   `json:\"spec,omitempty\"`\n    Status BannerStateStatus `json:\"status,omitempty\"`\n}\n</code></pre> <p>We will see later how the configuration and state scripts make use of the API we defined for both <code>Banner</code> and <code>BannerState</code> resources.</p>"},{"location":"development/apps/scripts/banner-script/#config-script","title":"Config script","text":"<p>It is time to have a look at the actual application code of the configuration script that uses the API we discussed above and implements the intent of the app.</p> <p>Both config and state intents are located in the <code>./&lt;app-name&gt;/intents</code> directory. In particular, the listing of the configuration script directory is as follows:</p> <pre><code>tree banners/intents/banner\n</code></pre> <pre><code>banners/intents/banner\n\u251c\u2500\u2500 config_intent.py\n\u251c\u2500\u2500 handlers.py\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 init.py\n\u251c\u2500\u2500 srl.py\n\u2514\u2500\u2500 sros.py\n</code></pre> <ul> <li><code>config_intent.py</code> - the main entrypoint of the configuration script.</li> <li><code>handlers.py</code> - contains the logic to select the particular vendor implementation for the configuration task.</li> <li><code>srl.py</code> - contains the logic of the configuration script for Nokia SR Linux.</li> <li><code>sros.py</code> - contains the logic of the configuration script for Nokia SR OS.</li> </ul>"},{"location":"development/apps/scripts/banner-script/#entrypoint","title":"Entrypoint","text":"<p>When you create an instance of the Banner resource, it triggers the execution of the config script, and the entrypoint for the script is the <code>process_cr</code> function in the <code>banners/intents/banner/config_intent.py</code> file:</p> <pre><code>def process_cr(cr):\n</code></pre> <p>The entrypoint function takes in a custom resource (cr) in form of a dictionary. The dictionary's content is a raw representation of the Banner resource as user submitted it to EDA.</p> <p>For example, if you commit a Banner resource in the following form, you get the respective dictionary:</p> Banner resourcedictionary input <pre><code>apiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: example-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf11\n  loginBanner: Hello EDA!\n</code></pre> <pre><code>{\n    \"metadata\": {\n        \"name\": \"example-banner\",\n        \"namespace\": \"eda\"\n    },\n    \"kind\": \"Banner\",\n    \"spec\": {\n        \"loginBanner\": \"Hello EDA!\",\n        \"nodes\": [\n            \"leaf11\"\n        ]\n    }\n}\n</code></pre>"},{"location":"development/apps/scripts/banner-script/#initialization-and-validation","title":"Initialization and Validation","text":"<p>After receiving the input to the entrypoint function, we can create an instance of the Banner class:</p> <pre><code>from banners.api.v1alpha1.pysrc.banner import Banner\nfrom utils.log import log_msg\n\ndef process_cr(cr):\n    \"\"\"Process Banner CR.\"\"\"\n    log_msg(\"Banner CR:\", dict=cr)\n    cr_obj = Banner.from_input(cr)\n    if cr_obj is None:\n        return\n\n    cr_name = cr_obj.metadata.name\n</code></pre> <p>EDABuilder generates the python classes, such as <code>Banner</code>, from the API schema we defined. The python classes are stored in the <code>banners.api.v1alpha1.pysrc</code> python package and a class has a method <code>from_input</code> that creates an instance of the class from the raw input dictionary. We store that instance in the <code>cr_obj</code> variable.</p> <p>When the object is created we can validate it and initialized some defaults if needed:</p> <pre><code>from banners.intents.banner.init import init_globals_defaults, validate\n\ndef process_cr(cr):\n# continuation of the process_cr function\n    validate(cr_obj)\n    init_globals_defaults(cr_obj)\n</code></pre> <p>In the Banner's case, these two functions are merely placeholder.</p>"},{"location":"development/apps/scripts/banner-script/#selecting-targets","title":"Selecting targets","text":"<p>The script progresses to its next logical step: selecting targets. Almost all configuration scripts will have a piece of their logic dedicated to selecting the nodes to apply config to.</p> <p>If you remember, the Banner's resource API provides two options how the targets can be selected by the user:</p> <ol> <li>selecting the targets based on the provided list of names</li> <li>selecting the targets based on the provided label selectors</li> </ol> <p>EDA API provides convenience functions to support both methods of node selection, and since our API allows both, we have implementations for both:</p> <pre><code>import utils.exceptions as e\nimport utils.node_utils as nutils\n\ndef process_cr(cr):\n# continuation of the process_cr function\n    nodes = {}\n\n    if cr_obj.spec.nodeSelector is not None and len(cr_obj.spec.nodeSelector) &gt; 0:\n        log_msg(\"Filtering nodes with node selectors:\", dict=cr_obj.spec.nodeSelector)\n        for node_cr in nutils.list_nodes(filter=[], label_filter=cr_obj.spec.nodeSelector):\n            node_name = node_cr[\"metadata\"][\"name\"]\n            nodes[node_name] = node_cr\n            log_msg(\"Found node:\", dict=node_name)\n\n    if cr_obj.spec.nodes is not None and len(cr_obj.spec.nodes) &gt; 0:\n        for node in cr_obj.spec.nodes:\n            if node not in nodes:\n                node_cr = nutils.get_node(name=node)\n                if node_cr is None:\n                    msg = f\"Node {node} not found\"\n                    raise e.InvalidInput(msg)\n                nodes[node] = node_cr\n</code></pre> <p>Using the <code>list_node</code> and <code>get_node</code> functions from the <code>utils.node_utils</code> package we can get a list of nodes for a selector or a single node by its name. We store the list of Node objects in the <code>nodes</code> variable.</p> <p>Once we have all nodes fetched, it is time to perform configuration action on them.</p>"},{"location":"development/apps/scripts/banner-script/#multivendor-handlers","title":"Multivendor handlers","text":"<p>Regardless if we provided the nodes by name or by selectors, the node list may include Network OSes from different vendors. In the case of the Try EDA topology we have Nokia SR Linux and Nokia SR OS nodes, which are two very distinct operating systems. Yet, our Banner resource should be applied to all supported nodes, how does it work?</p> <p>The answer lies in the NOS-specific handlers that each app implements individually. Let's look at the code block that follows the node selection:</p> <pre><code>from banners.intents.banner.handlers import get_config_handler\nfrom common.constants import PLATFORM_SRL, PLATFORM_SROS\n\ndef process_cr(cr):\n# continuation of the process_cr function\n\n    for node, node_cr in nodes.items():\n        if node_cr is not None:\n            node_spec = node_cr[\"spec\"]\n            if node_spec.get(\"operatingSystem\", None) is not None:\n                if node_spec.get(\"operatingSystem\") == PLATFORM_SRL:\n                    srl_handler = get_config_handler(PLATFORM_SRL)\n                    if srl_handler is not None:\n                        srl_handler.handle_cr(cr_obj, node_cr)\n                elif node_spec.get(\"operatingSystem\") == PLATFORM_SROS:\n                    sros_handler = get_config_handler(PLATFORM_SROS)\n                    if sros_handler is not None:\n                        sros_handler.handle_cr(cr_obj, node_cr)\n                else:\n                    msg = f\"Operating system unsupported for {node}, os is {node_spec.get('operatingSystem', None)}\"\n                    raise e.InvalidInput(msg)\n            else:\n                msg = f\"Operating system unsupported for {node}, os is {node_spec.get('operatingSystem', None)}\"\n                raise e.InvalidInput(msg)\n</code></pre> <p>Here, the nodes we iterate on are the <code>TopoNode</code> objects from the <code>core.eda.nokia.com</code> API group. Based on the <code>operatingSystem</code> value in the TopoNode spec, the code selects either SR Linux or SR OS handler.</p> <p>The handler-selection function is quite simple:</p> banners/intents/banner/handlers.py<pre><code>from common.constants import PLATFORM_SRL, PLATFORM_SROS\nfrom .srl import SrlBaseConfigHandler\nfrom .sros import SrosBaseConfigHandler\n\n_config_handlers = {\n    f\"{PLATFORM_SRL}\": SrlBaseConfigHandler(),\n    f\"{PLATFORM_SROS}\": SrosBaseConfigHandler(),\n}\n\n\ndef get_config_handler(os) -&gt; SrlBaseConfigHandler | SrosBaseConfigHandler | None:\n    return _config_handlers.get(os)  # pragma: no cover\n</code></pre> <p>The corresponding handler class is typically stored in its own file - <code>banners/intents/banner/srl.py|sros.py</code> - and this class implements translation of the abstracted vendor-agnostic intent to the node-specific configuration.</p>"},{"location":"development/apps/scripts/banner-script/#node-specific-config","title":"Node-specific config","text":"<p>Now that we know how different handlers are instantiated, let's have a look again at how they are being used:</p> <pre><code>def process_cr(cr):\n# continuation of the process_cr function\n\n    for node, node_cr in nodes.items():\n        if node_cr is not None:\n            node_spec = node_cr[\"spec\"]\n            if node_spec.get(\"operatingSystem\", None) is not None:\n                if node_spec.get(\"operatingSystem\") == PLATFORM_SRL:\n                    srl_handler = get_config_handler(PLATFORM_SRL)\n                    if srl_handler is not None:\n                        srl_handler.handle_cr(cr_obj, node_cr)\n                elif node_spec.get(\"operatingSystem\") == PLATFORM_SROS:\n                    sros_handler = get_config_handler(PLATFORM_SROS)\n                    if sros_handler is not None:\n                        sros_handler.handle_cr(cr_obj, node_cr)\n</code></pre> <p>Based on the <code>operatingSystem</code> field in the node CR, the appropriate handler is instantiated and the <code>handle_cr</code> method is called with the Banner instance and the TopoNode passed as arguments. At this point, we pass the abstracted, high-level Banner intent, and we expect that the appropriate handler will turn this into the node-specific config.</p> <p>Here is how the implementation of the SR Linux handler class:</p> <pre><code>class SrlBaseConfigHandler:\n    def handle_cr(self, cr_obj: Banner, node_cr=None):\n        configs = []\n        log_msg(f\"cr_obj: {cr_obj}\")\n        log_msg(f\"node_cr: {node_cr}\")\n        node_name = node_cr[Y_METADATA][Y_NAME]\n        self._generate_config(cr_obj, configs)\n        eda.update_cr(\n            schema=s.CONFIG_SCHEMA,\n            name=f\"banner-{cr_obj.metadata.name}-{node_name}\",\n            spec={\"node-endpoint\": node_name, \"configs\": configs},\n        )\n\n    def _generate_config(self, cr_obj: Banner, configs: list):\n        _config = {}\n        if cr_obj.spec.loginBanner is not None:\n            _config[\"login-banner\"] = cr_obj.spec.loginBanner\n\n        configs.append(\n            {\n                \"path\": \".system.banner\",\n                \"config\": json.dumps(_config),\n                \"operation\": \"Create\",\n            },\n        )\n</code></pre> <p>We focus on the <code>handle_cr</code> method that receives the Banner and the TopoNode resources. The high-level operation of any handler function would look like this:</p> <ol> <li>Receive the abstracted intent</li> <li>Process the received abstracted intent and emit sub resource(s)<ol> <li>The sub resource may be any sub resource registered within EDA, for example the Fabric application may emit BridgeDomain, ISL and so on.</li> <li>For simple apps that can translate the abstracted intent directly into the node configuration, they emit <code>NodeConfig</code> resource that Config Engine provisions on the nodes via NPPs.</li> </ol> </li> <li>Create the state intent to trigger the state processing.</li> </ol> <p>Looking more closely at the <code>handle_cr</code> of our Banner script we can spot that it follows this pattern to the dot and generates the <code>NodeConfig</code> resource as part of its operation.</p> <p>With <code>eda.update_cr</code> method we create a <code>NodeConfig</code> resource in EDA by providing the schema of the NodeConfig resource and its specification:</p> <pre><code>eda.update_cr(\n    schema=s.CONFIG_SCHEMA, #(1)!\n    name=f\"banner-{cr_obj.metadata.name}-{node_name}\",\n    spec={\"node-endpoint\": node_name, \"configs\": configs},\n)\n</code></pre> <ol> <li><code>schema=s.CONFIG_SCHEMA</code> - the schema of the <code>NodeConfig</code> resource</li> </ol> <p>The specification of the <code>NodeConfig</code> gets the node-endpoint which is the node name fetched from the <code>node_cr</code> variable and the <code>configs</code> which is the list of configurations generated in the <code>_generate_config</code> method.</p> <p>The same process is followed by the SR OS handler, which you will find in the <code>sros.py</code>.</p> <p>Ultimately, even if an application script does not directly generate the <code>NodeConfig</code> resource, the emitted sub-resources will eventually resolve to the <code>NodeConfig</code> instances and this is how EDA unwraps the high level abstract intent to an actual node-level implementation.</p>"},{"location":"development/apps/scripts/banner-script/#creating-state-resource","title":"Creating state resource","text":"<p>At the very end of the <code>banners/intents/banner/config_intent.py</code> script you will find a peculiar code piece:</p> <pre><code>eda.update_cr(\n    schema=BANNERSTATE_SCHEMA,\n    name=cr_name,\n    spec={\n        \"nodes\": list(nodes.keys()),\n    },\n)\n</code></pre> <p>This is how the configuration intent triggers the state intent run - it creates the <code>BannerState</code> resource for this. As we just defined the API specification of the <code>BannerState</code> resource ourselves, we know that the <code>BannerState</code> specification receives a list of nodes to which we provisioned the login banner.</p> <p>In the same spirit as with the configuration script, the corresponding state script will be triggered based on the fact that the <code>BannerState</code> resource appeared in the system.</p>"},{"location":"development/apps/scripts/banner-script/#state-script","title":"State script","text":"<p>State scripts are executed in the State Engine component and are triggered by the corresponding state resource. State scripts are meant to be used to achieve the following:</p> <ol> <li>Compute the state for the corresponding abstracted resource</li> <li>Generate alarms for the resource</li> </ol> <p>State script is not a mandatory app component, but you will find that most applications have one.</p> <p>Our Banner application has a state script and you can find it in the <code>bannerstate</code> directory:</p> <pre><code>tree banners/intents/bannerstate \n</code></pre> <pre><code>banners/intents/bannerstate\n\u251c\u2500\u2500 eda.py\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 init.py\n\u251c\u2500\u2500 state_handlers.py\n\u2514\u2500\u2500 state_intent.py\n</code></pre> <p>The entrypoint for the state script is, like in the config script case, implemented as the <code>process_cr</code> function found in the <code>state_intent.py</code> file. It takes in the customer resource input:</p> <pre><code>def process_state_cr(cr):\n    log_msg(\"BannerState CR:\", dict=cr)\n    cr_obj = BannerState.from_input(cr)\n    validate(cr_obj)\n    init_globals_defaults(cr_obj)\n    handler = get_state_handler(PLATFORM_EDA)\n    handler.handle_cr(cr_obj)\n</code></pre> <p>In contrast with the config intent, the state script does not have require different NOS-specific handlers, instead a single EDA handler is used.</p> <p>The handler does a trivial task of updating the status field of the <code>Banner</code> resource:</p> <pre><code>class EdaStateHandler:\n    def handle_cr(self, cr_obj: BannerState):\n        nodes = cr_obj.spec.nodes\n        eda.update_cr(\n            schema=BANNER_SCHEMA,\n            name=cr_obj.metadata.name,\n            status={\n                Y_NODES: nodes,\n            },\n        )\n</code></pre> <p>It is worth reiterating, that the state script does not target the state BannerState resource, but updates the status field of the configuration - <code>Banner</code> - resource. It is somewhat and indirect way of populating the status field of the Banner resource and is done in that way to achieve high scale.</p> <p>Technically, the <code>Banner</code> resource does not need a state script at all, as we could've updated its status directly from the config script, but this is done to demonstrate how state scripts work when you start writing applications that compute some more elaborated state.</p>"},{"location":"development/apps/scripts/building-abstractions/","title":"Building Abstractions","text":"<p>One of the key pillars of EDA is the notion of abstractions. Abstractions allow users to express a higher-level intent in a way that is decoupled from the underlying implementation details and/or vendor specific knowledge. In EDA, every application is typically made up of one or more abstracted resources.</p> <p>Some resources provide a low-level abstraction - e.g., a familiar Banner resource that abstracts away the vendor-specific configuration details of configuring a banner and MOTD on a network device, but is still fairly close to the actual configuration model of the target device. Other resources provide a much higher abstraction that is built on top of a bunch of smaller abstractions - like a Fabric resource that on its own abstracts away all configuration details required to build an EVPN VXLAN fabric on a set of multivendor devices and uses Interfaces, BGP Peers, Route Reflectors, and so on.</p> Fabric resource and its lower-level abstractions it is based on <p>When do you need to build an app on top of existing abstractions? Typically, the following goals call for building new abstractions:</p> <ul> <li>simplification - you want to provide a simpler interface for users to interact with, hiding fields and options that are not relevant to the use case at hand or setting sensible defaults for them.</li> <li>customization - you want to encode specific operational logic or policies into the allocated resources that would otherwise require users to manually provide input.</li> <li>composition - you want to combine multiple existing abstractions into a single higher-level abstraction that fits a specific use case.</li> </ul> <p>In this in-depth tutorial, we will learn how to build applications that leverage existing EDA resources to provide customized abstractions that fit a desired use case.</p>"},{"location":"development/apps/scripts/building-abstractions/#simple-fabrics-application","title":"Simple Fabrics Application","text":"<p>Warning</p> <p>This tutorial assumes you are running</p> <ul> <li>EDA 25.12 or later</li> <li>Fabrics app 5.0.0 or later.</li> </ul> <p>To keep things real, we are going to build an application that provisions a fully functional EVPN VXLAN fabric, but with a very minimal set of options exposed to the user. We are going to call this application Simple Fabrics.</p> <p>As the name suggests, the Simple Fabrics app will build an abstraction on top of the existing Fabric resource that EDA provides out of the box as part of the Fabrics application.</p> <p>EDA's native Fabric resource is an already abstracted resource, yet it is very flexible and exposes dozens of options to ensure many different fabric designs can be accommodated. However, in many cases, as an operator, you may want to standardize the way your fabrics are built, limit the number of options that users can choose from, and set meaningful defaults for the rest. This is exactly the goal of the Simple Fabrics application that we are going to build.</p> Simple Fabric provides abstraction on top of Fabric resource <p>Our Simple Fabric app should be able to build an EVPN VXLAN fabric with the following design requirements:</p> <ul> <li>use IPv6-LLA unnumbered addressing in the underlay</li> <li>use eBGP as the underlay routing protocol</li> <li>use eBGP as the overlay routing protocol</li> <li>default to <code>asn-pool</code> for ASN allocation</li> <li>auto-select leaf, spine and ISL label selectors based on pre-defined labels assigned to the resources in EDA</li> <li>create the underlying Fabric app with a distinct name pattern to backtrack it to the Simple Fabric resource</li> <li>report state from the underlying Fabric resource for ease of monitoring</li> </ul> <p>With these requirements in mind, we can derive all inputs for the original Fabric app, thus reducing the cognitive load for an operator. Let's compare the original Fabric resource input and the Simple Fabric resource we are going to build.</p> Original Fabric Resource InputSimple Fabric Resource Input <pre><code>apiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: original-fabric\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n</code></pre> <pre><code>apiVersion: simple-fabrics.eda.local/v1alpha1\nkind: SimpleFabric\nmetadata:\n  namespace: eda\n  name: simple-fabric\nspec:\n  underlayASNPool: asn-pool #(1)!\n</code></pre> <ol> <li>This is a default, pre-filled value.</li> </ol> <p>Comparing the two resource specs shows how the design goal of the Simple Fabrics app is achieved - by exposing only a minimal set of options to the user while setting sensible defaults for the rest. While not strictly needed, we will expose one option to allow users to choose the ASN pool for the underlay BGP protocol to demonstrate how to pass user-provided input down to the underlying Fabric resource. However, you can imagine that even this option could be assumed by the app if desired, further simplifying the user input.</p> <p>Building applications that reuse existing Fabric and Virtual Networks resources is a popular use case to tailor these abstractions to specific design requirements.</p>"},{"location":"development/apps/scripts/building-abstractions/#initializing-the-project","title":"Initializing the Project","text":"<p>To begin the development of our Simple Fabrics application, we first need to initialize a new project using <code>edabuilder</code> CLI. The project may contain one or more applications, each in its own sub-directory. And while we plan to build only one application in this tutorial, we will still need to create a project that hosts it.</p> <p>Navigate to a directory where you want to create the project and run:</p> <pre><code>edabuilder init --vendor eda-labs simple-fabric #(1)!\n</code></pre> <ol> <li> <p>The <code>vendor</code> parameter specifies the vendor name that applications in this project will inherit. It is a free-form text field, and you can choose any name you like here. If you plan to publish your application to the catalog in the future, pick a vendor name that is unique to you or your organization.</p> <p>You may see an informational message about a missing registry parameter. The registry parameter is used to specify a custom registry for publishing applications, but it is not required for local development or for this tutorial, so you can safely ignore this message.</p> <p>The project name <code>simple-fabric</code> is also arbitrary and can be changed to any name you prefer, it does not have to match the application name and is only used to create the project directory.</p> </li> </ol> <p>This command will create a new directory called simple-fabric containing the initial project structure and files. Open this project directory in your favorite code editor to continue development.</p> <p>Initialize the python environment for this project. If you are using <code>uv</code>, simply run:</p> <pre><code>uv sync\n</code></pre> <p>This will create a virtual environment and install all required dependencies for the project.</p> <p>The project also contains an <code>.envrc</code> file that can be used with direnv to automatically load the virtual environment when navigating to the project directory.</p> <p>Initialize a git repository in the project directory to track the changes as we progress with the development:</p> <pre><code>git init\n</code></pre>"},{"location":"development/apps/scripts/building-abstractions/#creating-the-application","title":"Creating the Application","text":"<p>After initializing the project, we can proceed with the Simple Fabrics application creation. To do so, run the following command from the project root directory:</p> <pre><code>edabuilder create app simple-fabrics \n</code></pre> <p>This command will create a new application named <code>simple-fabrics</code> in the <code>simple_fabrics</code> sub-directory of the project. The application directory will contain the initial structure and files needed for the application development.</p> Application Directory Structure <pre><code>\u276f tree simple_fabrics\nsimple_fabrics\n\u251c\u2500\u2500 alarms\n\u2502   \u2514\u2500\u2500 pysrc\n\u251c\u2500\u2500 api\n\u2502   \u2514\u2500\u2500 v1alpha1\n\u2502       \u251c\u2500\u2500 groupversion_info.go\n\u2502       \u2514\u2500\u2500 pysrc\n\u2502           \u251c\u2500\u2500 __init__.py\n\u2502           \u2514\u2500\u2500 constants.py\n\u251c\u2500\u2500 build\n\u251c\u2500\u2500 crds\n\u251c\u2500\u2500 docs\n\u2502   \u251c\u2500\u2500 CHANGELOG.md\n\u2502   \u251c\u2500\u2500 LICENSE.md\n\u2502   \u251c\u2500\u2500 README.md\n\u2502   \u251c\u2500\u2500 SUPPORT.md\n\u2502   \u251c\u2500\u2500 media\n\u2502   \u251c\u2500\u2500 resources\n\u2502   \u2514\u2500\u2500 snippets\n\u251c\u2500\u2500 examples\n\u251c\u2500\u2500 go.mod\n\u251c\u2500\u2500 intents\n\u251c\u2500\u2500 manifest.yaml\n\u251c\u2500\u2500 openapiv3\n\u251c\u2500\u2500 rbac\n\u251c\u2500\u2500 test\n\u251c\u2500\u2500 ui\n\u2514\u2500\u2500 workflows\n</code></pre> <p>The files and folders you get with the initial application creation are explained in detail in the Application Components section.</p>"},{"location":"development/apps/scripts/building-abstractions/#creating-the-resource","title":"Creating the Resource","text":"<p>On its own, the application we just created has no functionality; it merely serves as a container for the resources, workflows, and other components that developers build next. In our case, we need to create a new resource - Simple Fabric - that will implement the desired abstraction and logic on top of the existing Fabric resource.</p> <p>To create the resource, provide the resource kind name<sup>1</sup> and the application name via the <code>--app</code> argument and run the command from the project root directory:</p> <pre><code>edabuilder create resource SimpleFabric --app simple-fabrics\n</code></pre> <p>This operation will create a set of files defining the API of the SimpleFabric resource, but since <code>edabuilder</code> can't quite read our minds yet, it will just lay down a skeleton structure of the API without any fields defined in the spec or status sections. We need to fill in the details ourselves.</p>"},{"location":"development/apps/scripts/building-abstractions/#resource-api","title":"Resource API","text":"<p>EDA is 100% API-defined, meaning that every resource is described by its API/schema. For the API definition, EDA uses the Kubernetes Resource Model as its foundation with some EDA-specific extensions to make the resource rules even more expressive.  </p> <p>Every resource typically has the following main sections in its API definition:</p> <ul> <li><code>apiVersion</code> - defines the API group and version of the resource.</li> <li><code>kind</code> - defines the resource kind name.</li> <li><code>metadata</code> - contains standard fields like <code>name</code>, <code>namespace</code>, <code>labels</code>, and <code>annotations</code> that are common to all Kubernetes resources.</li> <li><code>spec</code> - contains the desired state of the resource, defined by the user.</li> <li><code>status</code> - contains the observed state of the resource, typically filled in by the controller.</li> </ul> <p>For our newly created SimpleFabric resource, we need to define the <code>spec</code> and <code>status</code> sections to reflect the desired abstraction and functionality; the other sections have already been scaffolded by <code>edabuilder</code> for us.</p> <p>Both specification and status API definitions are located in the <code>simple_fabrics/api/v1alpha1/simplefabric_api_types.go</code> file that was created by <code>edabuilder</code>. Open this file and you will see the scaffolded API definition in Go language:</p> <pre><code>package v1alpha1 //(1)!\n\n// SimpleFabricSpec defines the desired state of SimpleFabric\ntype SimpleFabricSpec struct {\n    // INSERT ADDITIONAL SPEC FIELDS - define desired state of cluster\n    // Important: Run \"edabuilder generate\" to regenerate code after modifying this file\n    Foo string `json:\"foo\"`\n}\n\n// SimpleFabricStatus defines the observed state of SimpleFabric\ntype SimpleFabricStatus struct {\n    // INSERT ADDITIONAL STATUS FIELDS - define observed state of cluster\n    // Important: Run \"edabuilder generate\" to regenerate code after modifying this file\n    Baz string `json:\"baz,omitempty\"`\n}\n</code></pre> <ol> <li>The package name matches the API version of the resource, and since we did not specify any custom version during the resource creation, it defaults to <code>v1alpha1</code>.</li> </ol> <p>As you can see, the <code>spec</code> and <code>status</code> sections of a resource are expressed as Go structs, but fear not, you don't need to be a Go programmer to create an application API.</p> <p>Following the design requirements we outlined earlier for the Simple Fabrics app, we can start defining the fields our app needs. Starting with the <code>spec</code> section, let's remove the placeholder <code>Foo</code> field and add the <code>underlayASNPool</code> field that we want to expose to the user:</p> <pre><code>type SimpleFabricSpec struct {\n    UnderlayASNPool string `json:\"underlayASNPool\"`\n}\n</code></pre> <p>If you recall, our Simple Fabrics app only exposes one field to the user, the ASN pool for the underlay BGP protocol, the rest of the parameters are defaulted by the app to reduce the complexity for the user and further abstract the fabric creation.</p> <p>To add a new field to the <code>spec</code>, we have to come up with a field name in PascalCase format (<code>UnderlayASNPool</code>), define its type (<code>string</code>), and provide the JSON tag that defines how the field will be represented in the YAML/JSON manifest of the resource (e.g., <code>json:\"underlayASNPool\"</code>). For those familiar with Kubernetes CRD development, this should look very familiar.</p> <p>With these changes, our API definition kept in the <code>simplefabric_api_types.go</code> file now looks like this:</p> <pre><code>package v1alpha1\n\n// SimpleFabricSpec defines the desired state of SimpleFabric\ntype SimpleFabricSpec struct {\n    UnderlayASNPool string `json:\"underlayASNPool\"`\n}\n\n// SimpleFabricStatus defines the observed state of SimpleFabric\ntype SimpleFabricStatus struct {\n}\n</code></pre>"},{"location":"development/apps/scripts/building-abstractions/#deploying-the-app","title":"Deploying the App","text":"<p>When developing an application, it is often useful to deploy it to a running EDA instance to test and validate its functionality. Making sure iterating on the application is easy and fast was one of the main goals when designing <code>edabuilder</code>.</p> <p>Even though our Simple Fabrics app is not yet functional, we can still deploy it to EDA to ensure that the API definition we created is valid, installable, and shows up in the EDA UI.</p> <p>To deploy the application at any given point during the development, simply run:</p> <pre><code>edabuilder deploy --app simple-fabrics\n</code></pre> <p>The <code>edabuilder deploy</code> command takes care of building the application, setting up the internal container registry in the active EDA cluster, pushing the application image to it, and installing the app via the regular EDA App Installer workflow. A lot of magic happens under the hood, but the developer only needs to run this single command to get the application deployed.</p> Application installation via Workflow <p>Now that our app is installed, where do we find it in the UI? If you search for \"simple\" in the EDA sidebar, you will find the app listed under the \"Simple Fabrics\" section:</p> Simple Fabrics App in EDA UI <p>As evident from the screenshot above, the app is categorized under the \"SIMPLE FABRICS\" category and the resource is titled \"simplefabrics\" - both values come from the <code>simple_fabrics/manifest.yaml</code> file created by <code>edabuilder</code>. We will see how to customize these values later in the tutorial.</p> <p>If you select the \"simplefabrics\" resource from the sidebar and click on \"Create\" button, you will see the schema form for this resource, which should look like this:</p> Simple Fabric Resource Schema Form <p>Even though our resource does not have any functionality yet, we can see that the basic API definition we created is valid, and the <code>underlayASNPool</code> field is correctly represented in the schema form.</p> <p>Also note the \"SimpleFabricSpec defines the desired state of SimpleFabric\" description under the Specification section in the screenshot above. It comes straight from the comment we added above the <code>SimpleFabricSpec</code> struct in the API definition file. Developers can add such comments and additional metadata to the API fields to enrich the schema. This is the topic of the next section.</p>"},{"location":"development/apps/scripts/building-abstractions/#api-annotations","title":"API Annotations","text":"<p>Through comments and annotations in the API definition, developers can provide additional metadata about the resource and its fields, add constraints, defaults, validation rules, and drive the UI representation of the resource.</p>"},{"location":"development/apps/scripts/building-abstractions/#descriptions","title":"Descriptions","text":"<p>The most basic form of metadata that can be provided in the API definition Go file is comments. Comments can be added to the structs as well as to the individual fields. For example, our default descriptions are meaningless, so let's improve them by updating the comments in the <code>simplefabric_api_types.go</code> file as follows:</p> <pre><code>@@ -16,8 +16,16 @@ limitations under the License.\n\n package v1alpha1\n\n-// SimpleFabricSpec defines the desired state of SimpleFabric\n+// This app demonstrates how developers\n+// can build abstractions using the existing resources.\n+// The Simple Fabric application configures the EVPN VXLAN fabric\n+// with a simplified set of inputs when compared to the Fabrics app.\n+// It assumes the default values for the node selectors, protocol configuration, etc,\n+// while exposing a minimal set of parameters to a user.\n type SimpleFabricSpec struct {\n+       // The ASN pool used for the underlay network.\n+       // The `asn-pool` default value is the default ASN pool\n+       // that comes with \"Try EDA\" installation.\n        UnderlayASNPool string `json:\"underlayASNPool\"`\n}\n</code></pre> <p>By adding comments above the SimpleFabricSpec struct and the UnderlayASNPool field, we have enriched the API definition with meaningful descriptions that will show up in the UI schema form, making it easier for users to understand the purpose of the resource and its fields.</p> <p>If you were to call <code>edabuilder deploy --app simple-fabrics</code> again after saving these changes and reload the UI, you would see the updated descriptions in the schema form.</p> Updated Descriptions in Schema Form"},{"location":"development/apps/scripts/building-abstractions/#title","title":"Title","text":"<p>By default, the field names in the schema form are generated from the JSON tags defined in the API struct fields. That is why you see <code>underlayASNPool</code> as the field name in the form, which is not pretty.</p> <p>To change the title of any given field, add <code>+eda:ui:title=\"Your title goes here\"</code> annotation above it. For example, to change the title of the <code>underlayASNPool</code> field to \"Underlay ASN Pool\", we can update the API definition as follows:</p> <pre><code>@@ -26,6 +26,7 @@ type SimpleFabricSpec struct {\n        // The ASN pool used for the underlay network.\n        // The `asn-pool` default value is the default ASN pool\n        // that comes with \"Try EDA\" installation.\n+       // +eda:ui:title=\"Underlay ASN Pool\"\n        UnderlayASNPool string `json:\"underlayASNPool\"`\n}\n</code></pre>"},{"location":"development/apps/scripts/building-abstractions/#default-value","title":"Default Value","text":"<p>Right now, the <code>underlayASNPool</code> field is mandatory, and users have to provide a value for it when creating a SimpleFabric resource. However, we want to set a default value of <code>asn-pool</code> for this field so that users don't have to specify it unless they want to override it.</p> <p>Setting the defaults as per the design is a popular pattern in custom applications</p> <p>To provide the default value of <code>asn-pool</code>, we leverage another annotation - <code>+kubebuilder:default=\"default-value\"</code> - that can be added to a field. Updating the API definition as follows will set the desired default for the <code>underlayASNPool</code> field:</p> <pre><code>@@ -27,6 +27,7 @@ type SimpleFabricSpec struct {\n        // The `asn-pool` default value is the default ASN pool\n        // that comes with \"Try EDA\" installation.\n        // +eda:ui:title=\"Underlay ASN Pool\"\n+       // +kubebuilder:default=\"asn-pool\"\n        UnderlayASNPool string `json:\"underlayASNPool\"`\n}\n</code></pre> <p>To see the effect of this change, redeploy the app again, and open the schema form for the SimpleFabric resource. You will see that the <code>Underlay ASN Pool</code> field now has a default value of <code>asn-pool</code> pre-filled in the form - beautiful!</p> Default Value set in the Schema Form"},{"location":"development/apps/scripts/building-abstractions/#autocompletion","title":"Autocompletion","text":"<p>With the default value set, users can rely on a sensible default when creating a SimpleFabric resource. However, they may still want to choose a different ASN pool, and right now they have to find the desired pool name and set it manually, which is not very user-friendly.</p> <p>To further improve the user experience when filling in the schema form, we can make use of the autocompletion annotation that looks like this</p> <pre><code>+eda:ui:autocomplete=`{\"group\":\"core.eda.nokia.com\", \"resource\":\"indexallocationpools\"}`\n</code></pre> <p>With the autocompletion annotation configured in this way, EDA will query for all existing <code>IndexAllocationPool</code> resources from the API group <code>core.eda.nokia.com</code> in the cluster and provide their names as suggestions when the user puts the cursor in the <code>Underlay ASN Pool</code> field in the schema form.</p> <p>Let's add it:</p> <pre><code>@@ -28,6 +28,7 @@ type SimpleFabricSpec struct {\n        // that comes with \"Try EDA\" installation.\n        // +eda:ui:title=\"Underlay ASN Pool\"\n        // +kubebuilder:default=\"asn-pool\"\n+       // +eda:ui:autocomplete=`{\"group\":\"core.eda.nokia.com\", \"resource\":\"indexallocationpools\"}`\n        UnderlayASNPool string `json:\"underlayASNPool\"`\n}\n</code></pre> <p>And now after redeploying the app and opening the schema form, when you focus on the <code>Underlay ASN Pool</code> field, you will see a dropdown with all available ASN pools in the cluster:</p> Autocompletion in Schema Form <p>The section and field descriptions, titles, default values, and autocompletion are just a few of the annotations available to EDA developers to enrich their resource API definitions. For the sake of this tutorial, we will stop here and move on to implementing the actual logic of the Simple Fabrics app.</p>"},{"location":"development/apps/scripts/building-abstractions/#adding-config-script","title":"Adding Config Script","text":"<p>As an application developer, your work typically gets split between three main areas:</p> <ul> <li>deciding what resources and components your application will consist of</li> <li>defining the individual resources API</li> <li>implementing the application logic</li> </ul> <p>We have already taken care of the first two parts by defining the SimpleFabric resource API. Now it is time to put some code in place to implement the logic of our Simple Fabrics app, guided by the design requirements we outlined earlier.</p> <p>An EDA application that only leverages internal EDA resources and does not need to interact with external systems is called an Intent or Script app.</p> <p>The application logic that results in configuration being applied to the target devices is implemented in the so-called config intent - a MicroPython script that receives the resource instance as input and uses EDA's Intent API to create, read, update, or delete resources as needed.</p> <p>To create the scaffolded python file for the SimpleFabrics resource that will hold our application logic, run the following command from the project root directory:</p> <pre><code>edabuilder --app simple-fabrics create intent SimpleFabric config \n</code></pre> <p>where <code>SimpleFabric</code> should match the resource kind we added at the Creating the Resource step and <code>config</code> is the intent type.</p> <p>You'll have a bunch of new files added as a result of this command. Edabuilder will scaffold the python files in the <code>simple_fabrics/intents/simplefabric</code> directory:</p> <pre><code>\u276f tree ./simple_fabrics/intents/\n./simple_fabrics/intents/\n\u2514\u2500\u2500 simplefabric\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 config_intent.py\n    \u251c\u2500\u2500 eda.py\n    \u251c\u2500\u2500 handlers.py\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 srl.py\n    \u2514\u2500\u2500 sros.py\n</code></pre> <p>The main entrypoint for our intent script is the <code>config_intent.py</code> file.</p> <p>It will also update the manifest.yaml file to register the new script intent. This is an important concept in EDA - every intent is associated with a resource through an explicit registration in the manifest file. The screenshot below shows how the <code>config_intent.py</code> script is associated with the SimpleFabric resource via the manifest file by the <code>trigger</code> section:</p> Intent Registration in Manifest <p>By associating the intent script with the resource, the EDA Config Engine knows which script to execute when a SimpleFabric resource is created, updated, or deleted.</p>"},{"location":"development/apps/scripts/building-abstractions/#config-entrypoint","title":"Config Entrypoint","text":"<p>The main entrypoint for our config intent is in the <code>simple_fabrics/intents/simplefabric/config_intent.py</code> file <code>process_cr</code> function. Edabuilder scaffolded this file for us with the basic structure:</p> Default content in config_intent.py<pre><code>#!/usr/bin/env python3\n\n# imports omitted for brevity\n\ndef process_cr(cr):\n    \"\"\"Process SimpleFabric CR.\"\"\"\n    log_msg(\"SimpleFabric CR:\", dict=cr)\n    cr_obj = SimpleFabric.from_input(cr)\n    if cr_obj is None:\n        return\n\n    cr_name = cr_obj.metadata.name\n    validate(cr_obj)\n    init_globals_defaults(cr_obj)\n</code></pre> <p>The <code>process_cr</code> function is called each time there is a change to a SimpleFabric resource instance - be it creation, update, or deletion. The function receives the resource instance as input in the form of a dictionary called <code>cr</code>, which contains the resource manifest as provided by the user. Let's see this in action by deploying the app in its current state and creating a debug session for the SimpleFabric config intent using <code>edactl</code>:</p> <pre><code>edactl -n eda intent config debug simplefabric\n</code></pre> <p>This command will start the debug session and wait for a SimpleFabric resource to be modified. The log message says \"Matched 0 instances in namespace eda\" because we don't have any SimpleFabric resources yet. Let's create one using <code>kubectl</code>:</p> Paste the command in your terminal to create a SimpleFabric resource<pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: simple-fabrics.eda.local/v1alpha1\nkind: SimpleFabric\nmetadata:\n  name: my-simple-fabric\n  namespace: eda\nspec:\n  underlayASNPool: asn-pool\nEOF\n</code></pre> <p>Running this command will create an instance of the SimpleFabric resource named <code>my-simple-fabric</code>. As soon as the resource is created, you will see the debug session output show the following:</p> <pre><code>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 eda SimpleFabric/v1alpha1/SimpleFabric my-simple-fabric \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nInputCR:\n    {\n      \"kind\": \"SimpleFabric\",\n      \"metadata\": {\n        \"name\": \"my-simple-fabric\",\n        \"namespace\": \"eda\"\n      },\n      \"spec\": {\n        \"underlayASNPool\": \"asn-pool\"\n      }\n    }\nStdout:\nSimpleFabric CR:\n{\"metadata\": {\"name\": \"my-simple-fabric\", \"namespace\": \"eda\"}, \"kind\": \"SimpleFabric\", \"spec\": {\"underlayASNPool\": \"asn-pool\"}}\n\nInputDb:\nOutputDb:\n</code></pre> <p>The debug output shows the input resource manifest in the InputCR block and the log message that is part of our <code>process_cr</code> function in the Stdout section. This confirms that our intent script is being executed correctly when a SimpleFabric resource is created and we receive the resource manifest in its entirety.</p>"},{"location":"development/apps/scripts/building-abstractions/#simplefabric-object","title":"SimpleFabric Object","text":"<p>The first step to take care of in the <code>process_cr</code> function is to instantiate a proper Python object representing our SimpleFabric resource based on the input that the config script received. Thankfully, everything is made ready by <code>edabuilder</code>, and we can leverage the <code>SimpleFabric.from_input(cr)</code> method that is already present in the scaffolded code. This method takes care of converting the input dictionary into a strongly typed Python object that we can work with in the rest of the script.</p> <p>Here are the changes in the <code>config_intent.py</code> we make compared to the scaffolded code:</p> <pre><code> #!/usr/bin/env python3\n-import eda_common as eda\n-import utils.node_utils as nutils\n-import utils.exceptions as e\n-import simple_fabrics.api.v1alpha1.pysrc.constants as c\n-\n-from common.constants import PLATFORM_SRL, PLATFORM_SROS\n-from utils.log import log_msg\n\n from simple_fabrics.api.v1alpha1.pysrc.simplefabric import SimpleFabric\n from simple_fabrics.intents.simplefabric.handlers import get_config_handler\n from simple_fabrics.intents.simplefabric.init import init_globals_defaults, validate\n\n+\n def process_cr(cr):\n     \"\"\"Process SimpleFabric CR.\"\"\"\n-    log_msg(\"SimpleFabric CR:\", dict=cr)\n-    cr_obj = SimpleFabric.from_input(cr)\n-    if cr_obj is None:\n+    sf = SimpleFabric.from_input(cr)\n+    if sf is None:\n         return\n\n-    cr_name = cr_obj.metadata.name\n-    validate(cr_obj)\n-    init_globals_defaults(cr_obj)\n+    validate(sf)\n+    init_globals_defaults(sf)\n</code></pre> <p>We remove the imports that are not needed at this stage and rename the <code>cr_obj</code> variable to <code>sf</code> to better reflect that it is a SimpleFabric object. The rest of the code remains unchanged for now.</p> <p>The <code>SimpleFabric.from_input(cr)</code> method will parse the input dictionary and populate the fields of the SimpleFabric object accordingly. The <code>SimpleFabric</code> Python class is defined in the <code>simple_fabrics/api/v1alpha1/pysrc/simplefabric.py</code> file and is generated by <code>edabuilder</code> based on the Go API definition we created earlier.</p> <p>Working with fully typed Python object is a great convenience for developers, as it allows them to leverage IDE features like autocompletion, type checking, and so on.</p>"},{"location":"development/apps/scripts/building-abstractions/#config-handler","title":"Config Handler","text":"<p>Now that we have the SimpleFabric object instantiated, we need to create an entity that will take the SimpleFabric object as input and implement the logic to create the underlying Fabric resource based on the design requirements. This entity is called a config handler in EDA terminology as it handles the configuration logic of the resource.</p> <p>Every EDA intent application has a config handler class that is responsible for implementing the configuration logic. Based on the application design, you will see two types of config handlers:</p> <ul> <li>EDA config handler - used when the application only creates other EDA resources and does not emit node-level configuration.</li> <li>Network OS config handler - used when the application needs to generate device-level configuration snippets for a Network OS. Based on the target OS, different config handlers are implemented - e.g., SROS config handler, SR Linux config handler, and so on.</li> </ul> <p>For our app that only creates an underlying Fabric resource, we need to leverage an EDA config handler, identified by the <code>PLATFORM_EDA</code> constant. Open the <code>simple_fabrics/intents/simplefabric/config_intent.py</code> and add the highlighted lines:</p> adding config handler to config_intent.py<pre><code>#!/usr/bin/env python3\n\nfrom common.constants import PLATFORM_EDA\nfrom simple_fabrics.api.v1alpha1.pysrc.simplefabric import SimpleFabric\nfrom simple_fabrics.intents.simplefabric.handlers import get_config_handler\nfrom simple_fabrics.intents.simplefabric.init import init_globals_defaults, validate\n\n\ndef process_cr(cr):\n    \"\"\"Process SimpleFabric CR.\"\"\"\n    sf = SimpleFabric.from_input(cr)\n    if sf is None:\n        return\n\n    validate(sf) #(1)!\n    init_globals_defaults(sf)\n\n    eda_handler = get_config_handler(PLATFORM_EDA)\n    eda_handler.handle_cr(sf)\n</code></pre> <ol> <li>The <code>validate</code> and <code>init_globals_defaults</code> functions are utility functions that can be used to validate the resource and initialize any global defaults needed by the application. We will leave these functions unimplemented.</li> </ol> <p>The <code>get_config_handler(PLATFORM_EDA)</code> function call retrieves the EDA config handler for our application. We pass the <code>PLATFORM_EDA</code> constant to indicate that we want the EDA config handler. The returned handler object is an empty object of a <code>EdaBaseConfigHandler</code> class that is defined in the <code>simple_fabrics/intents/simplefabric/eda.py</code> file.</p> simple_fabrics/intents/simplefabric/eda.py<pre><code>#!/usr/bin/env python3\nimport json\n\nimport eda_common as eda\nimport utils.schema as s\nfrom common.metadata import Y_METADATA, Y_NAME\nfrom simple_fabrics.api.v1alpha1.pysrc.simplefabric import SimpleFabric\n\n\nclass EdaBaseConfigHandler:\n    def handle_cr(self, cr_obj: SimpleFabric):\n        # implement this\n        pass\n</code></pre> <p>The scaffolded <code>EdaBaseConfigHandler</code> class has a <code>handle_cr</code> method that takes the SimpleFabric object as input with an empty body. This is where we should implement the logic to create the underlying Fabric resource based on the defaults and inputs from the SimpleFabric resource.</p>"},{"location":"development/apps/scripts/building-abstractions/#dependencies","title":"Dependencies","text":"<p>The Simple Fabrics app builds on top of the existing Fabric application, by effectively being a wrapper around it and setting sensible defaults and computing the required inputs. Therefore, our Simple Fabrics app has a dependency on the Fabrics app.</p> <p>To declare this dependency, and furthermore get access to the Fabric resource API in our application code, we need to import this application as a dependency in our Simple Fabrics app. Edabuilder makes this easy by providing a command that downloads the Python API for a given application.</p> <pre><code>edabuilder import pyapi --app simple-fabrics \\\n  --app-image ghcr.io/nokia-eda/apps/fabrics:v5.0.0\n</code></pre> <p>The <code>edabuilder import pyapi</code> command takes two arguments:</p> <ul> <li><code>--app</code> - specifies the application where the dependency should be added. In our case, it is the <code>simple-fabrics</code> app we are building that needs to add a dependency on the Fabrics app.</li> <li><code>--app-image</code> - specifies the application image to use to extract the Python API from. Here we provide the OCI image URL of the Fabrics app version 5.0.0<sup>2</sup> from the public GitHub Container Registry.</li> </ul> <p>Running this command will download the Python files representing the API of the Fabrics app (all of its resources) and add it as a dependency in the <code>simple_fabrics/manifest.yaml</code> file. The downloaded API files will be placed in the <code>deps</code> subdirectory of the application:</p> <pre><code>tree ./simple_fabrics/deps\n./simple_fabrics/deps\n\u2514\u2500\u2500 fabrics_eda_nokia_com\n    \u2514\u2500\u2500 v5_0_0\n        \u2514\u2500\u2500 api\n            \u2514\u2500\u2500 v1alpha1\n                \u2514\u2500\u2500 pysrc\n                    \u251c\u2500\u2500 __init__.py\n                    \u251c\u2500\u2500 constants.py\n                    \u251c\u2500\u2500 fabric.py\n                    \u251c\u2500\u2500 fabricstate.py\n                    \u251c\u2500\u2500 isl.py\n                    \u251c\u2500\u2500 islping.py\n                    \u2514\u2500\u2500 islstate.py\n</code></pre> <p>The dependency directory - <code>deps</code> is also added to the <code>manifest.yaml</code> file to instruct edabuilder to include it when building the application image:</p> simple_fabrics/manifest.yaml<pre><code>@@ -17,6 +17,8 @@ spec:\n         path: simple_fabrics/api/v1alpha1/pysrc\n     - file:\n         path: simple_fabrics/intents\n+    - file:\n+        path: simple_fabrics/deps\n</code></pre> <p>Because our app requires the Fabrics app to be installed we also need to add the Fabrics app as a required app in the <code>manifest.yaml</code> file:</p> simple_fabrics/manifest.yaml<pre><code>@@ -40,3 +40,6 @@ spec:\n         trigger:\n           kind: SimpleFabric\n         type: config\n+  requirements:\n+    - appId: fabrics.eda.nokia.com\n+      version: v5.0.*\n</code></pre> <p>The App ID is the fully qualified name of the Fabrics app as registered in the EDA App Catalog. It matches the <code>group</code> value in the apps' manifest.yaml file and can be seen in the URL when viewing the app details in the EDA Store UI.</p> <p>The version field sets the required version of an app we depend on. A loose version constraint like <code>v5.0.*</code> can be set to allow any minor or patch version of the Fabrics app in the 5.0 series to satisfy the dependency.</p> <p>If you now deploy the Simple Fabrics app again and open the EDA Store UI, you will see how the Fabrics app (and all the apps that Fabrics app requires) are automatically listed as requirements.</p> App Requirements in EDA Store"},{"location":"development/apps/scripts/building-abstractions/#creating-the-fabric","title":"Creating the Fabric","text":"<p>With the dependency added, we are finally ready to write code that creates the underlying Fabric resource with the desired defaults governed by the Simple Fabrics app design.</p> <p>As we established earlier, the configuration logic should go into the <code>handle_cr</code> method of the <code>EdaBaseConfigHandler</code> class in the <code>simple_fabrics/intents/simplefabric/eda.py</code> file. Let's start with importing the fabric package from the Fabrics app API that we added as a dependency:</p> simple_fabrics/intents/simplefabric/eda.py<pre><code>#!/usr/bin/env python3\nimport json\n\nimport eda_common as eda\n\nimport simple_fabrics.deps.fabrics_eda_nokia_com.v5_0_0.api.v1alpha1.pysrc.fabric as fabric\nimport utils.schema as s\nfrom common.metadata import Y_METADATA, Y_NAME\nfrom simple_fabrics.api.v1alpha1.pysrc.simplefabric import SimpleFabric\n</code></pre> <p>Now, lets instantiate a Fabric object in the <code>handle_cr</code> method and set its spec fields based on the SimpleFabric input:</p> Adding Fabric creation logic to simple_fabrics/intents/simplefabric/eda.py<pre><code>class EdaBaseConfigHandler:\n    def handle_cr(self, sf: SimpleFabric):\n        assert sf.metadata is not None\n        assert sf.spec is not None\n\n        fabricName = f\"sf-{sf.metadata.name}\"\n\n        _fabric = fabric.Fabric(\n            metadata=fabric.Metadata(\n                name=fabricName,\n                namespace=sf.metadata.namespace,\n            ),\n            spec=fabric.FabricSpec(\n                leafs=fabric.Leafs(\n                    leafNodeSelector=[\"eda.nokia.com/role=leaf\"],\n                ),\n                spines=fabric.Spines(\n                    spineNodeSelector=[\"eda.nokia.com/role=spine\"],\n                ),\n                interSwitchLinks=fabric.InterSwitchLinks(\n                    linkSelector=[\"eda.nokia.com/role=interSwitch\"],\n                    unnumbered=\"IPV6\",\n                ),\n                systemPoolIPV4=\"systemipv4-pool\",\n                underlayProtocol=fabric.UnderlayProtocol(\n                    bgp=fabric.UnderlayBGP(asnPool=sf.spec.underlayASNPool),\n                    protocol=[\"EBGP\"],\n                ),\n                overlayProtocol=fabric.OverlayProtocol(\n                    protocol=\"EBGP\",\n                ),\n            ),\n        )\n</code></pre> <p>Note how importing the Fabric API allows us to instantiate a fully typed and API-driven Fabric object. No more brittle Jinja2 templates or string manipulations - just pure Python code working with strongly typed objects.</p> <p>The code above creates a Fabric object with the name <code>sf-&lt;simple-fabric-name&gt;</code> in the same namespace as the SimpleFabric resource. We add the <code>sf</code> prefix to the underlying Fabric resource to additionally distinguish it from other Fabrics that may exist in the cluster. This technique is often used in abstractions.</p> <p>The spec of the Fabric resource is populated with the desired defaults as per the Simple Fabrics app design. The only field that is set based on the SimpleFabric input is <code>underlayASNPool</code>, which is taken from the <code>sf.spec.underlayASNPool</code> field. If you remember, we default this field to <code>asn-pool</code> in the SimpleFabric spec, so unless the user overrides it, the underlying Fabric will always be created with this default ASN pool.</p> <p>As per our design, the Fabric resource uses the predefined labels to select the leaf, spine, and inter-switch link nodes. The underlay protocol is configured to use BGP with EBGP as the protocol type, and the overlay protocol is also set to EBGP.</p> <p>Now that we constructed the Fabric object stored in the <code>_fabric</code> variable, the last step is to create it in the cluster using the EDA Intent API. For this we use the <code>update_cr</code> method from the already imported <code>eda_common</code> package:</p> Finalizing Fabric creation logic in simple_fabrics/intents/simplefabric/eda.py<pre><code>import eda_common as eda\n\nclass EdaBaseConfigHandler:\n    def handle_cr(self, sf: SimpleFabric):\n        # code omitted for brevity\n        _fabric = fabric.Fabric(\n            # code omitted for brevity\n        )\n\n        eda.update_cr(**_fabric.to_input())\n</code></pre> <p>The <code>eda.update_cr(**_fabric.to_input())</code> line takes care of converting the Fabric object into the input dictionary format expected by the EDA Intent API and calls the <code>update_cr</code> method to create or update the Fabric resource in the cluster. The effect of this line is the same as if we were to create the Fabric resource using the UI or <code>kubectl</code> by passing the Fabric manifest.</p> Full code listing of simple_fabrics/intents/simplefabric/eda.py <p>Removing the unused imports and putting everything together, the final code of the <code>simple_fabrics/intents/simplefabric/eda.py</code> file looks like this:</p> <pre><code>#!/usr/bin/env python3\nimport eda_common as eda\n\nimport simple_fabrics.deps.fabrics_eda_nokia_com.v5_0_0.api.v1alpha1.pysrc.fabric as fabric\nfrom simple_fabrics.api.v1alpha1.pysrc.simplefabric import SimpleFabric\n\n\nclass EdaBaseConfigHandler:\n    def handle_cr(self, sf: SimpleFabric):\n        assert sf.metadata is not None\n        assert sf.spec is not None\n\n        fabricName = f\"sf-{sf.metadata.name}\"\n\n        _fabric = fabric.Fabric(\n            metadata=fabric.Metadata(\n                name=fabricName,\n                namespace=sf.metadata.namespace,\n            ),\n            spec=fabric.FabricSpec(\n                leafs=fabric.Leafs(\n                    leafNodeSelector=[\"eda.nokia.com/role=leaf\"],\n                ),\n                spines=fabric.Spines(\n                    spineNodeSelector=[\"eda.nokia.com/role=spine\"],\n                ),\n                interSwitchLinks=fabric.InterSwitchLinks(\n                    linkSelector=[\"eda.nokia.com/role=interSwitch\"],\n                    unnumbered=\"IPV6\",\n                ),\n                systemPoolIPV4=\"systemipv4-pool\",\n                underlayProtocol=fabric.UnderlayProtocol(\n                    bgp=fabric.UnderlayBGP(asnPool=sf.spec.underlayASNPool),\n                    protocol=[\"EBGP\"],\n                ),\n                overlayProtocol=fabric.OverlayProtocol(\n                    protocol=\"EBGP\",\n                ),\n            ),\n        )\n\n        eda.update_cr(**_fabric.to_input())\n</code></pre>"},{"location":"development/apps/scripts/building-abstractions/#ui-category-and-resource-naming","title":"UI Category and Resource Naming","text":"<p>Right now, our app shows up in the EDA UI under the \"SIMPLE FABRICS\" category with the resource named \"simplefabrics\". These values are derived from the default settings in the <code>simple_fabrics/manifest.yaml</code> file created by <code>edabuilder</code>.</p> <p>To demonstrate how to customize these values, let's achieve the following:</p> <ul> <li>Change the simplefabrics resource name to \"Simple Fabrics\"</li> <li>Change the app category from \"SIMPLE FABRICS\" to \"Fabrics\", where the original Fabrics resource is located.</li> </ul> <p>Open the <code>simple_fabrics/manifest.yaml</code> file and change the fields under the <code>ui</code> category of the SimpleFabrics CRD entry:</p> simple_fabrics/manifest.yaml<pre><code>@@ -33,8 +33,8 @@ spec:\n         path: simple_fabrics/crds/simple-fabrics.eda.local_simplefabrics.yaml\n         schema: simple_fabrics/openapiv3/eda_oas_simple-fabrics.eda.local_simplefabrics.json\n         ui:\n-          category: Simple Fabrics\n-          name: simplefabrics\n+          category: Fabrics\n+          name: Simple Fabrics\n     - script:\n         path: simple_fabrics/intents/simplefabric/config_intent.py\n         trigger:\n</code></pre> <p>Redeploying the app and reloading the UI will now show the Simple Fabrics resource under the Fabrics category with the desired name:</p> Customized Resource Name and Category"},{"location":"development/apps/scripts/building-abstractions/#using-the-simple-fabrics-app","title":"Using the Simple Fabrics App","text":"<p>We have implemented the configuration portion of the Simple Fabrics app; now it is time to see it in action! To do so, redeploy the app one last time to make sure all the latest changes are applied.</p> <pre><code>edabuilder deploy --app simple-fabrics\n</code></pre> <p>Once the app is deployed, open the EDA UI and navigate to the Simple Fabrics resource under the Fabrics category. Click on \"Create\" to open the schema form for creating a new SimpleFabric resource.</p> Creating a SimpleFabric Resource <p>The video shows how to create a SimpleFabric resource named <code>my-simple-fabric</code> using the schema form. We accept the default value for the Underlay ASN Pool field, which is <code>asn-pool</code> and add the resource to the transaction basket. We then run the dry run to ensure everything is valid and finally commit the transaction to create the resource.</p> <p>The creation of the Simple Fabric resource triggers the config intent script we implemented, which in turn creates the underlying Fabric resource with the desired configuration. The created Fabric resource has the lock icon next to it, indicating that it is a derived resource - a resource that is created by some other resource and not by a user directly.</p>"},{"location":"development/apps/scripts/building-abstractions/#handling-state","title":"Handling State","text":"<p>We achieved our goal of building a simple abstraction on top of the existing Fabrics app, providing a simplified interface for users to create fabrics with sensible defaults. However, there is one bit that is still missing - our Simple Fabrics resource does not show the status of the underlying Fabric resource. While we can navigate to the derived Fabric resource to see its status, it would be much more convenient if our abstracted resource showed this information directly.</p> <p>As an EDA developer, you have ultimate freedom to decide what state to show in your resource and how to compute it. In our case, the Simple Fabrics resource does not have any state of its own, so we will simply propagate the state of the underlying Fabric resource to the SimpleFabric resource. To achieve this, we need to create a state intent for our SimpleFabric resource. The state intent is very similar to the config intent we created earlier, but instead of creating other resources or device-level configuration, it is responsible for fetching the state from the nodes and updating the status of the resource it is associated with.</p> <p>Let's go over the steps to create and implement the state intent, and since it is very similar to the config intent, we will keep the explanation brief.</p>"},{"location":"development/apps/scripts/building-abstractions/#resource-state-api","title":"Resource state API","text":"<p>First, we need to extend the SimpleFabric resource API to include a status field that will hold the state information. Open the <code>simple_fabrics/api/v1alpha1/simplefabric_api_types.go</code> file and add the fields under the <code>SimpleFabricStatus</code> struct:</p> <pre><code>// SimpleFabricStatus defines the observed state of SimpleFabric\ntype SimpleFabricStatus struct {\n    // +eda:ui:title=\"Derived Fabric Name\"\n    // The name of the backing Fabric that the Simple Fabric created.\n    FabricName string `json:\"fabricName,omitempty\"`\n    // +eda:ui:title=\"Operational State\"\n    // Operational state of the Simple Fabric uses the operational state\n    // of the backing fabric.\n    OperationalState string `json:\"operationalState,omitempty\"`\n}\n</code></pre> <p>Via this API declaration, we add two fields to the status of the SimpleFabric resource:</p> <ul> <li><code>fabricName</code> - holds the name of the underlying Fabric resource created by the Simple Fabrics app.</li> <li><code>operationalState</code> - holds the operational state of the Simple Fabric, which we will derive from the operational state of the underlying Fabric resource.</li> </ul>"},{"location":"development/apps/scripts/building-abstractions/#how-state-intents-work","title":"How State Intents Work","text":"<p>Let's break down how state intents work in EDA and what are the required components by following the sequence of events that happen when we create a Simple Fabric resource. When a SimpleFabric resource is created, to trigger the state intent, the config script should also emit the associated state resource that represents the state intent for the SimpleFabric resource.</p> Step 1. Config Intent creates the associated State resource <p>When the Config Intent creates the associated State resource, it should pass the necessary information to its spec so that the state intent can use it for fetching the state. In our case, the only information needed is the name of the underlying Fabric resource that was created. Therefore, the state resource spec will have a single field called <code>fabricName</code> that holds this information.</p> <p>The state intent will use the Intent API and its spec to fetch the state it needs, which in our case is the status of the underlying Fabric resource.</p> Step 2. State Intent fetches the necessary state using EDA Intent API and EDA DB <p>Once the state intent has fetched the necessary state information, it will compute the status fields of the SimpleFabric resource and update it accordingly. The key point here is that the State resource that was originally created by the config intent does not need to have state fields of its own; instead, it computes the state that the SimpleFabric resource has.</p> Step 3. Computing the state fields for Simple Fabric resource and updating it <p>In other words, the State resource acts as a helper resource that fetches the state for the SimpleFabric resource and updates its status.</p>"},{"location":"development/apps/scripts/building-abstractions/#state-resource","title":"State Resource","text":"<p>Now that we understand the role of a State resource, we need to create one that will represent the state intent for our SimpleFabric resource. Similar to the config intent, we use <code>edabuilder</code> to scaffold the state resource for us, but this time we add additional flags to indicate that we want to scaffold a state resource and it should not be visible in the UI<sup>3</sup>.</p> <pre><code> edabuilder create --app simple-fabrics resource SimpleFabricState --scaffold-state --suppress-ui\n</code></pre> <p>Note how the state resource kind is named <code>SimpleFabricState</code>. Appending the <code>State</code> suffix to the resource kind when creating a state intent is a convention in EDA.</p> <p>This command will scaffold a new resource and its API definition in the <code>simple_fabrics/api/v1alpha1/simplefabricstate_api_types.go</code> file. Here is how we model the state resource API:</p> <pre><code>package v1alpha1\n\n// SimpleFabricStateSpec defines the desired state of SimpleFabricState\ntype SimpleFabricStateSpec struct {\n    // FabricName is the name of the underlying fabric that SimpleFabric creates.\n    FabricName string `json:\"fabricName\"`\n}\n\n// SimpleFabricStateStatus defines the observed state of SimpleFabricState\ntype SimpleFabricStateStatus struct {\n    // SimpleFabricState has no status.\n}\n</code></pre> <p>And the manifest of our app will be automatically updated by <code>edabuilder</code> to register the new resource CRD and its associated state intent script:</p> <pre><code>    - crd:\n        path: simple_fabrics/crds/simple-fabrics.eda.local_simplefabricstates.yaml\n        schema: simple_fabrics/openapiv3/eda_oas_simple-fabrics.eda.local_simplefabricstates.json\n    - script:\n        path: simple_fabrics/intents/simplefabricstate/state_intent.py\n        trigger:\n          kind: SimpleFabricState\n        type: state\n</code></pre>"},{"location":"development/apps/scripts/building-abstractions/#creating-state-resource-in-config-script","title":"Creating State Resource in Config Script","text":"<p>Our config intent needs to create an instance of the SimpleFabricState resource each time a SimpleFabric resource is processed. This will trigger the state intent to run and fetch the state for the SimpleFabric resource.</p> <p>All we need to do is go back to our config handler implementation in the <code>simple_fabrics/intents/simplefabric/eda.py</code> file and add the logic to create the state resource after creating the underlying Fabric resource:</p> Adding State Resource creation logic to simple_fabrics/intents/simplefabric/eda.py<pre><code>import simple_fabrics.api.v1alpha1.pysrc.simplefabricstate as simplefabricstate\n\nclass EdaBaseConfigHandler:\n    def handle_cr(self, sf: SimpleFabric):\n        # code omitted for brevity\n\n        sf_state = simplefabricstate.SimpleFabricState(\n            metadata=simplefabricstate.Metadata(\n                name=sf.metadata.name,\n                namespace=sf.metadata.namespace,\n            ),\n            spec=simplefabricstate.SimpleFabricStateSpec(fabricName=fabricName),\n        )\n\n        eda.update_cr(**sf_state.to_input())\n</code></pre> <p>We import the <code>simplefabricstate</code> package that was generated by <code>edabuilder</code> for the SimpleFabricState resource API. Then, after creating the Fabric resource, we instantiate a SimpleFabricState object with the same name and namespace as the SimpleFabric resource and set its <code>fabricName</code> spec field to the name of the underlying Fabric resource we created earlier.</p> <p>Finally, we call the <code>eda.update_cr</code> method to create the SimpleFabricState resource in the cluster. This will trigger the state intent to run and fetch the state for our SimpleFabric resource.</p>"},{"location":"development/apps/scripts/building-abstractions/#state-handler","title":"State Handler","text":"<p>Next, we need to implement the state intent script that will fetch the state from the underlying Fabric resource and update the SimpleFabric status accordingly. As with the config script, the state script follows the same structure, with the main entrypoint being the <code>process_state_cr</code> function in the <code>simple_fabrics/intents/simplefabricstate/state_intent.py</code> file and a state handler class that implements the logic.</p> <p>Here is the entrypoint of the state intent:</p> simple_fabrics/intents/simplefabricstate/state_intent.py<pre><code>#!/usr/bin/env python3\nfrom common.constants import PLATFORM_EDA\nfrom simple_fabrics.api.v1alpha1.pysrc.simplefabricstate import SimpleFabricState\nfrom simple_fabrics.intents.simplefabricstate.init import init_globals_defaults, validate\nfrom simple_fabrics.intents.simplefabricstate.state_handlers import get_state_handler\n\n\ndef process_state_cr(cr):\n    sf_state = SimpleFabricState.from_input(cr)\n    if sf_state is None:\n        return\n\n    validate(sf_state)\n    init_globals_defaults(sf_state)\n\n    handler = get_state_handler(PLATFORM_EDA)\n    handler.handle_cr(sf_state)\n</code></pre> <p>The handler logic goes into the <code>handle_cr</code> method of the state handler class defined in the <code>simple_fabrics/intents/simplefabricstate/eda_state.py</code> file:</p> simple_fabrics/intents/simplefabricstate/eda_state.py<pre><code>#!/usr/bin/env python3\nimport eda_common as eda\n\nimport simple_fabrics.api.v1alpha1.pysrc.simplefabric as simplefabric\nfrom simple_fabrics.api.v1alpha1.pysrc.simplefabricstate import SimpleFabricState\nfrom utils.state import get_state_params\n\n\nclass EdaStateHandler:\n    def handle_cr(self, sf_state: SimpleFabricState):\n        _oper_state = \"UNKNOWN\"\n        fabric_path = f'.resources.cr.fabrics_eda_nokia_com.v1alpha1.fabric{{.name==\"{sf_state.spec.fabricName}\"}}'\n\n        fields = [\n            \"status.operationalState\",\n        ]\n        fabric_cr_fields = get_state_params(fabric_path, fields, False)\n        if not fabric_cr_fields or not isinstance(fabric_cr_fields, dict):\n            return\n\n        # Safely access nested dictionary with proper type checks\n        status = fabric_cr_fields.get(\"status\")\n        if isinstance(status, dict):\n            _oper_state = status.get(\"operationalState\", \"UNKNOWN\")\n\n        sf = simplefabric.SimpleFabric(\n            metadata=simplefabric.Metadata(\n                name=sf_state.metadata.name,\n                namespace=sf_state.metadata.namespace,\n            ),\n            status=simplefabric.SimpleFabricStatus(fabricName=sf_state.spec.fabricName, operationalState=_oper_state),\n        )\n        eda.update_cr(**sf.to_input())\n</code></pre> <p>Here is a breakdown of the code:</p> <ol> <li>The <code>EdaStateHandler</code> class that has been scaffolded by <code>edabuilder</code> contains the <code>handle_cr</code> method that we populate with the state fetching logic.</li> <li>Fetching the state. We want to fetch the <code>operationalState</code> field from the status of the underlying Fabric resource. We can do this by querying the EDA DB (EDB) using the Intent API utility function <code>get_state_params</code>. The steps are as follows:<ol> <li>Define the <code>fabric_path</code> variable that holds the EDA DB path to the underlying Fabric resource based on the <code>fabricName</code> spec field from the state resource.</li> <li>Define the <code>fields</code> list that contains the status fields we want to fetch from the Fabric resource.</li> <li>Call the <code>get_state_params</code> utility function (available by default) to fetch the specified fields from the Fabric resource using the EDA DB path.</li> <li>Safely access the nested dictionary to extract the <code>operationalState</code> field from the Fabric status.</li> </ol> </li> <li>Instantiate a SimpleFabric object with the same name and namespace as the SimpleFabricState resource and set only its status fields based on the fetched information.</li> <li>Finally, call the <code>eda.update_cr</code> method to update the SimpleFabric resource with the computed status fields.</li> </ol> <p>Now, this state intent will run each time the SimpleFabricState resource is created or updated, fetch the state from the underlying Fabric resource, and update the SimpleFabric resource status accordingly. This is a perpetual process, so whenever the underlying Fabric resource state changes, the SimpleFabric resource status will be updated to reflect the latest state.</p> <p>Deploy the app one last time to apply the state intent changes, and fetch the status of the SimpleFabric resource<sup>4</sup>, for example via <code>kubectl</code>:</p> <pre><code>kubectl -n eda get simplefabrics my-simple-fabric -o yaml\n</code></pre> <pre><code>apiVersion: simple-fabrics.eda.local/v1alpha1\nkind: SimpleFabric\nmetadata:\n  creationTimestamp: \"2025-12-11T11:05:48Z\"\n  generation: 1\n  name: my-simple-fabric\n  namespace: eda\n  resourceVersion: \"55753\"\n  uid: 373b271e-9cd8-41a7-9e8f-6f43e8098bd6\nspec:\n  underlayASNPool: asn-pool\nstatus:\n  fabricName: sf-my-simple-fabric\n  operationalState: up\n</code></pre> <p>Beautiful, the status of the SimpleFabric resource now shows the name of the underlying Fabric resource and its operational state, just as we intended!</p>"},{"location":"development/apps/scripts/building-abstractions/#summary","title":"Summary","text":"<p>It was a long journey, but app development on EDA is quite rewarding and powerful. Despite the verbose explanations, the actual code we wrote to implement the Simple Fabrics app is quite concise and straightforward. We spent more time explaining the machinery and concepts behind EDA resources and file structure than actually writing code.</p> <p>With the Simple Fabrics app, we demonstrated how to build an abstraction on top of an existing EDA app by creating a new resource that simplifies the user experience while leveraging the power of the underlying app. This technique can be used to build opinionated variations of existing apps tailored to the design requirements of your organization.</p> <p>You can find the resulting code of our application in the eda-labs/simple-fabrics repository.</p> <p>While we left out many cool features so as not to make this tutorial a novel, you can further explore the development documentation to learn about other EDA capabilities. For example, while we were deploying the app dozens of times today, but we pushed it to the internal development catalog. You probably want to learn how to publish your app to EDA Store, for this - refer to the Build and Publish guide.</p> <ol> <li> <p>Resource kind should be in PascalCase format, starting with an uppercase letter.\u00a0\u21a9</p> </li> <li> <p>You can choose any version of the Fabrics app that is compatible with your EDA installation. v5.0.0 is the latest version available for EDA 25.12.1 at the time of writing this tutorial. You can derive the OCI image URL of any Nokia app by appending its name and version to the base URL <code>ghcr.io/nokia-eda/apps/</code>.\u00a0\u21a9</p> </li> <li> <p>State resources are not meant to be created or managed by users directly, they are merely helpers to trigger the state intent scripts.\u00a0\u21a9</p> </li> <li> <p>Assuming you did not delete the SimpleFabric resource created earlier in the tutorial.\u00a0\u21a9</p> </li> </ol>"},{"location":"development/apps/scripts/config/","title":"Configuration scripts","text":"<p>Configuration scripts execute in Config Engine, and are deterministic, run-to-completion logic that is responsible for deriving the set of configurations to push to targets. Scripts can do this by either creating any other resource (like the script in the <code>Fabric</code> app creates VNET resource and so on), or by directly emitting <code>NodeConfig</code> resources - being the lowest level resource that is pushed to a target.</p> <p>Due to executing in Config Engine, configuration scripts are limited to the following libraries available in its runtime:</p> <ul> <li><code>eda_common</code></li> <li><code>eda_config</code>, for interacting with allocation pools (resources)</li> </ul>"},{"location":"development/apps/scripts/config/#triggering-scripts","title":"Triggering scripts","text":"<p>A configuration script is attached to a particular resource via the applications <code>manifest.yaml</code>:</p> snippet of the Banner app manifest<pre><code>apiVersion: core.eda.nokia.com/v1\nkind: Manifest\nmetadata:\n  name: banners\nspec:\n  components:\n    - crd:\n        api:\n          expose: readWrite\n        path: banners/crds/banners.eda.local_banners.yaml\n        schema: banners/openapiv3/eda_oas_banners.eda.local_banners.json\n        ui:\n          category: Banner\n          name: Banner\n    - script:\n        path: banners/intents/banner/config_intent.py\n        trigger:\n          kind: Banner\n        type: config\n</code></pre> <p>The manifest presented above results in the logic contained in <code>banners/intents/banner/config_intent.py</code> script being run whenever a <code>Banner</code> resource is created or updated. The <code>Banner</code> resource is added to the EDA API via the <code>crd</code> component defined in the same manifest file.</p>"},{"location":"development/apps/scripts/config/#entrypoint","title":"Entrypoint","text":"<p>The entrypoint to a configuration script is the <code>process_cr</code> function, which is called by Config Engine with the resource object passed as a dictionary to the function.</p> <pre><code>def process_cr(cr):\n    \"\"\"Process Banner CR.\"\"\"\n    ...\n</code></pre> <p>The main task of a configuration script is to take this input dict which represents the declarative abstracted intent and either directly transform it to the node-specific configuration blob, or to emit sub-resources which will be processed by other scripts.</p> <p>The configuration script also emits the input for the state script and triggers its execution.</p>"},{"location":"development/apps/scripts/debugging/","title":"Debugging","text":"<p>Generic debugging capabilities first introduced in 25.4.1</p> <p>EDA script apps run in a remote execution environment (config or state engine, depending on the script type) and this makes the usual debugging techniques not easy to apply. Adding <code>print</code> statements to the script files and fish for a printed message in a potentially very crowded stream of logs messages is not a great developer experience.</p> <p>Yet, it is crucial to give developers a way to introspect the data their scripts operate on or produce. And EDA has a built-in mechanism to help with that.</p>"},{"location":"development/apps/scripts/debugging/#edactl-debug","title":"<code>edactl</code> debug","text":"<p>If you look at the demo <code>banners</code> application scaffolded by <code>edabuilder</code>, you will notice that both configuration and state scripts<sup>1</sup> have the <code>log_msg</code><sup>2</sup> function; it is used to log debug messages in such a way that can be intercepted by the <code>edactl</code> tool and printed out for you on demand. During the normal application operation no debug messages are being printed, they are only printed when a developer uses <code>edactl intent debug</code> command.</p> <p>To start debugging a state or a configuration script, use the following command:</p> <pre><code>edactl -n &lt;namespace&gt; intent [config | state] debug &lt;resource kind&gt;\n</code></pre> <p>Let's see how this debugging workflow works.</p>"},{"location":"development/apps/scripts/debugging/#logging-and-monitoring","title":"Logging and monitoring","text":"<p>To get us a clean start, let's remove any instances of the Banner resource from your cluster:</p> <pre><code>kubectl delete --all -A banners.banners.eda.local\n</code></pre> <p>We will start with a basic task of seeing what exactly happens within our Banner application when we create the Banner resource. We can use the <code>edactl intent config debug &lt;config resource kind&gt;</code> command to start monitoring the logs of this app.</p> <p>Split the shell in two panes, and start the debug monitor in the left pane:</p> <pre><code>edactl intent config debug banners\n</code></pre> <p>This starts a debug monitor for the configuration intent of the <code>banners</code> app. The associated intent script is going to run when we create the Banner resource that triggers the script to run in the config engine pod. Let's create one in the right panel:</p> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: demo-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf11\n  loginBanner: Hello EDA!\nEOF\n</code></pre> <p>Immediately after creating the Banner resource you should see the debug messages appear in the left pane:</p> <p>The debug monitor will show the <code>Input CR</code> that triggered the intent script to run as well as every <code>log_msg</code> function call. For instance, the following output that you find in the output:</p> <pre><code>Banner CR:\n{\"metadata\": {\"name\": \"demo-banner\", \"namespace\": \"eda\"}, \"kind\": \"Banner\", \"spec\": {\"loginBanner\": \"Hello EDA!\", \"nodes\": [\"leaf11\"]}}\n</code></pre> <p>comes from the <code>log_msg</code> function defined in the <code>config_intent.py</code> script of the Banner app:</p> <pre><code>from utils.log import log_msg\n\ndef process_cr(cr):\n    \"\"\"Process Banner CR.\"\"\"\n    log_msg(\"Banner CR:\", dict=cr) #(1)!\n</code></pre> <ol> <li>This log message is rudimentary, since the Input CR is printed by default by the debug monitor.</li> </ol> <p><code>log_msg</code></p> <p>The <code>log_msg</code> function has the following signature:</p> <pre><code>def log_msg(*msg, dict=None)\n</code></pre> <p>You can also see that the debug output outputs any Errors raised during the script execution, and we happen to have one in the script:</p> <pre><code>Error:\nTraceback (most recent call last):\n  File \"banners/intents/banner/config_intent.py\", line 40, in process_cr\n</code></pre> <p>Having a look at the line 40 in our <code>config_intent.py</code> file we can spot what raises that:</p> <pre><code>    if cr_obj.spec.nodes is not None and len(cr_obj.spec.nodes) &gt; 0:\n        for node in cr_obj.spec.nodes:\n            if node not in nodes:\n                node_cr = nutils.get_node(name=node)\n                if node_cr is None:\n                    msg = f\"Node {node} not found\"\n                    raise e.InvalidInput(msg) #(1)!\n</code></pre> <ol> <li>The error is raised using the utility module <code>import utils.exceptions as e</code> which has different classes for different types of errors.</li> </ol> <p>Since our input CR provided a node name in the <code>nodes</code> field of the spec, the script went up querying the TopoNode resources for the one with the name <code>leaf11</code>, but our topology does not have such a node. This raised an error and our script execution stopped. Thanks to <code>edactl intent debug</code> we can clearly find the error in the logs.</p> <p>Let's fix our typo in the node name by passing a corrected Banner resource that references the <code>leaf-1</code> node that we have in our topology:</p> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: banners.eda.local/v1alpha1\nkind: Banner\nmetadata:\n  name: demo-banner\n  namespace: eda\nspec:\n  nodes:\n    - leaf-1\n  loginBanner: Hello EDA!\nEOF\n</code></pre> <p>With the corrected resource our debug monitor shows that the script completes and displays the resources the script generated and written to the EDB:</p> <p>The config script for the Banner app generated two custom resources during its run:</p> <ol> <li><code>BannerState</code> resource to trigger the state script</li> <li><code>NodeConfig</code> resource that contains the configuration snippets for the nodes matching our node selection.</li> </ol> <p>Similarly, you can debug state scripts by changing the command to <code>edactl -n &lt;namespace&gt; intent state debug &lt;state resource kind&gt;</code></p>"},{"location":"development/apps/scripts/debugging/#triggering-your-resource","title":"Triggering your resource","text":"<p>In the previous section we triggered the configuration script execution by creating or changing the <code>Banner</code> resource. But during the development cycle it is not convenient to delete+add or modify the resource whenever you want the config or state script to run.</p> <p>To assist with this workflow, the <code>debug</code> subcommand is equipped with the <code>--trigger | -t</code> flag that can be used to trigger the associated script to run as if the resource was created or changed. Here is a demonstration of this in action.</p> <p>If we were to start the debug monitor for the bannerstate resource just like before, we would not see anything in the output, because the BannerState resource has been created once the config script finished execution.</p> <pre><code>edactl -n eda intent state debug bannerstate\nMatched 1 instances in namespace eda\n</code></pre> <p>If we want to run our state script again without republishing BannerState CR, we could add the <code>-t</code> flag to the command, and this would trigger the script execution with the same BannerState CR passed to it as was recorded before:</p> <pre><code>edactl -n eda intent state debug bannerstate -t\n</code></pre> <pre><code>Matched 1 instances in namespace eda\nTriggered 1 instances\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 eda BannerState/v1alpha1/BannerState demo-banner \u2500\u2500\u2500\nInputCR:\n    {\n      \"kind\": \"BannerState\",\n      \"metadata\": {\n        \"name\": \"demo-banner\",\n        \"namespace\": \"eda\"\n      },\n      \"spec\": {\n        \"nodes\": [\n          \"leaf-1\"\n        ]\n      }\n    }\nStdout:\nBannerState CR:\n{\"kind\": \"BannerState\", \"metadata\": {\"name\": \"demo-banner\", \"namespace\": \"eda\"}, \"spec\": {\"nodes\": [\"leaf-1\"]}}\n\nInputDb:\nOutputDb:\n  .namespace{.name==\"eda\"}.resources.cr-status.banners_eda_local.v1alpha1.banner{.name==\"demo-banner\"}\n    -&gt; {\"apiVersion\":\"banners.eda.local/v1alpha1\",\"kind\":\"Banner\",\"metadata\":{\"name\":\"demo-banner\"},\"status\":{\"nodes\":[\"leaf-1\"]}}\nSubscriptions:\n</code></pre> <p>The trigger flag can be added to both config and state intents.</p> <ol> <li> <p>You will find them by the following paths:</p> <ul> <li><code>banners/intents/banner/config_intent.py</code></li> <li><code>banners/intents/bannerstate/state_intent.py</code></li> </ul> <p>\u21a9</p> </li> <li> <p>imported with <code>from utils.log import log_msg</code> \u21a9</p> </li> </ol>"},{"location":"development/apps/scripts/state/","title":"State scripts","text":"<p>State scripts enable EDA's unique ability to provide and act on the state of abstracted resources. They are being executed inside State Engine and are responsible for alarm generation, subscription and normalization of telemetry data, and publishing updates to the status field of resources, or the creation of state-only resources.</p> <p>State scripts perform more work than just providing the state of a declarative abstracted intent. It adds operational capabilities to the EDA platform in a broad sense.</p>"},{"location":"development/apps/scripts/state/#triggering-scripts","title":"Triggering scripts","text":"<p>A state script is attached to a particular resource via the applications <code>manifest.yaml</code> exactly the same way as configuration script:</p> snippet of the Banner app manifest<pre><code>apiVersion: core.eda.nokia.com/v1\nkind: Manifest\nmetadata:\n  name: banners\nspec:\n  components:\n    - crd:\n        path: banners/crds/banners.eda.local_bannerstates.yaml\n        schema: banners/openapiv3/eda_oas_banners.eda.local_bannerstates.json\n    - script:\n        path: banners/intents/bannerstate/state_intent.py\n        trigger:\n          kind: BannerState\n        type: state\n</code></pre> <p>The manifest presented above results in the logic contained in <code>banners/intents/bannerstate/state_intent.py</code> script being run whenever a <code>BannerState</code> resource is created or updated. The <code>BannerState</code> resource is added to the EDA API via the <code>crd</code> component defined in the same manifest file.</p> <p>The state-related custom resource (<code>BannerState</code> in the example above) is typically created by the configuration script attached to the resource it represents.</p>"},{"location":"development/apps/scripts/state/#entrypoint","title":"Entrypoint","text":"<p>Again, similar to configuration scripts, the entrypoint to a state script is the <code>process_state_cr</code> function, which is called by State Engine with the state resource object passed as a dictionary to the function.</p> <pre><code>def process_state_cr(cr):\n    \"\"\"Process Banner State CR.\"\"\"\n    ...\n</code></pre> <p>The state script then can:</p> <ul> <li>query the EDA in-memory database (EDB) for more state information using <code>eda_state.list_db</code> method</li> <li>update the EDB using <code>eda_state.update_db</code> method</li> <li>generate alarms using <code>eda_state.update_alarm</code> method when thresholds are crossed</li> <li>normalize paths and present the state data in a vendor-agnostic way</li> </ul>"},{"location":"development/terraform/","title":"Terraform","text":"<p> Nokia EDA Providers Reference</p> <p>Terraform is open-source infrastructure as code software that allows users to define resources in human-readable configuration files, which can be versioned, reused, and shared.</p> <p>Terraform can manage low-level components such as compute, storage, and networking resources, as well as high-level components like DNS entries and SaaS features. In the context of Nokia EDA, Terraform is used to declaratively manage EDA Resources<sup>1</sup> by defining them in Terraform files and applying them to the EDA cluster using providers from Nokia.</p>"},{"location":"development/terraform/#terraform-providers-for-eda","title":"Terraform Providers for EDA","text":"<p>Terraform creates and manages resources on cloud platforms and other services through their application programming interfaces (APIs). Providers enable Terraform to interact with virtually any platform or service that exposes an API.</p> <p>In the diagram above, the Nokia EDA API server represents the Target API, and the Terraform providers published by Nokia are used by Terraform to interface with it.</p> <p>Nokia EDA offers unprecedented extensibility, allowing users to install EDA applications at any time. As a result, its API surface is highly dynamic and extensible. Rather than a single Terraform provider for EDA, each EDA application has its own standalone provider. Terraform users install providers for each EDA application they wish to manage, specifying the desired API version.</p> <p>The Terraform providers for EDA are open sourced and published under the nokia-eda namespace in the Terraform registry.</p>"},{"location":"development/terraform/#versions","title":"Versions","text":"<p>Providers include two types of versioning information:</p>  API Version  <p>This refers to the specific application API version for which the provider is built. In EDA, applications may have several API versions (e.g., <code>v1alpha1</code>, <code>v1</code>, <code>v2</code>, and so on). The provider's name will include the API version; for example, the interfaces-v1alpha1 provider is designed to be used with the Interfaces v1alpha1 API version.</p> <p>This means automation users should focus on the API version supported, rather than the installed application version.</p>  Provider Version  <p>This is the version of the Terraform provider itself, which is independent of the Application API version. It follows Semantic Versioning principles and indicates changes to the provider's functionality, compatibility, documentation, and more. The provider version is visible in the registry UI and in the Git repository where the provider's code is stored.</p> <p>In summary, for the provider with the name <code>interfaces-v1alpha1</code> and version <code>1.0.0</code>:</p> <ul> <li>the application this provider is built for is <code>Interfaces</code></li> <li>the Interfaces API version is <code>v1alpha1</code></li> <li>and the provider version is <code>1.0.0</code>.</li> </ul>"},{"location":"development/terraform/#installation","title":"Installation","text":"<p>To install the Terraform providers for Nokia EDA, add the required provider block to your Terraform file<sup>2</sup>:</p> providers.tf<pre><code>terraform {\n  required_providers {\n    interfaces-v1alpha1 = {\n      source  = \"nokia-eda/interfaces-v1alpha1\"\n      version = \"1.0.0\"\n    }\n  }\n}\n</code></pre> <p>The <code>version</code> can be omitted; Terraform will default to the latest version.</p> <p>When you have the <code>required_providers</code> block in place, the Terraform CLI will download the required provider binary when initializing a working directory. It can automatically download providers from a Terraform registry:</p> Terraform initOutput <pre><code>terraform init\n</code></pre> <pre><code>Initializing the backend...\nInitializing provider plugins...\n- Finding nokia-eda/interfaces-v1alpha1 versions matching \"0.0.5\"...\n- Installing nokia-eda/interfaces-v1alpha1 v0.0.5...\n- Installed nokia-eda/interfaces-v1alpha1 v0.0.5 (self-signed, key ID 6F5BC22CD9F83F19)\nPartner and community providers are signed by their developers.\nIf you'd like to know more about provider signing, you can read about it here:\nhttps://developer.hashicorp.com/terraform/cli/plugins/signing\nTerraform has created a lock file .terraform.lock.hcl to record the provider\nselections it made above. Include this file in your version control repository\nso that Terraform can guarantee to make the same selections by default when\nyou run \"terraform init\" in the future.\n\n\nTerraform has been successfully initialized!\n\nYou may now begin working with Terraform. Try running \"terraform plan\" to see\nany changes that are required for your infrastructure. All Terraform commands\nshould now work.\n\nIf you ever set or change modules or backend configuration for Terraform,\nrerun this command to reinitialize your working directory. If you forget, other\ncommands will detect it and remind you to do so if necessary.\n</code></pre>"},{"location":"development/terraform/#configuration","title":"Configuration","text":"<p>The provider needs to be configured with the proper credential information before it can be used. Provider configuration is typically defined in the same file as your provider specifications. For example, if you defined your provider in the <code>providers.tf</code> file above, you can add the provider configuration block there as well:</p> providers.tf<pre><code>terraform {\n  required_providers {\n    interfaces-v1alpha1 = {\n      source  = \"nokia-eda/interfaces-v1alpha1\"\n      version = \"1.0.0\"\n    }\n  }\n}\n\nprovider \"interfaces-v1alpha1\" {\n  # Configuration options\n}\n</code></pre>"},{"location":"development/terraform/#options","title":"Options","text":"<p>At a minimum, provider configuration<sup>3</sup> specifies the API server address and authentication parameters.</p>  Base URL  <p>With <code>base_url</code> provider configuration, users set the address of the EDA API server. This is the same address you use to access the EDA UI and includes the schema and port. For example: <code>https://eda-demo.test.io:9443</code>.</p>  Authentication options  <p>Terraform, like other non-browser-based API clients, uses the Resource Owner Password Credentials Grant OAuth flow for authentication. This flow requires the API client to provide the following parameters:</p>  EDA Client ID  <p>The <code>client_id</code> is an identifier for the EDA API client. It is used to authenticate your requests to the EDA API. By default EDA comes with a pre-created client id of <code>eda</code>. Administrators can create other clients.</p> <p>Default value: <code>eda</code>.</p>  EDA Client Secret  <p>The <code>client_secret</code> is the secret that is associated with the <code>client_id</code>. Stored in Keycloak and can be retrieved by administrators and provided to the users of the API. Refer to the API documentation to see how to fetch the <code>client_secret</code> using Keycloak UI.</p> <p>Warning</p> <p>If you omit the <code>client_secret</code> parameter, the provider will try to fetch the secret by authenticating with the Keycloak service using <code>keycloak_*</code> variables that are set to their default values. While this might be tempting to use, this method is not recommended and should not be used in production.</p>  EDA Username and Password  <p>The API client - Terraform - should have credentials of the EDA user it authenticates as. This is done by providing the <code>username</code> and <code>password</code> parameters in the provider configuration.</p> <p>Default value for both is <code>admin</code> if not set.</p>  TLS Verification  <p>With <code>tls_skip_verify</code> boolean flag a user can select whether to verify the TLS certificate presented by EDA's API server or not.</p> <p>Default value: <code>false</code> (means validate certificate)</p> <p>With the mandatory options set, the provider configuration takes the following form:</p> snippet from providers.tf<pre><code>provider \"interfaces-v1alpha1\" {\n  base_url      = \"https://eda-demo.test.io:9443\"\n  client_id     = \"eda\" # default value, can be omitted if not changed\n  client_secret = \"your_client_secret\"\n  username      = \"your_username\"\n  password      = \"your_password\"\n}\n</code></pre>"},{"location":"development/terraform/#environment-variables","title":"Environment variables","text":"<p>All configuration variables that can be provided to the EDA providers have a matching environment variable. The below table summarizes all available options:</p> TF variable OS env variable Default Description base_url BASE_URL Base URL keycloak_master_realm KEYCLOAK_MASTER_REALM \"master\" Keycloak Master Realm keycloak_admin_client_id KEYCLOAK_ADMIN_CLIENT_ID \"admin-cli\" Keycloak Admin Client ID keycloak_admin_username KEYCLOAK_ADMIN_USERNAME \"admin\" Keycloak Admin Username keycloak_admin_password KEYCLOAK_ADMIN_PASSWORD \"admin\" Keycloak Admin Password client_id CLIENT_ID \"eda\" EDA Client ID client_secret CLIENT_SECRET EDA Client Secret realm REALM \"eda\" EDA Realm username USERNAME \"admin\" EDA Username password PASSWORD \"admin\" EDA Password tls_skip_verify TLS_SKIP_VERIFY false TLS skip verify rest_debug REST_DEBUG false REST Debug rest_timeout REST_TIMEOUT \"15s\" REST Timeout rest_retries REST_RETRIES 3 REST Retries rest_retry_interval REST_RETRY_INTERVAL \"5s\" REST Retry Interval"},{"location":"development/terraform/#bulk-installation","title":"Bulk Installation","text":"<p>If selecting and configuring providers in an a-la-carte manner feels like a cumbersome approach given they share the same config values, here is an all-you-can-eat buffet approach that lists a bunch of providers you can put in your <code>providers.tf</code> file and configure them all using variables:</p> Bulk install and configure example <pre><code>variable \"base_url\" {\n  default = \"https://eda-demo.test.io:9443\"\n}\n\nvariable \"eda_client_secret\" {\n  default = \"your_client_secret\"\n}\n\nvariable \"eda_username\" {\n  default = \"your_username\"\n}\n\nvariable \"eda_password\" {\n  default = \"your_password\"\n}\n\nterraform {\n  required_providers {\n    interfaces-v1alpha1 = {\n      source = \"nokia-eda/interfaces-v1alpha1\"\n    }\n    fabrics-v1alpha1 = {\n      source = \"nokia-eda/fabrics-v1alpha1\"\n    }\n    # add more providers here\n  }\n}\n\nprovider \"interfaces-v1alpha1\" {\n  base_url          = var.base_url\n  eda_client_secret = var.eda_client_secret\n  eda_username      = var.eda_username\n  eda_password      = var.eda_password\n}\n\nprovider \"fabrics-v1alpha1\" {\n  base_url          = var.base_url\n  eda_client_secret = var.eda_client_secret\n  eda_username      = var.eda_username\n  eda_password      = var.eda_password\n}\n\n# add more providers configs here if needed\n</code></pre>"},{"location":"development/terraform/#using-the-providers","title":"Using the Providers","text":"<p>With the providers configured a user can start managing their infrastructure in EDA using Terraform by defining the resources and data-sources that the providers expose.</p>"},{"location":"development/terraform/#resources","title":"Resources","text":"<p>Resources are the most important element in the Terraform language. Each resource block describes one or more infrastructure objects in general, and in EDA's case, these are the resources you create in EDA, such as an Interface, a Virtual Network, a Fabric, a User, etc.</p> <p>Each provider exposes its own set of resources and they are documented in the provider's documentation on Terraform registry, for example, here is a link to the list of resources provided by the Interfaces provider.</p> <p>The most obvious resource in the Interfaces app is the interface itself which, as the name suggests, allows users to manage Interface resources in EDA. The Terraform resources are modelled after the EDA resources, therefore it is very easy to map between the two, they are essentially the same.</p> <p>For example, let's compare what it takes to define an interface <code>ethernet-1/14</code> on <code>leaf1</code> using the Try EDA Playground from the Getting Started guide using EDA UI and Terraform:</p> EDA UITerraform <p>Navigating to the Topology \u2192 Interfaces in the left sidebar and creating a new interface with the following parameters:</p> <ul> <li>name: leaf1-ethernet-1-14</li> <li>namespace: eda</li> <li>enabled: true</li> <li>description: \"set via UI\"</li> <li>lldp: true</li> <li>encapType: 'null'</li> <li>members:<ul> <li>interface: ethernet-1-14</li> <li>node: leaf1</li> </ul> </li> </ul> <p>Would be represented like this in the UI:</p> <p>Now look what would be the equivalent Terraform configuration in the next tab.</p> <p>With terraform, the resources contain the same fields<sup>4</sup> and take in the same values as in the UI. Some may say \"obviously\", because at the end they use the same EDA API to create and manage the resources.</p> <p>Here is the definition of the same interface in the Hashicorp Configuration Language that Terraform uses:</p> <pre><code>resource \"interfaces-v1alpha1_interface\" \"leaf1-ethernet-1-14\" {\n  metadata = {\n    name      = \"leaf1-ethernet-1-14\"\n    namespace = \"eda\"\n  }\n  spec = {\n    enabled     = true\n    encap_type  = \"null\"\n    type        = \"interface\"\n    lldp        = true\n    description = \"set via Terraform\"\n    members = [{\n      enabled   = true\n      node      = \"leaf1\"\n      interface = \"ethernet-1-14\"\n    }]\n  }\n}\n</code></pre> <p>Warning</p> <p>Terraform style guide prescribes that the resource fields should be defined in <code>snake_case</code>, which is why you see <code>encap_type</code> instead of <code>encapType</code> as in the UI.</p> <p>Always consult the provider documentation for the exact field names.</p> <p>As shown in the Terraform tab above, the resources for the EDA applications are almost indistinguishable from the YAML representation you see in the EDA UI. One thing to note is that the Terraform resource omits the <code>apiVersion</code> and <code>kind</code> fields, because they are set by the provider already.</p>"},{"location":"development/terraform/#data-sources","title":"Data-sources","text":"<p>Data sources allow Terraform to use information defined outside of Terraform, defined by another separate Terraform configuration. Each provider exposes its own set of data-sources and they are documented in the provider's documentation on Terraform registry, for example, here is a link to the list of resources provided by the Interfaces provider.</p> <p>You will notice that the data-sources follow a particular pattern: a data-source ending with <code>_list</code> fetches multiple instances of a resource, while a data-source without it fetches a single instance. Here are some examples of how data sources can be used in different scenarios:</p> <pre><code># Get all interfaces.\ndata \"interfaces-v1alpha1_interface_list\" \"all\" {\n  namespace = \"eda\"\n}\n\n# Get all interfaces with label selector\ndata \"interfaces-v1alpha1_interface_list\" \"interswitch\" {\n  namespace     = \"eda\"\n  labelselector = \"eda.nokia.com/role=interSwitch\"\n}\n\n# Get a single interface by name\ndata \"interfaces-v1alpha1_interface\" \"leaf1_ethernet_1_1\" {\n  namespace = \"eda\"\n  name      = \"leaf1-ethernet-1-1\"\n}\n</code></pre>"},{"location":"development/terraform/#import","title":"Import","text":"<p>Terraform supports importing existing resources into your Terraform state. This is useful for managing resources that were created before you started to use Terraform or were created outside of Terraform. This is known as a brownfield deployment scenario.</p> <p>The import documentation covers various ways to import resources, including the generate configuration method that we show below to import a couple of existing interfaces into the <code>interfaces.tf</code> file<sup>5</sup>:</p> <pre><code>import {\n  to = interfaces-v1alpha1_interface.leaf1-ethernet-1-1\n  id = \"eda/leaf1-ethernet-1-1\"\n}\n\nimport {\n  to = interfaces-v1alpha1_interface.leaf2-ethernet-1-1\n  id = \"eda/leaf2-ethernet-1-1\"\n}\n</code></pre> <p>By adding these import statements to your module and running <code>terraform plan -generate-config-out=interfaces.tf</code>, Terraform will:</p> <ol> <li>Check the state file for the imported resources and proceed with fetching them if the state does not contain them.</li> <li>Reach out to the EDA API fetching the resources using the <code>.import.id</code> value defined.</li> <li>Create the <code>interfaces.tf</code> file where the imported resources will be written.</li> </ol> <p>After the successful import, you can remove the <code>import</code> blocks.</p> <p>The import ID is a unique identifier for the resource being imported. In EDA, this will typically be the resource's namespace and name, formatted as <code>namespace/name</code>.</p>"},{"location":"development/terraform/#issues-and-limitations","title":"Issues and Limitations","text":"<ol> <li>Transaction-based operations are not supported yet. These operations, where resources are jointly committed via the Transaction API, are instead managed via REST API calls to the respective application endpoints, not through the Transaction API.</li> </ol> <ol> <li> <p>Such as interfaces, fabrics, virtual networks and so on.\u00a0\u21a9</p> </li> <li> <p>Often the providers configuration goes into the <code>providers.tf</code> file as per the style guide.\u00a0\u21a9</p> </li> <li> <p>Full list of options you can find in the providers documentation hosted on Terraform registry.\u00a0\u21a9</p> </li> <li> <p>But represented with <code>snake_case</code> instead of <code>camelCase</code>.\u00a0\u21a9</p> </li> <li> <p>The file must not exist before the <code>terraform plan</code> command is run.\u00a0\u21a9</p> </li> </ol>"},{"location":"digital-twin/","title":"Digital Twin","text":"<p>The key ingredient in a recipe for a reliable infrastructure automation is the rigorous testing of the changes before they are applied to the production environment. And when networks are concerned, the testing is better done in a controlled environment that resembles the production as closely as possible. This is where the Digital Twin feature of Nokia EDA comes into play.</p> <p>The Digital Twin provides a scalable and flexible simulation platform for testing the changes in a controlled virtual environment, ensuring that your infrastructure remains stable and reliable.</p> <p>The component that implements the Digital Twin feature is called <code>eda-cx</code>, therefore, you may see us using the CX term when referring to the Digital Twin feature.</p> <p>If you completed the quickstart, you noticed that the three-node network topology that the Try EDA cluster comes with is in fact powered by the Digital Twin feature. The <code>eda-cx</code> component is responsible for creating a virtual representation of the network, allowing you to test changes without affecting the production environment.</p> <p>EDA's Digital Twin comes with unique features that set it apart from other network virtualization solutions:</p> <ul> <li>Scalability: The Digital Twin uses the Kubernetes platform to horizontally scale the simulation environment to match the size of your network. This means that you can deploy virtual topologies comprising hundreds of nodes and links, and the Digital Twin will schedule the nodes efficiently.</li> <li>Declarative API: As everything else in EDA, the Digital Twin operates in a declarative manner. The TopoNode and TopoLink resources that are used to define the physical topology of the network are also used to define the virtual topology in the Digital Twin. This means that you can use the same resources to define both the physical and virtual topologies, and the Digital Twin will automatically create the virtual representation of the network.</li> <li>Multivendor support: For every vendor device that is supported by EDA, there is a corresponding virtual simulator in the Digital Twin that you can use to create multivendor topologies.<sup>1</sup>.</li> </ul> <p>EDA's Digital Twin does not use Containerlab nor Clabernetes. It is a purpose-built, production-grade virtual simulation engine that delivers support for massive scale and a tight integration with the EDA platform to achieve the goals of building the virtual replica of a production network. However, if you want to use EDA with a network topology that is built with Containerlab, you can do so by using the Containerlab integration.</p>"},{"location":"digital-twin/#digital-twin-mode","title":"Digital Twin Mode","text":"<p>When installing EDA software, users can choose whether they want to spin up the EDA cluster for use in the Digital Twin mode or for use with the hardware devices. By default, the cluster is deployed in the \"Digital Twin\" mode, where the Network Topology created by a user results in virtual simulators deployed for the topology nodes and virtual links wired for the topology links.</p> <p>To deploy the cluster for use with hardware devices, set the <code>SIMULATE=false</code> in the preferences file during the installation customization.</p> <p>Warning</p> <p>As of EDA 25.12.1, once the cluster is deployed, users can't change the mode of the cluster without redeploying it.</p> <p>To check what mode your EDA cluster is deployed in, you can use the command:</p> <pre><code>kubectl get -n eda-system engineconfig \\\n-o custom-columns=\"SIMULATE MODE:.spec.simulate\"\n</code></pre> <pre><code>SIMULATE MODE\ntrue\n</code></pre>"},{"location":"digital-twin/#simulated-network-topologies","title":"Simulated Network Topologies","text":"<p>One of the key responsibilities of the Digital Twin system is to create and manage the virtual topologies that typically serve as a virtual replica of the production network allowing users to test and model the network changes, validate the designs, develop automation solutions and much more.</p> <p>As extensively covered in the Network Topology section, the network topology in EDA is modelled with the <code>TopoNode</code>, <code>TopoLink</code> and <code>TopoBreakout</code> resources. These resources are created by the Network Topology workflow and declaratively define the physical network topology. The three-node fabric we worked on in the Getting Started guide therefore is depicted as follows:</p> <p>When a user creates the topology resources in an EDA cluster running in the Digital Twin mode, the <code>eda-cx</code> component that is responsible for the simulation network will create the virtual counterparts for the <code>TopoNode</code> and <code>TopoLink</code> resources, namely the <code>SimNode</code>/<code>SimLink</code> resources. To illustrate this process, let's create a dummy topology with two nodes and one link between them in the <code>net-topo-test</code> namespace that we used in the Network Topology section:</p> Topology diagramWorkflow YAML<code>kubectl</code> <p>Note, that the workflow spec has nothing specific to the Digital Twin here, it is the same topology input as you would use for the physical topology as well:</p> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: 2-nodes-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n</code></pre> <p>Copy paste this command in your terminal to create the topology in the <code>net-topo-test</code> namespace:</p> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: 2-nodes-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n\nEOF\n</code></pre> <p>As shown in the diagram above, the <code>TopoNode</code> and <code>TopoLink</code> resources represent the network devices and the connections between them. The Digital Twin component in EDA uses these resources to create the virtual simulators and connect them together in a topology that mirrors the physical design. For each <code>TopoNode</code> resource, a corresponding <code>SimNode</code> resource is created, and for each <code>TopoLink</code> resource, a corresponding <code>SimLink</code> resource is created:</p> <p>Check the  Topologies section for more information on how to create and manage the topologies in EDA.</p>"},{"location":"digital-twin/#sim-topology-resources","title":"Sim topology resources","text":"<p>When a user deploys the topology onto the EDA cluster running in the Digital Twin mode, each TopoNode resource is backed by a virtual simulator instance<sup>2</sup> and each TopoLink resource is implemented as a datapath connection established in the cluster between the sim node containers. Therefore, for the topology we created above, the Digital Twin will create two simulator instances and connect them with a virtual link:</p> Sim Node resourcesSim Link resources <pre><code>kubectl get -n net-topo-test simnode\n</code></pre> <pre><code>NAME    AGE\nnode1   15h\nnode2   15h\n</code></pre> <pre><code>kubectl get -n net-topo-test simlink\n</code></pre> <pre><code>NAME          AGE\nnode1-node2   15h\n</code></pre> <p>The Digital Twin uses the Kubernetes platform to create a deployment for each TopoNode resource, which in turn creates a pod that runs two containers - the virtual simulator and the datapath wiring component (cxdp). The simulators are scheduled on the EDA's Kubernetes cluster based on resource requests by the Kubernetes scheduler. This ensures that the virtual topology can horizontally scale to match the size of the emulated network. All Digital Twin simulator nodes run in the <code>eda-system</code> namespace, and can be listed with the following command:</p> Digital Twin simulator deployments in <code>eda</code> and <code>net-topo-test</code> namespaces<pre><code>kubectl get -n eda-system deploy -l 'eda.nokia.com/app-group=cx-cluster'\n</code></pre> <pre><code>NAME                                    READY   UP-TO-DATE   AVAILABLE   AGE\ncx-eda--leaf1-sim                       1/1     1            1           22h\ncx-eda--leaf2-sim                       1/1     1            1           22h\ncx-eda--spine1-sim                      1/1     1            1           22h\ncx-eda--testman-default-sim             1/1     1            1           22h\ncx-net-topo-test--node1-sim             1/1     1            1           15h\ncx-net-topo-test--node2-sim             1/1     1            1           15h\n</code></pre> <p>The deployment name embeds the namespace the virtual simulator runs in and the TopoNode name, so you can easily identify which virtual simulator corresponds to which TopoNode resource.</p>"},{"location":"digital-twin/#edge-links","title":"Edge links","text":"<p>The Digital Twin automatically created the simulation resources for the TopoNodes representing the <code>node1</code> and <code>node2</code> devices, as well as the SimLink resource representing the link between them. However, you may have noticed that our simple topology had no edge links, just the inter-switch link.</p> <p>Let's see what happens if we add an edge link to <code>node2</code> and redeploy the topology:</p> Topology diagramWorkflow YAML<code>kubectl</code> <p>We add a new link template of type <code>edge</code> and create a new TopoLink resource that uses this template to connect to <code>node2</code>:</p> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: 2-nodes-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n    - name: edge\n      type: edge\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n    - name: node2-ethernet-1-10\n      template: edge\n      endpoints:\n        - local:\n            node: node2\n            interface: ethernet-1-10\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: 2-nodes-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n    - name: edge\n      type: edge\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n    - name: node2-ethernet-1-10\n      template: edge\n      endpoints:\n        - local:\n            node: node2\n            interface: ethernet-1-10\n\nEOF\n</code></pre> <p>A couple of interesting observations can be made after this new topology with an added edge link to the <code>node2</code> device is deployed:</p> <ol> <li> <p>There are no new SimLink resources created for the added edge TopoLink, only the original SimLink representing the inter-switch link is present:</p> TopoLinksSimLinks <pre><code>kubectl get -n net-topo-test topolink\n</code></pre> <p> <pre><code>NAME                  AGE\nnode1-node2           159m\nnode2-ethernet-1-10   159m\n</code></pre> </p> <pre><code>kubectl get -n net-topo-test simlink\n</code></pre> <p> <pre><code>NAME          AGE\nnode1-node2   68s\n</code></pre> </p> </li> <li> <p>There is a new Interface resource created for the edge link attached to the <code>node2</code> device, but it is operationally down:</p> <pre><code>kubectl get -n net-topo-test interface\n</code></pre> <p> <pre><code>NAME                  ENABLED   OPERATIONAL STATE   SPEED   LAST CHANGE   AGE\nnode1-ethernet-1-1    true      up                  100G    10m           11m\nnode2-ethernet-1-1    true      up                  100G    10m           11m\nnode2-ethernet-1-10   true      down                100G    11m           11m\n</code></pre> </p> </li> </ol> <p>The reason for this behavior is that the edge link defined in our topology is a stub, it has no other node to connect to, therefore no SimLink resource is created for it, and the Interface resource remains down. Edge links are typically used to connect to external systems (servers, storage, GPUs, etc) or testing endpoints, and in our case, since there is no such endpoint defined, the edge link remains unconnected. To bring the edge link up, a user would need to define a Sim Node that will represent the external system and connect the SimLink to it. This is the topic of the next section.</p>"},{"location":"digital-twin/#sim-nodes","title":"Sim nodes","text":"<p>As we have identified earlier in this section, the Digital Twin in EDA automatically creates SimNode resources for each TopoNode and SimLink resource for each TopoLink that has both endpoints (local and remote) defined. The Digital Twin won't create a SimLink resource for edge TopoLinks, as they by default only have a local endpoint defined and as such don't have a remote endpoint to connect to.</p> <p>However, the Network Topology workflow allows users to define custom Sim Nodes that can be used as a remote endpoint for edge TopoLinks. This way, users can connect edge links to a simulated external system in the Digital Twin.</p> <p>Building on top of our previous example, let's enhance our topology spec by defining a Sim Node that will be represented as a container image running off of <code>ghcr.io/srl-labs/network-multitool:latest</code> image and connect the edge link on <code>node2</code> to it:</p> Workflow YAML<code>kubectl</code> <p>The changes to the workflow spec include populating the <code>.spec.simulation</code> container and defining the simulation node template and its instance, the same way as we defined templates and instances for the nodes and links of the topology.</p> <p>In the <code>.spec.simulation.simNodeTemplates</code> section we define a new sim node template of type <code>Linux</code> which represents a generic Linux container with the specified container image. In the <code>.spec.simulation.simNodes</code> section we create an instance of the sim node template we just defined under the name <code>server2</code>. Finally, we update the edge link definition to feature the <code>sim</code> block in its endpoints list that references the newly created sim node and the interface name inside it.</p> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: 2-nodes-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n    - name: edge\n      type: edge\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n    - name: node2-ethernet-1-10\n      template: edge\n      endpoints:\n        - local:\n            node: node2\n            interface: ethernet-1-10\n          sim:\n            simNode: server2\n            simNodeInterface: eth1\n  simulation:\n    simNodeTemplates:\n      - name: multitool\n        type: Linux #(1)!\n        image: ghcr.io/srl-labs/network-multitool:latest\n    simNodes:\n      - name: server2\n        template: multitool\n</code></pre> <ol> <li> <p>The <code>.spec.simulation.simNodeTemplates[].type</code> field defines the type of the Sim Node. Two types are currently supported: <code>Linux</code> and <code>TestMan</code>. The <code>Linux</code> type represents a generic Linux container that can run any container image specified in the <code>image</code> field.</p> <p>The <code>TestMan</code> type represents a special container image that is purpose-built to assist in testing and validation in the EDA Digital Twin environment. See the TestMan section below for more details.</p> </li> </ol> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: 2-nodes-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n    - name: edge\n      type: edge\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n    - name: node2-ethernet-1-10\n      template: edge\n      endpoints:\n        - local:\n            node: node2\n            interface: ethernet-1-10\n          sim:\n            simNode: server2\n            simNodeInterface: eth1\n  simulation:\n    simNodeTemplates:\n      - name: multitool\n        type: Linux #(1)!\n        image: ghcr.io/srl-labs/network-multitool:latest\n    simNodes:\n      - name: server2\n        template: multitool\n\nEOF\n</code></pre> <p>Applying this topology will result in the Digital Twin creating a new SimNode resource, the associated k8s deployment for it and the SimLink object for the edge link that now has both local and sim (remote) endpoints defined:</p> Sim Nodes and deploymentsSimLinks and TopoLinks <p>The newly created SimNode resource is now present in the namespace:</p> <pre><code>kubectl get -n net-topo-test simnode\n</code></pre> <pre><code>NAME      AGE\nnode1     19m\nnode2     19m\nserver2   19m\n</code></pre> <p>And the corresponding simulator deployments are created in the <code>eda-system</code> namespace:</p> <pre><code>kubectl get -n eda-system deploy -l 'eda.nokia.com/app-group=cx-cluster' \\\n  -l 'cx-node-namespace=net-topo-test'\n</code></pre> <pre><code>NAME                            READY   UP-TO-DATE   AVAILABLE   AGE\ncx-net-topo-test--node1-sim     1/1     1            1           20m\ncx-net-topo-test--node2-sim     1/1     1            1           20m\ncx-net-topo-test--server2-sim   1/1     1            1           20m\n</code></pre> <p>The same number of TopoLink resources are present as before:</p> <pre><code>kubectl get -n net-topo-test topolink\n</code></pre> <pre><code>NAME                  AGE\nnode1-node2           159m\nnode2-ethernet-1-10   159m\n</code></pre> <p>But now there is a new SimLink resource connecting <code>node2</code> and <code>server2</code> that was not present before until we added a SimNode to connect to:</p> <pre><code>kubectl get -n net-topo-test simlink\n</code></pre> <pre><code>NAME                  AGE\nnode1-node2           23m\nnode2-ethernet-1-10   23m\n</code></pre> <p>Everything looks great, but the Interface resource <code>node2-ethernet-1-10</code> still shows as operationally down:</p> <pre><code>kubectl get -n net-topo-test interface\n</code></pre> <pre><code>NAME                  ENABLED   OPERATIONAL STATE   SPEED   LAST CHANGE   AGE\nnode1-ethernet-1-1    true      up                  100G    22m           24m\nnode2-ethernet-1-1    true      up                  100G    22m           24m\nnode2-ethernet-1-10   true      down                100G    23m           24m\n</code></pre> <p>Why? Because for SimNode of type <code>Linux</code>, EDA's Digital Twin does not automatically bring up the interfaces that we specified in the topology input. If we connect to the shell of the <code>server2</code> container image we will see that the <code>eth1</code> interface that we specified in the links section of our topology is operationally down. We can bring it up manually with the standard Linux commands:</p> connecting to the shell of the server2 SimNode<pre><code>kubectl -n eda-system exec -it \\\n$(kubectl get -n eda-system pods -l 'cx-node-namespace=net-topo-test' \\\n-l 'cx-pod-name=server2' \\\n-o jsonpath='{.items[].metadata.name}') \\\n-- bash\n</code></pre> <pre><code>[*]\u2500[cx-net-topo-test--server2-sim-58cb56dd56-sgh6r]\u2500[/]\n\u2514\u2500\u2500&gt; ip link show eth1\n3: eth1@eth1-cx: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000\n    link/ether 5e:80:14:5e:bf:6f brd ff:ff:ff:ff:ff:ff\n</code></pre> <p>Let's bring up the interface with the <code>ip link set</code> command:</p> <pre><code>[*]\u2500[cx-net-topo-test--server2-sim-58cb56dd56-sgh6r]\u2500[/]\n\u2514\u2500\u2500&gt; ip link set eth1 up\n</code></pre> <p>Immediately after that we can see that the Interface resource for the <code>ethernet-1-10</code> port on <code>node2</code> is now operationally up:</p> <pre><code>kubectl get -n net-topo-test interface\n</code></pre> <pre><code>NAME                  ENABLED   OPERATIONAL STATE   SPEED   LAST CHANGE   AGE\nnode1-ethernet-1-1    true      up                  100G    37m           38m\nnode2-ethernet-1-1    true      up                  100G    37m           38m\nnode2-ethernet-1-10   true      up                  100G    7s            38m\n</code></pre> <p>Now you know how to define SimNodes in the Network Topology workflow and connect edge links to them.</p>"},{"location":"digital-twin/#connections-topology","title":"Connections topology","text":"<p>In the Sim Nodes section we described how users can define custom Sim Nodes in the <code>.spec.simulation.simNodes</code> section of the Network Topology workflow spec and connect edge links to them by providing the <code>sim</code> block in the link endpoints. This way, users can selectively attach edge links to the simulated nodes, however, this approach may become tedious when there are many edge links to be connected in the same way. For example, when you want to connect ports <code>ethernet-1-1</code> on all nodes to a single Sim Node that represents a testing agent or a traffic generator. This is the case when the TestMan is used as a Sim Node to which multiple edge links can be connected simultaneously. To simplify the process of connecting multiple edge links to a single Sim Node, the Digital Twin supports the concept of a connection topology.</p> <p>The connection topology is defined in the <code>.spec.simulation.topology</code> section of the Network Topology workflow spec. Here, users can define the rules that specify which nodes and interfaces should be connected to which Sim Node and which Sim Node interface. The rules support wildcard patterns to match multiple nodes and interfaces, allowing for a concise definition of the connections.</p> <p>Let's work through a set of connection topologies examples that showcase the capabilities and use cases of this feature.</p> <p>The previous example in the Sim Nodes section showed how to connect the edge link <code>ethernet-1-10</code> on <code>node2</code> to a Sim Node named <code>server2</code>. The same connection can be defined with the connection topology as follows (and then no <code>sim</code> block is needed in the link definition):</p> <pre><code>spec:\n  simulation:\n    topology:\n      - node: \"node2\"\n        interface: \"ethernet-1-10\"\n        simNode: server2\n        simNodeInterface: \"eth1\"\n</code></pre> <p>The <code>.spec.simulation.topology</code> section defines a list of connection pairs that specify which node and interface should be connected to which Sim Node and Sim Node interface. For example, here is how several node/interface pairs can be defined:</p> <pre><code>spec:\n  simulation:\n    topology:\n      - node: \"node1\"\n        interface: \"ethernet-1-10\"\n        simNode: server1\n        simNodeInterface: \"eth1\"\n      - node: \"node2\"\n        interface: \"ethernet-1-10\"\n        simNode: server2\n        simNodeInterface: \"eth1\"\n</code></pre> <p>A more interesting use case where connection topology shines is when wildcards are used in the node and/or interface fields. For example, to connect all edge interfaces on <code>node1</code> to a single Sim Node named <code>server1</code>, the following connection topology can be defined:</p> <pre><code>spec:\n  simulation:\n    topology:\n      - node: \"node1\"\n        interface: \"*\"\n        simNode: server1\n</code></pre> <p>Note, how <code>*</code> is used in the <code>interface</code> field to match all interfaces on <code>node1</code>. The <code>simNodeInterface</code> field is omitted here, so the Digital Twin will automatically assign the interfaces on the Sim Node in the order they are connected using the <code>eth0</code>, <code>eth1</code>, <code>eth2</code>, ... naming convention.</p> <p>Another popular use case is to connect the same interface on all nodes to a single Sim Node. For example, to connect the <code>ethernet-1-10</code> interface on all nodes to a Sim Node named <code>testman-default</code>, the following connection topology can be defined:</p> <pre><code>spec:\n  simulation:\n    topology:\n      - node: \"*\"\n        interface: \"ethernet-1-10\"\n        simNode: testman-default\n</code></pre> <p>Here, the wildcard <code>*</code> is used in the <code>node</code> field to match all nodes in the topology while the interface field specifies the <code>ethernet-1-10</code> value. This results in all <code>ethernet-1-10</code> interfaces on all nodes being connected to the <code>testman-default</code> Sim Node. As before, since the Sim Node interface is not specified, the Digital Twin will automatically assign the interfaces on the Sim Node in the order they are connected.</p> <p>And lastly, a fully wildcarded connection topology can be defined to connect all edge interfaces on all nodes to a single Sim Node. We use this connection mode with the Try EDA topology for example, where we need to connect all edge interfaces on all nodes to the <code>testman-default</code> Sim Node to make all links up and running:</p> <pre><code>spec:\n  simulation:\n    topology:\n      - node: \"*\"\n        interface: \"*\"\n        simNode: testman-default\n</code></pre>"},{"location":"digital-twin/#testman","title":"TestMan","text":"<p>In a lot of cases, the simulated topology benefits from having emulated client devices that can be used to test the connectivity and functionality of the network. Containers running iperf, ICMP pings, HTTP clients, and other tools dear to network engineers are typically found in these emulated clients.</p> <p>While we showed above how users can define a Sim Node of type <code>Linux</code> and use any container image to run the testing tools, it might not be very convenient to run a standalone container for each access port in the topology. And while it is possible to use one generic Linux container and create VRFs and namespaces inside it, the burden of managing this configuration falls on the user. Another tension point is the API. The iPerfs, ICMPs and curls of the world don't have a native support for REST or gRPC API to allow a system to programmatically control the test execution and retrieve the results.</p> <p>These challenges and limitations served as a motivation to create the TestMan - a container image that is purpose-built to assist in testing and validation in the EDA Digital Twin environment. Having ownership of the TestMan allows us to tightly integrate it with the EDA Digital Twin and provide a seamless experience for users.</p> A single TestMan container emulates many clients <p>In fact, the \"Try EDA\" topology that is featured in the Getting Started guide leverages the TestMan as the emulated clients for all edge links in the topology.</p> TestMan container in Try EDA topology <p>To define the TestMan SimNode in the Network Topology users need to set the type of the Sim Node template to <code>TestMan</code> as follows:</p> Defining TestMan SimNode in Network Topology workflow (snippet)<pre><code>spec:\n  simulation:\n    topology:\n      - node: \"*\"\n        interface: \"*\"\n        simNode: testman-default\n    simNodeTemplates:\n      - name: default\n        type: TestMan #(2)!\n    simNodes:\n      - name: testman-default #(1)!\n        template: default\n</code></pre> <ol> <li>Currently <code>edactl</code> tool expects the TestMan node to be named <code>testman-default</code>.</li> <li>The <code>.spec.simulation.simNodeTemplates[].type</code> field is set to <code>TestMan</code> to indicate that this Sim Node template represents a TestMan container and not just a generic Linux container.</li> </ol>"},{"location":"digital-twin/#testman-interfaces","title":"TestMan interfaces","text":"<p>When the TestMan node is defined in the topology, the Digital Twin automatically creates and manages the interfaces inside the TestMan container to match the number of connections made to it. This will cause every TopoLink to be in the operational up state:</p> <pre><code>kubectl -n eda get topolink \\\n-o custom-columns=\"NAME:.metadata.name,NAMESPACE:.metadata.namespace,STATE:.status.operationalState\"\n</code></pre> <pre><code>NAME                 NAMESPACE   STATE\nleaf1-2-e1212        eda         up\nleaf1-e1011          eda         up\nleaf1-ethernet-1-3   eda         up\nleaf1-ethernet-1-4   eda         up\nleaf1-ethernet-1-5   eda         up\nleaf1-ethernet-1-6   eda         up\nleaf1-ethernet-1-7   eda         up\nleaf1-ethernet-1-8   eda         up\nleaf1-ethernet-1-9   eda         up\nleaf1-spine1-1       eda         up\nleaf1-spine1-2       eda         up\nleaf2-e1011          eda         up\nleaf2-ethernet-1-3   eda         up\nleaf2-ethernet-1-4   eda         up\nleaf2-ethernet-1-5   eda         up\nleaf2-ethernet-1-6   eda         up\nleaf2-ethernet-1-7   eda         up\nleaf2-ethernet-1-8   eda         up\nleaf2-ethernet-1-9   eda         up\nleaf2-spine1-1       eda         up\nleaf2-spine1-2       eda         up\n</code></pre> <p>However, without any services deployed in EDA, the edge interfaces inside the TestMan container will not be configured with any IP/MAC addresses:</p> <pre><code>edactl -n eda testman get-edge-if all\n</code></pre> <pre><code>No EdgeInterfaces found\n</code></pre> <p><code>edactl -n &lt;namespace&gt; testman</code> is the command line interface to interact with the TestMan features.</p> <p>If you were to create a Fabric and a Virtual Network in EDA that would target the edge interfaces connected to the TestMan, the Digital Twin would automatically configure the interfaces inside the TestMan container with the appropriate addressing.</p> Creating a Fabric and a Virtual Network <p>If you don't have a Fabric and a Virtual Network created in EDA yet, paste this snippet in your terminal to create them in the <code>eda</code> namespace:</p> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: myfabric-1\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n\n---\napiVersion: services.eda.nokia.com/v1\nkind: VirtualNetwork\nmetadata:\n  name: demo-vnet-bd-vlan-10\n  namespace: eda\nspec:\n  bridgeDomains:\n    - name: vnet-demo-bd\n      spec:\n        eviPool: evi-pool\n        tunnelIndexPool: tunnel-index-pool\n        type: EVPNVXLAN\n        vniPool: vni-pool\n  vlans:\n    - name: vnet-demo-vlan10\n      spec:\n        bridgeDomain: vnet-demo-bd\n        interfaceSelector:\n          - eda.nokia.com/role=edge\n        vlanID: \"10\"\n\nEOF\n</code></pre> <p>The above snippet creates an EVPN VXLAN fabric and a Layer 2 Virtual Network that uses VLAN 10 on all interfaces labelled with <code>eda.nokia.com/role=edge</code>. Based on this configuration, the Digital Twin will automatically configure the corresponding edge interfaces on the TestMan side to be part of VLAN 10 and assign IP and MAC addresses to them:</p> <pre><code>edactl -n eda testman get-edge-if all\n</code></pre> <pre><code>--------------------------------------------------------------------------------\n        Number of EdgeInterfaces found: 17\n--------------------------------------------------------------------------------\nNamespace           : eda\nName                : eif-lag-leaf1-2-e1212-local-vlan-10\nIfResName           : lag-leaf1-2-e1212-local\nIfName              : b2\nVlanID              : 10\nRouter              :\nBridgeDomain        : vnet-demo-bd\nMAC                 : FE:3F:BB:00:00:0B\nIPs                 : 10.0.0.12\n                    : fd12:3456:789a:1::c\n--------------------------------------------------------------------------------\nNamespace           : eda\nName                : eif-lag-leaf1-e1011-local-vlan-10\nIfResName           : lag-leaf1-e1011-local\nIfName              : b3\nVlanID              : 10\nRouter              :\nBridgeDomain        : vnet-demo-bd\nMAC                 : FE:3F:BB:00:00:08\nIPs                 : 10.0.0.9\n                    : fd12:3456:789a:1::9\n--------------------------------------------------------------------------------\n# snipped for brevity\n--------------------------------------------------------------------------------\nNamespace           : eda\nName                : eif-leaf1-ethernet-1-3-vlan-10\nIfResName           : leaf1-ethernet-1-3\nIfName              : eth1\nVlanID              : 10\nRouter              :\nBridgeDomain        : vnet-demo-bd\nMAC                 : FE:3F:BB:00:00:0C\nIPs                 : 10.0.0.13\n                    : fd12:3456:789a:1::d\n--------------------------------------------------------------------------------\n</code></pre> <p>The Digital Twin controller knows how to configure LAG interfaces as well, so for the local and multi-node ESI LAGs defined in the topology, TestMan will create the corresponding LAG interfaces and assign them the appropriate addressing as well.</p>"},{"location":"digital-twin/#ping","title":"Ping","text":"<p>As of 25.12.1, TestMan supports ICMP ping tests that can be executed against the edge interfaces. This allows users to quickly validate the connectivity of the simulated network from the client perspective.</p> <p>To execute a ping test from TestMan, users need to run the <code>edactl -n &lt;ns&gt; testman ping</code> command, that supports the following parameters:</p> <pre><code>ping dst-ip using edge-interface\n\nUsage:\n  edactl testman ping [command]\n\nAvailable Commands:\n  eif-name    ping dst-ip using specified edge-interface\n  interface   ping dst-ip using edge-interface identified by interface-resource and qtag\n  vrf-name    ping dst-ip using one of the edge-interface from specified vrf\n</code></pre> <p>Using the Try EDA topology as an example and the simple Layer 2 Virtual Network we created above, we can execute a ping test from TestMan from one of the edge interfaces to an IP address assigned to another edge interface. For a concrete example, let's validate that the client connected to <code>leaf1:ethernet-1-3</code> interface can reach the client connected to <code>leaf2:ethernet-1-3</code> interface. We start by identifying the edge interface name inside TestMan that corresponds to the <code>leaf1-ethernet-1-3</code> interface resource:</p> <pre><code>edactl -n eda testman get-edge-if interface leaf1-ethernet-1-3\n</code></pre> <pre><code>--------------------------------------------------------------------------------\n        Number of EdgeInterfaces found: 1\n--------------------------------------------------------------------------------\nNamespace           : eda\nName                : eif-leaf1-ethernet-1-3-vlan-10\nIfResName           : leaf1-ethernet-1-3\nIfName              : eth1\nVlanID              : 10\nRouter              :\nBridgeDomain        : vnet-demo-bd\nMAC                 : FE:3F:BB:00:00:0C\nIPs                 : 10.0.0.13\n                    : fd12:3456:789a:1::d\n--------------------------------------------------------------------------------\n</code></pre> <p>Next, let's identify the IP address assigned to the edge interface connected to <code>leaf2-ethernet-1-3</code> interface resource:</p> <pre><code>edactl -n eda testman get-edge-if interface leaf2-ethernet-1-3\n</code></pre> <pre><code>--------------------------------------------------------------------------------\n        Number of EdgeInterfaces found: 1\n--------------------------------------------------------------------------------\nNamespace           : eda\nName                : eif-leaf2-ethernet-1-3-vlan-10\nIfResName           : leaf2-ethernet-1-3\nIfName              : eth5\nVlanID              : 10\nRouter              :\nBridgeDomain        : vnet-demo-bd\nMAC                 : FE:3F:BB:00:00:0A\nIPs                 : 10.0.0.11\n                    : fd12:3456:789a:1::b\n--------------------------------------------------------------------------------\n</code></pre> <p>Great, we have everything we need to run the ping test now:</p> <ul> <li>the source edge interface name inside TestMan: <code>eif-leaf1-ethernet-1-3-vlan-10</code></li> <li>the destination IP address to ping: <code>10.0.0.11</code></li> </ul> <p>Let's run the ping test:</p> <pre><code>edactl -n eda testman ping eif-name eif-leaf1-ethernet-1-3-vlan-10 10.0.0.11\n</code></pre> <pre><code>--- timeout: 16.00 sec, interval: 1000000 \u00b5sec ---\nPING 10.0.0.11 10.0.0.13 &amp;{eda eif-leaf1-ethernet-1-3-vlan-10}: 56(84) bytes of data.\n84 bytes from 10.0.0.11: icmp_seq=0 ttl=128 time=2.886ms\n--- 10.0.0.11 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 104ms\nrtt min/avg/max/mdev = 2.886/2.886/2.886/0.000ms\n</code></pre> <p>More TestMan capabilities are coming soon, stay tuned!</p>"},{"location":"digital-twin/#connecting-to-the-digital-twin-nodes","title":"Connecting to the Digital Twin Nodes","text":"<p>By the virtue of being Kubernetes-native, each simulator node in the Digital Twin is represented by a pod that runs the network OS and the datapath component. Therefore, you can connect and expose the simulator nodes using the standard Kubernetes tooling and methods.</p> <p>For long-term access to the simulated nodes an administrator might create a service and an ingress or loadbalancer resource. This typically requires some additional configuration and infrastructure setup, but achieves persistent access to the selected ports and protocols.</p> <p>Typically, though, users would want to connect with SSH to the simulator nodes to inspect the configuration, logs or run ad-hoc commands. Start with listing the TopoNodes in your namespace using <code>kubectl</code>. If you are running the Try EDA cluster, you can expect to see the three nodes in the output:</p> <pre><code>kubectl -n eda get toponodes \n</code></pre> <pre><code>NAME     PLATFORM       VERSION   OS    ONBOARDED   MODE     NPP         NODE     AGE\nleaf1    7220 IXR-D3L   25.3.2    srl   true        normal   Connected   Synced   99m\nleaf2    7220 IXR-D3L   25.3.2    srl   true        normal   Connected   Synced   99m\nspine1   7220 IXR-H2    25.3.2    srl   true        normal   Connected   Synced   99m\n</code></pre> <p>As we explained earlier, each TopoNode is backed by a Kubernetes deployment that runs the simulator. These deployments are spawned in the EDA core namespace (<code>eda-system</code> by default) and have the <code>eda.nokia.com/app-group=cx-cluster</code> label set:</p> <pre><code>kubectl -n eda-system get deploy -l eda.nokia.com/app-group=cx-cluster\n</code></pre> <pre><code>NAME                          READY   UP-TO-DATE   AVAILABLE   AGE\ncx-eda--leaf1-sim             1/1     1            1           3h32m\ncx-eda--leaf2-sim             1/1     1            1           3h32m\ncx-eda--spine1-sim            1/1     1            1           3h32m\ncx-eda--testman-default-sim   1/1     1            1           3h32m\n</code></pre> If you are running the Try EDA cluster, you will see the <code>testman</code> deployment as well. This is a special testing agent that we will cover in a later section. <p>As per the virtual topology that comes with the Try EDA cluster, we got three simulator deployments for leaf1, leaf2 and spine1 nodes. Using <code>kubectl</code> we can connect to the node's shell and execute the CLI process to get the CLI access:</p> <pre><code>kubectl --namespace eda-system exec -it \\\n$(kubectl --namespace eda-system get pods -l cx-pod-name=leaf1 \\\n-o=jsonpath='{.items[*].metadata.name}') \\\n-- bash -l -c 'sudo sr_cli'\n</code></pre> <pre><code>Defaulted container \"leaf1\" out of: leaf1, cxdp\nLoading environment configuration file(s): ['/etc/opt/srlinux/srlinux.rc']\nWelcome to the Nokia SR Linux CLI.\n\n--{ + running }--[  ]--\nA:root@leaf1#\n</code></pre> <p>But typing in this multiline command is a bit too much for a repetitive process, so here is a little script that you can put in your <code>$PATH</code> to quickly SSH to the desired node by its name:</p> <code>node-ssh</code> script to connect to a simulator node scriptadding to <code>$PATH</code> <pre><code>#!/bin/bash\n\n# Script to SSH into a specific node in the EDA topology\n# Usage: ./node-ssh &lt;node-name&gt; [&lt;user-namespace&gt;:-eda] [&lt;core-namespace&gt;:-eda-system]\n\n# provide the TopoNode name as the first argument\n# e.g. node-ssh leaf1\nNODE_NAME=${1}\n\n# user namespace to look up the TopoNode in\n# default is eda\nUSER_NS=${2:-eda}\n\n# core namespace to cx pods in\n# default is eda\nCORE_NS=${3:-eda-system}\n\nfunction list_nodes() {\n  kubectl --namespace ${CORE_NS} get pods -l cx-cluster-name=eda \\\n  -o=jsonpath='{.items[*].metadata.labels.cx-pod-name}' | tr ' ' '\\n'\n}\n\nif [ -z \"${NODE_NAME}\" ]; then\n  echo \"Usage: $0 &lt;node-name&gt; [&lt;namespace&gt;]\"\n  echo \"  Available nodes are:\"\n  list_nodes | sed 's/^/    /'\n  exit 1\nfi\n\nNODE_ADDR=$(kubectl -n ${USER_NS} get targetnode \"${NODE_NAME}\" -o jsonpath='{.spec.address}')\nif [ -z \"${NODE_ADDR}\" ]; then\n  echo \"Node ${NODE_NAME} not found in namespace ${USER_NS}; available nodes are:\"\n  list_nodes | sed 's/^/    /'\n  exit 1\nfi\n\nUSERNAME=admin\n# SSH to the node from the eda-toolbox pod\nkubectl -n ${CORE_NS} exec -it \\\n  $(kubectl get -n ${CORE_NS} pods \\\n  -l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n  -- ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \\\n  -p 22 \"${USERNAME}@${NODE_ADDR}\" || {\n  echo \"Failed to SSH into node ${NODE_NAME} at ${NODE_ADDR}\"\n  exit 1\n}\n</code></pre> <p>You can paste this command in your terminal to add the script to <code>/usr/local/bin</code> directory, and make it executable:</p> <pre><code>cat &lt;&lt; 'EOF' | sudo tee /usr/local/bin/node-ssh\n#!/bin/bash\n\n# Script to SSH into a specific node in the EDA topology\n# Usage: ./node-ssh &lt;node-name&gt; [&lt;user-namespace&gt;:-eda] [&lt;core-namespace&gt;:-eda-system]\n\n# provide the TopoNode name as the first argument\n# e.g. node-ssh leaf1\nNODE_NAME=${1}\n\n# user namespace to look up the TopoNode in\n# default is eda\nUSER_NS=${2:-eda}\n\n# core namespace to cx pods in\n# default is eda\nCORE_NS=${3:-eda-system}\n\nfunction list_nodes() {\n  kubectl --namespace ${CORE_NS} get pods -l cx-cluster-name=eda \\\n  -o=jsonpath='{.items[*].metadata.labels.cx-pod-name}' | tr ' ' '\\n'\n}\n\nif [ -z \"${NODE_NAME}\" ]; then\n  echo \"Usage: $0 &lt;node-name&gt; [&lt;namespace&gt;]\"\n  echo \"  Available nodes are:\"\n  list_nodes | sed 's/^/    /'\n  exit 1\nfi\n\nNODE_ADDR=$(kubectl -n ${USER_NS} get targetnode \"${NODE_NAME}\" -o jsonpath='{.spec.address}')\nif [ -z \"${NODE_ADDR}\" ]; then\n  echo \"Node ${NODE_NAME} not found in namespace ${USER_NS}; available nodes are:\"\n  list_nodes | sed 's/^/    /'\n  exit 1\nfi\n\nUSERNAME=admin\n# SSH to the node from the eda-toolbox pod\nkubectl -n ${CORE_NS} exec -it \\\n  $(kubectl get -n ${CORE_NS} pods \\\n  -l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n  -- ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \\\n  -p 22 \"${USERNAME}@${NODE_ADDR}\" || {\n  echo \"Failed to SSH into node ${NODE_NAME} at ${NODE_ADDR}\"\n  exit 1\n}\nEOF\nsudo chmod +x /usr/local/bin/node-ssh\n</code></pre> <p>With the <code>node-ssh</code> script in place, you can connect with ssh to any node in your Digital Twin by its name:</p> <pre><code># Usage: ./node-ssh &lt;node-name&gt; [&lt;user-namespace&gt;:-eda] [&lt;core-namespace&gt;:-eda-system]\nnode-ssh spine1\n</code></pre> <p>For SimNodes that don't have SSH access (like SimNodes running generic Linux containers), use the <code>node-shell</code> script that opens up a shell in the simulator pod:</p> <code>node-shell</code> script to open a shell to a simulator node scriptadding to <code>$PATH</code> <pre><code>#!/bin/bash\n\n# Script to open shell into a simnode in EDA CX\n# Usage: ./node-shell &lt;simnode-name&gt; [&lt;user-namespace&gt;:-eda] [&lt;core-namespace&gt;:-eda-system]\n\n# provide the SimNode name as the first argument\n# e.g. node-shell client1\n\nSIMNODE_NAME=${1}\n\n# user namespace to look up the TopoNode in\n# default is eda\nUSER_NS=${2:-eda}\n\n# core namespace to look up cx pods in\n# default is eda\nCORE_NS=${3:-eda-system}\n\nfunction list_simnodes() {\n  kubectl --namespace ${USER_NS} get simnodes\n}\n\nif [ -z \"${SIMNODE_NAME}\" ]; then\n  echo \"Usage: $0 &lt;simnode-name&gt; [&lt;user-namespace&gt;:-eda] [&lt;core-namespace&gt;:-eda-system]\"\n  echo \"  Available nodes are:\"\n  list_simnodes | sed 's/^/    /'\n  exit 1\nfi\n\n# open shell to the cx pod\nkubectl -n ${CORE_NS} exec -it \\\n  $(kubectl get -n ${CORE_NS} pods \\\n  -l cx-node-namespace/${USER_NS} -l cx-pod-name=${SIMNODE_NAME} -o jsonpath=\"{.items[0].metadata.name}\") -- sh -c \"(bash -l || ash | sh)\" \\\n  || {\n  echo \"Failed to open shell into node ${SIMNODE_NAME} in ${USER_NS} namespace.\"\n  echo \"Available nodes are:\"\n  list_simnodes | sed 's/^/    /'\n  exit 1\n}\n</code></pre> <p>You can paste this command in your terminal to add the script to <code>/usr/local/bin</code> directory, and make it executable:</p> <pre><code>cat &lt;&lt; 'EOF' | sudo tee /usr/local/bin/node-shell\n#!/bin/bash\n\n# Script to open shell into a simnode in EDA CX\n# Usage: ./node-shell &lt;simnode-name&gt; [&lt;user-namespace&gt;:-eda] [&lt;core-namespace&gt;:-eda-system]\n\n# provide the SimNode name as the first argument\n# e.g. node-shell client1\n\nSIMNODE_NAME=${1}\n\n# user namespace to look up the TopoNode in\n# default is eda\nUSER_NS=${2:-eda}\n\n# core namespace to look up cx pods in\n# default is eda\nCORE_NS=${3:-eda-system}\n\nfunction list_simnodes() {\n  kubectl --namespace ${USER_NS} get simnodes\n}\n\nif [ -z \"${SIMNODE_NAME}\" ]; then\n  echo \"Usage: $0 &lt;simnode-name&gt; [&lt;user-namespace&gt;:-eda] [&lt;core-namespace&gt;:-eda-system]\"\n  echo \"  Available nodes are:\"\n  list_simnodes | sed 's/^/    /'\n  exit 1\nfi\n\n# open shell to the cx pod\nkubectl -n ${CORE_NS} exec -it \\\n  $(kubectl get -n ${CORE_NS} pods \\\n  -l cx-node-namespace/${USER_NS} -l cx-pod-name=${SIMNODE_NAME} -o jsonpath=\"{.items[0].metadata.name}\") -- sh -c \"(bash -l || ash | sh)\" \\\n  || {\n  echo \"Failed to open shell into node ${SIMNODE_NAME} in ${USER_NS} namespace.\"\n  echo \"Available nodes are:\"\n  list_simnodes | sed 's/^/    /'\n  exit 1\n}\nEOF\nsudo chmod +x /usr/local/bin/node-shell\n</code></pre> <p>With the script in place, you can connect to any node in your Digital Twin by its name:</p> <pre><code># Usage: ./node-ssh &lt;node-name&gt; [&lt;user-namespace&gt;:-eda] [&lt;core-namespace&gt;:-eda-system]\nnode-ssh spine1\n</code></pre> <p>With the <code>node-shell</code> script in place, you can open the shell to any node in your Digital Twin by its name:</p> <pre><code># Usage: ./node-shell &lt;node-name&gt; [&lt;user-namespace&gt;:-eda] [&lt;core-namespace&gt;:-eda-system]\nnode-shell testman-default\n</code></pre>"},{"location":"digital-twin/#configuring-simulator-resource-requests","title":"Configuring Simulator Resource Requests","text":"<p>When EDA CX component creates the virtual simulators in the Digital Twin, it creates a Kubernetes deployment for each simulator node in the topology. To guarantee that the simulators have enough resources to run under potentially high load, the deployments are configured with the resource requests for CPU and memory.</p> <p>For example, if you have the Try EDA cluster deployed, you can check the resource requests for the leaf1 simulator node with the command:</p> <pre><code>kubectl get pods -n eda-system -l cx-pod-name=leaf1 \\\n-o custom-columns=\"POD:.metadata.labels.cx-pod-name,\\\nCPU_REQUEST:.spec.containers[*].resources.requests.cpu,\\\nMEM_REQUEST:.spec.containers[*].resources.requests.memory\"\n</code></pre> <pre><code>POD     CPU_REQUEST   MEM_REQUEST\nleaf1   200m,200m     1Gi,250Mi\n</code></pre> <p>You will see at least two values reported for the CPU and memory requests. The first value is the resources requested for the simulator node itself, and the second value is the resources requested for the topology wiring service that EDA's Digital Twin uses to connect the simulator nodes in the topology. In the example above, the leaf1 simulator node requests 200m of CPU and 1Gi of memory for itself, and 200m of CPU and 250Mi of memory for the topology wiring service, resulting in a total of 400m of CPU and 1.25Gi of memory requested per the simulator node of the SR Linux type.</p> <p>The default values for the resource requests are chosen to ensure that the simulators can run under medium load. However, you may want to adjust the resource requests based on your specific use case and either increase or decrease them. Often, you may want to decrease the default values to save resources in the cluster and fit more simulator nodes, especially if you run development clusters with a limited amount of hardware resources.</p> <p>EDA allows you to configure CPU and memory requests and limits for the supported simulator types via the Config Engine setting. For example, to change the CPU and memory requests for the SR Linux simulator nodes and the CXDP (topology wiring service), start by entering the edit mode for the Config Engine:</p> <pre><code>kubectl edit -n eda-system engineconfig\n</code></pre> <p>Add the following block to the <code>spec</code> section:</p> <pre><code>customSettings:\n- applicationName: cx\n  settings:\n  - name: SrlCpuRequest\n    value: 100m\n  - name: SrlMemoryRequest\n    value: 500Mi\n  - name: CxdpCpuRequest\n    value: 50m\n  - name: CxdpMemoryRequest\n    value: 200Mi\n</code></pre> <p>This will change the default requests for the SR Linux simulator nodes and the CXDP container.</p> <p>After editing the Config Engine resource, you need to redeploy the topology for the changes to take effect.</p> Full list of setting names for the CX application Setting Name Default Value Description Nokia SR Linux <code>SrlCpuRequest</code> 200m SR Linux CPU request <code>SrlMemoryRequest</code> 1Gi SR Linux Memory request <code>SrlCpuLimit</code> SR Linux CPU limit <code>SrlMemoryLimit</code> SR Linux Memory limit Nokia SR OS <code>SrosCpuRequest</code> 200m SR OS CPU request <code>SrosMemoryRequest</code> 1Gi SR OS Memory request <code>SrosCpuLimit</code> SR OS CPU limit <code>SrosMemoryLimit</code> SR OS Memory limit Cisco NX OS <code>NxosCpuRequest</code> 200m NX-OS CPU request <code>NxosMemoryRequest</code> 1Gi NX-OS Memory request <code>NxosCpuLimit</code> NX-OS CPU limit <code>NxosMemoryLimit</code> NX-OS Memory limit Arista EOS <code>EosCpuRequest</code> 200m EOS CPU request <code>EosMemoryRequest</code> 1Gi EOS Memory request <code>EosCpuLimit</code> EOS CPU limit <code>EosMemoryLimit</code> EOS Memory limit Nokia EDA Edge Sim <code>EdgeSimCpuRequest</code> 200m EdgeSim CPU request <code>EdgeSimMemoryRequest</code> 500Mi EdgeSim Memory request <code>EdgeSimCpuLimit</code> EdgeSim CPU limit <code>EdgeSimMemoryLimit</code> EdgeSim Memory limit Nokia EDA CXDP <code>CxdpCpuRequest</code> 200m CXDP CPU request <code>CxdpMemoryRequest</code> 250Mi CXDP Memory request <code>CxdpCpuLimit</code> CXDP CPU limit <code>CxdpMemoryLimit</code> CXDP Memory limit <p>After editing the Config Engine resource and redeploying the topology, you can check that the new values have been applied:</p> <pre><code>kubectl get pods -n eda-system -l cx-pod-name=leaf1 \\\n-o custom-columns=\"POD:.metadata.labels.cx-pod-name,\\\nCPU_REQUEST:.spec.containers[*].resources.requests.cpu,\\\nMEM_REQUEST:.spec.containers[*].resources.requests.memory\"\n</code></pre> <pre><code>POD     CPU_REQUEST   MEM_REQUEST\nleaf1   100m,50m      500Mi,100Mi\n</code></pre> <ol> <li> <p>EDA does not bundle the virtual simulators for the 3<sup>rd</sup>-party vendors. Users should obtain the simulators themselves and made them available to the Digital Twin.\u00a0\u21a9</p> </li> <li> <p>Like Nokia SR Linux, Nokia SR OS (SR-SIM) or third-party vendor simulator, e.g. Arista EOS.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting-started/installation-process/","title":"Try EDA Installation process","text":"<p>The unattended \"Try EDA\" install procedure powered by the <code>make try-eda</code> step does a lot of steps in the background, making the installation process quick and easy. However, going over most important steps of the playground installation process will give you a better understanding of the underlying operations and can assist you in troubleshooting issues.</p> <p>Note</p> <ol> <li>If you want just to install EDA the easy way, you can skip this chapter and use the Try EDA procedure.</li> <li>This chapter explains the generic installation steps based on the Makefile operations and is not a reference for a production installation.</li> <li>The outlined steps are not meant to be executed in the way they presented. This page just explains some core installation steps, without maintaining a close relationship between them.</li> </ol> <p>The key installation step that the \"Try EDA\"<sup>1</sup> installation performs are:</p> <p> Setting up a development Kubernetes cluster if one does not exist.  Downloading and installing the external and EDA core packages using <code>kpt</code><sup>2</sup>.  Installing an initial set of EDA applications provided by Nokia.  Exposing UI/API endpoint to a user.</p> <p>The <code>make try-eda</code> command sets up the whole thing for you; Let us explain some steps it carries out in more details.</p>"},{"location":"getting-started/installation-process/#tools","title":"Tools","text":"<p>Who likes to manually install a bunch of tools that are needed for the installation process manually? Not us! That's why we automated the tools procurement our installation process relies on:</p> <pre><code>make download-tools #(1)!\n</code></pre> <ol> <li> <p>This will download <code>kind</code>, <code>kubectl</code>, <code>kpt</code>, and <code>yq</code> into a <code>tools</code> folder relative to the current working directory.</p> <p>Subsequent steps use these versions of the binaries - you may use your own binaries for your own interactions. If you don't have <code>kubectl</code> in your <code>$PATH</code>, then consider copying the <code>kubectl</code> binary from the <code>tools</code> directory to a location in your <code>$PATH</code> to make use of it in the following steps.</p> </li> </ol> <p>You will have to install the container runtime (e.g. <code>docker</code>) manually.</p>"},{"location":"getting-started/installation-process/#eda-packages","title":"EDA packages","text":"<p>EDA is packaged using <code>kpt</code>, and uses this package manager tool to install core EDA components as well as external tools like cert-manager. The installer downloads EDA kpt packages by cloning the nokia-eda/kpt. These packages install EDA core and some external components onto the k8s cluster in the later steps.</p> <p>But EDA kpt packages only install the core EDA components, such as its config engine, digital sandbox and so on. The EDA applications, though, are distributed via application catalogs, which are just git repositories with application manifests. The app catalog that \"Try EDA\" downloads contains Nokia apps such as Fabrics, Interfaces, AAA and other basic apps you get installed with EDA.</p> <p>To clone both EDA kpt packages and the app catalog, the makefile packs the following target:</p> <pre><code>make download-pkgs\n</code></pre>"},{"location":"getting-started/installation-process/#kind-cluster","title":"KinD cluster","text":"<p>EDA is a set of containerized applications that are meant to run in a Kubernetes cluster. Try EDA setup uses Kubernetes-in-Docker project, a.k.a <code>kind</code>, to setup a local k8s cluster<sup>3</sup>.</p> Already have a cluster? <p>Using the <code>kind</code> cluster for the quickstart is the easiest way to get started, but you are welcome to try EDA on a cluster of your own and even use the same <code>Makefile</code> to install EDA on it. Here is a short guide how to do that.</p> <p>The <code>make try-eda</code> step will setup the KinD cluster automatically for you and you should be able to verify that a one-node cluster is running with:</p> <pre><code>kubectl get nodes #(1)!\n</code></pre> <ol> <li><code>kubectl</code> is also installed during the <code>make download-tools</code> step; you will find the binary in the <code>./tools</code> directory.</li> </ol> <pre><code>NAME                     STATUS   ROLES           AGE   VERSION\neda-demo-control-plane   Ready    control-plane   88s   v1.25.3\n</code></pre>"},{"location":"getting-started/installation-process/#external-packages","title":"External packages","text":"<p>EDA relies on some open source projects like <code>fluentd</code> for logging, <code>certmanager</code> for certificate management and <code>gogs</code> for Git. You may provide these components as part of your own cluster installation, or the EDA install can add them for you. It is highly recommended if EDA is the only workload in the cluster to allow EDA to manage the installation of these dependencies.</p> <p>The external packages that EDA uses are defined in the <code>nokia-eda/kpt/eda-external-packages</code> directory and is installed as part of the <code>try-eda</code> step via this target:</p> <pre><code>make install-external-packages\n</code></pre>"},{"location":"getting-started/installation-process/#deployment-configuration","title":"Deployment configuration","text":"<p>To provide configuration flexibility for EDA installation, <code>kpt</code> packages have a lot of fields marked with the <code># kpt-set:</code> annotation. These fields can be set with the <code>kpt</code> CLI to change their default values. Parameters like TLS configuration, proxies, default credentials and more are configurable via <code>kpt</code> setters.</p> <p>Installation Customization section provides a deep dive on all customization options.</p> <p>For example, it is common for EDA to be behind a load balancer, with clients terminating on the load balancer address and having their traffic forwarded from there. As EDA performs redirects it needs to know the name/IP clients will use to reach it. This can be accomplished via the setters in <code>kpt</code>, but for persistency and convenience, the most common settings can be set via the <code>prefs.mk</code> file that is part of the playground repository.</p> subset of the options in the prefs.mk file<pre><code># EXT_DOMAIN_NAME = \"&lt;Domain name or IP address&gt;\"\n# EXT_HTTP_PORT = \"&lt;Port for http access&gt;\"\n# EXT_HTTPS_PORT = \"&lt;Port for https access&gt;\"\n# EXT_IPV4_ADDR = \"&lt;LB IP or external route&gt;\"\n# EXT_IPV6_ADDR = \"&lt;Same thing but in ipv6&gt;\"\n</code></pre> <p>Check out Trying EDA Like a Pro post for tips and tricks on how to configure EDA.</p>"},{"location":"getting-started/installation-process/#http-proxies","title":"HTTP Proxies","text":"<p>If your cluster requires an HTTP proxy to access the resources outside of it, you will need to set the <code>HTTPS_PROXY</code>, <code>HTTP_PROXY</code>, <code>NO_PROXY</code>, and their lowercase counterparts.</p> <p>The logic inside the <code>eda-configure-core</code> target will set these values automatically to the values in your environment. But if you're installing on a machine that has different proxy settings, you will need to set them manually in the <code>prefs.mk</code> file before running the <code>eda-configure-core</code> target.</p> <p>Once the desired values are set in the <code>prefs.mk</code> file, the <code>eda-configure-core</code> target can be run to set the values in the <code>eda-kpt</code> package:</p> <pre><code>make eda-configure-core\n</code></pre> <p>The end result of this command is that the manifests contained in the <code>eda-kpt</code> directory will have the corresponding values set to the values you provided.</p>"},{"location":"getting-started/installation-process/#installing-eda","title":"Installing EDA","text":"<p>An EDA deployment is composed of three parts:</p> <ol> <li>External packages: 3<sup>rd</sup> party, open source components EDA relies on. Like <code>fluentd</code> for logging or <code>cert-manager</code> for certificate management.     As we already discussed the external packages installation, the focus now is on the EDA core and apps.</li> <li>Core: this is a set of applications that bring the core functionality of EDA. It includes applications like the Config Engine, EDA Store, State Controller, and others.</li> <li>Applications: these are applications that extend EDA's core functionality. They are pluggable by nature and decoupled from the Core. Users can install and uninstall Nokia-provided applications as needed, as well as develop their own or consume third-party applications.</li> </ol>"},{"location":"getting-started/installation-process/#core","title":"Core","text":"<p>EDA Core is a <code>kpt</code> package located at <code>nokia-eda/kpt/eda-kpt-base</code> directory and is installed as part of the <code>try-eda</code> step with:</p> <pre><code>make eda-install-core #(1)!\n</code></pre> <ol> <li>Feel free to look at the <code>Makefile</code> to understand what happens during the install.</li> </ol> <p>The EDA deployments, daemonsets and services will be created by this target, and after ~2-5 minutes you should be able to see the EDA core components running.</p> Check deployment status <p>Check the deployment status with the following command, you want to see all the deployments ready:</p> <pre><code>kubectl -n eda-system get deploy | awk 'NR==1 || /eda/'\n</code></pre> <pre><code>NAME              READY   UP-TO-DATE   AVAILABLE   AGE\neda-api           1/1     1            1           117s\neda-appstore      1/1     1            1           117s\neda-asvr          1/1     1            1           117s\neda-bsvr          1/1     1            1           117s\neda-ce            1/1     1            1           2m37s\neda-cx            1/1     1            1           117s\neda-fe            1/1     1            1           117s\neda-fluentd       1/1     1            1           41m\neda-git           1/1     1            1           40m\neda-git-replica   1/1     1            1           40m\neda-keycloak      1/1     1            1           117s\neda-postgres      1/1     1            1           117s\neda-sa            1/1     1            1           117s\neda-sc            1/1     1            1           117s\neda-toolbox       1/1     1            1           2m37s\n</code></pre> <p>You can also check the <code>EngineConfig</code> to verify the ConfigEngine has started correctly, checking the <code>.status.run-status</code> field:</p> <pre><code>kubectl -n eda-system get engineconfig engine-config -o jsonpath='{.status.run-status}{\"\\n\"}'\n</code></pre> <pre><code>Started\n</code></pre> <p><code>Started</code> is good, anything else is bad!</p> <p>You can quickly verify the deployment with yet another target!</p> <pre><code>make eda-is-core-ready\n</code></pre> <p>If everything checks out, you're ready to install the apps!</p>"},{"location":"getting-started/installation-process/#apps","title":"Apps","text":"<p>EDA is an automation framework that is powered by Applications - the little nuggets of automation goodness that you're probably interested in using. Almost everything in EDA is considered an app - from the abstracted building blocks of the network services to the composite workflows enabling the automation of complex tasks.</p> <p>A basic set of Nokia-provided applications delivered via the default App Catalog is installed with:</p> <pre><code>make eda-install-apps #(1)!\n</code></pre> <ol> <li>Curious which apps are going to be installed? Check the <code>Makefile</code> and the <code>eda-install-apps</code> target.</li> </ol>"},{"location":"getting-started/installation-process/#bootstrap-eda","title":"Bootstrap EDA","text":"<p>By installing the applications we made EDA aware of them, but we haven't created any concrete instances of these apps yet. In the bootstrap step we create some example instances of these application types as well as some initial configuration.</p> <pre><code>make eda-bootstrap\n</code></pre> <p>The bootstrap step uses the <code>eda-kpt-playground</code> kpt package that contains the instances of the installed applications. For example, the concrete allocation pools or bootstrap configs for the networking nodes.</p>"},{"location":"getting-started/installation-process/#whats-next","title":"What's next?","text":"<p>You now have a ready-to-use EDA installation, with core services and some apps installed. What we miss is some network to automate. Let's have one!</p> <p> Virtual network</p> <ol> <li> <p>Try EDA is an installation mode for labs and demos. For production installation consult with the Software Installation document.\u00a0\u21a9</p> </li> <li> <p>kpt - pronounced \"kept\" - is a Kubernetes Packaging Tool. EDA uses <code>kpt</code> to package up all the resources needed to deploy EDA. See https://kpt.dev for more information.\u00a0\u21a9</p> </li> <li> <p>If you are using macOS you might be using another, non-KinD, k8s provider.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting-started/reset/","title":"Resetting the Playground","text":"<p>If you want to start fresh, or just shut down your playground, you can do so with the following commands:</p> <pre><code>make teardown-cluster\n</code></pre> <p>This will remove the KinD cluster and all the resources created by the EDA Playground.</p> <p>Then you can remove the existing <code>kpt</code> packages:</p> <pre><code>rm -rf eda-kpt\n</code></pre> <p>And you are ready to start over!</p>"},{"location":"getting-started/try-eda/","title":"Try EDA","text":"<p>We believe that EDA embodies what a network automation of the modern age should look like - declarative and programmable abstractions for both configuration and state, streaming-based engine, equipped with network-wide queries, extensible and multivendor-capable. And we don't want you to blindly take our word for it, instead we made EDA easily accessible<sup>1</sup> so that both network engineers and cloud practitioners could be the judge. With no license and no registration required, you are mere couple commands away from having the full EDA experience wherever you are - with your laptop, in the cloud or logged in the VM.</p> <p>To deliver the \"Try EDA\" experience, we have created an EDA playground - a repository that contains everything you need to install and provision a demo EDA instance with the virtual network on the side. Let us guide you through the installation process.</p> Quickstart video walkthrough <p>If you prefer a video walkthrough that starts from the very beginning, we have you covered! Check out the Event-Driven Automation playlist where Andy Lapteff walks you through the entire process step-by-step starting with installing a hypervisor all the way to the running EDA instance.</p> <ol> <li> <p>Choose where to run EDA</p> <p>Since EDA uses Kubernetes as its application platform, you can deploy the EDA Playground anywhere a k8s cluster runs. The most popular way to install the demo EDA instance is on a Linux server/VM, but you can also run it on macOS, in an existing Kubernetes cluster, or on Windows using WSL.</p> <p>If you get stuck with the installation, please reach out to us on Discord, we are happy to help!</p> </li> <li> <p>Ensure minimal system requirements are met</p> <p>Regardless of whether you run EDA Playground locally on a laptop, or in a VM locally or in the cloud, the underlying k8s cluster should have the following resources available to it<sup>2</sup>:</p> <p> 8 vCPUs  16GB of RAM  30GB of SSD storage</p> <p>For a VM-based installation, this means that the VM should be provisioned with (at the minium) this amount of resources.</p> </li> <li> <p>Clone the EDA Playground repository</p> <p>Proceed with cloning the EDA playground repository that contains everything you need to install and provision a demo EDA instance.</p> <p>If you are using a Linux VM or a server to deploy the Playground, you should clone the repository on that VM/server.</p> <p>You will need <code>git</code><sup>3</sup> to clone it:</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; \\\ncd playground\n</code></pre> </li> <li> <p>Prepare the VM/Server</p> <p>If you are deploying the EDA Playground on a VM/Server, you should take care of the following:</p> <p>Install <code>make</code> that orchestrates the installation of the EDA Playground.</p> aptyum <pre><code>sudo apt install -y make\n</code></pre> <pre><code>sudo yum install -y make\n</code></pre> <p>Install <code>docker</code> using our automated installer, if you don't have it already installed:</p> <pre><code>make install-docker\n</code></pre> <p>Or install it manually, by following the official Docker installation guide for your OS. If you installed docker via the package manager of your distribution, remove it and install as per the Docker installation guide.</p> Ensure sudo-less docker access <p>After completing the docker installation, check if you can run docker commands without <code>sudo</code> by running:</p> <pre><code>docker ps\n</code></pre> <p>If you get a <code>permission denied</code> error, then you need to add your user to the <code>docker</code> group:</p> <ol> <li> <p>Create the docker group.</p> <pre><code>sudo groupadd docker\n</code></pre> </li> <li> <p>Add your user to the docker group.</p> <pre><code>sudo usermod -aG docker $USER\n</code></pre> </li> <li> <p>Log out and log back in so that your group membership is re-evaluated.</p> </li> </ol> <p>Ensure the relevant sysctl values are properly sized by pasting and running the following:</p> <pre><code>make configure-sysctl-params\n</code></pre> </li> <li> <p>Install the EDA Playground</p> <p>A single command separates you from the EDA Playground installation. But before you run it, if you want to enable the Natural Language support for the EDA Query functionality, provide the LLM key (OpenAI) with an environment variable<sup>4</sup>:</p> <pre><code>export LLM_API_KEY=&lt;your-OpenAI-API-key&gt;\n</code></pre> <p>Now, run the EDA installer:</p> <pre><code>make try-eda\n</code></pre> <p>The installation will take approximately 10 minutes to complete. Once it is done, you can optionally verify the installation.</p> EDA License <p>As you may have noticed, the EDA Playground installation does not require a license. We wanted to ensure that automation with EDA is accessible to everyone, anytime. The EDA system can perfectly run without a license with the following caveats:</p> <ul> <li>Only the nodes inside the EDA's Digital Twin can be used. These include the SR Linux nodes that will be deployed for you by the time <code>make try-eda</code> step finishes as well as any 3<sup>rd</sup> party vendors supported by EDA's Digital Twin. No hardware nodes can be used in an unlicensed EDA mode<sup>5</sup>.</li> <li>No integration with the cloud systems such as OpenShift, VMware, etc.</li> </ul> </li> <li> <p>Access the UI</p> <p>EDA is an API-first framework, with its UI being a client of the very same API. After the <code>make try-eda</code> finishes, you will be able to access the EDA UI using the address printed in the terminal:</p> <pre><code>--&gt; The UI can be accessed using https://10.10.1.1:9443 #(1)!\n--&gt; INFO: EDA is launched\n</code></pre> <ol> <li>Instead of <code>10.10.1.1</code> IP you may see the IP address of the VM/Server where you installed EDA Playground or its hostname. You can use any address that resolves to the VM/Server hosting the Try EDA installation, not only the one printed in the terminal.</li> </ol> <p>Open your web browser and navigate to provided URL to access the EDA UI. As you would expect, credentials are required in order to log in. The default credentials are as follow:</p> <ul> <li>Username: <code>admin</code> </li> <li>Password: <code>admin</code></li> </ul> </li> </ol> <p>Now that you completed the installation, you can either read more on the installation details, or continue with creating your first unit of automation with EDA.</p> <ul> <li> <p> Creating a resource</p> <p>Now, that you are logged in, you are ready for your first EDA automation experience!</p> <p> Creating your first unit of automation</p> </li> <li> <p> How does install work?</p> <p>If you want to understand how EDA playground installer works and what makes up the EDA installation, you can continue with the Installation process section.</p> <p> Learn more about installation process</p> </li> </ul> Production installation <p>For a production installation instructions, please refer to the Software Installation document.</p> <ol> <li> <p>As no other framework of comparable scale.\u00a0\u21a9</p> </li> <li> <p>This as well accounts for the playground network topology. Running a bigger topology or changing the node types may require more resources.\u00a0\u21a9</p> </li> <li> <p>Many distributions come with <code>git</code> preinstalled, but if not you should install it via your package manager. For instance with <code>apt</code>-enabled systems:</p> <p><pre><code>sudo apt install -y git\n</code></pre> \u21a9</p> </li> <li> <p>You can provide the LLM key after the installation as well.\u00a0\u21a9</p> </li> <li> <p>Containerlab-deployed SR Linux nodes are planned to be supported in the unlicensed mode in the future.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting-started/units-of-automation/","title":"Units of automation","text":"<p>EDA is an automation framework that follows declarative principles. An operator's input is the desired state of the resources and EDA takes care of the deployment, provisioning, configuration and reconciliation of the resource. In other words, you tell EDA what state you want your infra to be in and EDA carries out the \"how\" for you in a reliable and most efficient way.</p> <p>What is a <code>Resource</code>?</p> <p>In EDA, a resource is a unit of automation and can represent virtually anything:</p> <ul> <li>an interface on a network device</li> <li>a complete fabric configuration<sup>1</sup></li> <li>a network service like a VPN or a VRF<sup>2</sup></li> <li>and even non-network related resources like a user account, a DNS record, or a firewall rule.</li> </ul> <p>As a Kubernetes citizen, EDA represents its resources via Custom Resources (CRs) of Kubernetes that can be created using multiple methods including the Kubernetes (K8s) API, the EDA API, or through a User Interface (UI).</p> <p>You probably wonder what resources are available in EDA and how to interact with them. Great question! EDA resources become available as soon as you install an EDA Application which is a way to extend EDA with new resources and capabilities on the fly. Applications may be provided by anyone: Nokia, our partners or indie developers - EDA is an open platform!</p> <p>Nothing beats a hands-on experience, so let's learn more about Resources by following a short but powerful example of configuring a fabric on top of our 3-node topology deployed as part of our playground.</p>"},{"location":"getting-started/units-of-automation/#a-fabric-resource","title":"A Fabric resource","text":"<p>You heard it right! We will configure a DC fabric using a single EDA resource in a fully declarative and reliable way. The Fabric resource is a high-level abstraction that allows you to define a fabric configuration suitable for environments ranging from small, single-node edge configurations to large, complex multi-tier and multi-pod networks.</p> <p>What is a Fabric?</p> <p>To put it simply, a Fabric resource represents a DC fabric configuration with all its components like:</p> <ul> <li>a set of leaf and spine devices</li> <li>allocation pools for system IPs, ASN numbers</li> <li>inter-switch links flavor (numbered, unnumbered, vlans)</li> <li>underlay protocol (eBGP, IGP)</li> <li>overlay protocol</li> </ul> <p>At the end of the day, a Fabric resource defines and configures everything a DC fabric needs to support overlay networks or L2/L3 services.</p> <p>The Fabric resource documentation provides a detailed description of the resource, its attributes and behavior. To not repeat ourselves, we will proceed with creating a Fabric resource and leave the exploration of its attributes to a reader.</p> <p>Recall, that you can create EDA resources using the Kubernetes API, the EDA API or through a User Interface (UI). Let's start with the Kubernetes API.</p>"},{"location":"getting-started/units-of-automation/#creating-a-resource-with-kubernetes-api","title":"Creating a resource with Kubernetes API","text":"<p>To create a resource via the Kubernetes API, you must first define a Kubernetes Custom Resource (CR) specific to your needs. As we set ourselves to create a Fabric resource, we need to define a Fabric CR using our Fabric resource documentation.</p> <p>To create the abstracted declarative definition of our Fabric in EDA we will use <code>kubectl</code><sup>3</sup> CLI tool. Paste the below command in your terminal to create a Fabric resource named <code>myfabric-1</code> in the <code>eda</code> namespace.</p> <p>Have a look at the Fabric CR input below as it highlights the power of abstraction and declarative configuration. In twenty lines of simple YAML, we defined an entire Fabric configuration, selected which leafs and spines, what inter switch links to select, and chose the underlay and overlay protocols.</p> <code>kubectl</code>YAML <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\napiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: myfabric-1\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n\nEOF\n</code></pre> <pre><code>apiVersion: fabrics.eda.nokia.com/v1alpha1\nkind: Fabric\nmetadata:\n  name: myfabric-1\n  namespace: eda\nspec:\n  leafs:\n    leafNodeSelector:\n      - eda.nokia.com/role=leaf\n  spines:\n    spineNodeSelector:\n      - eda.nokia.com/role=spine\n  interSwitchLinks:\n    linkSelector:\n      - eda.nokia.com/role=interSwitch\n    unnumbered: IPV6\n  systemPoolIPV4: systemipv4-pool\n  underlayProtocol:\n    protocol:\n      - EBGP\n    bgp:\n      asnPool: asn-pool\n  overlayProtocol:\n    protocol: EBGP\n</code></pre> <p>Just like that, in a single command we deployed the Fabric resource, as we can verify with:</p> <pre><code>kubectl -n eda get fabric myfabric-1 #(1)!\n</code></pre> <ol> <li> <p>You can see the Fabric with the name <code>myfabric-1</code> in the EDA UI as well under the Fabrics section.</p> <p></p> </li> </ol> <pre><code>NAME         LAST CHANGE   OPERATIONAL STATE\nmyfabric-1   1m            up\n</code></pre> <p>Ok, we see that the Fabric resource named <code>myfabric-1</code> has been created in our cluster, but what exactly has happened? Let's find out.</p> <p>Without getting you overwhelmed with the details, let's just say that EDA immediately recognized the presence of the Fabric resource and turned an abstracted declarative Fabric definition to dozens of important fabric-related sub-resources. The sub-resources in their turn have been translated to the node-specific configuration blobs and were pushed in an all-or-nothing, transactional manner to all of the nodes in our virtual topology; all of this in a split second.</p> <p>You see the power of abstraction and automation in action, where the complex configuration task is reduced to a single declarative statement that is reliably transacted to the nodes, just as it should be.</p> <p>\"I don't think that the Fabric should be abstracted like that\"</p> <p>It is absolutely fine if your view how the Fabric abstraction should look like is different from ours. EDA doesn't tell you how to do your infrastructure automation, EDA is here to help you do it.</p> <p>Leveraging the power of pluggable applications, you can create your own Fabric abstraction and use them to configure your fabric in a way that is most convenient for you.</p> <p>Now, when the abstracted and declarative input has been processed by EDA, a fully functional Fabric configuration has been deployed on the nodes of our virtual topology. Don't take our word for it, let's connect to the nodes and check what config they have now. Do you remember that all the nodes in our fabric had no configuration at all? Let's see what changed after we applied the fabric resource:</p> Checking the running configuration on <code>leaf1</code> <p>We can connect to the nodes with a single command like <code>make leaf1-ssh</code> and check the running configuration with <code>info</code> command:</p> <pre><code>interface ethernet-1/1 {\n    admin-state enable\n    subinterface 0 {\n        admin-state enable\n        ipv6 {\n            admin-state enable\n            router-advertisement {\n                router-role {\n                    admin-state enable\n                    max-advertisement-interval 10\n                    min-advertisement-interval 4\n                }\n            }\n        }\n    }\n}\ninterface ethernet-1/2 {\n    admin-state enable\n    subinterface 0 {\n        admin-state enable\n        ipv6 {\n            admin-state enable\n            router-advertisement {\n                router-role {\n                    admin-state enable\n                    max-advertisement-interval 10\n                    min-advertisement-interval 4\n                }\n            }\n        }\n    }\n}\ninterface ethernet-1/3 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/4 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/5 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/6 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/7 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/8 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/9 {\n    admin-state enable\n    vlan-tagging true\n}\ninterface ethernet-1/10 {\n    description lag-leaf1-e1011-local\n    admin-state enable\n    ethernet {\n        aggregate-id lag1\n        lacp-port-priority 32768\n    }\n}\ninterface ethernet-1/11 {\n    description lag-leaf1-e1011-local\n    admin-state enable\n    ethernet {\n        aggregate-id lag1\n        lacp-port-priority 32768\n    }\n}\ninterface ethernet-1/12 {\n    description lag-leaf1-2-e1212-local\n    admin-state enable\n    ethernet {\n        aggregate-id lag2\n        lacp-port-priority 32768\n    }\n}\ninterface lag1 {\n    description lag-leaf1-e1011-local\n    admin-state enable\n    vlan-tagging true\n    lag {\n        lag-type lacp\n        min-links 1\n        lacp-fallback-mode static\n        lacp-fallback-timeout 60\n        lacp {\n            interval FAST\n            lacp-mode ACTIVE\n            admin-key 1\n            system-id-mac FE:2F:AA:00:00:01\n            system-priority 32768\n        }\n    }\n}\ninterface lag2 {\n    description lag-leaf1-2-e1212-local\n    admin-state enable\n    vlan-tagging true\n    lag {\n        lag-type lacp\n        min-links 1\n        lacp-fallback-mode static\n        lacp-fallback-timeout 60\n        lacp {\n            interval FAST\n            lacp-mode ACTIVE\n            admin-key 2\n            system-id-mac FE:2F:AA:00:00:02\n            system-priority 32768\n        }\n    }\n}\ninterface mgmt0 {\n    admin-state enable\n    subinterface 0 {\n        admin-state enable\n        ipv4 {\n            admin-state enable\n            dhcp-client {\n                trace-options {\n                    trace [\n                        messages\n                    ]\n                }\n            }\n        }\n        ipv6 {\n            admin-state enable\n            dhcp-client {\n                trace-options {\n                    trace [\n                        messages\n                    ]\n                }\n            }\n        }\n    }\n}\ninterface system0 {\n    subinterface 0 {\n        admin-state enable\n        ipv4 {\n            admin-state enable\n            address 11.0.0.1/32 {\n            }\n        }\n    }\n}\nsystem {\n    configuration {\n        role sudo {\n        }\n    }\n    aaa {\n        authentication {\n            authentication-method [\n                local\n            ]\n            admin-user {\n                password $y$j9T$2efd42dad2479d9f$nGS3iroL4eaDjeQBcoj.A8C8gcLddS5sSHM05UexSQ/\n            }\n        }\n        authorization {\n            role sudo {\n                superuser true\n                services [\n                    cli\n                    gnmi\n                    netconf\n                ]\n            }\n        }\n        server-group local {\n            type local\n        }\n    }\n    ssh-server mgmt {\n        admin-state enable\n        network-instance mgmt\n    }\n    boot {\n        autoboot {\n            admin-state enable\n        }\n    }\n    lldp {\n        interface ethernet-1/1 {\n            admin-state enable\n        }\n        interface ethernet-1/2 {\n            admin-state enable\n        }\n        interface ethernet-1/3 {\n            admin-state enable\n        }\n        interface ethernet-1/4 {\n            admin-state enable\n        }\n        interface ethernet-1/5 {\n            admin-state enable\n        }\n        interface ethernet-1/6 {\n            admin-state enable\n        }\n        interface ethernet-1/7 {\n            admin-state enable\n        }\n        interface ethernet-1/8 {\n            admin-state enable\n        }\n        interface ethernet-1/9 {\n            admin-state enable\n        }\n        interface ethernet-1/10 {\n            admin-state enable\n        }\n        interface ethernet-1/11 {\n            admin-state enable\n        }\n        interface ethernet-1/12 {\n            admin-state enable\n        }\n    }\n    name {\n        host-name leaf1\n    }\n    grpc-server mgmt {\n        admin-state enable\n        rate-limit 65535\n        session-limit 1024\n        metadata-authentication true\n        tls-profile EDA\n        network-instance mgmt\n        port 57400\n        services [\n            gnmi\n            gnoi\n            gnsi\n        ]\n        gnmi {\n            commit-save false\n        }\n    }\n    network-instance {\n        protocols {\n            evpn {\n                ethernet-segments {\n                    bgp-instance 1 {\n                        ethernet-segment lag-leaf1-2-e1212-local {\n                            admin-state enable\n                            esi 00:FE:2F:AA:00:00:02:00:00:00\n                            multi-homing-mode all-active\n                            interface lag2 {\n                            }\n                            df-election {\n                                algorithm {\n                                    type default\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n            bgp-vpn {\n                bgp-instance 1 {\n                }\n            }\n        }\n    }\n}\nnetwork-instance default {\n    type default\n    admin-state enable\n    description \"fabric: myfabric-1 role: leaf\"\n    router-id 11.0.0.1\n    ip-forwarding {\n        receive-ipv4-check false\n    }\n    interface ethernet-1/1.0 {\n    }\n    interface ethernet-1/2.0 {\n    }\n    interface system0.0 {\n    }\n    protocols {\n        bgp {\n            admin-state enable\n            autonomous-system 102\n            router-id 11.0.0.1\n            dynamic-neighbors {\n                interface ethernet-1/1.0 {\n                    peer-group bgpgroup-ebgp-myfabric-1\n                    allowed-peer-as [\n                        101\n                    ]\n                }\n                interface ethernet-1/2.0 {\n                    peer-group bgpgroup-ebgp-myfabric-1\n                    allowed-peer-as [\n                        101\n                    ]\n                }\n            }\n            ebgp-default-policy {\n                import-reject-all true\n                export-reject-all true\n            }\n            afi-safi evpn {\n                admin-state enable\n                multipath {\n                    allow-multiple-as true\n                    maximum-paths 64\n                }\n                evpn {\n                    inter-as-vpn true\n                }\n            }\n            afi-safi ipv4-unicast {\n                admin-state enable\n                multipath {\n                    allow-multiple-as true\n                    maximum-paths 2\n                }\n                ipv4-unicast {\n                    advertise-ipv6-next-hops true\n                    receive-ipv6-next-hops true\n                }\n                evpn {\n                    rapid-update true\n                }\n            }\n            afi-safi ipv6-unicast {\n                admin-state enable\n                multipath {\n                    allow-multiple-as true\n                    maximum-paths 2\n                }\n                evpn {\n                    rapid-update true\n                }\n            }\n            preference {\n                ebgp 170\n                ibgp 170\n            }\n            route-advertisement {\n                wait-for-fib-install false\n            }\n            group bgpgroup-ebgp-myfabric-1 {\n                admin-state enable\n                export-policy [\n                    ebgp-isl-export-policy-myfabric-1\n                ]\n                import-policy [\n                    ebgp-isl-import-policy-myfabric-1\n                ]\n                afi-safi evpn {\n                    admin-state enable\n                }\n                afi-safi ipv4-unicast {\n                    admin-state enable\n                    ipv4-unicast {\n                        advertise-ipv6-next-hops true\n                        receive-ipv6-next-hops true\n                    }\n                }\n                afi-safi ipv6-unicast {\n                    admin-state enable\n                }\n            }\n        }\n    }\n}\nnetwork-instance mgmt {\n    type ip-vrf\n    admin-state enable\n    description \"Management network instance\"\n    interface mgmt0.0 {\n    }\n    protocols {\n        linux {\n            import-routes true\n            export-routes true\n        }\n    }\n}\nrouting-policy {\n    prefix-set prefixset-myfabric-1 {\n        prefix 11.0.0.0/8 mask-length-range 32..32 {\n        }\n    }\n    policy ebgp-isl-export-policy-myfabric-1 {\n        default-action {\n            policy-result reject\n        }\n        statement 10 {\n            match {\n                prefix-set prefixset-myfabric-1\n                protocol local\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 15 {\n            match {\n                protocol bgp\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 20 {\n            match {\n                protocol aggregate\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 25 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            1\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 30 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            2\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 35 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            3\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 40 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            4\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 45 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            5\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n    }\n    policy ebgp-isl-import-policy-myfabric-1 {\n        default-action {\n            policy-result reject\n        }\n        statement 10 {\n            match {\n                protocol bgp\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 25 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            1\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 30 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            2\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 35 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            3\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 40 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            4\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n        statement 45 {\n            match {\n                bgp {\n                    evpn {\n                        route-type [\n                            5\n                        ]\n                    }\n                }\n            }\n            action {\n                policy-result accept\n                bgp {\n                    local-preference {\n                        set 100\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>The result of the deployed Fabric app is a fully configured BGP EVPN fabric that is configured on all of the nodes in our topology.</p> <p>We can list the BGP neighbors on <code>leaf1</code> to see that it has established BGP sessions with <code>leaf2</code> and <code>spine1</code>.</p> <pre><code>--{ + running }--[  ]--\nA:leaf1# show network-instance default protocols bgp neighbor *\n--------------------------------------------------------------------------------------------------------------------------------------------\nBGP neighbor summary for network-instance \"default\"\nFlags: S static, D dynamic, L discovered by LLDP, B BFD enabled, - disabled, * slow\n+----------------+-----------------------+----------------+------+---------+-------------+-------------+-----------+-----------------------+\n|    Net-Inst    |         Peer          |     Group      | Flag | Peer-AS |    State    |   Uptime    | AFI/SAFI  |    [Rx/Active/Tx]     |\n|                |                       |                |  s   |         |             |             |           |                       |\n+================+=======================+================+======+=========+=============+=============+===========+=======================+\n| default        | fe80::53:beff:feff:1% | bgpgroup-ebgp- | D    | 101     | established | 0d:0h:16m:2 | evpn      | [0/0/0]               |\n|                | ethernet-1/1.0        | myfabric-1     |      |         |             | 2s          | ipv4-     | [2/2/1]               |\n|                |                       |                |      |         |             |             | unicast   | [0/0/0]               |\n|                |                       |                |      |         |             |             | ipv6-     |                       |\n|                |                       |                |      |         |             |             | unicast   |                       |\n| default        | fe80::53:beff:feff:2% | bgpgroup-ebgp- | D    | 101     | established | 0d:0h:16m:2 | evpn      | [0/0/0]               |\n|                | ethernet-1/2.0        | myfabric-1     |      |         |             | 2s          | ipv4-     | [3/2/3]               |\n|                |                       |                |      |         |             |             | unicast   | [0/0/0]               |\n|                |                       |                |      |         |             |             | ipv6-     |                       |\n|                |                       |                |      |         |             |             | unicast   |                       |\n+----------------+-----------------------+----------------+------+---------+-------------+-------------+-----------+-----------------------+\nSummary:\n0 configured neighbors, 0 configured sessions are established, 0 disabled peers\n2 dynamic peers\n</code></pre> <p>Everything a fabric needs has been provisioned and configured on the nodes in a declarative way, taking the inputs from the abstracted, sweet and short Fabric CR that everyone can understand.</p>"},{"location":"getting-started/units-of-automation/#state-of-a-resource","title":"State of a resource","text":"<p>Too often, the automation platforms are built solely around the configuration problem, leaving state handling to a different set of applications. In EDA we believe that the state of a resource is as important as the configuration, and state-triggered automation is a key part of the EDA's philosophy.</p> <p>Be it a higher-level abstracted resource such as Fabric or a lower-level Interface, you will find the state reported for every EDA-managed resource. The relationship between the resource's specification and its state allows us to work with the abstracted configuration and the abstracted state.</p> <p>Take the recently deployed Fabric resource which spans multiple nodes, and consists of multiple sub-resources. How do we know that the Fabric is healthy? Checking the operational status of every BGP peer and every inter-switch link is not a practical approach.</p> <p>In EDA, the application developer can define the rules to calculate the state of a resource and populate the resource with this information. By looking at the Fabric's state field an operator can confidently determine the health of the Fabric, without having to inspect the configuration of every single node.</p> <p>Users can access the status of a resource using <code>edactl</code>, <code>kubectl</code>, or UI.</p> <p><code>edactl</code></p> <p>Not all resources are published into K8s and therefore it is recommended to use <code>edactl</code> to view the status of resources. <code>edactl</code> is a CLI tool that runs in the toolbox pod in a cluster and provides a way to interact with the EDA API.</p> <p>To leverage <code>edactl</code>, paste the following command into your terminal to install a shell alias that would execute <code>edactl</code> in the toolbox pod each time you call it.</p> Install <code>edactl</code> alias<pre><code>alias edactl='kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- edactl'\n</code></pre> <p>Now we can inspect the created Fabric resource using both <code>edactl</code> and <code>kubectl</code>.</p> <code>edactl</code><code>kubectl</code> <pre><code>edactl -n eda get fabrics myfabric-1 -o yaml\n</code></pre> <pre><code>kind: Fabric\nmetadata:\n  annotations: {}\n  name: myfabric-1\n  namespace: eda\nspec:\n# -- snipped --\nstatus:\n  health: 100\n  healthScoreReason: |\n    Breakdown:\n    Metric \"ISL Health\", weight: 1, score: 100, calculation method: divide\n    Metric \"DefaultRouter Health\", weight: 1, score: 100, calculation method: divide\n  lastChange: \"2024-12-15T17:24:50.000Z\"\n  leafNodes:\n  - node: leaf1\n    operatingSystem: srl\n    operatingSystemVersion: 24.10.1\n    underlayAutonomousSystem: 102\n  - node: leaf2\n    operatingSystem: srl\n    operatingSystemVersion: 24.10.1\n    underlayAutonomousSystem: 100\n  operationalState: up\n  spineNodes:\n  - node: spine1\n    operatingSystem: srl\n    operatingSystemVersion: 24.10.1\n    underlayAutonomousSystem: 101\n</code></pre> <pre><code>kubectl -n eda get fabrics myfabric-1 -o yaml\n</code></pre> <p>The output will be the same as with <code>edactl</code>, but this is because the Fabric resource was \"the input\" resource, and EDA publishes those resources into K8s.</p> <p>Note, how the <code>health</code> and <code>operationalState</code> of the whole Fabric resource is reported in the <code>status</code> field. Having the abstracted state is as important as the configuration, since it allows operators to focus on the important information, without having to inspect the configuration of every single node or component of a composite resource.</p> <p>The operational state can have different values that would help an operator to determine the health of the Fabric. It is totally up to the application developer to define what status is reported for a given resource based on what is relevant for the application.</p> <p>And, of course, the same information can be layed out nicely in the UI using resources dashboards (you guessed it, they are also customizable by the application developer).</p> <p>With a glance at the Fabric's dashboard an operator can determine the state of the whole fabric, without having to inspect a dozen of dashboards in a separate system.</p>"},{"location":"getting-started/units-of-automation/#transactions","title":"Transactions","text":"<p>The Kubernetes reconciliation loop mechanism offers a way to enable the declarative approach for the infrastructure management. Define the desired state of the infrastructure stack, in the Kubernetes Resource Model, apply it, and the corresponding controllers start to reconcile the actual state of the infrastructure with the desired state.  </p> <p>Sounds great, but what if the desired state is not achievable? What if you deploy a workload with three replicas, but your infrastructure at the moment can only host two of them? The reconciliation loop will keep trying to reconcile the desired state with the actual state, and while it reconciles, you end up living with just two replicas running.</p> <p>Doesn't sound like a big deal? Yes, maybe if you deploy three web servers and have two only two of them running for some time it is not the end of the world. But in the networking world, having a partially deployed service is a big, big problem.</p> <ul> <li>What if your CPM filter is partially deployed?</li> <li>What if your routing policy has been deployed on a subset of edge nodes?</li> <li>What if your service has been added to 100 out of 110 leafs?</li> </ul> <p>In EDA every configuration change is done in an all-or-nothing fashion and transacted in Git. Always. If the desired state is not achievable even on a single target node, the whole transaction is pronounced failed and the changes are reverted immediately from all of the nodes. The transactions are network-wide.</p> <p>When you create any resource, EDA automatically initiates a transaction and publishes its result. To view the list of existing transactions, use <code>edactl</code>:</p> <pre><code>edactl transaction\n</code></pre> <pre><code> ID  Result  Age     Detail   DryRun  Username    Description\n 27  OK      56h37m  SUMMARY          workflow    [workflow 10] Installing App: services.nokia: v2.0.0+24.12.1 (catalog=eda-catalog-builtin-apps)\n 28  OK      56h37m  DEBUG            workflow    [workflow 9] Installing App: protocols.nokia: v2.0.0+24.12.1 (catalog=eda-catalog-builtin-apps)\n 29  OK      56h37m  DEBUG            kubernetes\n 30  OK      56h37m  DEBUG            kubernetes\n 31  OK      56h37m  DEBUG            kubernetes\n 32  OK      56h36m  DEBUG            kubernetes\n 33  OK      56h36m  DEBUG            kubernetes\n 34  OK      56h35m  DEBUG            kubernetes\n 35  OK      56h35m  DEBUG            kubernetes\n 36  OK      1h22m   DEBUG            kubernetes\n</code></pre> <p>The transaction list shows the transaction ID, the status and the user who initiated the transaction. The transaction ID can be used to view the details of the transaction, including the changes made to the resources. Transactions are sequential and can be viewed in the order they were initiated.</p> <p>What did we do last in this quickstart? Created a Fabric resource! Let's see what the latest transaction has to say about it:</p> <pre><code>edactl transaction 36\n</code></pre> <pre><code>input-crs:\n    gvk: fabrics.eda.nokia.com/v1alpha1, kind=Fabric name: myfabric-1 action: CreateUpdate\nintents-run:\n  - fabrics.eda.nokia.com/v1alpha1, kind=Fabric, myfabric-1\n    output-crs:\n    - fabrics.eda.nokia.com/v1alpha1, kind=FabricState, myfabric-1\n    - fabrics.eda.nokia.com/v1alpha1, kind=ISL, isl-leaf1-spine1-1\n# clipped\n    pool-allocs:\n    - template: Index:asn-pool name: global key: myfabric-1-spine value: 101\n    script:\n    - execution-time: 18.688ms\n  - fabrics.eda.nokia.com/v1alpha1, kind=ISL, isl-leaf1-spine1-1\n# clipped\n  - routingpolicies.eda.nokia.com/v1alpha1, kind=PolicyDeployment, policy-ebgp-isl-import-policy-myfabric-1-node-spine1\n      output-crs:\n      - core.eda.nokia.com/v1, kind=NodeConfig, policy-cfg-ebgp-isl-import-policy-myfabric-1-spine1\n      script:\n      - execution-time: 26.559ms\nnodes-with-config-changes:\n  - name: leaf1\n  - name: leaf2\n  - name: spine1\ngeneral-errors:\ncommit-hash: 0b0e155356a3b451e05b5aafacb92188729fecf4\nexecution-summary: intents-run: 43, nodes-changed: 3, engine-time=135.150566ms, push-to-node=2.045243438s, publish-cr=27.772\u00b5s, git-save=543.984017ms\ntimestamp: 2024-12-15 17:24:41 +0000 UTC [2024-12-15T17:24:41Z] - 1h23m ago\nresult: OK\ndry-run: false\n</code></pre> <p>You will see a lot of details, some of them we clipped from the output to keep it short, but essentially the transaction logged the input resource (kind=Fabric name: myfabric-1) and the output products of this resource being created (output-crs). Each of these outputs constitute a Fabric resource.</p> <p>At the very end of the transaction output you will see the identified nodes that are affected by this change and the result of the transaction. Since the result is OK, we are rightfully see the resulting configs applied to the nodes in our virtual network.</p>"},{"location":"getting-started/units-of-automation/#creating-a-resource-in-ui","title":"Creating a resource in UI","text":"<p>You've seen how to create a resource using the k8s API, and were introduced to the concept of transactions. Now, let's see how we can change an existing resource, perform a dry-run and finally commit the changes.</p> <p>Usually quickstarts show some simple operations to keep the flow clean and simple, like adding a VLAN to a switch. We won't bother you with these basics, instead lets swap the overlay protocol for every node in our Fabric from eBGP to iBGP with a single operation.</p> <p>Here is what happened in these 60 seconds:</p> <ol> <li>We've found the <code>myfabric-1</code> Fabric resource created earlier with <code>kubectl</code> in the UI under the Fabrics section.</li> <li>We opened the resource and navigated its configuration schema all the way to the Overlay Protocol section.</li> <li>We changed the overlay protocol from eBGP to iBGP and provided the required iBGP bits such as ASN number, Router ID.</li> <li>We also provided the labels for the nodes that should be used as RR (route reflector) and RR clients; Our topology has been labeled with <code>role: spine</code> and <code>role: leaf</code> when we deployed it.</li> <li>Instead of applying the change right away, we added it to the transaction basket. We could've added more changes to it, but for now we were ok with a single change.</li> <li>Before applying the change we ran the Dry-Run, which started the process of unwrapping the abstracted high-level Fabric resource into the sub-resources and dependent resources.</li> <li>The dry-run provided us with the extensive diff view of the planned changes to the nodes and all sub-resources touched by our single protocol change.</li> <li>We've reviewed the diff and decided that it is good to commit the change.</li> <li>Once we committed the change, we ensured that the change was immediately applied to the nodes by looking at <code>leaf1</code> show output and seeing how iBGP appeared in the output of peer neighbors.</li> </ol> <p>Have a look at the Fabric dashboard</p> <p>Once the change is committed, BGP will take some time to converge. During this period you can see the resource's state in action by opening a Fabric dashboard and observing how the Fabric status transitions from \"Degraded\" to \"Healthy\".</p> <p>Transactions made by a user in the UI<sup>5</sup> are also visible in the Transactions UI<sup>4</sup>:</p> <p>Congratulations, your fabric is now using iBGP as its overlay protocol  From a tiny change in the Fabric' declarative abstraction through the transformation to sub-resources and eventually to the node-level configurations, that are reliably transacted and pushed to the constituent nodes. How cool is that?</p> <ol> <li> <p>Like the Fabric resource documented in the Apps section.\u00a0\u21a9</p> </li> <li> <p>Like the Virtual Network resource documented in the Apps section.\u00a0\u21a9</p> </li> <li> <p>You can find the <code>kubectl</code> CLI tool in the <code>tools</code> folder of your playground repository. You can copy it to the <code>/usr/local/bin</code> dir to make it globally available.\u00a0\u21a9</p> </li> <li> <p>Soon you will be able to see the transactions made via the k8s API as well, when the relevant permissions are granted.\u00a0\u21a9</p> </li> <li> <p>Transactions made via kubectl will be visible in the UI in a later release.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting-started/verification/","title":"Verifying an install","text":"<p>When using the <code>make try-eda</code> command you will hopefully have a running EDA instance in under 10 minutes without any manual intervention. We embedded necessary checks in the Makefile to ensure that the steps are executed in the correct order and that the system is in a healthy state.</p> <p>However, while testing the setup process on several different platforms, we couldn't cover all the possible cases. If you encounter installation issues, this section may help you pinpoint the issue.</p>"},{"location":"getting-started/verification/#eda-core","title":"EDA core","text":"<p>You should be able to use <code>kubectl -n eda-system get pods</code> to verify that EDA core components have started and in the Ready state:</p> <pre><code>kubectl -n eda-system get pods | awk 'NR==1 || /eda/'\n</code></pre> <pre><code>NAME                                  READY   STATUS    RESTARTS   AGE\ncx-eda--leaf1-sim-864b97d58d-g9zq2    2/2     Running   0          12h\ncx-eda--leaf2-sim-6698fc668f-4blcm    2/2     Running   0          12h\ncx-eda--spine1-sim-677f5499cf-fn2pg   2/2     Running   0          12h\neda-api-9985cb78-gphnk                1/1     Running   0          12h\neda-appstore-8d679c5b-fqmt6           1/1     Running   0          12h\neda-asvr-dc9877c8d-5j62k              1/1     Running   0          12h\neda-bsvr-6bf77b64c-9l2zx              1/1     Running   0          12h\neda-ce-84c6486cb7-f8jzc               1/1     Running   0          12h\neda-cx-5dc6cf9d96-dcrrf               1/1     Running   0          12h\neda-fe-54d8db877f-xk7l8               1/1     Running   0          12h\neda-fluentbit-hkwvd                   1/1     Running   0          12h\neda-fluentd-54cf4bd5d7-j98zg          1/1     Running   0          12h\neda-git-754df68df5-8kgx4              1/1     Running   0          12h\neda-git-replica-784dbdbfc8-5zdzz      1/1     Running   0          12h\neda-keycloak-5d569565b7-2gmc7         1/1     Running   0          12h\neda-metrics-server-799d54cb7-688nz    1/1     Running   0          12h\neda-npp-eda-leaf1                     1/1     Running   0          12h\neda-npp-eda-leaf2                     1/1     Running   0          12h\neda-npp-eda-spine1                    1/1     Running   0          12h\neda-postgres-cd89bfc57-q56cc          1/1     Running   0          12h\neda-sa-576c98865f-66vq9               1/1     Running   0          12h\neda-sc-84546648c5-djr49               1/1     Running   0          12h\neda-se-1                              1/1     Running   0          12h\neda-toolbox-84c95bd8c6-lqxh7          1/1     Running   0          12h\n</code></pre> <p>You can also check the <code>EngineConfig</code> to verify the ConfigEngine has started correctly, checking the <code>.status.run-status</code> field:</p> <pre><code>kubectl -n eda-system get engineconfig engine-config \\\n-o jsonpath='{.status.run-status}{\"\\n\"}'\n</code></pre> <pre><code>Started\n</code></pre> <p><code>Started</code> is good, anything else is bad!</p>"},{"location":"getting-started/verification/#node-connectivity","title":"Node connectivity","text":"<p>The example topology deployed as part of the quickstart resulted in creation of topology nodes, with each node represented by an SR Linux simulator. The topology nodes in EDA are represented by the <code>TopoNode</code> resource, and this resource has a status field to indicate its health.</p> <p>The easiest way to tell the current state of nodes is via the UI, or via <code>kubectl</code>:</p>  All nodes are healthy Not all nodes are healthy <pre><code>kubectl -n eda get toponodes #(1)!\n</code></pre> <ol> <li><code>TopoNode</code> resources are scoped in the <code>eda</code> namespace, hence the <code>-n eda</code> flag.</li> </ol> <pre><code>NAME     PLATFORM       VERSION   OS    ONBOARDED   MODE     NPP         NODE     AGE\nleaf1    7220 IXR-D3L   24.10.1   srl   true        normal   Connected   Synced   12h\nleaf2    7220 IXR-D3L   24.10.1   srl   true        normal   Connected   Synced   12h\nspine1   7220 IXR-D5    24.10.1   srl   true        normal   Connected   Synced   12h\n</code></pre> <p>In this example the <code>leaf1</code> and <code>spine1</code> nodes are not healthy, since the NPP components are not connected to the nodes and the nodes are not synced: <pre><code>kubectl get toponodes\n</code></pre></p> <pre><code>NAME     PLATFORM       VERSION   OS    ONBOARDED   MODE     NPP         NODE     AGE\nleaf1    7220 IXR-D3L   24.7.1    srl   true        normal                        23h\nleaf2    7220 IXR-D3L   24.7.1    srl   true        normal   Connected   Synced   23h\nspine1   7220 IXR-D5    24.7.1    srl   true        normal   Connected   Synced   23h\n</code></pre> <p>In particular, the <code>NPP</code> and <code>NODE</code> columns define the state of the ConfigEngine to NPP connection, and the NPP to node connection. A node must be <code>Synced</code> or it will reject transactions.</p> <p>It is useful to verify the underlying Pod resources for the network simulator nodes have been created - this can take a while if it is your first time starting a simulator of a given version. You should see all your sims and the associated NPP (Node Push Pull) pods running:</p>  All pods running Not all pods running <pre><code>kubectl -n eda-system get pod | awk 'NR==1 || /cx-eda|npp/'\n</code></pre> <pre><code>NAME                                  READY   STATUS    RESTARTS   AGE\ncx-eda--leaf1-sim-864b97d58d-g9zq2    2/2     Running   0          14h\ncx-eda--leaf2-sim-6698fc668f-4blcm    2/2     Running   0          14h\ncx-eda--spine1-sim-677f5499cf-fn2pg   2/2     Running   0          14h\neda-npp-eda-leaf1                     1/1     Running   0          14h\neda-npp-eda-leaf2                     1/1     Running   0          14h\neda-npp-eda-spine1                    1/1     Running   0          14h\n</code></pre> <pre><code>kubectl -n eda-system get pod | awk 'NR==1 || /cx-eda|npp/'\n</code></pre> <pre><code>NAME                                 READY   STATUS    RESTARTS      AGE\ncx-eda--leaf1-sim-864b97d58d-g9zq2    2/2     Running   0          14h\ncx-eda--leaf2-sim-6698fc668f-4blcm    2/2     Running   0          14h\ncx-eda--spine1-sim-677f5499cf-fn2pg   2/2     Running   0          14h\neda-npp-eda-leaf1                     1/1     Running   0          14h\n</code></pre> <p>Note the <code>cx-eda-*</code> Pods (one for each <code>TopoNode</code> in the topology), these pods are SR Linux container images. You should also note there are three NPP Pods (also one for each <code>TopoNode</code>) each designated to a corresponding <code>TopoNode</code>.</p>"},{"location":"getting-started/verification/#transactions","title":"Transactions","text":"<p>EDA's brain - Config Engine - works off a sequential transaction log, processing transactions as they come in. \"in\" here is doing some heavy lifting, as items for processing may come in via:</p> <ul> <li>the UI.</li> <li>the API.</li> <li>the Kubernetes API.</li> </ul> <p>For items coming in via the UI and API, a failed transaction does not impact future transactions. For Kubernetes this behavior is inverse - the ConfigEngine will always try to ingest the full set of changes available for processing, and so an object that can never transact can cause other items to fail. You can verify transactions in the system with:</p> <pre><code>kubectl -n eda-system get transactionresults\n</code></pre> <pre><code>NAME                    RESULT   AGE    DRYRUN   DESCRIPTION\ntransaction-000000001   OK       151m            startup - no core manifest\ntransaction-000000002   OK       129m            Installing core:{v1.0.0+24.8.1-rc semver} (from eda-catalog-builtin-apps)\n-- snip --\ntransaction-000000013   OK       10m\ntransaction-000000014   OK       10m\n-- snip --\ntransaction-000000069   Failed   2m\n</code></pre> <p>If you see any transactions with a result of <code>Failed</code>, these should be investigated - especially if they came in via the Kubernetes interface. Like in the example the last transaction has a <code>Failed</code> result.</p> <p>You can investigate the transaction further with:</p> <pre><code>kubectl -n eda-system get transactionresults transaction-000000069 -o yaml\n</code></pre> <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: TransactionResult\nmetadata:\n  creationTimestamp: \"2024-04-29T22:17:40Z\"\n  generation: 3\n  name: transaction-000000069\n  namespace: default\n  resourceVersion: \"600591\"\n  uid: fc0ce238-dfed-44a5-badd-7b3a56f14706\nspec:\n  execution-summary: 'input-crs: 2, intents-run: 12, nodes-changed: 0, engine-time=725.396191ms,\n    push-to-node=10m0.052663836s'\n  general-errors:\n  - 'pod is not running or does not have an IP address ''spine1'': NPP pod ''eda-npp-spine1''\n    did not spin up'\n  - 'pod is not running or does not have an IP address ''leaf1'': NPP pod ''eda-npp-leaf1''\n    did not spin up'\n# -- snip --\n</code></pre> <p>The transaction details will give you a hint as to what went wrong. In the example above NPP Pod for <code>leaf1</code> and <code>spine1</code> did not start, and so the transaction to push the configs failed.</p>"},{"location":"getting-started/verification/#ui-access","title":"UI access","text":"<p>As covered in the Configure your deployment section, the EDA service requires a user to provide the desired DNS name/IP and port for external access. These parameters become the part of the Engine Config resource that, as the name suggests, configures the central part of EDA - the Config Engine.</p> <p>The values you provided in the prefs.mk file or in the CLI can be found in the Engine Config resource:</p> <pre><code>kubectl -n eda-system get engineconfig engine-config \\\n-o jsonpath='{.spec.cluster.external}' | yq -p json #(1)!\n</code></pre> <ol> <li>The <code>yq</code> CLI tool is installed in the <code>./tools</code> directory of the playground repo.</li> </ol> <pre><code>domainName: vm.home.lab\nhttpPort: 9200\nhttpsPort: 9443\nipv4Address: 10.1.0.11\nipv6Address: fd7a:115c:a1e0::be01:ff2f\n</code></pre> <p>The configuration above means that the EDA UI client (a browser) should use <code>https://vm.home.lab:9443</code> to access the EDA UI. You can change the <code>engine-config</code> resource post-install and change the <code>domainName</code> and/or port numbers, the changes will be in effect immediately without requiring a redeploy of the EDA.</p> <p>Secure-by-design</p> <p>In the secure-by-design paradigm, EDA exposes APIs and UI for its users only over the secure transport. That makes HTTPS the only supported transport for UI access.</p> <p>EDA UI is exposed in the k8s cluster via the <code>eda-api</code> service</p>"},{"location":"getting-started/virtual-network/","title":"Virtual network","text":"<p>To make sure that you can get the full EDA experience without upfronting any hardware investment, EDA is packaged with a Digital Sandbox solution called CX. CX is in charge of creating and managing virtual topologies running in the cluster.</p> <p>Note</p> <p>If you completed the Try EDA procedure the virtual network is already created for you. This section provides details on how the virtual network is created, what it consists of, and how to connect to the virtual nodes.</p>"},{"location":"getting-started/virtual-network/#example-topology","title":"Example topology","text":"<p>An example 3-node Leaf/Spine topology is provided with this quickstart and is automatically deployed when you run the all-in-one <code>try-eda</code> installation command.</p> <p>As part of this command a separate make target is called to load the topology resources into the cluster which, in its turn, triggers CX controller to start spinning up the nodes and wiring links between them.</p> <pre><code>make topology-load #(1)!\n</code></pre> <ol> <li> <p>No need to run this target if you already completed the Try EDA step, it has happened already.</p> <p><code>topology-load</code> targets loads the example topology provided in the json file as a ConfigMap into the cluster. The CX controller watches for ConfigMap changes and creates the corresponding topology resources.</p> </li> </ol> <p>As a result you will get you the following topology running in your cluster:</p> <p>As you would expect, it takes some time to spin up the nodes and establish the connections, you can check the status of the deployed topology in the Verify section of the quickstart.</p>"},{"location":"getting-started/virtual-network/#connecting-to-the-nodes","title":"Connecting to the nodes","text":"<p>Your network engineering roots may ask to check out what is going on on an individual node, which requires you to start a shell in the Pod running the SR Linux simulator. This can be accomplished with these simple commands:</p> <pre><code>make leaf1-ssh #(1)!\n</code></pre> <ol> <li>Of course, changing <code>leaf1</code> to <code>leaf2</code> or <code>spine1</code> will log you in the other nodes.</li> </ol> <pre><code>Using configuration file(s): ['/etc/opt/srlinux/srlinux.rc']\nWelcome to the srlinux CLI.\nType 'help' (and press &lt;ENTER&gt;) if you need any help using this.\n--{ + running }--[  ]--\nA:leaf1#\n</code></pre>"},{"location":"getting-started/virtual-network/#initial-configuration","title":"Initial configuration","text":"<p>The SR Linux nodes (the leaf and spine switches) that make up the virtual network come up with a minimal node configuration - only the bits that are required by EDA to onboard the nodes. By connecting to the node and running <code>info</code> command you can see the initial configuration and verify that it has no configuration besides the basic management settings.</p> <p>With this barebones topology deployed we can start exploring EDA automation powers. Let's explore how EDA framework can be used to provision complex services with simple declarative abstractions.</p> <p> Automating fabric configuration</p>"},{"location":"getting-started/virtual-network/#tearing-down-the-topology","title":"Tearing down the topology","text":"<p>In case you break your topology nodes beyond repair, you can always start over by tearing down the topology:</p> <pre><code>make teardown-topology\n</code></pre> <p>This will remove the topology nodes resources, the accompanying simulators and NPP pods associated with them.</p>"},{"location":"software-install/","title":"Software Installation Guide","text":"<p>This document describes the installation procedure in a production environment; to install EDA in a lab, development or test environment, see Getting Started. It includes procedures for preparing the nodes that host the application, installing the application, upgrading and uninstalling.</p> <p>Note</p> <p>This document covers the current release and may also contain some content that will be released in later maintenance loads. See the EDA Release Notes for information about features supported in each load.</p> Precautionary and information messages <p>Danger</p> <p>Danger warns that the described activity or situation may result in serious personal injury or death. An electric shock hazard could exist. Before you begin work on this equipment, be aware of hazards involving electrical circuitry, be familiar with networking environments, and implement accident prevention procedures.</p> <p>Warning</p> <p>Warning indicates that the described activity or situation may, or will, cause equipment damage, serious performance problems, or loss of data.</p> <p>Caution</p> <p>Caution indicates that the described activity or situation may reduce your component or system performance.</p> <p>Note</p> <p>Note provides additional operational information.</p> <p>Tip</p> <p>Tip provides suggestions for use or best practices.</p>"},{"location":"software-install/#installation-process-overview","title":"Installation process overview","text":"<p>The installation consists of the following high-level tasks:</p>"},{"location":"software-install/#general-preparation","title":"General preparation","text":"<p>These tasks must be completed for both Internet based installations and Air-gapped installations.</p> <ol> <li> <p>Downloading the EDA Installation playground     This task describes how to access the EDA installation playground for use during the installation. It also covers how to configure the playground.</p> </li> <li> <p>Downloading the edaadm tools     This task describes how to download the EDAADM repository and the <code>edaadm</code> tool, used for several steps in the installation process.</p> </li> <li> <p>Download the Talos machine image     This task describes how to download the Talos base image from the official Talos image factory for your environment.</p> </li> </ol>"},{"location":"software-install/#air-gapped-setup","title":"Air-gapped setup","text":"<p>In case the installation will be Air-gapped, this section provides steps on how to set up the Assets VM and load it with the necessary assets for deploying EDA in an Air-gapped environment.</p> <ol> <li> <p>Preparing the Assets VM     This task describes how to create the Asset VM image on a system with Internet access, so it can be used to deploy the Assets VM in the Air-gapped environment.</p> </li> <li> <p>Downloading the Assets     This task describes how to download all the necessary assets using a system with Internet access, so they can be used to deploy EDA in the Air-gapped environment.</p> </li> <li> <p>Preparing the Air-gapped environment     Describes how to prepare the Air-gapped environment by copying the files downloaded on the Internet facing system to the Air-gapped environment and prepare it so it can be used to install the Assets VM and EDA.</p> </li> <li> <p>Deploying the Assets VM     Deploys the Assets VM in the Air-gapped environment, bootstraps it and uploads all the Assets to the it.</p> </li> </ol>"},{"location":"software-install/#deploying-eda","title":"Deploying EDA","text":"<ol> <li> <p>Preparing the EDAADM configuration file     This task describes the details of the EDAADM configuration file and how to set it up.</p> </li> <li> <p>Generating the Talos machine configurations     Using the <code>edaadm</code> tool and the configuration file, this task generates specific Talos machine configuration files for each Talos VM.</p> </li> <li> <p>Deploying the Talos virtual machines     This task describes how to use the Talos base image and machine configuration files to deploy the Talos VMs in your KVM or VMware vSphere environment.</p> </li> <li> <p>Bootstrap the Talos Kubernetes cluster     This task bootstraps the Talos Kubernetes environment using the VMs you have created.</p> </li> <li> <p>Installing the EDA application     Using the EDA Installation playground, this step installs EDA on the Kubernetes environment in the EDA nodes.</p> </li> </ol>"},{"location":"software-install/#components","title":"Components","text":"<p>Several key concepts are used throughout the documentation; following is an overview of these concepts and components:</p> Talos Linux and Kubernetes EDA uses Talos Linux and Kubernetes to host its services. Talos Linux is a minimalistic, locked-down, read-only and secured Linux environment purposely built to run Kubernetes. This ensures a more secure environment with significantly lower security footprint than regular Linux and Kubernetes environments. Playground git repository The Playground git repository is publicly available and is used to deploy EDA itself. <code>edaadm</code> <p>A tool that will be used for several steps in the process:</p> <ul> <li>Get the location to download the base Talos image for KVM and VMware environments.</li> <li>Generate Talos machine configuration files for the deployment of both the Assets VM and the EDA Kubernetes cluster VMs.</li> <li>Initiate Talos Kubernetes clusters.</li> </ul> <code>edaadm</code> git repository <p>A publicly available git repository that contains details and definitions for:</p> <ul> <li>Assets bundles for air-gapped installations: EDA Assets are defined in different bundles, based on their purpose. The repository provides the bundles and the means to download the content of the bundles from the internet and then upload them to the deployed Assets VM.</li> <li>A KPT package to initiate the Assets VM.</li> </ul> Air-gapped Assets VM <p>Used in an air-gapped environment, the Assets VM is a Virtual Machine deployed on a KVM or VMware environment. It is a single VM K8s cluster that will run:</p> <ul> <li>A container registry to host all the container images used by EDA.</li> <li>A git server to host the App Store Catalog.</li> <li>A web server to host certain artifacts used by EDA.</li> </ul> Air-gapped Bundles Used in air-gapped installations, a bundle is a definition of a group of assets that are related. For instance a bundle for the core components of EDA for a specific version, or a bundle of the standard Apps for a specific version. Bundles are downloaded using the <code>edaadm</code> tool from the internet, and then uploaded using <code>edaadm</code> to the Assets VM. The product comes with a set of standard bundles and custom bundles can be created based on their examples. Air-gapped EDA Shipyard A name used to describe the combination of the container registry, git server and web server running on the Assets VM."},{"location":"software-install/#version-information","title":"Version information","text":"<p>The Talos Kubernetes version Nokia EDA is deployed on is set by the <code>edaadm</code> CLI tool. Edaadm downloads the respective Talos images and generates the machine configurations and bootstraps the Kubernetes cluster.</p> <p>The following table lists the default Talos and the corresponding Kubernetes versions for each <code>edaadm</code> version:</p> edaadm version Talos version Kubernetes version 3.0.0 1.11.5 1.34.1 2.0.0 1.9.2 1.32.1 1.0.0 1.8.3 1.31.2"},{"location":"software-install/#deployment-models","title":"Deployment models","text":"<p>Nokia EDA is deployed as an application on a compatible Kubernetes cluster comprised of one, three, or more nodes (validated for up to six nodes). The nodes (VMs) run a Kubernetes cluster with the following composition:</p> <ul> <li>One or three Kubernetes master nodes that also function as worker nodes: one, in case a single-VM deployment is used; otherwise three Kubernetes master nodes.</li> <li>Any remaining nodes (in a four or more node deployment) function as worker nodes.</li> <li>One, two or more nodes must also be designated as storage nodes. For redundancy, two is the minimum in a three or more node deployment. These nodes still function as worker (and potentially master) nodes as well. Rook-Ceph is used to create a storage cluster across the nodes indicated as storage nodes.</li> <li>(Optional) An Assets VM which will hold all the resources and files needed in case of an air-gapped environment.</li> </ul>"},{"location":"software-install/#openshift","title":"OpenShift","text":"<p>Nokia EDA can also be deployed on an existing OpenShift v4.16+ cluster<sup>1</sup> with the Security Context Constraint (SCC) resource applied prior to installing EDA packages. The SCC manifest is provided in nokia-eda/edaadm/openshift/eda-scc.yaml file.</p> <p>Adding the SCC resource is the only additional requirement that needs to be satisfied, the rest of the installation procedure remains the same.</p>"},{"location":"software-install/#networking-for-eda-nodes","title":"Networking for EDA nodes","text":"<p>This guide describes the deployment of EDA on a Kubernetes cluster with a single network, where access from both users and orchestrators to the UI and API, and access from EDA to the fabric (for example, SR Linux devices) go over the same interface.</p> <p>It is possible to use two separate networks for the EDA nodes:</p> <ul> <li> <p>OAM network     This interface is used to access the UI and the API of Nokia EDA. It is also through this network that the deployment tool reaches the nodes.</p> </li> <li> <p>Fabric management network     This interface is used to communicate with the management interfaces of the fabric (for example, SR Linux devices) and is where Nokia EDA exposes its DHCP and ZTP services.</p> </li> </ul>"},{"location":"software-install/#eda-nodes","title":"EDA nodes","text":"<p>The Nokia EDA nodes are the VMware vSphere-based or KVM-based virtual machines (VMs) that host the Kubernetes environment on which the Nokia EDA application and Digital Sandbox are run.</p> <p>These nodes run a hardened Talos Kubernetes environment. Talos is a secure, up-to-date and hardened platform for running Kubernetes.</p> <p>EDA supports the following deployment models:</p> <ul> <li>an environment with one node, which hosts only the Nokia EDA application for small scale deployments</li> <li>an environment with three or more nodes, which hosts only the Nokia EDA application</li> </ul>"},{"location":"software-install/#requirements-for-deployment","title":"Requirements for deployment","text":"<p>This section describes the platform requirements, node requirements, and virtual IP requirements for deploying EDA.</p>"},{"location":"software-install/#installation-platform-requirements","title":"Installation platform requirements","text":"<p>To execute the installation process, you need access to a Linux environment<sup>2</sup> with the following components installed:</p> <p>Component</p> <p>Requirement</p> <p>Linux environment</p> <p>Any Linux distribution. The procedures provided in this document are validated on Ubuntu.</p> <p>Container runtime</p> <p>Docker must be running and you should be able to run containers</p> <p>Tools</p> <ul> <li><code>make</code> - Used to execute several installation steps.</li> <li><code>git</code> - Used to check out git repositories.</li> <li><code>curl</code> - Used to download files.</li> <li><code>jq</code> and <code>yq</code> - Used to parse JSON and YAML files.</li> <li><code>sed</code> - Used to parse and replace content.</li> <li><code>tar</code> and <code>zip</code> - Used to create and unpack bundles and assets for the Air-gapped installation process.</li> <li><code>edaadm</code> - Used to generate configuration for Talos and other useful commands to initiate the Talos environments. It can be downloaded from the <code>edaadm</code> repository releases page.</li> <li><code>htpasswd</code> - (Optional) Used in case a custom username and password is required for the Assets VM web server.</li> <li><code>base64</code> - (Optional) Used in case a custom username and password is required for the Assets VM web server or git server.</li> <li><code>ovftool</code> - (Optional) Used to deploy the VMs in a VMware vSphere environment. Can be downloaded from the Broadcom Developer Portal</li> </ul> <p>The following tools are also helpful. If they are not present, the installation tool downloads them later:</p> <ul> <li><code>kubectl</code></li> <li><code>helm</code></li> <li><code>k9s</code></li> <li><code>kpt</code></li> </ul> <p>Internet access</p> <p>Required for Internet-based installations. For Air-gapped installations, at least one system needs internet access.</p> <p>Either directly or through a proxy.</p> <p>Note</p> <p>In case of an Air-gapped installation, the guide will refer to two tools-systems, one with public internet access and one in the air-gapped environment. These can be the same system that is moved from the public side to the air-gapped side after downloading all the resources; or it can be two different systems.</p>"},{"location":"software-install/#nokia-eda-node-requirements","title":"Nokia EDA node requirements","text":"<p>The Nokia EDA nodes are deployed as virtual machine servers. Node requirements summarizes the requirements of Nokia EDA nodes in KVM and VMware hypervisor.</p> <p>Component</p> <p>Requirement</p> <p>CPU</p> <p>32 vCPU on a modern x86-64 CPU that supports virtualization</p> <p>Memory</p> <p>64 GB</p> <p>Storage</p> <ul> <li>Operating system: 100GB of available SSD-based storage</li> <li>Storage nodes: 300GB of available SSD-based storage on a separate virtual disk</li> </ul> <p>Networking</p> <ul> <li>at least one 10 Gbps NIC</li> <li>the configured DNS servers must be reachable, functional, and able to resolve the hostnames used for the Nokia EDA nodes</li> <li>for internet-based installations: Internet access directly or through a proxy</li> <li>system time synced using NTP</li> </ul> <p>Virtualization platform</p> <p>You can run the Nokia EDA nodes as virtual machines using the following virtualization platforms:</p> <ul> <li>operating system: VMware vSphere 7.0 or 8.0 or RHEL/Rocky</li> <li>hypervisor: ESXi 7.0 or 8.0 or KVM</li> <li>resource reservation for CPU, memory, and disks must be set to 100% for the Nokia EDA node virtual machines</li> </ul>"},{"location":"software-install/#nokia-eda-assets-vm-requirements","title":"Nokia EDA Assets VM requirements","text":"<p>Note</p> <p>This only applies if you plan to use the Air-gapped installation process.</p> <p>The Assets VM runs as a single VM inside the air-gapped environment. This VM holds all of the assets and can be used across multiple deployments and EDA versions, containing the assets for multiple versions. This VM has the following requirements:</p> <p>Component</p> <p>Requirement</p> <p>CPU</p> <p>4 vCPU on a modern x86-64 CPU that supports virtualization</p> <p>Memory</p> <p>16 GB</p> <p>Storage</p> <ul> <li>Operating system: 300GB</li> </ul> <p>Networking</p> <ul> <li>1 Gbps NIC</li> <li>1 IPv4 IP and optionally 1 IPv6 IP</li> <li>Preferably in the same OAM network as the EDA Kubernetes VMs, but minimally accessible by the EDA Kubernetes VMs via the OAM network</li> <li>system time synced using NTP</li> </ul> <p>Virtualization platform</p> <p>You can run the EDA Assets VM as a virtual machine using the following virtualization platforms:</p> <ul> <li>operating system: VMware vSphere 7.0 or 8.0 or RHEL/Rocky</li> <li>hypervisor: ESXi 7.0 or 8.0 or KVM</li> </ul>"},{"location":"software-install/#virtual-ip-requirements","title":"Virtual IP requirements","text":"<p>The deployment of EDA requires two virtual IP addresses in the management network:</p> <ul> <li>Kubernetes VIP: the virtual IP address used by all the control plane nodes in the Kubernetes cluster.</li> <li>Nokia EDA API/UI VIP: the virtual IP address used by the Nokia EDA API and UI.</li> </ul> <ol> <li> <p>Alpha support in the current release.\u00a0\u21a9</p> </li> <li> <p>This system might also be referred to as the \"tools-system\" further in this documentation.\u00a0\u21a9</p> </li> </ol>"},{"location":"software-install/exposing-ui-api/","title":"Exposing the EDA UI/API","text":"<p>In a regular cluster you typically have an Ingress or Gateway API controller that handles the external traffic and routes them to the services running inside the cluster. For instance, to let external users reach the EDA UI/API service. These controllers are not part of EDA installation, and are typically managed by the cluster administrator.</p> <p>Still, in this chapter we will talk about how to configure Ingress or Gateway resources to expose the EDA UI/API service particularly.</p> <p>EDA UI and API are exposed inside a cluster via the <code>eda-api</code> service of type \"LoadBalancer\" and its <code>apiserver</code> (port 80) and <code>apiserverhttps</code> (port 443) ports:</p> <pre><code>kubectl -n eda-system get service eda-api -o yaml | \\\nyq e '.spec.ports[0,1]' - #(1)!\n</code></pre> <ol> <li>Using <code>yq</code> to extract the service port configuration.</li> </ol> <pre><code>name: apiserver\nnodePort: 32609\nport: 80\nprotocol: TCP\ntargetPort: 9200\nname: apiserverhttps\nnodePort: 30302\nport: 443\nprotocol: TCP\ntargetPort: 9443\n</code></pre> <p>Despite having port 80 in the service configuration, EDA UI/API is only served over HTTPS inside the cluster, therefore the external traffic should be routed to the <code>apiserverhttps</code> port. Generally speaking, there are two modes of exposing the EDA UI/API service using Ingress or Gateway API:</p> <ol> <li>Terminating TLS on Ingress/Gateway     External users have their TLS session terminated on the Ingress/Gateway and then the another HTTPS connection is established from the Ingress/Gatway to the <code>eda-api</code> deployment via the same-named service and its <code>apiserverhttps</code> port.</li> <li>Pass-through TLS     External users have their TLS session transparently passed through Ingress/Gateway and terminated on the <code>eda-api</code> deployment that has internal TLS certificate configured.</li> </ol> <p>Terminating TLS on Ingress/Gateway has an undeniable benefit of allowing users to use their own TLS certificates on ingress. Whereas the pass-through mode uses the internal TLS certificate configured on the <code>eda-api</code> deployment and raise a warning in the browser since the certificate is not trusted.</p> <p>In this section we will show how both modes can be configured using Ingress and Gateway API resources.</p>"},{"location":"software-install/exposing-ui-api/#cert-manager","title":"Cert Manager","text":"<p>By default, Ingress controllers come with a self-generated TLS certificate to allow TLS termination in test and development environments. For production installations users strive to have an Ingress service with a trusted certificate configured using the domain name designated for EDA UI/API access.</p> <p>Creation of a TLS certificate is easy when using cert-manager - a Kubernetes-native way to automate the management and issuance of TLS certificates from various issuing sources. EDA itself uses cert-manager to issue the internal TLS certificates for various components, thus users can also leverage it and create the Issuer that will handle the certificate creation.</p> <p>Creation of an Issuer is out of the scope of this guide, and is well explained in the cert-manager documentation.</p>"},{"location":"software-install/exposing-ui-api/#ingress-nginx","title":"Ingress Nginx","text":"<p>Ingress Nginx is a popular community-managed Ingress Controller based on NGINX.</p>"},{"location":"software-install/exposing-ui-api/#terminating-tls-on-ingress","title":"Terminating TLS on Ingress","text":"<p>To configure Ingress Nginx to terminate the TLS on the Ingress, you can create an Ingress resource with the following configuration.</p> <p>The code block annotations explain the important fields of the resource.</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    nginx.ingress.kubernetes.io/backend-protocol: HTTPS #(1)!\n    cert-manager.io/issuer: letsencrypt-issuer #(2)!\n    nginx.ingress.kubernetes.io/add-base-url: \"false\"\n    nginx.ingress.kubernetes.io/affinity: cookie\n    nginx.ingress.kubernetes.io/proxy-buffer-size: 128k\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"600\"\n    nginx.ingress.kubernetes.io/session-cookie-name: route\n  name: ingress\n  namespace: eda-system #(3)!\nspec:\n  ingressClassName: nginx\n  rules: #(4)!\n    - host: eda.rocks\n      http:\n        paths:\n          - backend:\n              service:\n                name: eda-api\n                port:\n                  number: 443\n            path: /\n            pathType: Prefix\n  tls: #(5)!\n    - hosts:\n        - eda.rocks\n      secretName: eda-rocks-cert\n</code></pre> <ol> <li>EDA UI/API is only served over HTTPS inside the cluster, therefore the external traffic should be routed to TLS secured <code>apiserverhttps</code> port. For this reason we need to set HTTPS as a backend protocol.</li> <li>For cert-manager to issue the certificate, we need to configure the <code>cert-manager.io/issuer</code> annotation with the name of the <code>Issuer</code> resource that has to be present in the same namespace as the Ingress resource.</li> <li>If eda-api service is deployed in the <code>eda-system</code> namespace, we need to create the Ingress resource in the same namespace.</li> <li>The Ingress's <code>rules</code> section defines the access rules and the routing of the incoming requests. Here we say that the requests destined to the <code>eda.rocks</code> domain should be routed to the <code>eda-api</code> service and its 443 port.</li> <li>The <code>tls</code> section defines the TLS configuration for the Ingress. Here we say that the Ingress should use the <code>eda-rocks-cert</code> secret to terminate the TLS and the SAN field in the cert should contain <code>eda.rocks</code> domain.</li> </ol> <p>With an Ingress resource like this created, users would be able to access the EDA UI/API using the <code>eda.rocks</code> domain.</p>"},{"location":"software-install/exposing-ui-api/#gateway-api","title":"Gateway API","text":"<p>If you're riding the Gateway API wave, you can create a <code>Gateway</code> resource to define your cluster gateway. As with the Ingress, the choice is yours if you want to terminate the TLS on the Gateway or not.</p> <p>As a demonstration, we will create the Gateway resource with the TLS listener so that we will pass the TLS traffic to the EDA UI service, without terminating it on the Gateway.</p> <p>Here is how you can create the <code>Gateway</code> resource:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: gateway.networking.k8s.io/v1\nkind: Gateway\nmetadata:\n  name: eda-gw-https\n  namespace: eda-system\nspec:\n  gatewayClassName: cilium\n  listeners:\n    - allowedRoutes:\n        namespaces:\n          from: Same\n      name: tls-gw\n      port: 8080\n      protocol: TLS\n      tls:\n        mode: Passthrough\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;'EOF'\napiVersion: gateway.networking.k8s.io/v1\nkind: Gateway\nmetadata:\n  name: eda-gw-https\n  namespace: eda-system\nspec:\n  gatewayClassName: cilium\n  listeners:\n    - allowedRoutes:\n        namespaces:\n          from: Same\n      name: tls-gw\n      port: 8080\n      protocol: TLS\n      tls:\n        mode: Passthrough\n\nEOF\n</code></pre> <p>Now, let's create the <code>TLSRoute</code> resource that will bind our <code>Gateway</code> to the <code>eda-api</code> resource to provide the connectivity to the EDA UI:</p> YAML Resource<code>kubectl apply</code> command <pre><code>apiVersion: gateway.networking.k8s.io/v1alpha2\nkind: TLSRoute\nmetadata:\n  name: eda-ui\n  namespace: eda-system\nspec:\n  parentRefs:\n    - name: eda-gw-https\n      namespace: eda-system\n  rules:\n    - backendRefs:\n        - kind: Service\n          name: eda-api\n          port: 443\n</code></pre> <pre><code>kubectl apply -f - &lt;&lt;'EOF'\napiVersion: gateway.networking.k8s.io/v1alpha2\nkind: TLSRoute\nmetadata:\n  name: eda-ui\n  namespace: eda-system\nspec:\n  parentRefs:\n    - name: eda-gw-https\n      namespace: eda-system\n  rules:\n    - backendRefs:\n        - kind: Service\n          name: eda-api\n          port: 443\n\nEOF\n</code></pre> <p>Now you should be able to access the EDA UI by navigating to the Gateway's URL.</p>"},{"location":"software-install/preparing-for-installation/","title":"Preparing for installation","text":""},{"location":"software-install/preparing-for-installation/#download-the-eda-installation-playground","title":"Download the EDA Installation playground","text":"<p>Ensure that your Linux installation<sup>1</sup> environment meets the requirements described in Installation platform requirements.</p> <p>Clone the playground repository to your tools-system.</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; cd playground \n</code></pre>"},{"location":"software-install/preparing-for-installation/#installing-additional-tools","title":"Installing additional tools","text":"<p>Download additional tools that can be used during the installation.</p> <pre><code>make download-tools\n</code></pre> <p>As a result of this command, the <code>kind</code>, <code>kubectl</code>, <code>kpt</code>, and <code>yq</code> utilities will be installed in the <code>./tools</code> directory.</p>"},{"location":"software-install/preparing-for-installation/#obtaining-the-eda-packages","title":"Obtaining the EDA packages","text":"<p>EDA is packaged using the Kubernetes Package Tool (kpt). EDA uses this package manager tool to install core EDA components. The installer downloads two kpt packages by downloading their relevant git repositories.</p> <p>To obtain the EDA package, enter the following command:</p> <pre><code>make download-pkgs\n</code></pre> <p>This command downloads the following git repositories to their respective directories:</p> <ul> <li>EDA kpt package in the <code>eda-kpt</code> directory</li> <li>EDA built-in catalog in the <code>catalog</code> directory</li> </ul>"},{"location":"software-install/preparing-for-installation/#download-edaadm-tools","title":"Download edaadm tools","text":"<p>Ensure that your Linux installation environment meets the requirements described in Installation platform requirements.</p> <p>Clone the EDAADM repository:</p> <pre><code>git clone https://github.com/nokia-eda/edaadm &amp;&amp; cd edaadm\n</code></pre> <p>The CLI tool that orchestrates the configuration and installation of the EDA platform in a production environment is called <code>edaadm</code>. To download <code>edaadm</code> run the following command from the root of the <code>edaadm</code> repository:</p> <pre><code>make -C bundles/ download-tools\n</code></pre> <p>This step downloads<sup>2</sup> the <code>edaadm</code> CLI tool for your architecture in the <code>./bundles/tools</code> directory. You can copy the <code>edaadm</code> binary from the <code>./bundles/tools</code> directory to a location in your <code>$PATH</code> to make it available in your shell for future use, for example:</p> copying edaadm to /usr/local/bin<pre><code>sudo cp bundles/tools/edaadm* /usr/local/bin/edaadm\n</code></pre>"},{"location":"software-install/preparing-for-installation/#download-the-talos-machine-image","title":"Download the Talos machine image","text":"<p>The <code>edaadm</code> tool provides you with the URL to download the latest Talos machine image for use with VMware or KVM.</p> <p>To deploy the Talos Kubernetes environment, download the Talos Machine image based on the environment in which you want to deploy the VMs.</p>"},{"location":"software-install/preparing-for-installation/#downloading-the-kvm-image","title":"Downloading the KVM image","text":"<p>Use the <code>edaadm</code> tool to display the URL from where you can download the latest image for use with KVM for the supported Talos version.</p> <pre><code>edaadm images --mach-type nocloud\n</code></pre> <pre><code>Schematic ID is :376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba\nAsset URLs are:\nhttps://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/nocloud-amd64.iso\nhttps://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/nocloud-amd64.raw.xz\n</code></pre> <p>Download the <code>nocloud-amd64.iso</code> image from the ISO URL, filepath.iso.</p> <p>You can download using your browser or you can use the curl command.</p>"},{"location":"software-install/preparing-for-installation/#downloading-the-vmware-ova-image","title":"Downloading the VMware OVA image","text":"<p>Use the <code>edaadm</code> tool to display the URL from where you can download latest image for use with VMware vSphere for the supported Talos version.</p> <pre><code>edaadm images --mach-type vmware\n</code></pre> <pre><code>Schematic ID is :903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40\nAsset URLs are:\nhttps://factory.talos.dev/image/903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40/v1.9.2/vmware-amd64.iso\nhttps://factory.talos.dev/image/903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40/v1.9.2/vmware-amd64.ova\n</code></pre> <p>Download the <code>vmware-amd64.ova</code> image from the OVA URL, filepath.ova.</p> <p>You can download using your browser or you can use the curl or wget commands. You can also use the URL directly with the ovftool command to deploy the OVA to your VMware vSphere environment.</p> <ol> <li> <p>This system might also be referred to as the \"tools-system\" further in this documentation.\u00a0\u21a9</p> </li> <li> <p>The <code>edaadm</code> binary for different platforms can be manually downloaded from https://github.com/nokia-eda/edaadm/releases/.\u00a0\u21a9</p> </li> </ol>"},{"location":"software-install/air-gapped/","title":"Air-gapped setup","text":"<p>In case the installation will be Air-gapped<sup>1</sup>, this section provides steps on how to set up the Assets VM and load it with the necessary assets for deploying EDA in an Air-gapped environment.</p>"},{"location":"software-install/air-gapped/#conceptual-overview","title":"Conceptual Overview","text":"<p>In an Air-Gapped environment, an Assets VM is deployed that will provide the services that will serve the container images, git repositories and artifacts used during installation of the EDA Talos Kubernetes cluster and EDA itself.</p> <p>The goal of the Air-Gapped solution design is to allow flexibility in the deployment and content of the Assets VM in the Air-Gapped environment. By providing a standalone Assets VM without any assets automatically included, there is freedom of choice of what assets are uploaded to the Assets VM.</p> <p>It allows for a single Assets VM to be used for multiple deployments and versions of EDA, as the assets for multiple versions of EDA can be uploaded to the same Assets VM.</p> <p>Similarly, by splitting up the assets in bundles, it is possible to only upload specific content to the Assets VM. The bundle concept also allows for the creation of custom bundles, for instance for 3<sup>rd</sup> party Apps, so they can also be hosted on the Assets VM.</p>"},{"location":"software-install/air-gapped/#environments","title":"Environments","text":"<p>Two environments will be discussed and used in an air-gapped installation:</p> Public Environment This environment has Internet access. You use a system with Internet access to create the Assets VM image and to download all the necessary assets and tools. Air-gapped Environment This environment does not have Internet access. It is the environment in which EDA is deployed. <p>In each environment, you must have a system from which you can execute the steps. You can use a system to first connect to the internet, execute the steps for the public network and then move the same system to the Air-gapped environment to continue. Or, you can have two systems, and you would copy the data from the public system to the Air-Gapped system. More details on the requirements for these systems are included later in this document.</p> <p>For each section, there will be a note in which environment the section applies.</p> <ol> <li> <p>An Air-gapped environment is an environment that does not have network connectivity to the Internet.\u00a0\u21a9</p> </li> </ol>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/","title":"Deploying the Assets VM","text":"<p>Caution</p> <p>These steps are meant to be executed in the air-gapped environment.</p> <p>The procedure to deploying the Assets VM is similar to deploying the EDA Talos Kubernetes cluster nodes and uses <code>edaadm</code> CLI to manage the deployment process.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#preparing-the-assets-vm-edaadm-configuration-file","title":"Preparing the Assets VM EDAADM Configuration File","text":"<p>The EDAADM configuration file declaratively defines the machine/VM configuration and the Kubernetes cluster parameters and is an abstraction on top of the Talos machine config. You will find the edaadm configuration for the Assets VM very similar to the config file used for EDA Kubernetes nodes with a few minor differences:</p> <ul> <li>It is a config file for a single machine.</li> <li>The <code>clusterName</code> must be unique and different from the EDA Kubernetes cluster.</li> <li> <p>The following additions fields must be present in the Assets VM edaadm config:</p> <pre><code>enableImageCache: true\nlocalPathProvisioner: \"/var/local-path-provisioner\"\n</code></pre> </li> </ul> <p>Notes</p> <ol> <li>Consult with the full list of edaadm configuration file options to customize your Assets VM configuration further: EDAADM Configuration file fields.</li> <li>The Assets VM only needs one network interface, preferably on the OAM network of the EDA Kubernetes cluster. It must be reachable from the OAM network of the EDA Kubernetes cluster.</li> <li>The <code>edaadm</code> tool still expects the definition of a storage disk in the machine definition, but this can be a reference to a non-existing disk.</li> </ol> <p>Consider an example edaadm configuration for an Assets VM that you can use as a reference when creating your own configuration file:</p> Example edaadm configuration for the Assets VM - <code>eda-assets-deployment.yaml</code><pre><code>version: 25.12.1 #(1)!\nclusterName: eda-airgap-assets #(2)!\nmachines:\n    - name: eda-assets\n      endpoint: 192.0.2.228\n      enableImageCache: true\n      localPathProvisioner: \"/var/local-path-provisioner\"\n      interfaces:\n        - name: eth0\n          dhcp: false\n          interface: eth0\n          addresses:\n            - 192.0.2.228/23\n          routes:\n            - network: 0.0.0.0/0\n              gateway: 192.0.2.1\n          mtu: 9000 #(4)!\n      disks:\n        os: /dev/vda\n        storage: /dev/vdb #(3)!\nk8s:\n    stack: ipv4\n    primaryNode: eda-assets\n    endpointUrl: https://192.0.2.228:6443\n    allowSchedulingOnControlPlanes: true\n    control-plane:\n        - eda-assets\n    time:\n        disabled: false\n        servers:\n            - 192.0.2.253\n            - 192.0.2.254\n    nameservers:\n        servers:\n            - 192.0.2.254\n            - 192.0.2.253\n</code></pre> <ol> <li>EDA version string. Not relevant for the Assets VM, but required by edaadm.</li> <li>The kubernetes cluster name for the Assets VM, must be unique and not the same as the ones specified for the EDA Kubernetes cluster when deploying EDA.</li> <li>The storage disk definition is required by edaadm, but the disk does not need to exist on the Assets VM. Can be set to any value.</li> <li>Pay attention to the set MTU value as the linux bridges, interfaces, and networks between the Assets VM and the EDA Kubernetes cluster nodes must allow for the same MTU size.</li> </ol> <p>Considering you are in the <code>edaadm</code> repository root, save the configuration file as <code>eda-assets-deployment.yaml</code>.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#generating-the-talos-machine-configuration-files","title":"Generating the Talos Machine Configuration Files","text":"<p>After creating the Assets VM EDAADM configuration file, the next step is to generate all the configuration files that are necessary to deploy the Kubernetes environment for the Assets VM.</p> <p>Use the <code>edaadm</code> tool to generate the Talos configuration out of the EDAADM configuration file:</p> <pre><code>edaadm generate -c eda-assets-deployment.yaml\n</code></pre> <p>The output should look similar to the following (a portion has been removed):</p> <pre><code>ConfigFile is eda-assets-deployment.yaml\n...\n[1/6] Validating Machines\n[1/6] Validated Machines\n[2/6] Validating Primary Node\n[2/6] Validated Primary Node\n[3/6] Validating Endpoint URL\n[3/6] Validated Endpoint URL\n[4/6] Validating Stack\n[4/6] Validated Stack\n[5/6] Validating Virtual IP\n[5/6] Validated Virtual IP\n[6/6] Validating Storage\n[6/6] Validated Storage\n[  OK  ] Spec is validated\n[ INFO ] Existing secrets file found - loading:eda-airgap-assets/secrets.yaml\n[ INFO ] Loaded secrets bundle eda-airgap-assets/secrets.yaml\ngenerating PKI and tokens\nCreated eda-airgap-assets/eda-assets.yaml\nCreated eda-airgap-assets/talosconfig.yaml\nCreated eda-airgap-assets/rook-ceph-operator-values.yaml\nCreated eda-airgap-assets/rook-ceph-cluster-values.yaml\n</code></pre> <p>The generated Talos configuration files will be available in the <code>eda-airgap-assets</code> folder which is named after the <code>clusterName</code> specified in the EDAADM configuration file. The machine config file for the Assets VM is named <code>eda-assets.yaml</code> after the <code>name</code> field specified in the <code>machines</code> section of the EDAADM configuration file.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#deploy-the-assets-vm","title":"Deploy the Assets VM","text":"<p>The Assets VM can be deployed on a KVM or VMware vSphere environment. Follow the steps below depending on your hypervisor.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#creating-the-assets-vm-on-kvm","title":"Creating the Assets VM on KVM","text":"<p>Caution</p> <p>This procedure is executed on the KVM Hypervisor which will host the Assets VM.</p> <ol> <li> <p>Ensure that the <code>virt-install</code> and <code>genisoimage</code> tools are installed on the KVM hypervisor.</p> <p>If you need to install the tools, use the following command:</p> <pre><code>sudo yum install virt-install genisoimage\n</code></pre> <p>or</p> <pre><code>sudo apt --no-install-recommends install virtinst genisoimage\n</code></pre> </li> <li> <p>Verify that the Assets VM ISO image is available.</p> <p>The Assets VM ISO image was generated in the Creating the KVM Assets VM Image and should be available in the Air-gapped environment when you copied the assets from the public environment.</p> executing the <code>ls</code> command from the edaadm repository root<pre><code>ls -lh ./bundles/eda-cargo/talos-asset-vm-boot-imgs/asset-vm-nocloud-amd64.iso\n</code></pre> <p> <pre><code>-rw-r--r-- 1 root root 684M Nov 12 18:10 eda-cargo/talos-asset-vm-boot-imgs/asset-vm-nocloud-amd64.iso\n</code></pre> </p> </li> <li> <p>Prepare Assets VM cloud-init files.</p> <p>The next step is to create the cloud-init ISO file with the machine configuration file and the necessary metadata.</p> <p>Standing in the root of the edaadm repository, copy the machine configuration file generated for the Assets VM to a file called <code>user-data</code>. If you have been using the example edaadm configuration file from above, the command would be:</p> <pre><code>cp eda-airgap-assets/eda-assets.yaml user-data\n</code></pre> <p>Create a file called <code>meta-data</code> with the instance-id and local-hostname values:</p> <pre><code>cat &lt;&lt;'EOF' &gt; meta-data\ninstance-id: eda-assets \nlocal-hostname: eda-assets\nEOF\n</code></pre> <p>And lastly, create a file called <code>network-config</code> for the node with the following content:</p> <pre><code>cat &lt;&lt;'EOF' &gt; network-config\nversion: 2\nEOF\n</code></pre> <p>Create an ISO file containing the newly created files. For ease of use, name the ISO file with the name of the node for which you are creating the ISO.</p> <pre><code>mkisofs -o eda-assets-data.iso -V cidata -J -r meta-data network-config user-data \n</code></pre> </li> <li> <p>Create the virtual machine.     This step uses both the newly created ISO file and the ISO file downloaded from the Talos Machine Factory.</p> <pre><code>virt-install -n eda-assets \\\n--description \"EDA Assets VM for EDA\" \\\n--noautoconsole --os-variant=generic \\ #(1)!\n--memory 16384 --vcpus 4 --cpu host \\\n--disk eda-assets-rootdisk.qcow2,format=qcow2,bus=virtio,size=300 \\\n--cdrom ./bundles/eda-cargo/talos-asset-vm-boot-imgs/asset-vm-nocloud-amd64.iso \\\n--disk eda-assets-data.iso,device=cdrom \\\n--network bridge=br0,model=virtio\n</code></pre> <ol> <li>Depending on the <code>virt-install</code> version, the <code>--os-variant=generic</code> option might not be supported. In that case use <code>--os-type=generic</code> instead.</li> </ol> <p>Warning</p> <p>Pay attention to the MTU value set on the Linux bridge, interfaces, and networks between the Assets VM and the EDA Kubernetes cluster nodes must allow for the same MTU size.</p> </li> </ol>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#creating-the-assets-vm-on-vmware-vsphere","title":"Creating the Assets VM on VMware vSphere","text":"<p>Caution</p> <p>This procedure is executed in the Air-gapped environment for a VMware vSphere deployment.</p> <ol> <li> <p>Ensure that the <code>ovftool</code> is installed.</p> <p>To deploy the Assets VM OVA image on VMware vSphere, the <code>ovftool</code> must be installed on the system from which you will create the deployment.</p> </li> <li> <p>Deploy Assets VM OVA image.</p> <p>Standing in the root of the edaadm repository, create a base64 encoded string from the Talos machine configuration for the Assets VM. If you have been using the example edaadm configuration file from above, the command would be:</p> <pre><code>export NODECONFIG=$(base64 -i eda-airgap-assets/eda-assets.yaml)\n</code></pre> <p>Deploy the Assets VM OVA image generated in the \"Creating the VMware Assets VM image\" section using the <code>ovftool</code> command:</p> <pre><code>ovftool --acceptAllEulas --noSSLVerify \\\n-dm=thin \\\n-ds=DATASTORE \\\n-n=eda-assets \\\n--net:\"VM Network=OAM\" \\\n--prop:talos.config=\"${NODECONFIG}\" \\\n./bundles/eda-cargo/talos-asset-vm-boot-imgs/vmware-amd64.ova \\\nvi://admin%40vsphere.local@vcenter.tld/My-DC/host/Cluster/Resources/My-Resource-Group\n</code></pre> </li> <li> <p>Adjust the Assets VM resources.</p> <p>After deploying the VM using the OVA image:</p> <ul> <li>Increase the number of vCPUs to 4.</li> <li>Increase the memory to 16G.</li> <li>Increase the main disk size to 300G. On boot, Talos automatically extends the file system.</li> <li>Enable 100% resource reservation for the CPU, memory and disk.</li> </ul> </li> </ol>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#bootstrap-the-assets-vm","title":"Bootstrap the Assets VM","text":"<p>The Assets VM runs Talos Kubernetes and needs to be bootstrapped using the <code>edaadm</code> tool. Use the edaadm configuration file created previously to bootstrap the Assets VM.</p> <pre><code>edaadm bootstrap-k8s -c eda-assets-deployment.yaml\n</code></pre>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#obtaining-the-kubernetes-config-file","title":"Obtaining the Kubernetes Config File","text":"<p>Once the Assets VM Kubernetes cluster is bootstrapped, use the <code>edaadm</code> command to fetch the Kubernetes configuration file (kubeconfig) for use with <code>kubectl</code>.</p> <ol> <li> <p>Obtain the Kubernetes configuration file.</p> <p>Execute the following command in the folder with the <code>eda-assets-deployment.yaml</code> EDAADM configuration file.</p> <pre><code>edaadm get-kubeconfig -c eda-assets-deployment.yaml\n</code></pre> </li> <li> <p>Configure the Kubernetes configuration file in your environment.</p> <p>You can configure your environment to use the \u200bkubeconfig\u200b file for use with the <code>kubectl</code> command.</p> <pre><code>export KUBECONFIG=eda-airgap-assets/kubeconfig.yaml\n</code></pre> </li> <li> <p>Inspect your server and check if all nodes are up and running.</p> <p>You can use the typical <code>kubectl</code> commands.</p> <pre><code>kubectl get nodes\n</code></pre> </li> </ol> <p>When the node is up and ready, continue with deploying the Assets VM services.</p>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#deploying-the-assets-vm-services","title":"Deploying the Assets VM Services","text":"<p>After deploying and bootstrapping the Assets VM itself, the container registry, git server and web server need to be deployed.</p> <pre><code>make -C kpt/ eda-setup-shipyard\n</code></pre>"},{"location":"software-install/air-gapped/deploying-the-assets-vm/#uploading-the-assets-to-the-assets-vm","title":"Uploading the Assets to the Assets VM","text":"<p>Now that the Assets VM and its services are up and running, upload all the assets that you downloaded previously to the Assets VM.</p> <p>Set the <code>EDA_CORE_VERSION</code><sup>1</sup> environment variable (and any <code>SKIP_...</code> environment variables you used when downloading the assets)<sup>1</sup> in your shell. This will ensure that the correct version of the cache and assets is uploaded to the Assets VM.</p> <pre><code>export EDA_CORE_VERSION=25.12.1\n</code></pre> <p>Then execute the following command to upload all the assets to the Assets VM:</p> <pre><code>make -C bundles/ load-all-bundles \\\n    ASSET_HOST=192.0.2.228 \\\n    ASSET_HOST_GIT_USERNAME=\"ZWRh\" \\\n    ASSET_HOST_GIT_PASSWORD=\"ZWRh\" \\\n    ASSET_HOST_ARTIFACTS_USERNAME=\"ZWRh\" \\\n    ASSET_HOST_ARTIFACTS_PASSWORD=\"ZWRh\"\n</code></pre> <p>Notes</p> <ol> <li>Make sure to replace the <code>ASSET_HOST</code> IP with the IP of your Asset VM.</li> <li>The username and passwords will be configurable in the near future. The <code>eda</code> username and password are used by default.</li> </ol> <p>Once all uploads have finished successfully, the Assets VM is ready to support the installation of the EDA Talos Kubernetes cluster in the Air-gapped environment.</p> <ol> <li> <p>If you used <code>SKIP_...</code> environment variables when downloading the assets, make sure to set the same variables when uploading the assets to the Assets VM.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"software-install/air-gapped/downloading-the-assets/","title":"Downloading the Assets","text":"<p>Caution</p> <p>These steps are meant to be executed in the public environment with Internet access.</p> <p>There are two types of assets that need to be downloaded:</p> <ul> <li>Assets Bundles - The bundles that contain all the resources needed to run Nokia EDA. This includes container images, repositories, tools and more.</li> <li>Base Talos VM Image - The base images for the EDA Kubernetes nodes (VMs) that will run the EDA application.</li> </ul>"},{"location":"software-install/air-gapped/downloading-the-assets/#downloading-the-assets-bundles","title":"Downloading the Assets Bundles","text":"<ol> <li> <p>Change into the <code>edaadm</code> repository.</p> <p>In case you have changed directories after the \"Preparing the Assets VM\" step, ensure that you are in the <code>edaadm</code> repository.</p> changing into edaadm repository directory<pre><code>cd path/to/edaadm\n</code></pre> </li> <li> <p>Select EDA version.</p> <p>Set the <code>EDA_CORE_VERSION</code> environment variable in your shell to the target EDA release version, otherwise the latest version will be assumed. This will ensure that the correct version of the cache and assets is downloaded and prepared for the Assets VM.</p> <pre><code>export EDA_CORE_VERSION=25.12.1\n</code></pre> </li> <li> <p>Download the Assets Bundles.</p> <p>Container images used in EDA which are grouped by their function are called Assets Bundles. Users need to download these bundles to have all the necessary components available for the air-gapped installation.  </p> <p>To optimize the download time and storage space, set the environment variables to skip downloading certain versions and/or types of assets. For example, consider the following set of environment variables and the inline explanations provided:</p> <pre><code>export SKIP_APPS_25_8=1 #(1)!\nexport SKIP_APPS_25_4=1\nexport SKIP_APPS_24_12=1\nexport SKIP_APPS_24_8=1\nexport SKIP_APPS_24_4=1\nexport SKIP_APPS_CONNECT=1 #(2)!\n</code></pre> <ol> <li>Skip EDA applications for older EDA versions.</li> <li>Skip EDA Connect related assets if EDA Cloud Connect is not in use.</li> </ol> <p>Instead of downloading all bundles, individual bundles can also be downloaded as described in the section below.</p> <p>The following command will download all Assets Bundles defined in the <code>bundles</code> folder respecting the environment variables set above and store them in the <code>eda-cargo</code> folder.</p> <pre><code>make -C bundles/ save-all-bundles\n</code></pre> Downloading individual bundles <p>In case individual bundles need to be downloaded, use the following command to list the available bundles:</p> <pre><code>make -C bundles/ ls-bundles\n</code></pre> <p>Using the following command, you can then use the following command to download a specific bundle:</p> <pre><code>make -C bundles/ save-&lt;bundle-name&gt;\n</code></pre> </li> </ol>"},{"location":"software-install/air-gapped/downloading-the-assets/#downloading-the-base-talos-vm-images","title":"Downloading the Base Talos VM Images","text":"<p>To deploy the EDA Kubernetes VMs, the base Talos image is needed for KVM or VMware vSphere. These images can also be downloaded using the edaadm bundles folder as described below.</p> <ol> <li> <p>Change into the <code>edaadm</code> repository.</p> <p>In case you have changed directories, ensure that you are in the <code>edaadm</code> repository.</p> changing into edaadm repository directory<pre><code>cd path/to/edaadm\n</code></pre> </li> <li> <p>Download the base Talos images.</p> <p>The following command downloads all images for both KVM and VMware vSphere.</p> <pre><code>make -C bundles/ download-talos-stock-boot-media\n</code></pre> <p>The output should look similar to the following:</p> <pre><code>--&gt; INFO: List of goals: download-talos-stock-boot-media\n--&gt; Downloading boot media for vmware\n    From: https://factory.talos.dev/image/903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40/v1.9.2/vmware-amd64.iso\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/vmware-amd64.iso\n############################################################################################################################### 100.0%\n    From: https://factory.talos.dev/image/903b2da78f99adef03cbbd4df6714563823f63218508800751560d3bc3557e40/v1.9.2/vmware-amd64.ova\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/vmware-amd64.ova\n############################################################################################################################### 100.0%\n--&gt; Downloading boot media for nocloud\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/nocloud-amd64.iso\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/nocloud-amd64.iso\n############################################################################################################################### 100.0%\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/nocloud-amd64.raw.xz\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/nocloud-amd64.raw.xz\n############################################################################################################################### 100.0%\n--&gt; Downloading boot media for metal\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/metal-amd64.iso\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/metal-amd64.iso\n############################################################################################################################### 100.0%\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/metal-amd64.raw.zst\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/metal-amd64.raw.zst\n############################################################################################################################### 100.0%\n    From: https://factory.talos.dev/image/376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba/v1.9.2/metal-amd64.qcow2\n    To: /path/to/edaadm-repository/bundles/eda-cargo/talos-stock-boot-media/metal-amd64.qcow2\n############################################################################################################################### 100.0%\n</code></pre> <p>The downloaded images will be stored in the <code>./bundles/eda-cargo/talos-stock-boot-media/</code> folder and can be used during the deploying the Assets VM step.</p> </li> </ol>"},{"location":"software-install/air-gapped/preparing-the-air-gapped-environment/","title":"Preparing the Air-gapped environment","text":"<p>After preparing the Assets VM and downloading the necessary assets, the fetched data needs to be made available in the Air-gapped environment. Two options are available:</p> <ol> <li>Move the system that was used to prepare the Assets VM to the Air-gapped environment. For instance, if it is a laptop or a VM, you can move to the Air-gapped environment by changing its network configuration.</li> <li>Copy the data from the system that was used to prepare the Assets VM to the Air-gapped environment using a USB key or a temporary network connection. The data should include:<ul> <li>The playground repository cloned during the \"Preparing for installation\" step.</li> <li>The edaadm repository which includes the <code>eda-cargo</code> folder holding the Air-gapped data (bundles, asset VM image and Talos base VM images). The <code>eda-cargo</code> folder was populated during the preparing the Assets VM and downloading the necessary assets steps.</li> </ul> </li> </ol>"},{"location":"software-install/air-gapped/preparing-the-air-gapped-environment/#loading-the-kpt-setters-image","title":"Loading the Kpt Setters image","text":"<p>Note</p> <p>These steps are to be executed in the air-gapped environment.</p> <p>The procedures for setting up the Assets VM and installing EDA use Kpt - a package manager for Kubernetes. Kpt relies on the <code>kpt-apply-setters</code> container to be present in the local Docker image cache of the air-gapped system to be able to perform its operations. The container image is part of the <code>eda-bundle-tools</code> bundle in the <code>edaadm/bundles</code> list. If you used the <code>save-all-bundles</code> option when downloading the assets, you will have that bundle on your air-gapped system. If you do not have it yet, you can download the bundle on the system with Internet and copy over the content of the bundle to the air-gapped environment before executing the steps.</p> <p>To load the <code>kpt-apply-setters</code> image from the <code>eda-bundle-tools</code> bundle, follow these steps:</p> <ol> <li> <p>Go to the <code>edaadm</code> repository directory.</p> <p>Change into the <code>edaadm</code> repository that you have copied from the Internet-connected system:</p> <pre><code>cd path/to/edaadm\n</code></pre> </li> <li> <p>Import the image into the local docker image cache</p> <p>Note that the version of the bundle might update to a newer version in the future. In that case, replace the <code>1-0-0</code> with the appropriate version and the correct <code>kpt-apply-setters</code> version as well.</p> <pre><code>docker load -i ./bundles/eda-cargo/eda-bundle-tools-1-0-0/images/srl-labs-kpt-apply-setters-0-1-1\n</code></pre> </li> </ol>"},{"location":"software-install/air-gapped/preparing-the-assets-vm/","title":"Preparing the Assets VM","text":"<p>The Assets VM will run as a single Virtual Machine inside the Air-Gapped environment. This VM will hold all of the assets and can be used across multiple deployments and EDA versions, containing the assets for multiple versions.</p> <p>These steps help create the Assets VM from a base Talos VM image and populate it with the local cache needed to deploy the Assets VM in the Air-Gapped environment.</p> <p>Caution</p> <p>These steps are meant to be executed in the public environment with Internet access.</p>"},{"location":"software-install/air-gapped/preparing-the-assets-vm/#creating-assets-vm-image-cache","title":"Creating Assets VM Image Cache","text":"<p>Before creating the Assets VM Image for a specific environment, an image cache must be created that will contain the necessary bootstrap images used by the Assets VM.</p> <p>Change into the cloned <code>edaadm</code> repository root directory.</p> <pre><code>cd path/to/edaadm\n</code></pre> <p>And run the following command to create the image cache:</p> <pre><code>make -C bundles/ create-assets-host-bootstrap-image-cache\n</code></pre>"},{"location":"software-install/air-gapped/preparing-the-assets-vm/#creating-the-kvm-assets-vm-image","title":"Creating the KVM Assets VM Image","text":"<p>Note</p> <p>This is only needed if you plan to deploy the Assets VM on KVM.</p> <p>Follow these steps to create the Assets VM Image for KVM. This will generate an ISO file based on the Talos VM base image containing a local cache. This image is different from the base Talos image ISO file that you will use for the EDA Kubernetes VMs, but is based on it.</p> <ol> <li> <p>Change into the <code>edaadm</code> repository.</p> <p>In case you have changed directories, ensure that you are in the <code>edaadm</code> repository.</p> changing into edaadm repository directory<pre><code>cd path/to/edaadm\n</code></pre> </li> <li> <p>Generate the Assets VM ISO for KVM.</p> <p>Execute the following command to generate the KVM Talos ISO for the Assets VM.</p> <pre><code>make -C bundles/ create-asset-vm-nocloud-boot-iso\n</code></pre> Output example <p>The output should look similar to:</p> <pre><code>--&gt; INFO: List of goals: create-asset-vm-nocloud-boot-iso\ndocker pull ghcr.io/siderolabs/imager:v1.9.2\nv1.9.2: Pulling from siderolabs/imager\nDigest: sha256:b99d29d04df9eea89d50cb0d13d57e1e035e54cbd9970a26af99b18154e443a9\nStatus: Image is up to date for ghcr.io/siderolabs/imager:v1.9.2\nghcr.io/siderolabs/imager:v1.9.2\nskipped pulling overlay (no overlay)\nprofile ready:\narch: amd64\nplatform: nocloud\nsecureboot: false\nversion: v1.9.2\ninput:\n  kernel:\n    path: /usr/install/amd64/vmlinuz\n  initramfs:\n    path: /usr/install/amd64/initramfs.xz\n  baseInstaller:\n    imageRef: ghcr.io/siderolabs/installer:v1.9.2\n  imageCache:\n    imageRef: \"\"\n    ociPath: /image-cache.oci\noutput:\n  kind: iso\n  imageOptions:\n    diskSize: 2147483648\n  outFormat: raw\nskipped initramfs rebuild (no system extensions)\nkernel command line: talos.platform=nocloud console=tty1 console=ttyS0 net.ifnames=0 talos.halt_if_installed=1 init_on_alloc=1 slab_nomerge pti=on consoleblank=0 nvme_core.io_timeout=4294967295 printk.devkmsg=on ima_template=ima-ng ima_appraise=fix ima_hash=sha512\nISO ready\noutput asset path: /out/nocloud-amd64.iso\nrenamed '/home/user/ws/edaadm/public/bundles/eda-cargo/talos-asset-vm-boot-imgs/nocloud-amd64.iso' -&gt; '/home/user/ws/edaadm/public/bundles/eda-cargo/talos-asset-vm-boot-imgs/asset-vm-nocloud-amd64.iso'\n--&gt; INFO: Created /home/user/ws/edaadm/public/bundles/eda-cargo/talos-asset-vm-boot-imgs/asset-vm-nocloud-amd64.iso\n</code></pre> <p>The ISO disk image will be saved at the relative path <code>./bundles/eda-cargo/talos-asset-vm-boot-imgs/asset-vm-nocloud-amd64.iso</code>.</p> </li> </ol>"},{"location":"software-install/air-gapped/preparing-the-assets-vm/#creating-the-vmware-assets-vm-image","title":"Creating the VMware Assets VM Image","text":"<p>Note</p> <p>This is only needed if you plan to deploy the Assets VM on VMware vSphere.</p> <p>This command requires Linux kernel version 6 or higher<sup>1</sup></p> <p>Follow these steps to create the Assets VM Image for VMware vSphere. This will generate an ISO file based on the Talos VM base image containing a local cache. This image is different from the base Talos image ISO file that you will use for the EDA Kubernetes VMs, but is based on it.</p> <ol> <li> <p>Change into the <code>edaadm</code> repository.</p> <p>In case you have changed directories, ensure that you are in the <code>edaadm</code> repository.</p> changing into edaadm repository directory<pre><code>cd path/to/edaadm\n</code></pre> </li> <li> <p>Generate the Assets VM OVA for VMware vSphere.</p> <p>Execute the following command to generate the VMware vSphere Talos OVA for the Assets VM.</p> <pre><code>make -C bundles/ create-asset-vm-vmware-boot-ova\n</code></pre> Output example <p>The output should look similar to:</p> <pre><code>--&gt; INFO: List of goals: create-asset-vm-vmware-boot-ova\ndocker pull ghcr.io/siderolabs/imager:v1.9.2\nv1.9.2: Pulling from siderolabs/imager\nDigest: sha256:b99d29d04df9eea89d50cb0d13d57e1e035e54cbd9970a26af99b18154e443a9\nStatus: Image is up to date for ghcr.io/siderolabs/imager:v1.9.2\nghcr.io/siderolabs/imager:v1.9.2\nskipped pulling overlay (no overlay)\nprofile ready:\narch: amd64\nplatform: vmware\nsecureboot: false\nversion: v1.9.2\ninput:\n  kernel:\n    path: /usr/install/amd64/vmlinuz\n  initramfs:\n    path: /usr/install/amd64/initramfs.xz\n  baseInstaller:\n    imageRef: ghcr.io/siderolabs/installer:v1.9.2\n  imageCache:\n    imageRef: \"\"\n    ociPath: /image-cache.oci\noutput:\n  kind: image\n  imageOptions:\n    diskSize: 2147483648\n    diskFormat: ova\n  outFormat: raw\nskipped initramfs rebuild (no system extensions)\nkernel command line: talos.platform=vmware talos.config=guestinfo console=tty0 console=ttyS0 earlyprintk=ttyS0,115200 net.ifnames=0 init_on_alloc=1 slab_nomerge pti=on consoleblank=0 nvme_core.io_timeout=4294967295 printk.devkmsg=on ima_template=ima-ng ima_appraise=fix ima_hash=sha512\ndisk image ready\noutput asset path: /out/vmware-amd64.ova\nrenamed '/home/user/ws/edaadm/public/bundles/eda-cargo/talos-asset-vm-boot-imgs/vmware-amd64.ova' -&gt; '/home/user/ws/edaadm/public/bundles/eda-cargo/talos-asset-vm-boot-imgs/asset-vm-vmware-amd64.ova'\n--&gt; INFO: Created /home/user/ws/edaadm/public/bundles/eda-cargo/talos-asset-vm-boot-imgs/asset-vm-vmware-amd64.ova\n</code></pre> <p>The OVA disk image will be saved at the relative path <code>./bundles/eda-cargo/talos-asset-vm-boot-imgs/asset-vm-vmware-amd64.ova</code>.</p> </li> </ol> <ol> <li> <p>See https://github.com/siderolabs/talos/issues/9264#issuecomment-2426756838 \u21a9</p> </li> </ol>"},{"location":"software-install/deploying-eda/","title":"Deploying EDA","text":"<p>These are the major steps for installing the EDA deployment. This applies to both Air-gapped installations and Internet based installations. Some steps will differ depending on the type of install, this will be clearly called out highlighting both options.</p> <ol> <li> <p>Preparing the EDAADM configuration file     This task describes the details of the EDAADM configuration file and how to set it up.</p> </li> <li> <p>Generating the Talos machine configurations     Using the EDA ADM tool and the configuration file, this task generates specific Talos machine configuration files for each Talos VM.</p> </li> <li> <p>Deploying the Talos virtual machines     This task describes how to use the Talos base image and machine configuration files to deploy the Talos VMs in your KVM or VMware vSphere environment.</p> </li> <li> <p>Bootstrap the Talos Kubernetes cluster     This task bootstraps the Talos Kubernetes environment using the VMs you have created.</p> </li> <li> <p>Installing the EDA application     Using the EDA Installation playground, this step installs EDA on the Kubernetes environment in the EDA nodes.</p> </li> </ol>"},{"location":"software-install/deploying-eda/bootstrap-the-talos-kubernetes-cluster/","title":"Bootstrap the Talos Kubernetes cluster","text":"<p>When all the virtual machines are deployed and running, you can set up the Kubernetes cluster on the virtual machines using Talos.</p> <p>Note</p> <p>The procedures in this chapter use the <code>edaadm</code> command. Ensure that the command is available, as well as the original EDAADM configuration file from which you generated Talos files.</p>"},{"location":"software-install/deploying-eda/bootstrap-the-talos-kubernetes-cluster/#bootstrapping-kubernetes-on-the-primary-node","title":"Bootstrapping Kubernetes on the primary node","text":"<p>After booting the Talos VMs, you can now bootstrap the Kubernetes cluster using the <code>edaadm</code> command.</p> <p>Execute the following command:</p> <pre><code>edaadm bootstrap-k8s -c eda-input-6-node.yaml #(1)!\n</code></pre> <ol> <li><code>-c</code>: Specifies the EDAADM configuration file.</li> </ol> <p>Wait for several minutes for the Kubernetes cluster to come up and for all the nodes join the cluster. The process should take less than 15 minutes.</p>"},{"location":"software-install/deploying-eda/bootstrap-the-talos-kubernetes-cluster/#obtaining-the-kubernetes-config-file-for-kubectl","title":"Obtaining the Kubernetes config file for kubectl","text":"<p>Use the talosctl command to obtain the Kubernetes configuration file for use with kubectl.</p> <p>Obtain the Kubernetes configuration file with:</p> <pre><code>edaadm get-kubeconfig -c eda-6-node-deployment.yaml #(1)!\n</code></pre> <ol> <li><code>-c</code>: Specifies the EDAADM configuration file.</li> </ol> <p>You can configure your environment to use the <code>\u200bkubeconfig</code>\u200b file for use with the kubectl command.</p> <pre><code>export KUBECONFIG=eda-compute-cluster/kubeconfig\n</code></pre> <p>Inspect your k8s cluster and check if all nodes are up and running.</p> <pre><code>kubectl get nodes\n</code></pre> <p>When all the nodes are up and Kubernetes is stable, continue with Setting up the Rook Ceph storage cluster.</p>"},{"location":"software-install/deploying-eda/bootstrap-the-talos-kubernetes-cluster/#setting-up-the-rook-ceph-storage-cluster","title":"Setting up the Rook Ceph storage cluster","text":"<p>EDA uses Rook Ceph as a secure, distributed, and redundant data store for all the data it stores. Using Ceph guarantees redundancy and high availability of all data by providing multiple copies of all data. The following steps guide you through the configuration and deployment of Rook Ceph.</p> <ol> <li> <p>Add the Rook Ceph Helm chart.</p> <p>Caution</p> <p>Only do this step for an Internet based installation, not for an Air-Gapped installation.</p> <pre><code>helm repo add rook-release https://charts.rook.io/release\n</code></pre> </li> <li> <p>Using the <code>rook-ceph-operator-values.yaml</code> file that edaadm generated based on the configuration, deploy the Rook Ceph Operator.</p> Internet based installationAir-gapped installation <pre><code>helm install --create-namespace \\\n  --namespace rook-ceph \\\n  -f path/to/rook-ceph-operator-values.yaml \\\n  rook-ceph rook-release/rook-ceph  \n</code></pre> <pre><code>helm install --create-namespace \\\n  --namespace rook-ceph \\\n  --version v1.15.0 \\\n  -f path/to/rook-ceph-operator-values.yaml \\\n  rook-ceph \\\n  http://eda:eda@&lt;ASSETS VM IP&gt;/artifacts/rook-ceph-v1.15.0.tgz\n</code></pre> </li> <li> <p>Using the <code>rook-ceph-cluster-values.yaml</code> file that the <code>edaadm</code> tool generated, deploy the Rook Ceph Cluster.</p> Internet based installationAir-gapped installation <pre><code>helm install \\\n  --namespace rook-ceph \\\n  --set operatorNamespace=rook-ceph \\\n  -f path/to/rook-ceph-cluster-values.yaml \\\n  rook-ceph-cluster rook-release/rook-ceph-cluster\n</code></pre> <pre><code>helm install \\ \n  --namespace rook-ceph \\ \n  --set operatorNamespace=rook-ceph \\ \n  -f path/to/rook-ceph-cluster-values.yaml \\ \n  rook-ceph-cluster \\\n  http://eda:eda@&lt;ASSETS VM IP&gt;/artifacts/rook-ceph-cluster-v1.15.0.tgz\n</code></pre> <p>The output from this command can report missing CRDs; wait until the Rook Ceph Operator is running in the Kubernetes cluster.</p> </li> <li> <p>Using <code>kubectl</code> commands, verify that the operator is deployed and the necessary pods are deployed before installing the EDA application.     This example is for a six-node cluster, with six storage nodes.</p> <pre><code>kubectl -n rook-ceph get pods\n</code></pre> <p> <pre><code>NAME                                               READY   STATUS      RESTARTS        AGE\ncsi-cephfsplugin-22rmj                             2/2     Running     1 (6m32s ago)   7m6s\ncsi-cephfsplugin-25p9d                             2/2     Running     1 (6m30s ago)   7m6s\ncsi-cephfsplugin-2gr8v                             2/2     Running     4 (5m16s ago)   7m6s\ncsi-cephfsplugin-48cwk                             2/2     Running     1 (6m30s ago)   7m6s\ncsi-cephfsplugin-fknch                             2/2     Running     2 (5m32s ago)   7m6s\ncsi-cephfsplugin-provisioner-67c8454ddd-mpq4w      5/5     Running     1 (6m1s ago)    7m6s\ncsi-cephfsplugin-provisioner-67c8454ddd-qmdrq      5/5     Running     1 (6m18s ago)   7m6s\ncsi-cephfsplugin-vfxnf                             2/2     Running     1 (6m32s ago)   7m6s\nrook-ceph-mds-ceph-filesystem-a-7c54cdf5bc-lmf6n   1/1     Running     0               2m40s\nrook-ceph-mds-ceph-filesystem-b-6dc794b9f4-2lc64   1/1     Running     0               2m37s\nrook-ceph-mgr-a-55b449c844-wpps8                   2/2     Running     0               4m30s\nrook-ceph-mgr-b-5f97fd5746-fzngx                   2/2     Running     0               4m30s\nrook-ceph-mon-a-76fcb96c4c-vscnc                   1/1     Running     0               5m53s\nrook-ceph-mon-b-68bf5974bb-p2vnj                   1/1     Running     0               4m57s\nrook-ceph-mon-c-6d7c64dcb6-phs99                   1/1     Running     0               4m47s\nrook-ceph-operator-5f4c4bff8d-2fsq2                1/1     Running     0               7m54s\nrook-ceph-osd-0-bf89f779-zh4kd                     1/1     Running     0               3m49s\nrook-ceph-osd-1-64dcd64c5f-7xcbm                   1/1     Running     0               3m49s\nrook-ceph-osd-2-54ddd95489-5qkdt                   1/1     Running     0               3m49s\nrook-ceph-osd-3-56cbd54bd6-7mt8w                   1/1     Running     0               3m39s\nrook-ceph-osd-4-567dcff476-wljll                   1/1     Running     0               2m56s\nrook-ceph-osd-5-6f69c998b6-2l5wp                   1/1     Running     0               2m54s\nrook-ceph-osd-prepare-eda-dev-node01-7rfkn         0/1     Completed   0               4m8s\nrook-ceph-osd-prepare-eda-dev-node02-rqdkx         0/1     Completed   0               4m8s\nrook-ceph-osd-prepare-eda-dev-node03-xtznb         0/1     Completed   0               4m8s\nrook-ceph-osd-prepare-eda-dev-node04-db4v8         0/1     Completed   0               4m7s\nrook-ceph-osd-prepare-eda-dev-node05-29wwm         0/1     Completed   0               4m7s\nrook-ceph-osd-prepare-eda-dev-node06-zxp2x         0/1     Completed   0               4m7s\nrook-ceph-tools-b9d78b5d4-8r62p                    1/1     Running     0               7m6s\n</code></pre> </p> <p>Note</p> <p>Some of the pods may restart as they initiate Ceph. This behavior is expected.</p> </li> </ol>"},{"location":"software-install/deploying-eda/installing-the-eda-application/","title":"Installing the EDA application","text":"<p>After setting up EDA nodes and bootstrapping the Talos Kubernetes cluster, you can now install Nokia EDA applications using the playground repository cloned during the preparation phase.</p>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#customizing-the-installation","title":"Customizing the installation","text":"<p>The Kpt Kubernetes package manager is used to configure and install EDA components. As any other package manager, kpt packages can be customized to allow users to customize EDA installation according to their needs.</p>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#preferences-file","title":"Preferences file","text":"<p>The most common customization options are provided in the <code>prefs.mk</code> preferences file you find at the playground directory's root.</p> <p>This file contains customization parameters that you can set to adjust the essential installation parameters, such as the EDA version to install, the installation components to include, the Kubernetes namespace where EDA components are installed, proxy settings, the reachability settings for the EDA cluster, and so on. You will find the list of all the available parameters in the section below.</p> Customizable parameters in the <code>prefs.mk</code> file: <p>Parameter</p> <p>Description</p> Namespace settings for EDA components <p><code>EDA_CORE_NAMESPACE</code></p> <p>Sets the kubernetes namespace where the EDA core components are installed.</p> <p>Default: <code>eda-system</code></p> <p><code>EDA_USER_NAMESPACE</code></p> <p>Sets the kubernetes and EDA namespace where the user components are installed.</p> <p>Default: <code>eda</code></p> Version selection for EDA packages <p><code>EDA_CORE_VERSION</code></p> <p>Version of the EDA core components to install.</p> <p>Defaults to the latest stable version.</p> <p><code>EDA_APPS_VERSION</code></p> <p>Version of the EDA applications to install.</p> <p>Defaults to the latest stable version.</p> KinD cluster options <p><code>NO_KIND</code></p> <p>When set to any non-zero value will skip the KinD cluster deployment used for lab/demo installations. Must be set to <code>yes</code> for production installation.</p> <p><code>KIND_CONFIG_FILE</code></p> <p>Path to the KinD configuration file.</p> <p>Default: <code>configs/kind.yaml</code> - the path to the KinD configuration file in the playground directory.</p> <p><code>KIND_CLUSTER_NAME</code></p> <p>Name of the KinD cluster.</p> <p>Default: <code>eda-demo</code>.</p> <p><code>KIND_API_SERVER_ADDRESS</code></p> <p>IP address to use for the KinD API server. If you want to reach your cluster from outside of the host machine, you must set this to the IP address of the host machine.</p> <p>Default: <code>127.0.0.1</code>.</p> <p><code>NO_HOST_PORT_MAPPINGS</code></p> <p>When set to <code>yes</code> will not create the extra port mappings in the KinD cluster and will not create the nodePort service to expose the EDA UI/API.</p> <p>Default: variable is not set. Results in port mappings and nodePort service being created.</p> Cluster reachability settings <p><code>METALLB_VIP</code></p> <p>Specifies the VIP address of your EDA deployment. Make sure to use a CIDR format, preferably as a /32 (or /128 for an IPv6 VIP).</p> <p>If you use two networks, this VIP address must be the one used on the fabric management network. \u200b\u200bIf you use a single network, this setting must match the VIP address used for <code>\u200bEXT_DOMAIN_NAME\u200b</code> FQDN or IP.\u200b</p> <p>Example: <code>203.0.113.10/32</code></p> <p><code>EXT_DOMAIN_NAME</code></p> <p>The FQDN that resolves to the EDA VIP or the VIP itself.</p> <p>This value must be the FQDN or VIP address that is used to access the UI. If you use two networks, this value must be the FQDN or IP address of the OAM network.</p> <p><code>EXT_HTTP_PORT</code></p> <p>The HTTP port that the EDA UI/API should use to redirect to HTTPS. Set to 80.</p> <p><code>EXT_HTTPS_PORT</code></p> <p>The HTTPS port on which the EDA UI/API listens. Set to 443.</p> <p><code>EXT_IPV4_ADDR</code></p> <p>The IPv4 IP address used as the VIP address.</p> <p>If you use two networks, this VIP address must be the one used on the fabric management network.\u200b \u200bIf you use a single network, this VIP address must be the VIP that matches your \u200bEXT_DOMAIN_NAME\u200b FQDN (or IP address).</p> <p><code>EXT_IPV6_ADDR</code></p> <p>The IPv6 IP address used as the VIP.</p> <p>If you use two networks, this VIP address must be the one used on the fabric management network.\u200b \u200bIf you use a single network, this VIP address must be the VIP that matches your \u200bEXT_DOMAIN_NAME\u200b FQDN (or IP address).</p> Proxy settings <p><code>HTTPS_PROXY</code> and <code>https_proxy</code></p> <p>Optional: The proxy address for the HTTPS proxy.</p> <p><code>HTTP_PROXY</code> and <code>http_proxy</code></p> <p>Optional: The proxy address for the HTTP proxy.</p> <p><code>NO_PROXY</code> and <code>no_proxy</code></p> <p>Optional: The list of IP addresses, IP ranges and hostnames that should not be proxied.</p> Asset host settings <p><code>USE_ASSET_HOST</code></p> <p>Must be set to <code>1</code> for an Air-gapped Installation and set to <code>0</code> for an Internet based installation. <code>0</code> is the default value if not set.</p> <p><code>ASSET_HOST</code></p> <p>The IP address of the Assets VM for the Air-gapped installation.</p> <p><code>ASSET_HOST_GIT_USERNAME</code></p> <p>The username for the git server running on the Asset VM. Needs to be set to <code>eda</code>, in the future this will be changeable.</p> <p><code>ASSET_HOST_GIT_PASSWORD</code></p> <p>The password for the git server running on the Asset VM. Needs to be set to <code>eda</code>, in the future this will be changeable.</p> <p><code>ASSET_HOST_ARTIFACTS_USERNAME</code></p> <p>The username for the artifact server running on the Asset VM. Needs to be set to <code>eda</code>, in the future this will be changeable.</p> <p><code>ASSET_HOST_ARTIFACTS_PASSWORD</code></p> <p>The password for the artifact server running on the Asset VM. Needs to be set to <code>eda</code>, in the future this will be changeable.</p> KPT settings <p><code>KPT_SETTERS_FILE</code></p> <p>Advanced configuration file for kpt.</p> <p><code>KPT_LIVE_INIT_FORCE</code></p> <p>Set to <code>1</code> to ignore if a kpt package was already initialized against a cluster. Results in an overwrite of the existing inventory (resource group).</p> <p>Default: <code>0</code></p> <p><code>KPT_INVENTORY_ADOPT</code></p> <p>Set to <code>1</code> to adopt already applied and unmanaged resources that the kpt package is trying to clear, it will update/reconcile any differences.</p> <p>Default: <code>0</code></p> External packages settings <p><code>NO_CERT_MANAGER_INSTALL</code></p> <p>Set to <code>yes</code> to skip the installation of the Cert Manager package. This is useful if you want to use an existing Cert Manager running in the <code>cert-manager</code> namespace.</p> <p>Default: unset - the Cert Manager package is installed.</p> <p><code>NO_CSI_DRIVER_INSTALL</code></p> <p>Set to <code>yes</code> to skip the installation of the Cert Manager's CSI driver. This is useful if you want to use an existing Cert Manager CSI driver running in the <code>cert-manager</code> namespace.</p> <p>Default: unset - the Cert Manager CSI driver package is installed.</p> <p><code>NO_EDA_ISSUER_API_INSTALL</code></p> <p>Set to <code>yes</code> to skip the installation of the certificate issuers for EDA.</p> <p>Default: unset - the EDA certificate issuers are installed.</p> Other settings <p><code>LLM_API_KEY</code></p> <p>Optional: The OpenAI API key for the EDA Natural Language Query functionality.</p> <p><code>SINGLESTACK_SVCS</code></p> <p>Optional: Indicates that internal services should be single stack instead of dual stack, if Kubernetes is dual stack. Boolean.</p> <p><code>SIMULATE</code></p> <p>Specifies if the EDA deployment is to manage simulated workloads (Digital Sandbox) or real hardware.</p> <p>Values:</p> <ul> <li><code>true</code> - EDA installation will manage only simulated nodes (Digital Sandbox)</li> <li><code>false</code> - EDA installation will manage only real hardware nodes.</li> </ul> <p>By default, this parameter is set to <code>true</code> if the parameter is not provided in the file.</p> <p>Caution</p> <p>The simulation mode can't be changed post-install.</p> <p>You can find examples of the <code>prefs.mk</code> file contents for Internet based and Air-gapped installations for your reference:</p> Internet based installationAir-gapped installation <pre><code>NO_KIND=1\nSIMULATE=false\nMETALLB_VIP=203.0.113.10/32\nEXT_DOMAIN_NAME=eda.domain.tld \nEXT_HTTP_PORT=80 \nEXT_HTTPS_PORT=443 \nEXT_IPV4_ADDR=203.0.113.10\nEXT_IPV6_ADDR=\"\"\nHTTPS_PROXY=http://192.0.2.254:8080 \nHTTP_PROXY=http://192.0.2.254:8080 \nNO_PROXY=192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108 \nhttps_proxy=http://192.0.2.254:8080 \nhttp_proxy=http://192.0.2.254:8080 \nno_proxy=192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108 \nLLM_API_KEY=...\n</code></pre> <pre><code>NO_KIND=1\nSIMULATE=false\nMETALLB_VIP=203.0.113.10/32\nEXT_DOMAIN_NAME=eda.domain.tld \nEXT_HTTP_PORT=80 \nEXT_HTTPS_PORT=443 \nEXT_IPV4_ADDR=203.0.113.10\nEXT_IPV6_ADDR=\"\"\nHTTPS_PROXY=http://192.0.2.254:8080 \nHTTP_PROXY=http://192.0.2.254:8080 \nNO_PROXY=192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108 \nhttps_proxy=http://192.0.2.254:8080 \nhttp_proxy=http://192.0.2.254:8080 \nno_proxy=192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108 \nLLM_API_KEY=...\nUSE_ASSET_HOST=1\nASSET_HOST=192.0.2.228\nASSET_HOST_GIT_USERNAME=\"eda\"\nASSET_HOST_GIT_PASSWORD=\"eda\"\nASSET_HOST_ARTIFACTS_USERNAME=\"eda\"\nASSET_HOST_ARTIFACTS_PASSWORD=\"eda\"\n</code></pre>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#kpt-setters","title":"Kpt setters","text":"<p>For the most part, the <code>prefs.mk</code> file is just a hand-picked selection of the most common customization options that the installation procedure passes over to the Kpt package manager.</p> <p>In Kpt, the customization of packages is done by setting the values of the parameters marked with the <code>kpt-set</code> annotation. Consider the Catalog manifest from the <code>eda-kpt-base</code> package:</p> <pre><code>apiVersion: appstore.eda.nokia.com/v1\nkind: Catalog\nmetadata:\n  name: eda-catalog-builtin-apps\n  namespace: eda-system # kpt-set: ${EDA_CORE_NAMESPACE}\nspec:\n  title: EDA built in apps catalog\n  remoteURL: https://github.com/nokia-eda/catalog.git # kpt-set: ${APP_CATALOG}\n  authSecretRef: gh-catalog\n</code></pre> <p>The <code># kpt-set: ${APP_CATALOG}</code> annotation indicates that the <code>.spec.remoteURL</code> value of the manifest can be overwritten using the <code>APP_CATALOG</code> Kpt setter.</p> <p>When you use the <code>prefs.mk</code> file and set the values for the variables exposed there you essentially provide the Kpt setters values, that will be used to customize the Kpt packages during the installation. However, the <code>prefs.mk</code> file exposes only a limited set of variables, while there are many more Kpt setters available in the EDA Kpt packages.</p> <p>EDA uses three Kpt packages published in the <code>nokia-eda/kpt</code> repository:</p> <ul> <li><code>eda-external-packages</code> - the package that contains the external packages used by EDA, such as Fluentd and Cert Manager.</li> <li><code>eda-kpt-base</code> - the core package that contains the EDA components, such as the Config Engine, the necessary secrets and configmaps.</li> <li><code>eda-kpt-playground</code> - the package that contains the EDA resources that bootstrap your EDA cluster with the node profiles, allocation pools and node users.</li> </ul> <p>Each package has its own set of Kpt setters that you can choose to use to overwrite the default values in the manifests. You will find the complete list of setters and the default values in the block below.</p> Kpt setters reference <p>Run <code>make list-kpt-setters-external-packages</code>, <code>make list-kpt-setters-core</code> or <code>make list-kpt-setters-playground</code> to see the list of setters for the respective package in your terminal and their current values.</p> eda-external-packageseda-kpt-baseeda-kpt-playground Name Current Value eda-external-packages/cert-manager/cert-manager.yaml <code>CORE_IMG_CREDENTIALS</code> core <code>CMCA_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-cainjector:v1.16.2\" <code>CMCT_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-controller:v1.16.2\" <code>CM_ARGS</code> Non scalar value, see the file for details. <code>CMWH_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-webhook:v1.16.2\" Name Current Value eda-external-packages/csi-driver/cert-manager-csi-driver.in.yaml <code>EDA_CORE_NAMESPACE</code> eda-system <code>CSI_REGISTRAR_IMG</code> \"ghcr.io/nokia-eda/ext/sig-storage/csi-node-driver-registrar:v2.12.0\" <code>CSI_LIVPROBE_IMG</code> \"ghcr.io/nokia-eda/ext/sig-storage/livenessprobe:v2.12.0\" <code>CSI_DRIVER_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-csi-driver:v0.10.1\" Name Current Value eda-external-packages/eda-api-ingress-https-passthrough/api-ingress-ssl-passthrough.yaml <code>EXT_DOMAIN_NAME</code> \"\" <code>INT_HTTPS_PORT</code> 443 Name Current Value eda-external-packages/eda-api-ingress-https/eda-api-ingress-cert.yaml <code>EXT_IPV4_ADDR</code> \"\" <code>EXT_IPV6_ADDR</code> \"\" Name Current Value eda-external-packages/fluentd/fluentd-bit-ds.yaml <code>FB_IMG</code> ghcr.io/nokia-eda/core/fluent-bit:3.0.7-amd64 Name Current Value eda-external-packages/fluentd/fluentd.yaml <code>FD_IMG</code> ghcr.io/nokia-eda/core/fluentd:v1.17.0-debian-1.0 Name Current Value eda-external-packages/git-no-pvc/gogs-admin-user.yaml <code>EDA_GOGS_NAMESPACE</code> eda-system <code>GOGS_ADMIN_USER</code> ZWRhCg== <code>GOGS_ADMIN_PASS</code> ZWRhCg== Name Current Value eda-external-packages/git-no-pvc/gogs-deployment-no-pvc.yaml <code>GOGS_IMG_TAG</code> ghcr.io/nokia-eda/core/gogs:0.13.0 Name Current Value eda-external-packages/git-no-pvc/gogs-replica-service.yaml <code>GIT_SVC_TYPE</code> ClusterIP Name Current Value eda-external-packages/git/gogs-pv-claim.yaml <code>GOGS_PV_CLAIM_SIZE</code> 24Gi Name Current Value eda-external-packages/git/gogs-replica-pv-claim.yaml <code>GOGS_REPLICA_PV_CLAIM_SIZE</code> 24Gi Name Current Value eda-external-packages/trust-manager/trust-manager.yaml <code>EDA_TRUSTMGR_NAMESPACE</code> eda-system <code>TRUSTMGRBUNDLE_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/cert-manager-package-debian:20210119.0\" <code>TRUSTMGR_IMG</code> \"ghcr.io/nokia-eda/ext/jetstack/trust-manager:v0.15.0\" <code>TRUSTMGR_ARGS</code> Non scalar value, see the file for details. <code>EDA_TRUSTMGR_ISSUER_DNSNAMES</code> Non scalar value, see the file for details. Name Current Value eda-kpt-base/appstore-gh/catalog-secret.yaml <code>GH_CATALOG_TOKEN</code> SomeCatalogToken <code>GH_CATALOG_USER</code> bm9raWEtZWRhLWJvdA== <code>EDA_CORE_NAMESPACE</code> eda-system Name Current Value eda-kpt-base/appstore-gh/catalog.yaml <code>APP_CATALOG</code> https://github.com/nokia-eda/catalog.git Name Current Value eda-kpt-base/appstore-gh/registry-secret.yaml <code>GH_REGISTRY_TOKEN</code> SomeRegistryToken <code>GH_REGISTRY_USER</code> bm9raWEtZWRhLWJvdA== Name Current Value eda-kpt-base/appstore-gh/registry.yaml <code>APP_REGISTRY</code> ghcr.io <code>APP_REGISTRY_SKIPTLSVERIFY</code> false <code>APP_REGISTRY_MIRROR</code> \"\" Name Current Value eda-kpt-base/core/apps/bootstrap.yaml <code>INT_DHCPV6_PORT</code> 547 <code>INT_DHCPV4_PORT</code> 67 Name Current Value eda-kpt-base/core/apps/ce-deployment.yaml <code>CORE_IMG_CREDENTIALS</code> core <code>CE_IMG</code> ghcr.io/nokia-eda/core/config-engine:25.4.3 <code>CE_LIMIT_CPU</code> \"2\" <code>CE_LIMIT_MEM</code> \"2Gi\" <code>CE_REQ_CPU</code> \"1\" <code>CE_REQ_MEM</code> \"1Gi\" <code>HTTP_PROXY</code> \"\" <code>HTTPS_PROXY</code> \"\" <code>NO_PROXY</code> \"\" <code>http_proxy</code> \"\" <code>https_proxy</code> \"\" <code>no_proxy</code> \"\" Name Current Value eda-kpt-base/core/apps/cxdp-image-config-map.yaml <code>CXDP_IMG</code> ghcr.io/nokia-eda/core/cxdp:25.4.3 Name Current Value eda-kpt-base/eda-toolbox/eda-toolbox-deployment.yaml <code>EDA_TOOLBOX_IMG</code> ghcr.io/nokia-eda/core/eda-toolbox:25.4.3 Name Current Value eda-kpt-base/engine-config/engineconfig.yaml <code>CLUSTER_MEMBER_NAME</code> engine-config <code>GIT_SERVERS</code> Non scalar value, see the file for details. <code>EXT_DOMAIN_NAME</code> \"\" <code>EXT_HTTP_PORT</code> 0 <code>EXT_HTTPS_PORT</code> 0 <code>EXT_IPV4_ADDR</code> \"\" <code>EXT_IPV6_ADDR</code> \"\" <code>INT_HTTP_PORT</code> 80 <code>INT_HTTPS_PORT</code> 443 <code>GIT_REPO_CHECKPOINT</code> /eda/customresources.git <code>GIT_REPO_APPS</code> /eda/apps.git <code>GIT_REPO_USER_SETTINGS</code> /eda/usersettings.git <code>GIT_REPO_SECURITY</code> /eda/credentials.git <code>GIT_REPO_IDENTITY</code> /eda/identity.git <code>ASVR_IMG</code> ghcr.io/nokia-eda/core/artifact-server:25.4.3 <code>ASVR_LIMIT_CPU</code> \"\" <code>ASVR_LIMIT_MEM</code> \"\" <code>ASVR_REQ_CPU</code> \"\" <code>ASVR_REQ_MEM</code> \"\" <code>BSVR_IMG</code> ghcr.io/nokia-eda/core/bootstrap-server:25.4.3 <code>BSVR_LIMIT_CPU</code> \"\" <code>BSVR_LIMIT_MEM</code> \"\" <code>BSVR_REQ_CPU</code> \"\" <code>BSVR_REQ_MEM</code> \"\" <code>ECC_IMG</code> ghcr.io/nokia-eda/core/cert-checker:25.4.3 <code>ECC_LIMIT_CPU</code> \"\" <code>ECC_LIMIT_MEM</code> \"\" <code>ECC_REQ_CPU</code> \"\" <code>ECC_REQ_MEM</code> \"\" <code>CX_IMG</code> ghcr.io/nokia-eda/core/cx:25.4.3 <code>CX_LIMIT_CPU</code> \"\" <code>CX_LIMIT_MEM</code> \"\" <code>CX_REQ_CPU</code> \"\" <code>CX_REQ_MEM</code> \"\" <code>CXCLUSTER_ISAGENT</code> false <code>CXCLUSTER_ADDR</code> eda-cx-standalone <code>CXCLUSTER_PORT</code> 52200 <code>EMS_IMG</code> ghcr.io/nokia-eda/core/metrics-server:25.4.3 <code>EMS_LIMIT_CPU</code> \"\" <code>EMS_LIMIT_MEM</code> \"\" <code>EMS_REQ_CPU</code> \"\" <code>EMS_REQ_MEM</code> \"\" <code>NPP_IMG</code> ghcr.io/nokia-eda/core/npp:25.4.3 <code>NPP_LIMIT_CPU</code> \"\" <code>NPP_LIMIT_MEM</code> \"\" <code>NPP_REQ_CPU</code> \"\" <code>NPP_REQ_MEM</code> \"\" <code>SE_IMG</code> ghcr.io/nokia-eda/core/state-engine:25.4.3 <code>SE_REPLICAS</code> 1 <code>SE_LIMIT_CPU</code> \"\" <code>SE_LIMIT_MEM</code> \"\" <code>SE_REQ_CPU</code> \"\" <code>SE_REQ_MEM</code> \"\" <code>SA_IMG</code> ghcr.io/nokia-eda/core/state-aggregator:25.4.3 <code>SA_REPLICAS</code> 1 <code>SA_LIMIT_CPU</code> \"\" <code>SA_LIMIT_MEM</code> \"\" <code>SA_REQ_CPU</code> \"\" <code>SA_REQ_MEM</code> \"\" <code>SC_IMG</code> ghcr.io/nokia-eda/core/state-controller:25.4.3 <code>SC_LIMIT_CPU</code> \"\" <code>SC_LIMIT_MEM</code> \"\" <code>SC_REQ_CPU</code> \"\" <code>SC_REQ_MEM</code> \"\" <code>FE_IMG</code> ghcr.io/nokia-eda/core/flow-engine:25.4.3 <code>FE_LIMIT_CPU</code> \"\" <code>FE_LIMIT_MEM</code> \"\" <code>FE_REQ_CPU</code> \"\" <code>FE_REQ_MEM</code> \"\" <code>API_IMG</code> ghcr.io/nokia-eda/core/api-server:25.4.3 <code>API_REPLICAS</code> 1 <code>API_SVC_ENABLE_LB_NODE_PORTS</code> false <code>API_LIMIT_CPU</code> \"\" <code>API_LIMIT_MEM</code> \"\" <code>API_REQ_CPU</code> \"\" <code>API_REQ_MEM</code> \"\" <code>ASC_IMG</code> ghcr.io/nokia-eda/core/appstore-server:25.4.3 <code>ASC_LIMIT_CPU</code> \"\" <code>ASC_LIMIT_MEM</code> \"\" <code>ASC_REQ_CPU</code> \"\" <code>ASC_REQ_MEM</code> \"\" <code>ASF_IMG</code> ghcr.io/nokia-eda/core/appstore-flow:25.4.3 <code>TM_IMG</code> ghcr.io/nokia-eda/core/testman:25.4.3 <code>TM_LIMIT_CPU</code> \"\" <code>TM_LIMIT_MEM</code> \"\" <code>TM_REQ_CPU</code> \"\" <code>TM_REQ_MEM</code> \"\" <code>KC_IMG</code> ghcr.io/nokia-eda/core/eda-keycloak:25.4.3 <code>KC_LIMIT_CPU</code> \"\" <code>KC_LIMIT_MEM</code> \"\" <code>KC_REQ_CPU</code> \"\" <code>KC_REQ_MEM</code> \"\" <code>PG_IMG</code> ghcr.io/nokia-eda/core/eda-postgres:25.4.3 <code>PG_LIMIT_CPU</code> \"\" <code>PG_LIMIT_MEM</code> \"\" <code>PG_REQ_CPU</code> \"\" <code>PG_REQ_MEM</code> \"\" <code>LLM_API_KEY</code> \"\" <code>LLM_MODEL</code> gpt-4o <code>SIMULATE</code> true <code>SINGLESTACK_SVCS</code> false Name Current Value eda-kpt-base/namespaces/eda.yaml <code>EDA_USER_NAMESPACE</code> eda Name Current Value eda-kpt-base/secrets/identity-realm-auth.yaml <code>SECRET_EDA_ADMIN_USERNAME</code> YWRtaW4= Name Current Value eda-kpt-base/secrets/keycloak-admin-secret.yml <code>SECRET_KC_ADMIN_USERNAME</code> YWRtaW4= <code>SECRET_KC_ADMIN_PASSWORD</code> YWRtaW4= Name Current Value eda-kpt-base/secrets/postgres-db-secret.yml <code>SECRET_PG_DB_USERNAME</code> cG9zdGdyZXM= <code>SECRET_PG_DB_PASSWORD</code> cGFzc3dvcmQ= Name Current Value eda-kpt-playground/allocations/asn-pool.yaml <code>EDA_USER_NAMESPACE</code> eda Name Current Value eda-kpt-playground/cx/cx-cxdp-init.yaml <code>EDA_CORE_NAMESPACE</code> eda-system Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.1/engine_v1_nodeprofile_srlinux_24.10.1.yaml <code>SRL_24_10_1_GHCR</code> ghcr.io/nokia/srlinux:24.10.1-492 <code>CORE_IMG_CREDENTIALS</code> core Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.1/llm-embeddings-db-srlinux-24.10.1.yaml <code>LLM_DB_REMOTE_URL</code> https://github.com/nokia-eda/llm-embeddings/releases/download/nokia-srl-v24.10.1/llm-embeddings-srl-24-10-1.tar.gz Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.1/yang-srlinux-24.10.1.yaml <code>YANG_REMOTE_URL</code> https://github.com/nokia/srlinux-yang-models/releases/download/v24.10.1/srlinux-24.10.1-492.zip Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.2/engine_v1_nodeprofile_srlinux_24.10.2.yaml <code>SRL_24_10_2_GHCR</code> ghcr.io/nokia/srlinux:24.10.2-357 Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.3/engine_v1_nodeprofile_srlinux_24.10.3.yaml <code>SRL_24_10_3_GHCR</code> ghcr.io/nokia/srlinux:24.10.3-201 Name Current Value eda-kpt-playground/srlinux-ghcr-24.10.4/engine_v1_nodeprofile_srlinux_24.10.4.yaml <code>SRL_24_10_4_GHCR</code> ghcr.io/nokia/srlinux:24.10.4-244 Name Current Value eda-kpt-playground/srlinux-ghcr-25.3.2/engine_v1_nodeprofile_srlinux_25.3.2.yaml <code>SRL_25_3_2_GHCR</code> ghcr.io/nokia/srlinux:25.3.2-312 <p>If you need to customize the installation besides the parameters provided in the <code>prefs.mk</code> file, you should create the YAML file with the Kpt setters key/value pairs that follows the Kpt setters format like this:</p> <code>my-setters.yml</code><pre><code>apiVersion: v1\nkind: ConfigMap #(1)!\nmetadata:\n  name: my-setters\ndata:\n  GOGS_REPLICA_PV_CLAIM_SIZE: 10Gi #(2)!\n  # add more setters if required\n</code></pre> <ol> <li>The setters file resembles a K8s ConfigMap resource, but it is not applied to your cluster, it is only used by the kpt tool to read the values from it.</li> <li>The setter's key must match the name of the setter variable in the manifest file.</li> </ol> <p>Now that you have your setters file with the necessary values, you should set the path to it in the preferences file:</p> <pre><code>KPT_SETTERS_FILE := my-setters.yml\n</code></pre> <p>And that's it! The kpt will read the values from the setters file and apply them to the manifests when you run the installation commands.</p>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#credentials-and-secrets","title":"Credentials and secrets","text":"<p>Nokia EDA platform uses a set of credentials to authenticate and authorize access to various components. These credentials are set to their respective default values and can be modified pre and post installation. The tables below lists the components, the associated credentials and the matching Kpt setters that an admin can use to customize them at the installation time.</p>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#git","title":"Git","text":"Component Default value Kpt Setter Notes Internal Git server (Gogs) admin username <code>eda</code> <code>GOGS_ADMIN_USER</code> Sets the username for the internal Git server. Not applicable if an external Git server is used. Base64 encoded Internal Git server (Gogs) admin password <code>eda</code> <code>GOGS_ADMIN_PASS</code> Same note as for the admin username. Base64 encoded Config Engine Git username <code>eda</code> <code>CE_GIT_USERNAME</code> Should match the Git server admin username. Base64 encoded Config Engine Git password <code>eda</code> <code>CE_GIT_PASSWORD</code> Should match the Git server admin password. Base64 encoded <p>In case the value of <code>GOGS_ADMIN_USER</code>/<code>CE_GIT_USERNAME</code> was changed, make sure to set the setters for the repository paths as per the table below. The path values are provided as raw text values.</p> Component Default value Kpt Setter Notes Custom resources repo <code>/eda/customresources.git</code> <code>GIT_REPO_CHECKPOINT</code> Apps repo <code>/eda/apps.git</code> <code>GIT_REPO_APPS</code> User settings repo <code>/eda/usersettings.git</code> <code>GIT_REPO_USER_SETTINGS</code> Credentials repo <code>/eda/credentials.git</code> <code>GIT_REPO_SECURITY</code> Identity repo <code>/eda/identity.git</code> <code>GIT_REPO_IDENTITY</code>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#eda-user","title":"EDA user","text":"<p>EDA users are managed by the Keycloak identity provider and by default an admin user is created during the installation process. Using the following setter it is possible to change the default admin user password<sup>1</sup>.</p> Component Default value Kpt Setter Notes EDA admin password <code>admin</code> <code>SECRET_EDA_ADMIN_PASSWORD</code> Base64 encoded"},{"location":"software-install/deploying-eda/installing-the-eda-application/#keycloak","title":"Keycloak","text":"<p>The Keycloak identity provider is managed by its own admin user and its credentials can be customized using the following setters:</p> Component Default value Kpt Setter Notes Keycloak admin username <code>admin</code> <code>SECRET_KC_ADMIN_USERNAME</code> Base64 encoded Keycloak admin password <code>admin</code> <code>SECRET_KC_ADMIN_PASSWORD</code> Base64 encoded"},{"location":"software-install/deploying-eda/installing-the-eda-application/#postgres-db","title":"Postgres DB","text":"<p>Lastly, there is a postgres database used by the Keycloak. The database password can also be customized:</p> Component Default value Kpt Setter Notes Postgres DB password <code>password</code> <code>SECRET_PG_DB_PASSWORD</code> Base64 encoded"},{"location":"software-install/deploying-eda/installing-the-eda-application/#installing-nokia-eda","title":"Installing Nokia EDA","text":"<p>When the necessary parameters are set, follow these steps to install EDA.</p> <p>Note</p> <p>Steps 1 and 2 can be skipped if these have already been executed during the preparation phase of the installation procedure.</p> <ol> <li> <p>Download the latest tools.</p> <pre><code>make download-tools\n</code></pre> </li> <li> <p>Set the desired EDA version. (optional)</p> <p>To install a specific version of EDA instead of the latest version, set the <code>EDA_CORE_VERSION</code> and <code>EDA_APPS_VERSION</code> variables in the preferences file. For example, to choose the 25.12.1 version of EDA, add the following lines to the <code>prefs.mk</code> file:</p> <pre><code>EDA_CORE_VERSION=25.12.1\nEDA_APPS_VERSION=25.12.1\n</code></pre> <p>In the current release, both variables must be set to the same version.</p> </li> <li> <p>Download EDA packages.</p> <pre><code>make download-pkgs\n</code></pre> </li> <li> <p>Set up the MetalLB environment for VIP management.</p> <pre><code>make metallb\n</code></pre> </li> <li> <p>Install the necessary external packages.</p> <pre><code>make install-external-packages\n</code></pre> <p>Note</p> <p>If this command exits with an error, wait 30 seconds and try again. Sometimes Kubernetes is a bit slower in reconciling the change than the command waits for.</p> </li> <li> <p>Change the eda-git Kubernetes service to a ClusterIP service instead of a LoadBalancer type.</p> <pre><code>kubectl -n eda-system patch service eda-git -p '{\"spec\": {\"type\": \"ClusterIP\"}}'\n</code></pre> </li> <li> <p>Generate the EDA core configuration.</p> <pre><code>make eda-configure-core\n</code></pre> </li> <li> <p>Install EDA core components.</p> <pre><code>make eda-install-core\n</code></pre> <p>Note</p> <p>If the command hangs for a long time (&gt;5 minutes) on \"reconcile pending\" for a workflow definition, cancel the command and try again; KPT is designed to handle these cases. This can happen occasionally depending on the Kubernetes cluster.</p> </li> <li> <p>Verify that the EDA Config Engine is up and running.</p> <pre><code>make eda-is-core-ready\n</code></pre> </li> <li> <p>Install all the standard EDA apps.</p> <p>This step can take approximate 5 to 15 minutes, depending on your connectivity.</p> <pre><code>make eda-install-apps\n</code></pre> </li> <li> <p>Bootstrap EDA.</p> <p>Bootstrapping will create base resources into the EDA cluster, such as IP pools.</p> <pre><code>make eda-bootstrap\n</code></pre> </li> <li> <p>Configure two-networks deployment.</p> <p>If your deployment uses two networks, create a second VIP pool for the OAM VIP address.</p> <pre><code>make metallb-configure-pools METALLB_VIP=&lt;OAM VIP&gt; LB_POOL_NAME=pool-nb\n</code></pre> <p>And create the OAM UI/API service using the new VIP pool.</p> <pre><code>make eda-create-api-lb-svc API_LB_POOL_NAME=pool-nb\n</code></pre> </li> <li> <p>Optional: Deploy an example topology.</p> <p>If you configured EDA to manage the simulated network (Digital Sandbox), you can load an example topology that will be instantiated as virtual simulators in the same EDA cluster by running:</p> <pre><code>make topology-load\n</code></pre> </li> </ol>"},{"location":"software-install/deploying-eda/installing-the-eda-application/#accessing-the-eda-deployment","title":"Accessing the EDA deployment","text":"<p>You can now access the new EDA deployment using the following methods:</p> <ul> <li>use <code>https://OAM-VIP</code> if Virtual IP (VIP) was provided as <code>EXT_DOMAIN_NAME</code> in the preferences file used during the installation.</li> <li>if an FQDN is configured for the <code>EXT_DOMAIN_NAME</code> field, use <code>https://FQDN</code></li> </ul> <p>Both examples assume that <code>EXT_HTTPS_PORT</code> was set to <code>443</code> in the preferences file.</p> <ol> <li> <p>Note, that it is not possible to change the default admin username.\u00a0\u21a9</p> </li> </ol>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/","title":"Setting up the EDA virtual machine nodes","text":"<p>This section describes how to the prepare the configurations file, generate the configuration files, and deploy the Talos virtual machines.</p>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#preparing-the-edaadm-configuration-file","title":"Preparing the EDAADM configuration file","text":"<p>The <code>edaadm</code> tool helps with the creation of the necessary machine configuration files for the Talos VMs that are part of your deployment.</p>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#edaadm-configuration-file-fields","title":"EDAADM configuration file fields","text":"<p>The EDAADM configuration file is a YAML file that describes your Talos Kubernetes environment. You can use it to configure the different nodes and the general Kubernetes cluster environment.</p> <p>Top-level parameter</p> <p>Description</p> <p><code>version</code></p> <p>The version of the EDA environment to be deployed. Example: 25.4.1</p> <p><code>clusterName</code></p> <p>The name of your EDA environment. Example: <code>eda-production-cluster</code></p> <p><code>machines</code></p> <p>A list of Kubernetes nodes. Each Kubernetes node has the following settings:</p> <p><code>name</code></p> <p>The name of a node. Example: <code>eda-node01</code></p> <p><code>endpoint</code></p> <p>The IP address on which the node is reachable for Talos to control. Optional.</p> <p><code>interfaces</code></p> <p>A list of interfaces present in the node, each with the following settings:</p> <ul> <li> <p><code>name</code>: the name of the interface.     Example: <code>eth0</code></p> </li> <li> <p><code>dhcp</code>: indicates if DHCP is to be used for the interface.     Values: <code>true</code> or <code>false</code>. For production environments, set to <code>false</code>.</p> </li> <li> <p><code>mtu</code>: the MTU setting for the interface. For an interface used to connect to nodes under management, set to 9000 for best practice. Optional.</p> </li> <li> <p><code>interface</code>: the interface name as it appears in Linux. Typically, <code>eth0</code>, <code>eth1</code>, and so forth. Optional.</p> </li> <li> <p><code>addresses</code>: a list of IP addresses; for dual-stack deployments, you can specify both IPv4 and IPv6 addresses. If DHCP is not provided, specify at least one address.</p> </li> <li> <p><code>routes</code>: a list of static routes to configure, including the default route. Optional. Routes have the following components:</p> <ul> <li> <p><code>gateway</code>: the next-hop or gateway for the route.</p> </li> <li> <p><code>metric</code>: a metric to indicate the priority of the route. Optional.</p> </li> <li> <p><code>mtu</code>: a specific MTU for the route. Optional.</p> </li> <li> <p><code>network</code>: the destination CIDR of the route.</p> </li> <li> <p><code>source</code>: a source interface for the route to apply to. Optional.</p> </li> </ul> </li> <li> <p><code>deviceSelector</code>: specifies how to select the device associated with this interface.</p> <ul> <li> <p><code>busPath</code>: a PCI buspath that can contain wildcards. Optional.</p> </li> <li> <p><code>hardwareAddr</code>: a MAC address that can contain wildcards. Optional.</p> </li> </ul> </li> </ul> <p><code>disks</code></p> <p>Identifies the disks available in the node:</p> <ul> <li> <p><code>os</code>: Specifies which disk to use for the OS. Required setting.</p> <p>Typically <code>/dev/sda</code> or <code>/dev/vda</code>, depending on the hypervisor platform</p> </li> <li> <p><code>storage</code>: Optional disk for use with nodes that are to be part of the storage cluster.</p> </li> </ul> <p><code>k8s</code></p> <p>The Kubernetes-specific configuration. The following parameters define the Kubernetes cluster:</p> <p><code>stack</code></p> <p>Indicates the network stack to support. Values: <code>ipv4</code>, <code>ipv6</code>, or <code>dual</code>.</p> <ul> <li> <p>Set to <code>ipv6</code> for IPv6-only deployments. The value of <code>.k8s.vip.ipv6</code> will be used to set the Talos Virtual IP (VIP) address.</p> </li> <li> <p>For IPv4-only deployments, set to <code>ipv4</code>. The value of <code>.k8s.vip.ipv4</code> will be used to set the Talos Virtual IP (VIP) address.</p> </li> <li> <p>For dual-stack deployments, set to <code>dual</code>. Only one value can be specified for the VIP (<code>.k8s.vip.ipv4</code> or <code>.k8s.vip.ipv6</code>) address and the set value will be used to set the Talos Virtual IP (VIP) address.</p> </li> </ul> <p>IPv6 and dual-stack are supported from EDA 25.8.2 onwards.</p> <p><code>vip</code></p> <p>The Virtual IP (VIP) address used for Kubernetes API access and the interfaces to which they should be attached in the control plane nodes. Choose the value depending on the IP stack in use:</p> <ul> <li> <p><code>interface</code>: the interface to which the VIP is attached on the nodes.</p> <p>Example: <code>eth0</code></p> </li> <li> <p><code>ipv4</code>: the IPv4 VIP address.</p> <p>Example: <code>192.0.2.10</code></p> </li> <li> <p><code>ipv6</code>: the IPv6 VIP address.</p> </li> </ul> <p>Since VIP functionality relies on etcd for elections, the shared IP will not come alive until after you have bootstrapped Kubernetes.</p> <p><code>primaryNode</code></p> <p>The first control plane node in the cluster to be used for bootstrapping the Kubernetes cluster.</p> <p>Specify the name of a machine.</p> <p><code>endpointUrl</code></p> <p>The URL on which to reach the Kubernetes control plane. This setting uses the Kubernetes VIP address. Example: <code>https://192.0.2.10:6443</code></p> <p><code>allowSchedulingOnControlPlanes</code></p> <p>Specifies if workloads can be deployed on the control plane node. Values: <code>true</code> or <code>false</code>. For best practice, set to <code>true</code>.</p> <p><code>control-plane</code></p> <p>A list of control plane nodes. Specify a machine name.</p> <p><code>worker</code></p> <p>A list of worker nodes. Specify a machine name.</p> <p><code>nodeIP</code></p> <p>Network settings for the nodes:</p> <ul> <li> <p><code>validSubnets</code>: the list of IPv4 and/or IPv6 subnets used by the k8s nodes.     Can be used to force the node convergence in a multi-nic environment to a single or a set of subnets.     Also sets the subnet over which etcd should converge, perform heartbeats and leader election.     This property in the adm configuration sets the following talos machine config properties:  </p> <ul> <li><code>cluster.k8s.etcd.advertisedSubnets</code></li> <li><code>machine.kubelet.nodeIP.validSubnets</code></li> </ul> <p>Must be within the configured addresses on one of the interfaces in the <code>machine.interface[*]</code> otherwise the node won't be able to join the cluster.</p> <p>Example: <pre><code>- 192.168.123.101/24\n- 2001:0db8:0ca2:0006:0000:0000:0000:1001/64\n</code></pre></p> </li> </ul> <p><code>network</code></p> <p>Kubernetes pods and services network settings.</p> <ul> <li> <p><code>podSubnets</code>: Talos by default only configures an IPv4 pod subnet.     If you want to change the default IPv4 pod subnet or add an IPv6 pod subnet, provide the subnet(s) here as a list.     This property sets the <code>cluster.network.podsSubnets</code> Talos machine config property.</p> <p>Example: <pre><code>- 10.244.0.0/16\n- fd31:e17c:f07f:8b6d::/64\n</code></pre></p> </li> <li> <p><code>serviceSubnets</code>: Talos by default only configures an IPv4 service subnet.     If you want to change the default IPv4 service subnet or add an IPv6 service subnet, provide the subnet(s) here as a list.     This property sets the <code>cluster.network.serviceSubnets</code> Talos machine config property.</p> <p>Example: <pre><code>- 10.96.0.0/12\n- fd31:e17c:f07f:2dc0:4e2b:2ebc:cbc0:0/108\n</code></pre></p> </li> <li> <p><code>node-cidr-mask-size-ipv4</code>: Defines the subnet mask size for IPv4 network as defined by the <code>podSubnets</code> that each node will use.     Default: <code>24</code></p> <p>Sets the <code>cluster.controllerManager.extrArgs.node-cidr-mask-size-ipv4</code> Talos machine config property.</p> <p>Example value: <code>28</code></p> </li> <li> <p><code>node-cidr-mask-size-ipv6</code>: Defines the subnet mask size for IPv6 network as defined by the <code>podSubnets</code> that each node will use.     Default: <code>64</code></p> <p>Sets the <code>cluster.controllerManager.extrArgs.node-cidr-mask-size-ipv6</code> Talos machine config property.</p> <p>Example value: <code>80</code></p> </li> </ul> <p><code>flannelArgs</code></p> <p>Flannel CNI CLI arguments allow a user to customize the flannel configuration. Provided as a list of <code>key=value</code> pairs.</p> <p>Example: <pre><code>- --iface=eth0\n</code></pre></p> <p>A common use case is to specify the interface used by flannel when the default route is not set up or the CNI needs to bound to a specific interface due to security or operational reasons.</p> <p><code>env</code></p> <p>Section that includes the optional proxy settings for the Kubernetes nodes:</p> <ul> <li> <p><code>http_proxy</code>: The HTTP proxy URL to use.</p> <p>Example: <code>http://192.0.2.254:808</code></p> </li> <li> <p><code>https_proxy</code>: the HTTPS proxy URL to use.</p> <p>Example: <code>http://192.0.2.254:808</code></p> </li> <li> <p><code>no_proxy</code>: the no proxy setting for IP addresses, IP ranges, and hostnames</p> </li> </ul> <p><code>time</code></p> <p>Defines NTP settings.</p> <ul> <li><code>disabled</code>: Specifies whether NTP is enabled. For production environments, set to false to enable NTP.</li> <li><code>servers</code>: A list of NTP servers; required for production environments.</li> </ul> <p><code>nameservers</code></p> <p>A list of DNS servers specified under the following sub-element:</p> <ul> <li><code>servers</code>: the list of DNS servers</li> </ul> <p><code>certBundle</code></p> <p>An optional set of PEM-formatted certificates that need to be trusted; this setting is used for trust external services.</p> <p><code>mirror</code></p> <p>Only needed for Air-gapped environment, following settings can be set:</p> <ul> <li><code>name</code>: The name of the mirror</li> <li><code>url</code>: The URL of the mirror</li> <li><code>insecure</code>: should be <code>true</code></li> <li><code>overridePath</code>: should be <code>false</code></li> <li><code>skipFallback</code>: should be <code>true</code></li> <li> <p><code>mirrors</code>: A list of online registry domain names for which the mirror is used. This should look like:</p> <pre><code>- docker.io\n- gcr.io\n- ghcr.io\n- registry.k8s.io\n- quay.io\n</code></pre> </li> </ul>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#example-edaadm-configuration-file","title":"Example EDAADM configuration file","text":"<p>The following examples show an EDAADM configuration file for a 6-node Kubernetes cluster. For a standard Internet based installation, as well as for an Air-gapped installation. These are the same two files, with only the <code>mirror</code> addition on the second tab/file.</p> Internet based installationAir-gapped installation <pre><code>version: 25.4.1\nclusterName: eda-compute-cluster\nmachines:\n  - name: eda-node01\n    endpoint: \"192.0.2.11\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.11/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.11/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node02\n    endpoint: \"192.0.2.12\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.12/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.12/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node03\n    endpoint: \"192.0.2.13\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.13/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.13/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node04\n    endpoint: \"192.0.2.14\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.14/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.14/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n  - name: eda-node05\n    endpoint: \"192.0.2.15\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.15/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.15/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n  - name: eda-node06\n    endpoint: \"192.0.2.16\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.16/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.16/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\nk8s:\n  stack: ipv4\n  primaryNode: eda-node01\n  endpointUrl: https://192.0.2.5:6443\n  allowSchedulingOnControlPlanes: true\n  control-plane:\n    - eda-node01\n    - eda-node02\n    - eda-node03\n  worker:\n    - eda-node04\n    - eda-node05\n    - eda-node06\n  vip:\n    ipv4: 192.0.2.5\n    interface: eth0\n  env:\n    http_proxy: http://192.0.2.254:8080\n    https_proxy: http://192.0.2.254:8080\n    no_proxy: 192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108\n  time:\n    disabled: false\n    servers:\n      - 192.0.2.253\n      - 192.0.2.254\n  nameservers:\n    servers:\n      - 192.0.2.253\n      - 192.0.2.254\n</code></pre> <pre><code>version: 25.4.1\nclusterName: eda-compute-cluster\nmachines:\n  - name: eda-node01\n    endpoint: \"192.0.2.11\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.11/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.11/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node02\n    endpoint: \"192.0.2.12\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.12/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.12/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node03\n    endpoint: \"192.0.2.13\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.13/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.13/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n      storage: /dev/vdb\n  - name: eda-node04\n    endpoint: \"192.0.2.14\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.14/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.14/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n  - name: eda-node05\n    endpoint: \"192.0.2.15\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.15/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.15/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\n  - name: eda-node06\n    endpoint: \"192.0.2.16\"\n    interfaces:\n      - name: eth0\n        dhcp: false\n        interface: eth0\n        addresses:\n          - 192.0.2.16/24\n        routes:\n          - network: 0.0.0.0/0\n            gateway: 192.0.2.1\n        mtu: 9000\n      - name: eth1\n        dhcp: false\n        interface: eth1\n        addresses:\n          - 203.0.113.16/24\n        mtu: 9000\n    disks:\n      os: /dev/vda\nk8s:\n  stack: ipv4\n  primaryNode: eda-node01\n  endpointUrl: https://192.0.2.5:6443\n  allowSchedulingOnControlPlanes: true\n  control-plane:\n    - eda-node01\n    - eda-node02\n    - eda-node03\n  worker:\n    - eda-node04\n    - eda-node05\n    - eda-node06\n  vip:\n    ipv4: 192.0.2.5\n    interface: eth0\n  env:\n    http_proxy: http://192.0.2.254:8080\n    https_proxy: http://192.0.2.254:8080\n    no_proxy: 192.0.2.0/24,203.0.113.0/24,.domain.tld,172.22.0.0/16,localhost,127.0.0.1,10.0.1.0/24,0.0.0.0,169.254.116.108\n  time:\n    disabled: false\n    servers:\n      - 192.0.2.253\n      - 192.0.2.254\n  nameservers:\n    servers:\n      - 192.0.2.253\n      - 192.0.2.254\n  mirror:\n    name: 192.0.2.228\n    url: https://192.0.2.228\n    insecure: true\n    overridePath: false\n    skipFallback: true\n    mirrors:\n      - docker.io\n      - gcr.io\n      - ghcr.io\n      - registry.k8s.io\n      - quay.io\n</code></pre>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#generating-the-talos-machine-configurations","title":"Generating the Talos machine configurations","text":"<p>After creating the EDAADM configuration file, the next step is to generate all the configuration files that are necessary to deploy the Kubernetes environment using Talos.</p> <p>Use the <code>edaadm</code> tool to generate the deployment files.</p> <pre><code>edaadm generate -c eda-input-6-node.yaml\n</code></pre> <pre><code>$ edaadm generate -c eda-input-6-node.yaml\nConfigFile is eda-input-6-node.yaml\n...\n[1/4] Validating Machines\n[1/4] Validated Machines\n[2/4] Validating PrimaryNode\n[2/4] Validated PrimaryNode\n[3/4] Validating Endpoint URL\n[3/4] Validated Endpoint URL\n[4/4] Validating Virtual IP\n[4/4] Validated Virtual IP\n[  OK  ] Spec is validated\nGenerating secrets for eda-compute-cluster\nCreated eda-compute-cluster/secrets.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node01.yaml\nCreated eda-compute-cluster/talosconfig.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node02.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node03.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node04.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node05.yaml\ngenerating PKI and tokens\nCreated eda-compute-cluster/eda-node06.yaml\n</code></pre> <p>The configuration files created by the <code>edaadm</code> tool are used in the next steps when you deploy the virtual machines.</p> <p>Note</p> <p>Nokia strongly recommends that you store these files securely and keep a backup.</p>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#deploying-the-talos-virtual-machines","title":"Deploying the Talos virtual machines","text":"<p>This section provides the procedures for deploying an EDA node as a virtual machine on KVM or VMware vSphere.</p>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#creating-the-vm-on-bridged-networks-on-kvm","title":"Creating the VM on bridged networks on KVM","text":"<p>Complete the following steps to deploy an EDA node as a virtual machine on KVM. These steps are executed on the RedHat Enterprise Linux or Rocky Linux hypervisor directly. The steps below assume the deployment of the eda-node01 virtual machine as per the above configuration file. Ensure that you use the correct machine configuration file generated by the <code>edaadm</code> tool.</p> <p>Note</p> <p>This procedure expects two networks to be available on the KVM hypervisors. The OAM network is referred to as br0 and the fabric management network is referred to as br1. Both of these networks are standard Linux bridge networks. If you use only one interface, adapt Step <code>7</code> to only use the br0 network only.</p> <ol> <li> <p>Ensure that the virt-install tool is installed on the KVM hypervisor.     If you need to install the tool, use the following command:</p> <pre><code>yum install virt-install\n</code></pre> </li> <li> <p>Verify that the ISO image downloaded in Downloading the KVM image is available on the hypervisor.</p> </li> <li> <p>Copy the machine configuration file generated for this specific node to a file called user-data.</p> <pre><code>cp eda-node01-control-plane.yaml user-data \n</code></pre> </li> <li> <p>Create a file called meta-data for the node.     Use the appropriate instance-id and local-hostname values.</p> <pre><code>instance-id: eda-node01 \nlocal-hostname: eda-node01 \n</code></pre> </li> <li> <p>Create a file called <code>network-config</code> for the node.</p> <p>The file should have the following content:</p> <pre><code>version: 2\n</code></pre> </li> <li> <p>Create an ISO file containing the newly created files.     For ease of use, name the ISO file with the name of the node for which you are creating the ISO.</p> <pre><code>mkisofs -o eda-node01-data.iso -V cidata -J -r meta-data network-config user-data \n</code></pre> </li> <li> <p>Create the virtual machine.     This step uses both the newly created ISO file and the ISO file downloaded from the Talos Machine Factory.</p> <pre><code>virt-install -n eda-node01 \\ \n--description \"Talos 1.9.2 vm for node eda-node01\" \\ \n--noautoconsole --os-type=generic \\ \n--memory 65536 --vcpus 32 --cpu host \\ \n--disk eda-node01-rootdisk.qcow2,format=qcow2,bus=virtio,size=100 \\ \n--disk eda-node01-storagedisk.qcow2,format=qcow2,bus=virtio,size=300 \\ \n--cdrom nocloud-amd64.iso \\ \n--disk eda-node01-data.iso,device=cdrom \\ \n--network bridge=br0,model=virtio \\ \n--network bridge=br1,model=virtio\n</code></pre> <p>Note</p> <p>If the node is not a storage node, you can remove the second --disk line.</p> </li> </ol>"},{"location":"software-install/deploying-eda/setting-up-the-eda-virtual-machine-nodes/#creating-the-vm-on-bridged-networks-on-vmware-vsphere","title":"Creating the VM on bridged networks on VMware vSphere","text":"<p>Complete the following steps to deploy an EDA node as a virtual machine on VMware vSphere. The steps below assume the deployment of the eda-node01 virtual machine as per the above configuration file. Ensure that you are using the correct machine configuration file generated by the <code>edaadm</code> tool.</p> <p>You can use one of the following methods to deploy the VM on VMware vSphere:</p> <ul> <li> <p>the VMware vSphere vCenter or ESXi UI</p> <p>For instructions, see Deploy an OVF or OVA Template in the VMware vSphere documentation.</p> </li> <li> <p>the VMware Open Virtualization Format Tool CLI (VMware OVF Tool CLI)</p> <p>This procedure provides an example of how to use the VMware OVF Tool CLI.</p> </li> </ul> <p>Note</p> <p>This procedure uses two networks (portgroups) to be available on the ESXi hypervisors. The OAM network is referred to as OAM and the fabric management network is referred to as FABRIC. Both of these networks can be standard PortGroups or distributed PortGroups. If you only use one network, you do not need to create a second interface on the VM.</p> <ol> <li>Download and install the latest version of the VMware OVF Tool from the VMware Developer website.</li> <li> <p>Display details about the OVA image.</p> <pre><code>ovftool vmware-amd64.ova \n</code></pre> <p> <pre><code>OVF version:   1.0\nVirtualApp:    false\nName:          talos\n\nDownload Size:  103.44 MB\n\nDeployment Sizes:\n  Flat disks:   8.00 GB\n  Sparse disks: Unknown\n\nNetworks:\n  Name:        VM Network\n  Description: The VM Network network\n\nVirtual Machines:\n  Name:               talos\n  Operating System:   other3xlinux64guest\n  Virtual Hardware:\n    Families:         vmx-15\n    Number of CPUs:   2\n    Cores per socket: automatic\n    Memory:           2.00 GB\n\n    Disks:\n      Index:          0\n      Instance ID:    4\n      Capacity:       8.00 GB\n      Disk Types:     SCSI-VirtualSCSI\n\n    NICs:\n      Adapter Type:   VmxNet3\n      Connection:     VM Network\n\nProperties:\n  Key:         talos.config\n  Label:       Talos config data\n  Type:        string\n  Description: Inline Talos config\n\nReferences:\n  File:  disk.vmdk\n</code></pre> </p> </li> <li> <p>Create a base64 encoded hash from the Talos machine configuration for the node.</p> <p>In this example, the output is stored as an environment variable to make it easy to use in the command to deploy the image using the OVF Tool.</p> <pre><code>export NODECONFIG=$(base64 -i eda-node01-control-plane.yaml)\n</code></pre> </li> <li> <p>Deploy the OVA image using the OVF Tool.     For details about command line arguments, see the OVF Tool documentation from the VMware website.</p> <p>Note</p> <p>If you prefer using the VMware vCenter UI to create the virtual machines, use the regular method of deploying an OVA/OVF template. In this process, in the Customize template step, when you are prompted to provide the Inline Talos config, you must provide the base64 encoded data from the Talos machine configuration for the node. This very long string that is returned when you execute the base64 -i eda-node01.yaml command. Copy that long string and paste it into the field in the UI, then continue.</p> <pre><code>ovftool --acceptAllEulas --noSSLVerify \\\n-dm=thick \\\n-ds=DATASTORE \\\n-n=eda-node01 \\\n--net:\"VM Network=OAM\" \\\n--prop:talos.config=\"${NODECONFIG}\" \\\nvmware-amd64.ova \\\nvi://administrator%40vsphere.local@vcenter.domain.tld/My-DC/host/My-Cluster/Resources/My-Resource-Group\n</code></pre> <p> <pre><code>Opening OVA source: vmware-amd64.ova\nThe manifest validates\nEnter login information for target vi://vcenter.domain.tld/\nUsername: administrator%40vsphere.local\nPassword: ***********\nOpening VI target: vi://administrator%40vsphere.local@vcenter.domain.tld:443/My-DC/host/My-Cluster/Resources/My-Resource-Group\nDeploying to VI: vi://administrator%40vsphere.local@ vcenter.domain.tld:443/My-DC/host/My-Cluster/Resources/My-Resource-Group  \nTransfer Completed\nCompleted successfully\n</code></pre> </p> <p>This step deploys the VM with the CPU, memory, disk, and NIC configuration of the default OVA image. The next step updates these settings.</p> </li> <li> <p>In vCenter, edit the VM settings.</p> <p>Make the following changes:</p> <ul> <li>Increase the number of vCPU to 32.</li> <li>Increase the memory to 64G.</li> <li>Increase the main disk size to 100G. On boot, Talos automatically extends the file system.</li> <li>Optionally, if this VM is a storage node, add a new disk with a size of 300G.</li> <li>Optionally, add a second network interface and connect it to the FABRIC PortGroup.</li> <li>Enable 100% resource reservation for the CPU, memory and disk.</li> </ul> </li> <li> <p>Power on the virtual machine.</p> </li> </ol>"},{"location":"software-install/non-production/","title":"Installation Overview","text":"<p>There are several non-production deployment options that can be used to run and deploy EDA in a lab environment for testing, development and demo purposes:</p> Own On-prem cluster <p>Use your own Kubernetes cluster to deploy EDA. This can be used for most types of standard Kubernetes clusters.</p> Playground using KinD <p>Deploy EDA in a Kubernetes environment running on Linux server.</p> Playground on macOS <p>Deploy EDA Playground in a Kubernetes environment running on your personal Macbook, whether it is ARM or Intel-based.</p> Playground on WSL <p>Deploy EDA Playground in a Kubernetes environment running on your personal Windows machine, be it a laptop or a desktop.</p> <p>You can also customize your EDA installation following the Installation customization guide. This will provide you with the details on how to manipulate the kpt packages to fit your specific needs and design.</p>"},{"location":"software-install/non-production/kind/","title":"EDA on KinD","text":"<p>Installing EDA on a KinD cluster is covered in the quickstart section.</p>"},{"location":"software-install/non-production/macos/","title":"EDA on macOS","text":"<p>Do you want to get full EDA experience on your macOS machine? Well, can't judge you!</p> <p>Typically, the management and automation platforms of EDA' caliber require a ton of resources to run. But that is not the case with EDA! The microservices architecture and reliance on Kubernetes as a deployment platform make it possible to run EDA on a laptop using open-source tools. And macOS-powered machines (even with M chips<sup>1</sup>) is not an exception!</p> Watch the video <p>This guide will talk you through installing the EDA Playground which consists of a simulated network topology and full EDA platform installation. No EDA licenses are required to run the Playground.</p>"},{"location":"software-install/non-production/macos/#playground-repository","title":"Playground repository","text":"<p>We will need the playground repository on our machine to run EDA installation steps. Pull it, as explained in the Try EDA section.</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; \\\ncd playground\n</code></pre> <p>When the playground repo is cloned (you will need to install <code>git</code> to clone it), let's install the CLI tools that we will need to run EDA installation steps.</p> <pre><code>make download-tools #(1)!\n</code></pre> <ol> <li> <p>This will download <code>kind</code>, <code>kubectl</code>, <code>kpt</code>, and <code>yq</code> into a <code>tools</code> folder relative to the current working directory.</p> <p>Subsequent steps use these versions of the binaries - you may use your own binaries for your own interactions. If you don't have <code>kubectl</code> in your <code>$PATH</code>, then consider copying the <code>kubectl</code> binary from the <code>tools</code> directory to a location in your <code>$PATH</code> to make use of it in the following steps.</p> </li> </ol> <p>The installer is smart enough to download the tools for the right OS/architecture.</p>"},{"location":"software-install/non-production/macos/#macos-prerequisites","title":"macOS prerequisites","text":"<p>Before we begin, let's ensure that you run macOS Sonoma v14.6.1 or newer, as the older versions of macOS might have issues with Rosetta emulation. The version can be checked with <code>sw_vers -productVersion</code> command in your terminal.</p> <p>For Apple products with an M-chip the next step prescribes to check that macOS Rosetta virtualization support enabled. This can be done by running the following command:</p> <pre><code>softwareupdate --install-rosetta\n</code></pre>"},{"location":"software-install/non-production/macos/#docker","title":"Docker","text":"<p>Now it is time to install Docker support on your macOS. There are many options available, the most common ones are:</p> <ol> <li>OrbStack Our pick!</li> <li>Docker Desktop for Mac</li> <li>Rancher Desktop</li> <li>Colima</li> </ol> <p>Below you will find short guides on how to install Docker on your macOS using some of the tools mentioned above. If you already have one installed, you can skip to the next section.</p> OrbStackColima <p>OrbStack is a relatively new software that brings Docker support to macOS. The reason we can recommend it is that it has a great UX, has a VM management support, comes with a lightweight k8s cluster and free for personal use.</p> <p>It is a native macOS app for both Intel and ARM64-based macs, so the installation is as easy as downloading the <code>dmg</code> file and installing it as usual. OrbStack installer will install the Docker CLI on your system, and will provide the Docker VM to run containers and k8s clusters, and enable the kubernetes cluster on the Kubernetes tab:</p> <p>If you are installing Orbstack for the first time, you will see a dialog that asks you what do you plan to use OrbStack for, select \"Kubernetes\".</p> <p>When OrbStack is installed, you can check the app settings to ensure that you have the sufficient resources allocated to an internal VM that runs docker daemon:</p> <p></p> <p>Check the minimum requirements on the Try EDA page, but it is best to have more CPU and Memory available to the OrbStack VM. On the screenshot above 24GB and all CPUs are allocated to the OrbStack VM, and this has no negative/noticable impact on the overall system performance.</p> <p>Colima is an open-source, free and lightweight CLI tool that brings container runtimes to macOS.</p> <p>It has a variety of installation options, with Homebrew being likely the most popular one:</p> <pre><code>brew install colima\n</code></pre> <p>Colima does not provide the Docker CLI client, so you will need to install one separately if you don't have one installed already. Thankfully, it is as easy as running:</p> <pre><code>brew install docker\n</code></pre> <p>Now, Colima can launch a linux/arm64 VM for us; this VM runs the Docker daemon so that we could run KinD with EDA inside. Here is a command to start the VM with 8 vcpu cores and 16 GB of RAM; this should be enough to run the quickstart demo:</p> <pre><code>colima start --cpu 8 --memory 16 --profile eda \\\n--vm-type=vz --vz-rosetta --network-address\n</code></pre> <p>We can ensure that the VM is running by checking the status:</p> <pre><code>colima status -e --profile eda\nINFO[0000] colima [profile=eda] is running using macOS Virtualization\nINFO[0000] arch: aarch64                                \nINFO[0000] runtime: docker                              \nINFO[0000] mountType: virtiofs                          \nINFO[0000] address: 192.168.107.3                       \nINFO[0000] socket: unix:///Users/romandodin/.colima/eda/docker.sock \nINFO[0000] cpu: 8                                       \nINFO[0000] mem: 16GiB                                   \nINFO[0000] disk: 60GiB \n</code></pre> <p>Your docker CLI should also \"sense\" the docker engine availability and set the context to the Colima VM:</p> <pre><code>docker context ls\nNAME           DESCRIPTION                DOCKER ENDPOINT                                    ERROR\ncolima-eda *   colima [profile=eda]       unix:///Users/romandodin/.colima/eda/docker.sock   \n</code></pre> Networking and Load Balancer with Colima <p>The downside of having a VM that runs the Docker daemon is that additional layer of networking is introduced. Hence, the MetalLB Load Balancer that we install in the kind cluster will use the IP range that is not visible from the macOS host.</p> <p>You don't need Load Balancer to enjoy EDA, since you can always expose the UI and the necessary services using <code>kubectl expose</code> command, but if you want to have the Load Balancer you will have to setup additional routes[^3].</p>"},{"location":"software-install/non-production/macos/#kubernetes-cluster","title":"Kubernetes cluster","text":"<p>With the container runtime installed and running via one of the tools mentioned above, we need to ensure we have a k8s cluster running on our macOS. You typically have two options:</p> <ol> <li>Use the embedded k8s cluster provided by the tool that adds Docker support on your mac</li> <li>Setup the kind cluster manually using <code>kind</code>/<code>k3s</code>/etc.</li> </ol> <p>The first option might be the easiest way to get started, since it offers more tight integration with the macOS environment, for example by exposing services and providing a LoadBalancer implementation out of the box.</p> OrbStackKinD <p>If you're running OrbStack, you can spin up an embedded, one-node, lightweight cluster by checking the Enable Kubernetes cluster box in the settings (if unchecked): </p> <p>When OrbStack is done with creating a k8s cluster for you, you will be able to use regular cluster management tools like <code>kubectl</code>/<code>k9s</code>/etc to manage your cluster.</p> <pre><code>kubectl get nodes #(1)!\n</code></pre> <ol> <li><code>kubectl</code> is also installed during the <code>make download-tools</code> step.</li> </ol> <pre><code>NAME       STATUS   ROLES                  AGE   VERSION\norbstack   Ready    control-plane,master   28m   v1.29.3+orb1\n</code></pre> <p>Now, your cluster is ready to run its first EDA installation!</p> <p>Should you choose not to use embedded k8s support in the tool of your choice, you can install a KinD cluster manually.</p> <p>Run the following command from your playground repository to install a KinD cluster:</p> <pre><code>make kind\n</code></pre>"},{"location":"software-install/non-production/macos/#installing-eda","title":"Installing EDA","text":"<p>When running docker/k8s on a mac we have some layered networking to deal with, as the k8s cluster runs in a VM.</p> <p>First, we need to set the <code>EXT_IPV4_ADDR</code> and/or <code>EXT_IPV6_ADDR</code> variables to the IP address of the cluster node. You can find these addresses by running the following command:</p> <pre><code>kubectl get nodes -o jsonpath='{.items[0].status.addresses}'\n</code></pre> <p>And also set a pair of no proxy variables set to the cluster cidr of your cluster. You can get it with:</p> <pre><code>kubectl get nodes -o jsonpath='{.items[0].spec.podCIDR}'\n</code></pre> <p>And once all the variables are known, you can start the installation. If you are running OrbStack, you can use the following command verbatim to install EDA:</p> <pre><code>EXT_IPV4_ADDR=198.19.249.2 \\\nEXT_IPV6_ADDR=fd07:b51a:cc66::2 \\\nEXT_HTTPS_PORT=443 \\\nNO_PROXY=192.168.194.0/25 \\\nno_proxy=192.168.194.0/25 \\\nmake try-eda NO_KIND=yes NO_LB=yes\n</code></pre> <p>Potential turbulence</p> <p>You may experience some hiccups during install, for example</p> <ol> <li>Some application is stuck during install</li> <li>Simulator nodes not starting up</li> <li>NPP pods not starting up</li> </ol> <p>This is all due to the fact that the majority of the images are running under Rosetta virtualization (they are not available yet in ARM64 arch). The workaround is to restart the <code>eda-ce</code> deployment when things get stuck.</p>"},{"location":"software-install/non-production/macos/#connecting-to-the-uiapi","title":"Connecting to the UI/API","text":"<p>Depending on the tool you're using to run k8s, your method of connecting to the UI will vary.</p> OrbStack <p>In OrbStack, the k8s services are already exposed to your by the software, making it possible to access the UI by opening https://eda-api.k8s.orb.local/ in your browser.</p> <p>This integration, though, will make our generic installer bark about the port being already in use when we try to setup the port-forward for the UI access at the very end of the <code>make try-eda</code> command. Please ignore this error, as OrbStack already took care of the UI access for you.</p> <p>macOS 15+</p> <p>If your browser can not resolve the <code>eda-api.k8s.orb.local</code> domain, you need to add enable Local Network access policy for the browser of your choice since <code>.local</code> domain is resolved via mDNS. Check the Apple's documentation and this screenshot showing where the settings are located.</p> <p></p> <p>The default EDA credentials are <code>admin:admin</code>.</p>"},{"location":"software-install/non-production/macos/#tearing-down","title":"Tearing down","text":"<p>If something goes wrong during installation, or if you want to reinstall, or maybe you finished playing with EDA, feel free to destroy the cluster following the documentation for the tool you're using to run k8s.</p> In OrbStack <p>To remove the k8s cluster provided by OrbStack run the following command in the terminal:</p> <pre><code>orb delete k8s\n</code></pre> <p>This will remove the VM that backs up the k8s cluster. To bring back the empty k8s cluster run</p> <pre><code>orb start k8s\n</code></pre> <p>and now you can restart the EDA installation.</p> <ol> <li> <p>These performance cores finally have a purpose!\u00a0\u21a9</p> </li> </ol>"},{"location":"software-install/non-production/on-prem-cluster/","title":"EDA on an on-prem k8s cluster","text":"<p>The quickstart guide did a great job of getting you up and running with a local Kubernetes cluster powered by KinD. However, you may be willing to step away from the beaten path and install EDA in a non-KinD cluster. Well, EDA welcomes courageous souls like you!</p> <p>Note</p> <ol> <li>In this section we are not going into the details of how to install EDA in a production setting, since there are many environment-specific considerations to take into account. Instead, we will focus on bringing up the playground environment on a non-KinD k8s cluster.</li> <li> <p>The default installation procedure assumes that <code>cert-manager</code> does not exist in the cluster and will be installed by the playground installer.</p> <p>If you already have the cert-manager installed in your cluster (cert-manager and cert-manager-csi-driver) you can skip the installation of cert-manager by setting the <code>NO_CERT_MANAGER_INSTALL := yes</code> in your preferences file.</p> </li> </ol> <p>Alright, truth be told, the installation process is almost identical to the one you followed in the quickstart guide. This is one of the perks of running on top of Kubernetes that EDA enjoys - no matter what cluster it is (GKE, Openstack, k3s, minikube, etc), the installation process for the greater part would be the same.</p> <p>Take a seat, we are going to install EDA on a \"real\" k8s cluster running on bare VMs. But first, let's see what we are working with:</p> <pre><code>kubectl get nodes\n</code></pre> <pre><code>NAME         STATUS   ROLES           AGE   VERSION\nrd-eda1-cp   Ready    control-plane   31d   v1.30.1\nrd-eda1-w1   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w2   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w3   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w4   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w5   Ready    &lt;none&gt;          31d   v1.30.1\nrd-eda1-w6   Ready    &lt;none&gt;          31d   v1.30.1\n</code></pre> <p> A 6-node k8s cluster running vanilla Kubernetes 1.30.1 release! Each node has 4vCPU and 16GB of RAM amounting to a total of 24vCPU and 96GB of RAM. This is a decent-sized cluster for running EDA playground.</p>"},{"location":"software-install/non-production/on-prem-cluster/#storage-classes","title":"Storage classes","text":"<p>Alright, first thing to ensure (besides of having the right context set in your <code>kubectl</code> of course) is that your cluster has some storage provider that gives you the default storage class. EDA Git deployments will have some PV claims and something needs to satisfy them, right?</p> <p>There are plenty of cloud-native storage solutions to choose from, pick one that suites your needs in case your cluster doesn't have one.</p> <p>To ensure you have one:</p> <pre><code>kubectl get storageclass\n</code></pre> <pre><code>NAME                 PROVISIONER          RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\nlonghorn (default)   driver.longhorn.io   Delete          Immediate           true                   36d\nlonghorn-static      driver.longhorn.io   Delete          Immediate           true                   36d\n</code></pre>"},{"location":"software-install/non-production/on-prem-cluster/#security-context","title":"Security context","text":"<p>If you run a cluster with a Pod Security Policy in place (like in case of a Talos cluster with defaults), make sure to allow a privileged policy for the <code>eda-system</code> namespace. The <code>cert-manager-csi-driver</code> daemonset requires this to run.</p> <pre><code>kubectl create namespace eda-system\n\nkubectl label namespace eda-system \\\npod-security.kubernetes.io/enforce=privileged \\\neda.nokia.com/core-ns=eda-system\n</code></pre>"},{"location":"software-install/non-production/on-prem-cluster/#playground-repository","title":"Playground repository","text":"<p>We will drive the installation process using the instrumentation provided by the Makefile stored in the playground repository. If you haven't done so yet, clone the repository and change into it:</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; \\\ncd playground\n</code></pre> <p>If you already have the repository cloned, make sure to pull in the latest changes and remove the <code>eda-kpt</code> and <code>catalog</code> directories before proceeding.</p>"},{"location":"software-install/non-production/on-prem-cluster/#parametrizing-the-installation","title":"Parametrizing the installation","text":"<p>To no-one's surprise, the EDA installation process on an existing cluster would require us at least to skip the creation of the KinD cluster that <code>make try-eda</code> target would call otherwise. Let's do that by using the prefs.mk file that the playground repository provides and set the following variables:</p> <pre><code># KinD cluster options\n# -----------------------------------------------------------------------------|\n# Do not deploy the kind cluster\n# Uncomment this variable to perform playground installation\n# on an already available k8s cluster\nNO_KIND := yes\n\n# How do clients reach your cluster?\n#  EXT_DOMAIN_NAME can also be set to an ipv4/6 address if no domain record\n#  is present. In that case EXT_IPV4_ADDR = $(EXT_DOMAIN_NAME) or its ipv6\n#  counterpart.\n# -----------------------------------------------------------------------------|\nEXT_DOMAIN_NAME = \"eda.mydomain.com\" #(1)!\nEXT_HTTPS_PORT = \"443\"\n</code></pre> <ol> <li>Set the DNS name or IP address of the cluster' ingress/gateway endpoint.</li> </ol> <p>The key variables to set would be <code>NO_KIND := yes</code> to skip the creation of the KinD cluster and <code>EXT_DOMAIN_NAME</code> and <code>EXT_HTTPS_PORT</code> to set the ingress/gateway endpoint and port.</p>"},{"location":"software-install/non-production/on-prem-cluster/#running-the-installation","title":"Running the installation","text":"<p>With the <code>prefs.mk</code> file populated, we can simply run:</p> <pre><code>make try-eda\n</code></pre> <p>Right, the same target that would otherwise install EDA on a local development KinD cluster can be used to install EDA on an existing cluster, like the one we have in this guide. After the installation process completes, you can use the verification commands to make sure everything is up and running.</p> <p></p> <p>Now you have a fully functional EDA installation running in a real Kubernetes cluster. Congratulations </p> <p>With a real cluster, you would likely want to have a GatewayAPI or Ingress configured so that you can access the EDA UI and API. We've prepared a separate guide to help you with that.</p>"},{"location":"software-install/non-production/wsl/","title":"EDA on Windows (WSL)","text":"<p>Thanks to EDA's deployment model that uses Kubernetes, you can install EDA anywhere where a Kubernetes cluster can run. And Windows is no exception! Thanks to the Windows Subsystem Linux (aka WSL). WSL allows Windows users to run a Linux distribution as a tightly-integrated VM.</p>"},{"location":"software-install/non-production/wsl/#installation-prerequisites","title":"Installation prerequisites","text":""},{"location":"software-install/non-production/wsl/#hardware-requirements","title":"Hardware requirements","text":"<p>Before proceeding with the installation, users have to ensure they meet the hardware requirements for EDA Playground installation that are outlined in the Try EDA section:</p> <p> 8 vCPUs  16GB of RAM  30GB of SSD storage</p> <p>The CPU/Memory/Storage requirements should be available to the WSL virtual machine, and the default settings used by the WSL system may not be enough to meet those requirements.</p> <p>Users can fine tune the resource allocations for the WSL virtual machine to meet their needs. Make sure to allocate the required number of CPU/Memory/Storage resources to the WSL virtual machine.</p>"},{"location":"software-install/non-production/wsl/#wsl-version","title":"WSL version","text":"<p>An important prerequisite for installing EDA on WSL is to have WSL version at 2.5 version or later. Check what version of the WSL you have running on your Windows, by running the following command in the Windows terminal:</p> <pre><code>wsl --version\n</code></pre> <p>If the version is older than 2.5 you will need to upgrade it. At the time of this writing, the WSL version 2.5 is available as a pre-release, to update your WSL to the pre-release version, run the following:</p> <pre><code>wsl --update --pre-release\n</code></pre>"},{"location":"software-install/non-production/wsl/#wsl-distributive","title":"WSL distributive","text":"<p>Windows offers you a choice of distributives you can install on WSL. While you can choose any Linux distributive, we can recommend running the WSL-Containerlab distributive that has been preconfigured with tools like Docker engine.</p> <p>Download the <code>.wsl</code> distributive file from the releases page and simply double click on it to install WSL-Containerlab WSL distributive.</p> <p>You should be able to see \"Containerlab\" as a program in your start menu, and by opening this program you will start the distributive.</p>"},{"location":"software-install/non-production/wsl/#eda-installation","title":"EDA installation","text":"<p>Once you are in the shell of a chosen WSL distributive, proceed with the EDA installation steps as laid out on the Try EDA page.</p>"},{"location":"software-install/non-production/wsl/#uiapi-access","title":"UI/API access","text":"<p>Once the installation of the EDA Playground is complete, you can start the UI/API port forward as outlined in Step 6 from the Try EDA page.</p>"},{"location":"software-install/upgrades/","title":"Upgrading EDA","text":"<p>Assuming you have a working EDA cluster the upgrade procedure will consist of the following steps:</p> <ol> <li>Backup your existing cluster.</li> <li>Update the playground repository.</li> <li>Uninstall the existing version of EDA.</li> <li>Install the new EDA <code>kpt</code> package (on both active and standby members if running geo redundant).</li> <li>Restore your backup.</li> <li>Upgrade your applications.</li> </ol> <p>Nuances for Air-gapped and Geo-redundant clusters</p> <p>The upgrade procedure does not change based on whether you have the Internet or Air-gapped cluster. But keep in mind that with the Air-gapped installation the target release bundles should be uploaded to the Assets VM first before proceeding with an upgrade.</p> <p>In geo redundant clusters, cluster members cannot run different versions. Therefore, before the software upgrade, you must first break cluster redundancy and then restore redundancy after the upgrade. To break the redundancy, remove the <code>.spec.cluster.redundant</code> section from the <code>EngineConfig</code> resource as described later in this document.</p> <p>EDA upgrade procedure scope</p> <p>This is the Nokia EDA software upgrade procedure, it does not cover upgrading Talos Linux or Kubernetes.</p> <p>To upgrade Talos and Kubernetes perform one of the following:</p> Install a new EDA clusterUpgrade in a running EDA cluster <p>When running EDA cluster on virtual machines it might be easier to perform a new installation with the desired Talos and Kubernetes versions and restore your existing cluster backup into the new cluster:</p> <ol> <li>Take a backup of your existing EDA cluster.</li> <li>Download an <code>edaadm</code> version that comes with the desired Talos and Kubernetes versions as per the version matrix.</li> <li>Install a new EDA cluster following the installation procedure.</li> <li>Restore your backup in the new cluster and upgrade your EDA applications if necessary.</li> </ol> <p>Follow the respective Talos Linux upgrade documentation for upgrading Talos Linux and Kubernetes versions in a running EDA cluster.</p>"},{"location":"software-install/upgrades/#backing-up-your-cluster","title":"Backing up your cluster","text":"<p>Backing up your existing cluster is performed using the <code>edactl</code> CLI tool:</p> <pre><code>edactl platform backup\n</code></pre> <pre><code>Platform backup done at eda-backup-engine-config-2025-04-22_13-51-50.tar.gz\n</code></pre> <p>This will create a backup in a gzipped tarball format in the toolbox pod. The backup archive contains all the necessary information to restore your cluster.</p> <p>Copy this backup outside of your <code>eda-toolbox</code> pod - as this pod is destroyed and recreated during the upgrade. Replace the file name with the one from the <code>edactl platform backup</code> command output and run:</p> <pre><code>toolboxpod=$(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\")\n\nkubectl cp eda-system/$toolboxpod:/eda/eda-backup-engine-config-2025-04-22_13-51-50.tar.gz \\\n    /tmp/eda-backup.tar.gz\n</code></pre> <p>The backup file will be copied to the <code>/tmp/eda-backup.tar.gz</code> file on your system.</p>"},{"location":"software-install/upgrades/#updating-playground-repository","title":"Updating playground repository","text":"<p>The workflow to upgrade EDA slightly differs depending on whether you have the original playground repository present in a system that you used to install EDA originally from or not.</p> Playground repository presentPlayground repository missing <p>If you have an existing playground repository ensure it is up to date by running:</p> <pre><code>git pull --rebase --autostash -v\n</code></pre> <p>This will update the playground repository while keeping any customizations you may have done to the <code>prefs.mk</code> file.</p> <p>If the original playground repository is missing, you should clone the repository again:</p> <pre><code>git clone https://github.com/nokia-eda/playground &amp;&amp; \\\ncd playground &amp;&amp; \\\nmake download-tools\n</code></pre> <p>Identify what EDA version you are running using edactl:</p> <pre><code>edactl cluster\n</code></pre> <pre><code>Name           Address  ActivityState  BuildVersion                  CoreVersion  AvgLatency(ms)  Reachable  Synchronized\n engine-config  self     Active         v25.4.1-2504252348-g720b7d2e  v2.0.0-0                     true       true\n</code></pre> <p>In this example, we have EDA version <code>25.4.1</code>.</p> <p>Set the <code>EDA_CORE_VERSION</code> and <code>EDA_APPS_VERSION</code> variables in the <code>prefs.mk</code> file to the existing version you noted above if it is not already set. For example:</p> snippet from prefs.mk<pre><code>EDA_CORE_VERSION=25.4.1\nEDA_APPS_VERSION=25.4.1\n</code></pre> <p>Apply any other customizations required to the <code>prefs.mk</code> file as explained on the installation page.</p> <p>With the existing version set and customizations added to the <code>prefs.mk</code> file, download the EDA packages for the currently running EDA system:</p> <pre><code>make download-pkgs\n</code></pre> <pre><code>\u276f make download-pkgs\n--&gt; INFO: Updating /home/rd/nokia-eda/playground/eda-kpt\n--&gt; INFO: Updating /home/rd/nokia-eda/playground/catalog\n--&gt; INFO: /home/rd/nokia-eda/playground/eda-kpt - selected version: 25.4.1\n--&gt; INFO: /home/rd/nokia-eda/playground/eda-kpt - is at 25.4.1\n--&gt; INFO: /home/rd/nokia-eda/playground/catalog - selected version: 25.4.1\n--&gt; INFO: /home/rd/nokia-eda/playground/catalog - is at 25.4.1\n</code></pre> <p>Ensure the package inventory is in sync with your existing cluster:</p> <pre><code>make cluster-restore-inventory\n</code></pre>"},{"location":"software-install/upgrades/#uninstalling-eda-core-components","title":"Uninstalling EDA core components","text":"<p>The existing EDA core components must be uninstalled, before installing the new version.</p>"},{"location":"software-install/upgrades/#breaking-geo-redundancy-optional","title":"Breaking geo redundancy (optional)","text":"<p>If you have a geo-redundant installation, on your active cluster member, update your <code>EngineConfig</code> to remove the <code>.spec.cluster.redundant</code> section. This will break the geo redundancy and allow you to upgrade the active member without affecting the standby member.</p> <p>Changes on standby members</p> <p>Do not update the EngineConfig resource on standby members. Although stopped, if the standby members were to start, they must continue to look for the active member (and fail to do so) throughout the upgrade.</p>"},{"location":"software-install/upgrades/#pausing-npp-interactions","title":"Pausing NPP interactions","text":"<p>Place your <code>TopoNode</code> resources into <code>emulate</code> mode by setting the resource's <code>.spec.npp.mode</code> from <code>normal</code> to <code>emulate</code>.</p> <ul> <li>In this mode, EDA does not interact with targets, effectively pausing the cluster's interaction with your infrastructure.</li> <li>You can still interact with EDA and the <code>TopoNode</code> resources; changes are pushed upon switching back to <code>normal</code> mode.</li> </ul> <p>You can do this with running the following script in on your machine where you have <code>kubectl</code> configured to access your cluster:</p> <pre><code>make set-npp-mode-emulate\n</code></pre> <p>After patching script is run, verify that the <code>TopoNode</code> resources are in <code>emulate</code> mode:</p> <pre><code>kubectl get toponode -A \\\n-o custom-columns='NAMESPACE:.metadata.namespace,NAME:.metadata.name,MODE:.spec.npp.mode'\n</code></pre> <pre><code>NAMESPACE       NAME     MODE\neda-telemetry   leaf1    emulate\neda-telemetry   leaf2    emulate\neda-telemetry   leaf3    emulate\neda-telemetry   leaf4    emulate\neda-telemetry   spine1   emulate\neda-telemetry   spine2   emulate\neda             leaf1    emulate\neda             leaf2    emulate\neda             spine1   emulate\n</code></pre>"},{"location":"software-install/upgrades/#stopping-eda-platform","title":"Stopping EDA platform","text":"<p>To stop EDA components, enter the following command:</p> <pre><code>make eda-stop-core\n</code></pre> <p>This command returns no output, but will result in all Pods packaged as part of <code>eda-kpt-base</code> being stopped and removed from the cluster.</p>"},{"location":"software-install/upgrades/#uninstalling-eda-core","title":"Uninstalling EDA core","text":"<p>Proceed with EDA core components uninstallation:</p> <pre><code>make eda-uninstall-core\n</code></pre> <p>Now you should see no core components in your cluster. Check with the following command<sup>1</sup>:</p> <pre><code>kubectl get pods -n eda-system\n</code></pre> <pre><code>NAME                                  READY   STATUS    RESTARTS   AGE\ncert-manager-csi-driver-n9bwk         3/3     Running   0          95m\neda-fluentbit-b7fns                   1/1     Running   0          96m\neda-fluentd-7cd48db9c5-9pvvp          1/1     Running   0          96m\neda-git-5db9dfc7bc-mn4rw              1/1     Running   0          95m\neda-git-replica-f69b9c9f4-bngf8       1/1     Running   0          95m\neda-toolbox-6d598f6db7-thlj7          1/1     Running   0          95m\ntrust-manager-69955c46b8-bghj6        1/1     Running   0          95m\n</code></pre> Nuances for geo redundant clusters <p>For geo redundant clusters, execute the <code>edactl platform stop</code> command on both active and standby members, via their respective <code>eda-toolbox</code> Pods.</p>"},{"location":"software-install/upgrades/#updating-eda-kpt-packages","title":"Updating EDA kpt packages","text":"<p>Set the desired EDA version in the <code>prefs.mk</code> file to match the target version you want to upgrade to. For example, to choose the 25.12.1 version:</p> <pre><code>EDA_CORE_VERSION=25.12.1\nEDA_APPS_VERSION=25.12.1\n</code></pre> <p>Download the tools and packages by executing the following command:</p> <pre><code>make download-tools download-pkgs\n</code></pre>"},{"location":"software-install/upgrades/#customizing-kpt-packages","title":"Customizing kpt packages","text":"<p>If you started with a freshly cloned repository, you want to add customizations to your EDA installation by setting the variables in the <code>prefs.mk</code> file; this process is explained in details at the installation phase.</p> <p>At a minimum, ensure <code>EXT_DOMAIN_NAME</code> and <code>EXT_HTTPS_PORT</code> are set correctly in your <code>prefs.mk</code> file.</p> <p>Configure the packages downloaded for the target EDA version with the customizations you added to the <code>prefs.mk</code> file:</p> <pre><code>make eda-configure-core\n</code></pre>"},{"location":"software-install/upgrades/#installing-the-new-version-of-eda","title":"Installing the new version of EDA","text":"<p>Install the new version of EDA core components by running:</p> <pre><code>make install-external-packages eda-install-core eda-is-core-ready\n</code></pre>"},{"location":"software-install/upgrades/#restoring-your-backup","title":"Restoring your backup","text":"<p>Copy the backup file you extracted at the beginning of this procedure back into the new <code>eda-toolbox</code> pod:</p> <pre><code>toolboxpod=$(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\")\n\nkubectl -n eda-system cp /tmp/eda-backup.tar.gz \\\n  $toolboxpod:/tmp/eda-backup.tar.gz\n</code></pre> <p>Restore your cluster to its previous state by running:</p> <pre><code>edactl platform restore /tmp/eda-backup.tar.gz\n</code></pre>"},{"location":"software-install/upgrades/#upgrading-your-applications","title":"Upgrading your applications","text":"<p>A default install of EDA will install current-version applications, but your restore will have restored previous versions. These versions may be incompatible with the new version of EDA core, and must be upgraded immediately following the upgrade. The existing <code>Makefile</code> can be used to do so:</p> <pre><code>make eda-install-apps\n</code></pre>"},{"location":"software-install/upgrades/#verifying-cluster-health","title":"Verifying cluster health","text":"<p>Check the following to ensure your cluster is healthy:</p> <ul> <li>All pods are running and healthy.</li> <li>All <code>TopoNode</code> resources are in <code>normal</code> mode, and have synced with their targets.</li> <li>No transaction failures exist.</li> <li>All cluster members are synchronized.</li> </ul> <ol> <li> <p>replace with your base namespace if you modified it.\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/access-control/","title":"Access Control","text":"<p>Warning</p> <p>This page covers access control of the EDA API Server and GUI. The EDA Config Engine can also be operated via the Kubernetes API. Kubernetes RBAC configuration should be considered when securing EDA Config Engine access.</p> <p>Role-based access control (RBAC) restricts access to resources based on the user's role in your organization. EDA uses KeyCloak to authenticate users and group membership, and the EDA API server handles request authorization based on the role(s) assigned to user group(s).</p>"},{"location":"user-guide/access-control/#users-user-groups","title":"Users &amp; User Groups","text":"<p>EDA users and user groups are stored in KeyCloak. The EDA API (and GUI) exposes the most common KeyClock administrative actions including User and User Group management. In the EDA UI, you'll find Users and User Groups in the <code>System Administration</code> panel under <code>User Management</code> &gt; <code>User Management</code>.</p> <p>User passwords set by an administrator can be flagged as temporary; this will prompt the user to change the password on first login. Administrators can also perform password resets, which sends the user an email with a password reset link.</p> <p>Note</p> <p>Email server configuration is not exposed in the EDA API/GUI. This must be configured directly in KeyCloak.</p>"},{"location":"user-guide/access-control/#federations","title":"Federations","text":"<p>Federations configure users and user group synchronization with remote directories such as OpenLDAP or Active Directory. In the GUI, federation providers can be configured in the <code>System Administration</code> panel under <code>User Management</code> &gt; <code>User Management</code>.</p>"},{"location":"user-guide/access-control/#password-policy","title":"Password Policy","text":"<p>A password policy allows a system administrator to define requirements around local user password complexity &amp; brute force protection. Note that these requirements do not apply to users sourced from a remote directory. In the GUI, you'll find Users and User Groups in the <code>System Administration</code> panel under <code>User Management</code> &gt; <code>Password Policy</code>.</p>"},{"location":"user-guide/access-control/#roles","title":"Roles","text":"<p>EDA <code>Cluster Roles</code> and <code>Roles</code> define which permissions the users have for the EDA API/GUI<sup>1</sup>.</p> <p><code>Roles</code> define permissions within a specific namespace, whereas <code>Cluster Roles</code> apply to all namespaces.</p> <p>Non-namespaced API endpoints can only be enforced by <code>Cluster Roles</code>. This includes cluster-wide resources (e.g. httpproxies), EDA administrative APIs, transaction results, etc. Basically, any API that doesn't specify a namespace in the path or payload is enforced by <code>Cluster Roles</code>.</p> <p>The EDA UI allows you to switch between 'All Namespaces' and specific namespace views. In the 'All Namespaces' view, requests use cluster-wide APIs which require ClusterRole permission. Users with permission only for specific namespaces will not see their resources in the 'All Namespaces' view.</p>"},{"location":"user-guide/access-control/#access-rule-types","title":"Access Rule Types","text":"<p>Both <code>ClusterRoles</code> &amp; <code>Roles</code> provide the following rule types:</p> <ul> <li> <p>Resource Rules controls EDA resource and workflow permissions using Group-Version-Kind (GVK) semantics. Each Resource Rule can include one or more API Groups in group/version format (e.g. \"core.eda.nokia.com/v1\") and one or more Resources (i.e. Kind). Either can be an exact match or wildcard (<code>*</code>).</p> </li> <li> <p>Table Rules provides a fine-tuning of permissions for queries to EDB. Table Rules support wildcarding of the final EDA path segment (<code>.*</code>) or multiple EDA path segments (<code>.**</code>)</p> </li> <li> <p>URL Rules define permission for EDA API endpoints based on their URL path. URL Rules support wildcarding of the final URL segment (<code>/*</code>) or multiple URL segments (<code>/**</code>). URL Rule permission is not required for API endpoints which are Resource Rule or Table Rule enforced.</p> </li> </ul>"},{"location":"user-guide/access-control/#requests-matching-multiple-rules","title":"Requests Matching Multiple Rules","text":"<p>Rules in EDA are additive. If a request matches both a <code>read</code> and <code>read write</code> rule, the user is granted <code>read write</code> access. If no rule is matched, the request is implicitly denied.</p> <p><code>None</code> permissions act as an override. If there is a matching <code>none</code> rule, access is always denied.</p> <p>Avoid <code>None</code> Rules</p> <p>If resource/table/URL access is not required for a role, the best practice is to not include a matching rule for that resource/table/URL. This ensures that users with multiple roles receives all required permissions.</p>"},{"location":"user-guide/access-control/#assigning-roles-to-users","title":"Assigning Roles to Users","text":"<p>Roles are associated to Users via User Groups. A User can be part of multiple User Groups, and each User Group may have multiple Roles.</p>"},{"location":"user-guide/access-control/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"user-guide/access-control/#transaction-result-access","title":"Transaction Result Access","text":"<p>Access to Transaction results is based on the user's access to the input resources of that transaction. If the user has read permission for all the input resources of a transaction, they can list all changed resources (both input and derived) and view the resource diffs. If the user has read permission for none or some of the input resources, they can not list any derived resources or view their diffs. Access to Node Configuration diffs must be opted-in using a urlRule. This is because the Node Configuration diff API returns the full node config, and not limited to the scope of the transaction.</p> <p>To revert a transaction, the user must have readWrite permission for all input resources of the transaction. To restore the EDA cluster to a specific transaction, the user must have readWrite permission to the restore API from a ClusterRole URL Rule. Restore is a powerful action which should be limited to trusted administrators.</p>"},{"location":"user-guide/access-control/#workflow-access","title":"Workflow Access","text":"<p>Just like EDA Resources, EDA Workflows follow the Kubernetes Group-Version-Kind (GVK) resource model. resourceRules grant read and readWrite permission to workflows.</p> <p>Additionally, users inherit access to subflows based on their access to the top-level parent flow. For example, a <code>DeployImage</code> workflow creates <code>Ping</code> subflows during it's pre and post check stages. If user A has read permission to the 'DeployImage' workflow definition they will be able to read the subflow results even if they do not have access to the <code>Ping</code> workflow definition.</p>"},{"location":"user-guide/access-control/#topology-access-in-specific-namespaces","title":"Topology Access in Specific Namespaces","text":"<p>Topology diagrams and their overlays are defined cluster-wide in EDA, but the state data which populates the topology diagrams is namespaced. Therefore, to view topologies in the UI for specific namespaces a combination of ClusterRoles and Roles is required.</p> ClusterRole - Physical topology <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: ClusterRole\nmetadata:\n  name: topology-definitions\n  namespace: eda-system\nspec:\n  description: Access descriptions of physical topology and its overlays\n  resourceRules:\n    - apiGroups:\n        - topologies.eda.nokia.com/v1alpha1\n      permissions: read\n      resources:\n        - topologygroupings\n  tableRules: []\n  urlRules:\n    - path: /core/topology/v1\n      permissions: read\n    - path: /core/topology/v1/topologies.eda.nokia.com_v1alpha1_physical\n      permissions: read\n    - path: /core/topology/v1/topologies.eda.nokia.com_v1alpha1_physical/overlay\n      permissions: read\n    - path: /core/topology/v1/topologies.eda.nokia.com_v1alpha1_physical/groupings\n      permissions: read\n</code></pre> Role - Physical topology <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: Role\nmetadata:\n  name: ns-topo\n  namespace: eda\nspec:\n  description: Access physical topology state in namespace 'eda'\n  urlRules:\n    - path: /core/topology/v1/topologies.eda.nokia.com_v1alpha1_physical/state\n      permissions: readWrite\n  resourceRules: []\n  tableRules: []\n</code></pre>"},{"location":"user-guide/access-control/#more-example-roles","title":"More Example Roles","text":"ClusterRole - Read only everything <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: ClusterRole\nmetadata:\n  name: readonly\n  namespace: eda-system\n  labels: null\nspec:\n  description: Read only for everything\n  resourceRules:\n    - apiGroups:\n      - '*'\n      permissions: read\n      resources:\n        - '*'\n  tableRules:\n    - path: .**\n      permissions: read\n  urlRules:\n    - path: /**\n      permissions: read\n</code></pre> ClusterRole - Read and write fabric resources and read-only related resources <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: ClusterRole\nmetadata:\n  name: fabric\n  namespace: eda-system\n  labels: null\nspec:\n  description: Read and Write for Fabrics and read-only for related resources\n  resourceRules:\n    - apiGroups:\n      - fabrics.eda.nokia.com/v1alpha1\n      permissions: readWrite\n      resources:\n        - '*'\n    - apiGroups:\n        - routing.eda.nokia.com/v1alpha1\n        - protocols.eda.nokia.com/v1alpha1\n        - core.eda.nokia.com/v1\n      permissions: read\n      resources:\n        - '*'\n  urlRules:\n    - path: /openapi/**\n      permissions: read\n  tableRules: []\n</code></pre> ClusterRole - run queries and update alarms (ack/delete/suppress/etc) <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: ClusterRole\nmetadata:\n  name: queryandalarms\n  labels: null\n  namespace: eda-system\nspec:\n  description: 'Permission to run queries and update alarms (ack/delete/suppress/etc)'\n  resourceRules: []\n  tableRules:\n    - path: .**\n      permissions: read\n  urlRules:\n    - path: /core/alarm/**\n      permissions: readWrite\n</code></pre> <ol> <li> <p>EDA <code>ClusterRoles</code> &amp; <code>Roles</code> are not the same as Kubernetes <code>ClusterRoles</code> &amp; <code>Roles</code>. Kubernetes RBAC controls are not used by the EDA API.\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/allocation-pools/","title":"Allocation Pools","text":"<p>There comes a time where every automation platform needs to allocate addresses and indexes \u2014 Whether it\u2019s an IP address, CIDR subnet, VLAN ID, subinterface index, autonomous system number, or more.</p> <p>EDA provides users and app developers a simple framework for defining and consuming allocation pools. Behind the scenes EDA ConfigEngine works to ensure:</p> <ul> <li>Deterministic allocations \u2014 If provided the same allocation input, the value of any previous allocation will be returned. No surprises!</li> <li>Persist allocations \u2014 Restarting the platform does not result in any re-indexing.</li> <li>Implicit freeing of allocations \u2014 If a resource is updated and no longer needs an allocation, it\u2019s freed up for something else.</li> </ul> <p>All of that while supporting the resizing of allocation pools, whether you need to grow or shrink them!</p>"},{"location":"user-guide/allocation-pools/#allocation-pool-types","title":"Allocation Pool Types","text":"<p>EDA offers four types of allocation pools:</p> <ol> <li>Indices<ul> <li>Specify a size and starting value</li> <li>Return an integer on allocation</li> </ul> </li> <li>IP Addresses<ul> <li>Specify an IPv4 or IPv6 subnet including mask in CIDR format (e.g. <code>192.0.2.0/24</code>)</li> <li>Return an address from the subnet on allocation, without any mask information (e.g. <code>192.0.2.1</code>)</li> </ul> </li> <li> <p>IP Addresses + Masks</p> <ul> <li>Specify an IPv4 or IPv6 subnet including mask in CIDR format (e.g. <code>192.0.2.0/24</code>)</li> <li>Return an address from the subnet on allocation, with mask information (e.g. <code>192.0.2.1/24</code>) <p>By default, EDA will not allocate the first and last address in the subnet.  </p> <ul> <li>To enable allocation of the first address, set 'Allocate Network Address' to True.</li> <li>To enable allocation of the last address, set 'Allocate Broadcast Address' to True.</li> </ul> </li> </ul> </li> <li> <p>Subnets</p> <ul> <li>Specify an IPv4 or IPv6 subnet including mask in CIDR format (e.g. <code>192.0.2.0/24</code>), and a subnet length (e.g. <code>31</code>)</li> <li>Return a subnet of the specified length from the provided subnet on allocation, with mask information (e.g. <code>192.0.2.8/31</code>)</li> </ul> </li> </ol>"},{"location":"user-guide/allocation-pools/#allocation-pool-segments-and-next-allocation","title":"Allocation Pool Segments and Next Allocation","text":"<p>An allocation pool consists of a set of segments. You can think of a segment as a block of indexes \u2014 some indexes are taken (allocated) and some are free (either because they were freed or have yet to be used).</p> <p>In a fresh system where no resources has been deleted, you would see allocations start in the first segment at index 0, and proceeding forwards by 1 for each allocation (i.e allocations within a segment are sequential and consecutive.)</p> <p>Let\u2019s look at an example. Suppose you have an index pool with two segments:</p> <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: IndexAllocationPool\nmetadata:\n  name: example\n  namespace: eda\nspec:\n  segments:\n  - start: 0\n    size: 5\n  - start: 100\n    size: 5\n</code></pre> <p>Initially, the pool would look like this (where <code>X</code> represents an allocation):</p> <pre><code>| 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|---|---|---|---|---|-----|-----|-----|-----|-----|\n|   |   |   |   |   |     |     |     |     |     |\n</code></pre> <p>Assuming a resource was created and the config script requests one index, the resulting pool would look like this:</p> <pre><code>| 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|---|---|---|---|---|-----|-----|-----|-----|-----|\n| X |   |   |   |   |     |     |     |     |     |\n</code></pre> <p>If the user created five more instances of the resource, the resulting pool would look like:</p> <pre><code>| 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|---|---|---|---|---|-----|-----|-----|-----|-----|\n| X | X | X | X | X |  X  |     |     |     |     |\n</code></pre> <p>Now assume the resource driving the second instance of the script was deleted (which would result in an implicit free), the pool would look like:</p> <pre><code>| 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|---|---|---|---|---|-----|-----|-----|-----|-----|\n| X |   | X | X | X |  X  |     |     |     |     |\n</code></pre> <p>It is hopefully obvious that the next resource to use the same pool would get the index 1, rather than index 101. A more interesting exercise at this point is to introduce a new segment at the start of the pool:</p> <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: IndexAllocationPool\nmetadata:\n  name: example\n  namespace: eda\nspec:\n  segments:\n  - start: 200\n    size: 5\n  - start: 0\n    size: 5\n  - start: 100\n    size: 5\n</code></pre> <p>The resulting pool would now look like:</p> <pre><code>| 200 | 201 | 202 | 203 | 204 | 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|-----|-----|-----|-----|-----|---|---|---|---|---|-----|-----|-----|-----|-----|\n|     |     |     |     |     | X |   | X | X | X |  X  |     |     |     |     |\n</code></pre> <p>Note that if any of the previous config scripts ran for any reason, they would get their existing allocations, as they have registered keys against them.</p> <p>If a new allocation was performed now, it would be drawn from the new segment:</p> <pre><code>| 200 | 201 | 202 | 203 | 204 | 0 | 1 | 2 | 3 | 4 | 100 | 101 | 102 | 103 | 104 |\n|-----|-----|-----|-----|-----|---|---|---|---|---|-----|-----|-----|-----|-----|\n|  X  |     |     |     |     | X |   | X | X | X |  X  |     |     |     |     |\n</code></pre> <p>Adding or rearranging segments does not result in any allocation changes.</p> <p>Now let's look at what happens when you shrink a pool by removing a segment:</p> <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: IndexAllocationPool\nmetadata:\n  name: example\n  namespace: eda\nspec:\n  segments:\n  - start: 200\n    size: 5\n  - start: 100\n    size: 5\n</code></pre> <p>Allocations in the removed segment (indexes 0, 2, 3, and 4) are freed, and all config scripts dependent on this pool will rerun. The resulting pool would look like:</p> <pre><code>| 200 | 201 | 202 | 203 | 204 | 100 | 101 | 102 | 103 | 104 |\n|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|\n|  X  |  X  |  X  |  X  |  X  |  X  |     |     |     |     |\n</code></pre> <p>Note that index 100 was not impacted by the change, nor was index 200.</p> <p>While this example covers an IndexAllocationPool, the principles are the same across all pool types \u2014 the only difference is how you define the segment ranges.</p>"},{"location":"user-guide/allocation-pools/#segment-pre-allocations-reservations","title":"Segment (Pre-)Allocations &amp; Reservations","text":"<p>Do you want to use allocation pools, but there are scenarios where you need to take the wheel and decide which IP address goes where? 'Allocations' and 'Reservations' options are available in all allocation pool segments to give the manual control you need.</p> <ul> <li> <p>Allocations predefine an allocation against a given key.</p> </li> <li> <p>Reservations block a range within the segment, preventing it from being allocated by EDA.</p> </li> </ul> <p>Note</p> <p>The allocation mechanism is also how a default gateway can be provided via a pool and retrieved via an EDA app.</p>"},{"location":"user-guide/allocation-pools/#allocation-scope","title":"Allocation Scope","text":"<p>Not every allocation needs to be global. For example, subinterface indexes in SR Linux are locally significant to their interface. A user shouldn't need to define separate allocation pools for each interface in the network.</p> <p>This is where allocation scope comes in!</p> <p>In EDA, every allocation pool supports scope. Think of the allocation pool resource as a template and the scope as an instance of that template. By default, allocations use the 'global' scope but an app developer can define a scope based on their needs \u2014 whether it\u2019s per interface, per node, or something entirely different. The possibilities are endless!</p>"},{"location":"user-guide/containerlab-integration/","title":"Containerlab Integration","text":"<p>To facilitate end-to-end testing and validation of configuration changes, EDA comes equipped with its own multi vendor network emulation engine abbreviated as CX. CX is a highly scalable network emulation platform that powers EDA's Digital Twin capabilities.</p> <p>Acknowledging that EDA CX is a new network emulation platform that is still in the process of maturing, we wanted to offer a way to integrate EDA with multitude of existing network topologies built with Containerlab.</p> <p>In this section we cover how to integrate EDA with a lab built with Containerlab in a fully automated way first, and then explain how to do this manually with a deep dive on things involved in the onboarding process. To keep things practical, we will take a real lab built with Containerlab - srl-labs/srlinux-vlan-handling-lab and integrate it with EDA.</p> VLAN handling lab <p>This tiny lab consists of two SR Linux nodes and two clients connected to it which is all we need to demonstrate the integration. Let's deploy it like any other containerlab topology:</p> <pre><code>sudo containerlab deploy -t srl-labs/srlinux-vlan-handling-lab #(1)!\n</code></pre> <ol> <li>The lab will be cloned to the current working directory and deployed.</li> </ol> <p>Containerlab, SR Linux, and EDA versions</p> <p>For a successful integration you need to ensure the following minimal version requirements:</p> <ul> <li>Containerlab 0.62.2</li> <li>SR Linux 24.10.1</li> <li>EDA 24.12.1</li> </ul> <p>This article was validated using the following versions:</p> <ul> <li>Containerlab: 0.62.2</li> <li>SR Linux: 24.10.1</li> <li>EDA: 24.12.1</li> </ul> <p>Our end game is to install EDA and integrate it with the Containerlab topology so that we could manage the lab nodes using EDA. The integration scenario is depicted in the diagram below.</p>"},{"location":"user-guide/containerlab-integration/#installing-eda","title":"Installing EDA","text":"<p>The reason we started this section with a mention of EDA CX is because as of EDA v24.12.1 the platform is installed by default with the CX engine enabled. What this means is that EDA will spin up virtual simulator nodes using the CX engine for every topology node. To let EDA manage external nodes (either real hardware or virtual nodes spawned outside of EDA) we need to provide a specific installation option.</p> <p>Clone the EDA Playground repository if you haven't already and uncomment the following line in the preferences (<code>prefs.mk</code>) file :</p> <pre><code>SIMULATE = false\n</code></pre> <p>And start deploying EDA:</p> <pre><code>make try-eda\n</code></pre> <p>With the disabled simulation mode, EDA will be installed without the <code>eda-cx</code> deployment present and no topology loaded.</p> <p>License required</p> <p>Unfortunately, the nodes spawned outside of EDA CX are currently considered as hardware nodes and are licensed. Even the virtual SR Linux nodes that are spawned by Containerlab </p> <p>You can reach out to the EDA PLM team member in discord to check if they can help acquire one.</p> <p>If you have a license, apply it to your cluster like this:</p> License manifestapply command eda-license.yaml<pre><code>apiVersion: core.eda.nokia.com/v1\nkind: License\nmetadata:\n  name: eda-license\n  namespace: eda-system\nspec:\n  enabled: true\n  data: \"YoUrLiCeNsEDaTa\"\n</code></pre> <pre><code>kubectl apply -f eda-license.yaml\n</code></pre>"},{"location":"user-guide/containerlab-integration/#reachability-requirements","title":"Reachability requirements","text":"<p>For EDA to manage nodes spawned outside of the Kubernetes cluster it is deployed in, it must be able to reach them. In this tutorial we are installing EDA in the KinD cluster that comes as a default with the EDA Playground installation; so our EDA installation will be running alongside the Containerlab topology on the same host machine.</p> <p>Yet, even though KinD and Containerlab are running on the same host, these two environments are isolated from each other as prescribed by the Docker networking model and enforced by iptables. In order to allow KinD cluster to communicate with Containerlab nodes Containerlab 0.62.2 release installs allowing iptables rules to the <code>DOCKER-USER</code> chain for v4 and v6 families.</p> <p>To confirm that the communication is indeed allowed, we can take a management IP of one of our Containerlab nodes and ping it from the <code>eda-bsvr</code> pod that is one of the pods requiring connectivity with the Containerlab nodes.</p> <p>Let's issue a ping from the <code>eda-bsvr</code> pod to the <code>clab-vlan-srl1</code> node:</p> copy-paste command to srl1<pre><code>kubectl -n eda-system exec -i \\\n$(kubectl -n eda-system get pods -l eda.nokia.com/app=bootstrapserver \\\n-o=jsonpath='{.items[*].metadata.name}') \\\n-- ping -c 2 $(sudo docker inspect -f '{{.NetworkSettings.Networks.clab.IPAddress}}' clab-vlan-srl1)\n</code></pre> <p>If you managed to copy-paste things right, you should see packets happily flying between EDA and Containerlab nodes. OK, now, with the containerlab topology running, EDA installed and connectivity requirements satisfied, we can proceed with the actual integration.</p>"},{"location":"user-guide/containerlab-integration/#automated-integration","title":"Automated integration","text":"<p>In pursue of a one-click integration experience, we have created the <code>clab-connector</code> CLI tool that automates the integration process.</p>"},{"location":"user-guide/containerlab-integration/#installation","title":"Installation","text":"<p>The <code>clab-connector</code> tool is easily installable using <code>uv</code> package manager, therefore start with installing <code>uv</code> and then <code>clab-connector</code>:</p> Install clab-connector (requires uv)Install uv <pre><code>uv tool install git+https://github.com/eda-labs/clab-connector.git\n</code></pre> <p>If you wanted to save a click, here is a quick one-liner installer from uv website:</p> for Linux and macOS<pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre>"},{"location":"user-guide/containerlab-integration/#usage","title":"Usage","text":"<p>Clab-connector leverages Kubernetes API, EDA API and Containerlab topology export data to automate the integration process. Consequently, the host machine where the <code>clab-connector</code> tool is installed must have access to the kube config file, EDA API endpoint and Containerlab's <code>topology-data.json</code><sup>1</sup> file.</p>"},{"location":"user-guide/containerlab-integration/#integrate","title":"Integrate","text":"<p>If you haven't changed any of the default credentials in your EDA installation, you can integrate EDA with Containerlab as simply as:</p> <pre><code>clab-connector integrate \\\n--eda-url https://your.eda.host \\\n-t ~/path/to/your-lab/clab-yourlab/topology-data.json #(1)!\n</code></pre> <ol> <li>The <code>topology-data.json</code> file is located in the Containerlab Lab Directory, which is created next to the lab's topology file.</li> </ol> <p>If you happen to change the default user credentials, you can provide them with <code>--eda-user</code> and <code>--eda-password</code> flags. Run <code>clab-connector integrate --help</code> to see all the available flags.</p> <p>The connector tool will create a new EDA namespace matching the Containerlab lab name and will create the required resources in it. This allows you to managed as many distinct labs as you want, without having clashing resources between them.</p>"},{"location":"user-guide/containerlab-integration/#remove","title":"Remove","text":"<p>To remove the EDA integration, run:</p> <pre><code>clab-connector remove \\\n--eda-url https://your.eda.host \\\n-t ~/path/to/your-lab/clab-yourlab/topology-data.json\n</code></pre> <p>This will remove the previously created namespace and all the resources inside it.</p>"},{"location":"user-guide/containerlab-integration/#manual-integration","title":"Manual integration","text":"TLDR <p>To integrate SR Linux nodes spawned by Containerlab with EDA in the manual mode you need to:</p> <ol> <li>Apply an EDA license to be able to integrate with SR Linux nodes spawned outside of EDA CX</li> <li>optional Change the default NodeUser resource to use the <code>NokiaSrl1!</code> password</li> <li>Create a NodeProfile resource with the OS/version/yang fields set to the corresponding values</li> <li>Create a TopoNode resource for each SR Linux node</li> <li>Create an Interface resource per each endpoint of SR Linux nodes.</li> <li>Create a TopoLink resource for each link referencing the created Interface resources</li> </ol> Copy/Paste snippets <p>If you want to quickly onboard SR Linux nodes after spawning the srl-labs/srlinux-vlan-handling-lab containerlab topology, you can copy paste the following snippet entirely in your terminal.</p> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: NodeUser\nmetadata:\n  name: admin\n  namespace: eda\nspec:\n  groupBindings:\n    - groups:\n        - sudo\n      nodeSelector:\n        - \"\"\n  username: admin\n  password: NokiaSrl1!\n  sshPublicKeys:\n    # an optional list of ssh public keys for the node user\n    # - \"ssh-ed25519 AAAAC3NzaC1lZYOURKEYHEREYOURKEYHEREYOURKEYHEREYOURKEYHEREHDLeDteKN74\"\n\n$(ssh-add -L | awk '{print \"    - \\\"\"$0\"\\\"\"}')\nEOF\n\ncat &lt;&lt; 'EOF' | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: NodeProfile\nmetadata:\n  name: srlinux-clab-24.10.1\n  namespace: eda\nspec:\n  operatingSystem: srl\n  version: 24.10.1\n  versionPath: .system.information.version\n  versionMatch: v24\\.10\\.1.*\n  images:\n    - image: fake.bin\n      imageMd5: fake.bin.md5\n  port: 57410\n  yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n  onboardingUsername: admin\n  onboardingPassword: NokiaSrl1!\n  nodeUser: admin\n  annotate: true\n\nEOF\n\ncat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl1\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: $(sudo docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' clab-vlan-srl1)\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl2\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: $(sudo docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' clab-vlan-srl2)\nEOF\n\ncat &lt;&lt; 'EOF' | kubectl apply -f -\n#########################\n#### srl1 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl1\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl1-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl1\n  type: interface\n\n#########################\n#### srl2 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl2-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl2\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl2-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl2\n  type: interface\n\nEOF\n\ncat &lt;&lt; 'EOF' | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-client1\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl1-ethernet-1-1\n      remote:\n        node: clab-vlan-client1\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-srl2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl1-ethernet-1-10\n      remote:\n        node: clab-vlan-srl2\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl2-ethernet-1-10\n      type: interSwitch\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl2-client2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl2\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl2-ethernet-1-1\n      remote:\n        node: clab-vlan-client2\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n\nEOF\n</code></pre> <p>Even though automated integration makes the integration so easy, it is the manual integration that explains the moving parts and the underlying concepts. By completing this section you will get a decent understanding of the onboarding process and will breeze through the automated integration later on.</p>"},{"location":"user-guide/containerlab-integration/#sr-linux-configuration","title":"SR Linux configuration","text":"<p>Our goal is to have EDA to discover and onboard the SR Linux nodes running as part of the Containerlab topology. When Containerlab<sup>2</sup> spins up the SR Linux nodes it will add two EDA-specific gRPC servers to the default config; these servers will allow EDA to discover and later manage the nodes.</p> <pre><code>sudo docker exec clab-vlan-srl1 sr_cli info system grpc-server 'eda*'\n</code></pre> <pre><code>    system {\n        grpc-server eda-discovery {\n            admin-state enable\n            rate-limit 65535\n            session-limit 1024\n            metadata-authentication true\n            default-tls-profile true\n            network-instance mgmt\n            port 50052 #(1)!\n            services [\n                gnmi\n                gnsi\n            ]\n        }\n# snipped for brevity\n        grpc-server eda-mgmt {\n            ### Unable to retrieve TLS profile 'EDA'\n            admin-state enable\n            rate-limit 65535\n            session-limit 1024\n            metadata-authentication true\n            tls-profile EDA #(2)!\n            network-instance mgmt\n            port 57410 #(3)!\n            services [\n                gnmi\n                gnoi\n                gnsi\n            ]\n        }\n    }\n</code></pre> <ol> <li>EDA expects the discovery gRPC server to listen on port 50052.</li> <li>The <code>EDA</code> TLS profile is a hardcoded name of the TLS profile that the EDA bootstrap server will install during the onboarding process. Since this profile does not exist until the onboarding process is completed, the annotation says that the profile with this name can not be retrieved. This annotation will be removed once the onboarding process is completed and the TLS profile is created by the bootstrap server.</li> <li>Since Containerlab already sets up the <code>mgmt</code> gRPC server on port 57400 for the SR Linux nodes, the additional <code>eda-mgmt</code> gRPC server is configured to listen on a custom port 57410 that references the <code>EDA</code> TLS profile.</li> </ol> <p>You will find the <code>eda-discovery</code> grpc server that is used by EDA to discover the node and setup the TLS certificates and the <code>eda-mgmt</code> grpc server that is used by EDA to manage the node after the initial discovery using the provisioned TLS certificates.</p>"},{"location":"user-guide/containerlab-integration/#toponode","title":"TopoNode","text":"<p>It is time to let EDA know about the Containerlab topology and onboard the two SR Linux nodes that are running under the names <code>clab-vlan-srl1</code> and <code>clab-vlan-srl2</code>. But how do we do it?</p> <p>It all starts with the TopoNode resource. The TopoNode resource is part of the EDA core and describes an abstracted node in the topology. In order to let EDA know about a node it needs to manage, we need to create a TopoNode resource per each SR Linux node in our Containerlab topology.</p> <p>TopoNode's Custom Resource Definition (CRD) documentation describes the fields a resource of this type might have, but we need only a subset of them. Here are our two TopoNode resources named according to the container names of our SR Linux nodes in the topology:</p> <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl1\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: # IP address of the clab-vlan-srl1 node\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl2\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: # IP address of the clab-vlan-srl2 node\n</code></pre> <p>If you feel lost, don't worry, we will explain what these fields mean in a moment.</p>"},{"location":"user-guide/containerlab-integration/#metadata","title":"Metadata","text":"<p>Following the Kubernetes Resource Model (KRM), we specify the <code>apiVersion</code> and <code>kind</code> of the resource we are describing in YAML format. The TopoNode resource belongs to the <code>core.eda.nokia.com</code> API group of the <code>v1</code> version and the resource kind is - <code>TopoNode</code>.</p> <p>Next comes the metadata section. There, we specify the desired resource name. The name of the TopoNode resource does not have to match anything specific, but to keep things consistent with the Containerlab topology, we will use the corresponding container name of the SR Linux node.</p> <p>In the labels section we need to add a label that describes how the node TLS certificates should be handled. EDA is a secure-first platform where all the communications are secured by default, and interactions with the networking nodes are no exception. With the <code>eda.nokia.com/security-profile: managed</code> label we tell EDA that it needs to manage the certificate lifecycle for the node. Without going into the details, this mode ensures fully automated certificate management for the node.</p> <p>EDA Playground installation comes with a pre-created user namespace called <code>eda</code>. This pre-provisioned namespace should contain all user-provided resources, like TopoNode. Hence, we set the namespace to <code>eda</code> in the <code>metadata</code> section.</p>"},{"location":"user-guide/containerlab-integration/#system-information","title":"System information","text":"<p>Jumping over to the <code>.spec</code> object of the TopoNode resource, we can spot a block with System Information data:</p> <pre><code>operatingSystem: srl\nplatform: 7220 IXR-D2L\nversion: 24.10.1\n</code></pre> <ul> <li>The <code>operatingSystem</code> field is set to <code>srl</code> for Nokia SR Linux nodes we about to get onboarded.</li> <li>And the <code>platform</code> field should contain the SR Linux platform name in its full text form. Since in the Containerlab topology we did not specify the SR Linux platform type, it defaults to 7220 IXR-D2L</li> <li>The <code>version</code> field must match the version of the SR Linux container image we are using in our topology.</li> </ul>"},{"location":"user-guide/containerlab-integration/#address","title":"Address","text":"<p>Since our SR Linux nodes were deployed with Containerlab, EDA can't possibly know the nodes IP addresses. We need to provide this information, and TopoNode resource has a field for that:</p> <pre><code>productionAddress:\n  ipv4: # IP address of the clab-vlan-srl1 node\n</code></pre> <p>We chose to use the IPv4 address assigned by Containerlab, but IPv6 addresses are also supported. EDA will use this IP address to reach the node and start the onboarding process once the TopoNode resource is created in cluster.</p> <p>Providing the production address information disables the whole DHCP/ZTP workflow at the bootstrap server side, as the node is considered to be bootstrapped by an external system (like Containerlab).</p> <p>Bootstrap server in this case will just ensure that the node is reachable and setup a valid TLS certificate.</p>"},{"location":"user-guide/containerlab-integration/#node-profile","title":"Node profile","text":"<p>The last piece in the TopoNode resource that we must set is a NodeProfile.</p> <pre><code>nodeProfile: srlinux-clab-24.10.1\n</code></pre> <p>The NodeProfile, surprise-surprise, defines the profile of the node that a particular TopoNode resource is going to use.</p> <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: NodeProfile\nmetadata:\n  name: srlinux-clab-24.10.1\n  namespace: eda\nspec:\n  operatingSystem: srl\n  version: 24.10.1\n  versionPath: .system.information.version\n  versionMatch: v24\\.10\\.1.*\n  images:\n    - image: fake.bin\n      imageMd5: fake.bin.md5\n  port: 57410\n  yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n  onboardingUsername: admin\n  onboardingPassword: NokiaSrl1!\n  nodeUser: admin\n  annotate: true\n</code></pre> <p>It contains more details about the node transport parameters, imaging information and YANG schema. Let's cover the most important fields of this resource.</p>"},{"location":"user-guide/containerlab-integration/#os-and-version","title":"OS and version","text":"<p>The first thing you see in the NodeProfile spec is the OS and version information. It has to match the OS and version provided in the associated TopoNode resource. Besides that, it also has to specify the path in JSPath notation to use to fetch the version value from the node and the regex to match against the fetched version value.</p> <pre><code>operatingSystem: srl\nversion: 24.10.1\nversionPath: .system.information.version\nversionMatch: v24\\.10\\.1.*\n</code></pre>"},{"location":"user-guide/containerlab-integration/#image","title":"Image","text":"<p>When a hardware node running SR Linux uses the ZTP process, the Bootstrap server provides a ZTP script that contains the initial bootstrap configuration and the target image URL. The URL that the Bootstrap server uses is provided with the <code>.spec.images[].image</code> field of the NodeProfile resource.</p> <pre><code>images:\n  - image: fake.bin\n    imageMd5: fake.bin.md5\n</code></pre> <p>You might ask why we need that for a Containerlab-spawned virtual node that does not need to be imaged? Good question. Since this field is marked as required in the CRD we have to provide some value but for the virtual nodes we can provide a dummy URL. This is exactly what we did in our NodeProfile resource.</p>"},{"location":"user-guide/containerlab-integration/#grpc-port","title":"gRPC port","text":"<p>With the <code>port</code> field we specify the gRPC port number for the server that EDA will use to manage the node. If you remember, in the SR Linux configuration section we mentioned that Containerlab adds <code>eda-mgmt</code> gRPC server listening on port 57410. This port is set in the NodeProfile resource and EDA will use it to connect to the node once the onboarding process is done.</p>"},{"location":"user-guide/containerlab-integration/#yang-schema","title":"YANG schema","text":"<p>One of the EDA's core features is its ability to validate the intents before applying them to the nodes. The validation piece is crucial for the mission-critical networks and EDA takes care of that.</p> <p>To validate the intents, no matter how complex they are, EDA needs to know the YANG schema of the node it talks to. This requirement makes YANG schema a mandatory field in the NodeProfile resource; it should point to an HTTP location where EDA can fetch the YANG schema. We call this YANG bundle a Schema Profile.</p> <pre><code>yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n</code></pre> <p>As part of the EDA Playground installation, the schema profile for SR Linux 24.10.1 version is already provided and is server by the EDA's Artifact server.</p>"},{"location":"user-guide/containerlab-integration/#user","title":"User","text":"<p>EDA uses gNMI protocol to communicate with the nodes, starting from discovery and onboarding. The gNMI server authenticates the client using the username and password pair provided in the gRPC metadata.</p> <p>For the onboarding step to be successful, a pair of credentials needs to be provided via the <code>onboardingUsername</code> and <code>onboardingPassword</code> fields.</p> <pre><code>onboardingUsername: admin\nonboardingPassword: NokiaSrl1!\n</code></pre> <p>When EDA will reach to the node's discovery gRPC server over the predefined <code>50052</code> port it will supply this credentials in the gRPC metadata. The provided credentials must be valid and since we are using the default <code>admin</code> credentials in these fields we can rest assured that the authentication will succeed.</p> <p>But the onboarding user might not be the same as the one used for the ongoing management of the node. When EDA creates the Node Push/Pull (NPP) pods that are responsible for the configuration push and pull operations, these pods will use the credentials of a user defined in the NodeUser resource that we refer to in the NodeProfile as well:</p> <pre><code>nodeUser: admin\n</code></pre> <p>The <code>admin</code> NodeUser resource has been created as part of the EDA Playground installation, but it uses a non-default SR Linux password, that we would like to change. To do that, we will craft a resource manifest that uses the default <code>NokiaSrl1!</code> password, as well as add a public key<sup>3</sup> to enable typing-free SSH access.</p> <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: NodeUser\nmetadata:\n  name: admin\n  namespace: eda\nspec:\n  groupBindings:\n    - groups:\n        - sudo\n      nodeSelector:\n        - \"\"\n  username: admin\n  password: NokiaSrl1!\n  sshPublicKeys:\n    # an optional list of ssh public keys for the node user\n    # - \"ssh-ed25519 AAAAC3NzaC1lZYOURKEYHEREYOURKEYHEREYOURKEYHEREYOURKEYHEREHDLeDteKN74\"\n</code></pre> <p>The NodeUser resource references the NodeGroup resource that contains the AAA parameters this user should inherit.</p>"},{"location":"user-guide/containerlab-integration/#topolink","title":"TopoLink","text":"<p>If we were to apply the TopoNode resource right now, we would end up getting the following topology diagram in EDA UI:</p> <p></p> <p>There is obviously a piece missing - the topology doesn't have any links! And the reason is simple - we haven't defined any topology link resources.</p> <p>The TopoLink resource is responsible for defining the topology links. As the CRD description says:</p> <p>TopoLink represents a logical link between two TopoNodes. It may include more than one physical link, being used to represent a LAG or multihomed link.</p> <p>Looking at our lab diagram we can identify three topology links (highlighted in cyan):</p> TopoLink objects <p>In EDA, we call links between the switches inter switch links, links between the switches and the clients edge links, and loopback links are called just loopback. So our three topology links will be:</p> <ol> <li>The link between <code>srl1</code> and <code>client1</code> - <code>edge</code> link</li> <li>The link between <code>srl1</code> and <code>srl2</code> switches - <code>interSwitch</code> link</li> <li>The link between <code>srl2</code> and <code>client2</code> - <code>edge</code> link</li> </ol> <p>The TopoLink resource definition has a straightforward specification:</p> <pre><code>spec:\n  links:\n    - local: # required\n        interface:\n        interfaceResource: # required\n        node: # required\n      remote: # same as local\n      speed:\n      type: # required\n</code></pre> <p>A TopoLink, like any other link-like object is identified by a local endpoint and an optional remote endpoint. The local/remote endpoints are \"connecting\" to the TopoNode objects via <code>node</code> field.</p> <p>But this is not everything a TopoLink needs. It also requires us to provide a link to the Interface resource via the <code>interfaceResource</code> field, as this is the bind point for the link in a particular node.</p>"},{"location":"user-guide/containerlab-integration/#interface","title":"Interface","text":"<p>The Interface resource creates a physical interface on the node. In our topology we have two physical interfaces per each managed SR Linux node:</p> Interface objects <p>For a TopoLink resource to be valid, the Interface resources must be created first and then referenced in the TopoLink specification.</p> <p>Here is how you would define the <code>ethernet-1/1</code> interface on SR Linux node <code>srl1</code> that connects it to the <code>client1</code> node:</p> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl1\n  type: interface\n</code></pre> <p>As indicated in the spec, the Interface resource has a <code>members</code> field that can contain one (for a single interface) or multiple (for a LAG) interfaces objects. An implementation detail worth calling out is that the physical interface name should be normalized, i.e. SR Linux's <code>ethernet-1/1</code> becomes <code>ethernet-1-1</code>.</p> <p>As we do not have LAG interfaces in our lab topology, all our interfaces will have identical configuration.</p>"},{"location":"user-guide/containerlab-integration/#applying-the-resources","title":"Applying the resources","text":"<p>Let's summarize what we have learned so far:</p> <ol> <li>The TopoNode resource defines the node in the EDA topology.</li> <li>Creation of the TopoNode resource triggers onboarding process for the node.</li> <li>TopoNode resource references the NodeProfile resource that defines the lower level node parameters used in bootstrapping/onboarding and the management workflows.</li> <li>Onboarding happens over the well-known gRPC port 50052, this gRPC server is configured by Containerlab<sup>2</sup> automatically for the SR Linux nodes.</li> <li>Onboarding/Bootstrapping procedure sets up the <code>EDA</code> TLS profile using gNSI for SR Linux nodes. Once the certificate is installed, the node is marked as <code>onBoarded=true</code>.</li> <li>Onboarding user and the user used for the EDA management might be different. The \"permanent\" user is declaratively defined by the NodeUser resource.</li> <li>The gRPC server used for the management of the node is tied to the NodeProfile resource and is identified by the <code>port</code> field. This server should reference a dynamic <code>EDA</code> TLS profile that EDA's bootstrap server sets up during the onboarding workflow.</li> <li>When the node is onboarded, the NPP pod is spawned and connects to the node; it replaces the existing node configuration with the configuration calculated by EDA based on the defined intents.</li> <li>To create TopoLink resources, we need to create Interface resources first and then reference them in the TopoLink resource.</li> </ol> <p>Before we rush to apply the resources, let's capture the state of the current config present on our SR Linux nodes and verify that the configuration will be wiped out and replaced once EDA starts to manage the nodes.</p> <p>If you take a look at the lab's topology file, you will notice that the two SR Linux nodes are defined with the startup config blobs that create a pair of interfaces and attach them to a bridge domain <code>bridge-1</code>. It is easy to verify that:</p> interfacesnetwork instance <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'show interface ethernet-1/{1,10} brief'\n</code></pre> <pre><code>+---------------------+----------+----------+----------+----------+----------+\n|        Port         |  Admin   |   Oper   |  Speed   |   Type   | Descript |\n|                     |  State   |  State   |          |          |   ion    |\n+=====================+==========+==========+==========+==========+==========+\n| ethernet-1/1        | enable   | up       | 25G      |          |          |\n| ethernet-1/10       | enable   | up       | 25G      |          |          |\n+---------------------+----------+----------+----------+----------+----------+\n</code></pre> <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'show network-instance bridge-1 interfaces'\n</code></pre> <pre><code>==================================================================================\nNet instance    : bridge-1\nInterface       : ethernet-1/1.0\nType            : bridged\nOper state      : up\n==================================================================================\nNet instance    : bridge-1\nInterface       : ethernet-1/10.0\nType            : bridged\nOper state      : up\n==================================================================================\n</code></pre>"},{"location":"user-guide/containerlab-integration/#nodeuser","title":"NodeUser","text":"<p>With the initial state captured, let's start applying the resources in the bottom-up order, starting with the NodeUser resource:</p> NodeUser<code>kubectl</code> apply <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: NodeUser\nmetadata:\n  name: admin\n  namespace: eda\nspec:\n  groupBindings:\n    - groups:\n        - sudo\n      nodeSelector:\n        - \"\"\n  username: admin\n  password: NokiaSrl1!\n  sshPublicKeys:\n    # an optional list of ssh public keys for the node user\n    # - \"ssh-ed25519 AAAAC3NzaC1lZYOURKEYHEREYOURKEYHEREYOURKEYHEREYOURKEYHEREHDLeDteKN74\"\n</code></pre> <p>In this command we retrieve the public keys from the SSH agent and add add them to the NodeUser resource.</p> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: NodeUser\nmetadata:\n  name: admin\n  namespace: eda\nspec:\n  groupBindings:\n    - groups:\n        - sudo\n      nodeSelector:\n        - \"\"\n  username: admin\n  password: NokiaSrl1!\n  sshPublicKeys:\n    # an optional list of ssh public keys for the node user\n    # - \"ssh-ed25519 AAAAC3NzaC1lZYOURKEYHEREYOURKEYHEREYOURKEYHEREYOURKEYHEREHDLeDteKN74\"\n\n$(ssh-add -L | awk '{print \"    - \\\"\"$0\"\\\"\"}')\nEOF\n</code></pre>"},{"location":"user-guide/containerlab-integration/#nodeprofile","title":"NodeProfile","text":"<p>With <code>admin</code> NodeUser modified to feature the <code>NokiaSrl1!</code> password, let's create the NodeProfile resource named <code>srlinux-clab-24.10.1</code>:</p> NodeProfile<code>kubectl</code> apply <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: NodeProfile\nmetadata:\n  name: srlinux-clab-24.10.1\n  namespace: eda\nspec:\n  operatingSystem: srl\n  version: 24.10.1\n  versionPath: .system.information.version\n  versionMatch: v24\\.10\\.1.*\n  images:\n    - image: fake.bin\n      imageMd5: fake.bin.md5\n  port: 57410\n  yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n  onboardingUsername: admin\n  onboardingPassword: NokiaSrl1!\n  nodeUser: admin\n  annotate: true\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: NodeProfile\nmetadata:\n  name: srlinux-clab-24.10.1\n  namespace: eda\nspec:\n  operatingSystem: srl\n  version: 24.10.1\n  versionPath: .system.information.version\n  versionMatch: v24\\.10\\.1.*\n  images:\n    - image: fake.bin\n      imageMd5: fake.bin.md5\n  port: 57410\n  yang: https://eda-asvr.eda-system.svc/eda-system/schemaprofiles/srlinux-ghcr-24.10.1/srlinux-24.10.1.zip\n  onboardingUsername: admin\n  onboardingPassword: NokiaSrl1!\n  nodeUser: admin\n  annotate: true\n\nEOF\n</code></pre>"},{"location":"user-guide/containerlab-integration/#toponode_1","title":"TopoNode","text":"<p>So far the resources that we have modified or created did not trigger any activity in our EDA cluster; we just prepared the grounds for the next step of creating the TopoNode resources:</p> TopoNode resources<code>kubectl</code> apply <p>When applying the TopoNode resources, the difference between the resources (besides the resource name) is in the <code>productionAddress</code> field. The <code>kubectl</code> apply tab shows how to programmatically fetch the current assigned IP address from the docker state and populate the resources accordingly so that you can copy and paste the command on the host that runs the containerlab topology.</p> <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl1\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: # IP address of the clab-vlan-srl1 node\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl2\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: # IP address of the clab-vlan-srl2 node\n</code></pre> <pre><code>cat &lt;&lt; EOF | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl1\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: $(sudo docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' clab-vlan-srl1)\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  name: clab-vlan-srl2\n  labels:\n    eda.nokia.com/security-profile: managed\n  namespace: eda\nspec:\n  nodeProfile: srlinux-clab-24.10.1\n  operatingSystem: srl\n  platform: 7220 IXR-D2L\n  version: 24.10.1\n  productionAddress:\n    ipv4: $(sudo docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' clab-vlan-srl2)\nEOF\n</code></pre>"},{"location":"user-guide/containerlab-integration/#interface_1","title":"Interface","text":"<p>A topology without links is not a topology. Time to add the links between the nodes. And a prerequisite to creating the TopoLink resources is to create the Interface resources.</p> Interface resources<code>kubectl</code> apply <pre><code>#########################\n#### srl1 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl1\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl1-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl1\n  type: interface\n\n#########################\n#### srl2 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl2-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl2\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl2-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl2\n  type: interface\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\n#########################\n#### srl1 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl1\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl1-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl1\n  type: interface\n\n#########################\n#### srl2 Interface #####\n#########################\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: access\n  name: clab-vlan-srl2-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      node: clab-vlan-srl2\n  type: interface\n\n---\napiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    role: interSwitch\n  name: clab-vlan-srl2-ethernet-1-10\n  namespace: eda\nspec:\n  enabled: true\n  encapType: \"null\"\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      node: clab-vlan-srl2\n  type: interface\n\nEOF\n</code></pre> <p>The moment we created the Interface resources, EDA will configure the associated physical interfaces on the SR Linux nodes. We will see it in the Verification section. Yet, the topology UI will not show the interfaces until we create the TopoLink resources.</p>"},{"location":"user-guide/containerlab-integration/#topolink_1","title":"TopoLink","text":"<p>Now, that we have the Interfaces created we can create the last resource type - TopoLink.</p> Interface resources<code>kubectl</code> apply <pre><code>---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-client1\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl1-ethernet-1-1\n      remote:\n        node: clab-vlan-client1\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-srl2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl1-ethernet-1-10\n      remote:\n        node: clab-vlan-srl2\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl2-ethernet-1-10\n      type: interSwitch\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl2-client2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl2\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl2-ethernet-1-1\n      remote:\n        node: clab-vlan-client2\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl apply -f -\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-client1\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl1-ethernet-1-1\n      remote:\n        node: clab-vlan-client1\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl1-srl2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl1\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl1-ethernet-1-10\n      remote:\n        node: clab-vlan-srl2\n        interface: ethernet-1/10\n        interfaceResource: clab-vlan-srl2-ethernet-1-10\n      type: interSwitch\n---\napiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  name: srl2-client2\n  namespace: eda\nspec:\n  links:\n    - local:\n        node: clab-vlan-srl2\n        interface: ethernet-1/1\n        interfaceResource: clab-vlan-srl2-ethernet-1-1\n      remote:\n        node: clab-vlan-client2\n        interface: eth1\n        interfaceResource: eth1\n      type: edge\n\nEOF\n</code></pre>"},{"location":"user-guide/containerlab-integration/#verifying-integration","title":"Verifying integration","text":"<p>Applying the TopoNode resources triggers a lot of activity in EDA. Starting with Bootstrap server to setup the dynamic TLS profile named <code>EDA</code> as part of the bootstrap workflow, finishing with NPP pods connecting to the SR Linux nodes and replacing the existing configuration with the configuration calculated by EDA based on the intents defined in the system.</p> <p>You should see the TopoNode resources and their associated state looking like this after approximately 30-60s after applying the TopoNode resources:</p> <pre><code>kubectl -n eda get toponodes\n</code></pre> <pre><code>NAME             PLATFORM       VERSION   OS    ONBOARDED   MODE     NPP         NODE     AGE\nclab-vlan-srl1   7220 IXR-D2L   24.10.1   srl   true        normal   Connected   Synced   12m\nclab-vlan-srl2   7220 IXR-D2L   24.10.1   srl   true        normal   Connected   Synced   12m\n</code></pre> <p>If you don't see the same output, check the TransactionResults resource that will reveal any potential issues with the transactions.</p> <pre><code>kubectl -n eda-system get transactionresults\n</code></pre> <p>If your TopoNode resources look all good, how about the SR Linux nodes? What has changed there? Remember that we warned you about the config replacement that happens the moment the nodes become managed by EDA? Let's check the configuration on the <code>clab-vlan-srl1</code> node using the same <code>sr_cli</code> commands as we did in the beginning of the Applying the resources section.</p> interfacesnetwork instanceEDA dynamic TLS profile <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'show interface ethernet-1/{1,10} brief'\n</code></pre> <pre><code>+---------------------+---------+---------+---------+---------+---------+\n|        Port         |  Admin  |  Oper   |  Speed  |  Type   | Descrip |\n|                     |  State  |  State  |         |         |  tion   |\n+=====================+=========+=========+=========+=========+=========+\n| ethernet-1/1        | enable  | up      | 25G     |         |         |\n| ethernet-1/10       | enable  | up      | 25G     |         |         |\n+---------------------+---------+---------+---------+---------+---------+\n</code></pre> <p>Note, that the interfaces are all up, because they have been configured when we created Interface resources.</p> <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'show network-instance bridge-1 interfaces'\n</code></pre> <pre><code>================================================================================\n================================================================================\n</code></pre> <p>But contrary to the Interfaces, the <code>bridge-1</code> mac-vrf network instance is completely gone, because we have not created any resources that would trigger a network instance creation.</p> <p>Besides things that were removed, EDA added a new dynamic TLS profile named <code>EDA</code>. The Bootstrap server created it and the <code>eda-mgmt</code> gRPC server has been referring to it as part of the default configuration of SR Linux.</p> <pre><code>docker exec -t clab-vlan-srl1 sr_cli \\\n'info from state system tls server-profile EDA'\n</code></pre> <pre><code>    system {\n        tls {\n            server-profile EDA {\n                key $aes1$AW7HyIAIvykjUG8=$0...Rk=\n                certificate \"-----BEGIN CERTIFICATE-----\nMIIC5DCCAoqgAwIBAgIRANnUH/DLuCeMdQd5vp3VLw8wCgYIKoZIzj0EAwIwMzEO\n...\nQJNoWhdMyz++Nl83AzQOzRXKB7VbWxO7\n-----END CERTIFICATE-----\n\"\n                authenticate-client false\n                dynamic true\n                cipher-list [\n                    ecdhe-ecdsa-aes256-gcm-sha384\n                    ecdhe-ecdsa-aes128-gcm-sha256\n                    ecdhe-rsa-aes256-gcm-sha384\n                    ecdhe-rsa-aes128-gcm-sha256\n                ]\n                certz {\n                    ssl-profile-id EDA\n                    certificate {\n                        version eda-01_05_25_16_01_13\n                        created-on \"2025-01-05T16:01:13.000Z (an hour ago)\"\n                    }\n                }\n            }\n        }\n    }\n</code></pre> <p>This completes the manual integration of EDA with a topology created by Containerlab. You were the witness of the process that is, well, manual, but the good news is that we you can use the clab-connector to automate the process.</p> <ol> <li> <p><code>topology-data.json</code> file is generated by Containerlab when the lab is deployed. It can be found in the Containerlab's Lab Directory.\u00a0\u21a9</p> </li> <li> <p>versions &gt;= 0.61.0\u00a0\u21a9\u21a9</p> </li> <li> <p>set your own public key, this one is for demonstration purposes only\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/network-topology/","title":"Network Topology","text":"<p>A network topology in a broader sense describes the network design on physical and logical levels. Be it a Clos, a Fat Tree or a Ring design, the topology is what inherently defines the network.</p> <p>Like an arbitrary topology is defined by its nodes and links, the network topology in EDA is modelled with the <code>TopoNode</code> and <code>TopoLink</code> resources. The EDA topology nodes are represented by the devices in your network, and the topology links define the connectivity between them.</p> <p>If you come here after finishing the Getting Started guide, you may remember the 3-node topology that the \"Try EDA\" setup comes with:</p> Physical topology <p>To represent this network topology in EDA the <code>TopoNode</code> and <code>TopoLink</code> resources must be created for each node and link in the network topology. Without network topology modelled with the respective topo resources, EDA cannot start managing the network devices.</p> <p>Here is how the same 3-node topology is modelled with the <code>TopoNode</code> and <code>TopoLink</code> resources:</p> <ul> <li>For each device in the topology there is a corresponding <code>TopoNode</code></li> <li>For each link between the nodes there is a corresponding <code>TopoLink</code> representing the inter-switch connections</li> <li>For each link from a node to an edge device (not shown in the diagram) there is a corresponding <code>TopoLink</code> representing the edge connections.<sup>1</sup></li> <li>For each interface breakout on the nodes there is a corresponding <code>TopoBreakout</code> resource<sup>2</sup></li> </ul> <p>The diagram below illustrates how the topology resources represent the same network topology:</p> EDA topology modelled with TopoNode and TopoLink resources <p>Almost no difference with a physical topology, right? To see the topology diagram in EDA UI select Topologies in the left-hand menu and click on the Physical row in the table of topologies:</p> <p>Digital Twin topology</p> <p>The Network Topology is used to model both the physical network and its matching Digital Twin. The Digital Twin topology (also known as the simulation topology) is covered in more detail on the Digital Twin page.</p>"},{"location":"user-guide/network-topology/#topology-resources","title":"Topology resources","text":"<p>The <code>TopoNode</code>, <code>TopoLink</code> and <code>TopoBreakout</code> resources in EDA make up the network topology that is used both by the real physical network and the Digital Twin. With the 3-node topology created in the EDA cluster you can see these resources in the EDA UI and using <code>kubectl</code> or <code>edactl</code>:</p> EDA UI<code>kubectl</code> TopoNodeTopoLink <p>TopoNodes are displayed in the EDA UI under Targets &gt; Nodes:</p> <p>And to see the TopoLinks go to Topology &gt; Links:</p> <p>TopoNodes:</p> <pre><code>kubectl -n eda get toponodes\n</code></pre> <pre><code>NAME     PLATFORM       VERSION   OS    ONBOARDED   MODE     NPP         NODE     AGE\nleaf1    7220 IXR-D3L   25.10.1   srl   true        normal   Connected   Synced   21m\nleaf2    7220 IXR-D3L   25.10.1   srl   true        normal   Connected   Synced   21m\nspine1   7220 IXR-D5    25.10.1   srl   true        normal   Connected   Synced   21m\n</code></pre> <p>TopoLinks:</p> <pre><code>kubectl -n eda get topolinks\n</code></pre> <pre><code>NAME                 AGE\nleaf1-2-e1212        21m\nleaf1-e1011          21m\nleaf1-ethernet-1-3   21m\nleaf1-ethernet-1-4   21m\nleaf1-ethernet-1-5   21m\nleaf1-ethernet-1-6   21m\nleaf1-ethernet-1-7   21m\nleaf1-ethernet-1-8   21m\nleaf1-ethernet-1-9   21m\nleaf1-spine1-1       21m\nleaf1-spine1-2       21m\nleaf2-e1011          21m\nleaf2-ethernet-1-3   21m\nleaf2-ethernet-1-4   21m\nleaf2-ethernet-1-5   21m\nleaf2-ethernet-1-6   21m\nleaf2-ethernet-1-7   21m\nleaf2-ethernet-1-8   21m\nleaf2-ethernet-1-9   21m\nleaf2-spine1-1       21m\nleaf2-spine1-2       21m\n</code></pre> <p>If the <code>TopoNode</code>, <code>TopoLink</code> and <code>TopoBreakout</code> objects make up a topology, how do we create them? A straightforward way is to create these resources directly, either in UI or using CLI tools or API, but this is going to be a tedious and likely an error-prone process as the number of nodes and especially links may grow quickly.</p> <p>To assist with the topology creation, EDA provides the Network Topology Workflow - a workflow to define and deploy arbitrary topologies in a transactional manner.</p>"},{"location":"user-guide/network-topology/#network-topology-workflow","title":"Network topology workflow","text":"<p>Instead of creating the topology resources individually, EDA provides a way to describe the topology via the Network Topology workflow that can be triggered via UI, REST API, or via CLIs and applied in a single transaction.</p> <p>A Workflow in EDA is a resource that defines a job or a set of jobs to be executed in a run-to-completion manner. A typical example of a workflow is the Image Upgrade workflow that performs the upgrade of a network device OS image.</p> <p>Let's look at the structure of Network Topology Workflow resource and how the Try EDA topology is defined with it:</p> Network Topology workflow structureTry EDA topology workflow <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  name: try-eda-topology\n  namespace: eda\nspec:\n  operation: create  # operation to perform\n\n  nodeTemplates: []     # list of node templates\n  nodes: []             # list of nodes \n\n  linkTemplates: []     # list of link templates\n  links: []             # list of links\n\n  breakoutTemplates: [] # list of breakout templates\n  breakouts: []         # list of breakouts\n\n  simulation: {}        # digital twin topology settings\n  checks: {}            # topology checks and dry runs\n</code></pre> <p>The three-node topology used in the Try EDA setup is defined with the following Network Topology workflow:</p> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  name: try-eda-topology-a\n  namespace: eda\nspec:\n  operation: replaceAll\n  nodeTemplates:\n    - name: leaf\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n        eda.nokia.com/role: leaf\n    - name: spine\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D5\n      labels:\n        eda.nokia.com/security-profile: managed\n        eda.nokia.com/role: spine\n  nodes:\n    - name: leaf1\n      template: leaf\n    - name: leaf2\n      template: leaf\n    - name: spine1\n      template: spine\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n      speed: 25G\n      encapType: \"null\"\n      labels:\n        eda.nokia.com/role: interSwitch\n    - name: edge\n      type: edge\n      encapType: dot1q\n      labels:\n        eda.nokia.com/role: edge\n  links:\n    ####################\n    # ISLs\n    ####################\n    - name: leaf1-spine1-1\n      template: isl\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-1\n          remote:\n            node: spine1\n            interface: ethernet-1-1\n    - name: leaf1-spine1-2\n      template: isl\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-2\n          remote:\n            node: spine1\n            interface: ethernet-1-2\n    - name: leaf2-spine1-1\n      template: isl\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-1\n          remote:\n            node: spine1\n            interface: ethernet-1-3\n    - name: leaf2-spine1-2\n      template: isl\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-2\n          remote:\n            node: spine1\n            interface: ethernet-1-4\n    ####################\n    # Edges\n    ####################\n    - name: leaf1-ethernet-1-3\n      template: edge\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-3\n    - name: leaf1-ethernet-1-4\n      template: edge\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-4\n    - name: leaf1-ethernet-1-5\n      template: edge\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-5\n    - name: leaf1-ethernet-1-6\n      template: edge\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-6\n    - name: leaf1-ethernet-1-7\n      template: edge\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-7\n    - name: leaf1-ethernet-1-8\n      template: edge\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-8\n    - name: leaf1-ethernet-1-9\n      template: edge\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-9\n    - name: leaf1-e1011\n      template: edge\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-10\n        - local:\n            node: leaf1\n            interface: ethernet-1-11\n    - name: leaf2-ethernet-1-3\n      template: edge\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-3\n    - name: leaf2-ethernet-1-4\n      template: edge\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-4\n    - name: leaf2-ethernet-1-5\n      template: edge\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-5\n    - name: leaf2-ethernet-1-6\n      template: edge\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-6\n    - name: leaf2-ethernet-1-7\n      template: edge\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-7\n    - name: leaf2-ethernet-1-8\n      template: edge\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-8\n    - name: leaf2-ethernet-1-9\n      template: edge\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-9\n    - name: leaf2-e1011\n      template: edge\n      endpoints:\n        - local:\n            node: leaf2\n            interface: ethernet-1-10\n        - local:\n            node: leaf2\n            interface: ethernet-1-11\n    - name: leaf1-2-e1212\n      template: edge\n      endpoints:\n        - local:\n            node: leaf1\n            interface: ethernet-1-12\n        - local:\n            node: leaf2\n            interface: ethernet-1-12\n  simulation:\n    topology:\n      - node: \"*\"\n        interface: \"*\"\n        simNode: testman-default\n    simNodeTemplates:\n      - name: default\n        type: TestMan\n    simNodes:\n      - name: testman-default\n        template: default\n</code></pre> <p>As per the structure, the Network Topology workflow resource spec uses the template-based approach to define nodes, links and breakouts. Corresponding templates are defined in the <code>nodeTemplates</code>, <code>linkTemplates</code> and <code>breakoutTemplates</code> sections, and then referenced in the <code>nodes</code>, <code>links</code> and <code>breakouts</code> sections, respectively.</p> <p>Using the template-based approach reduces repetition in the topology definition and lets users quickly change the common parameters in one place.</p> <p>Note</p> <p>This document does not dive into the details of the Digital Twin topology (<code>simulation</code> section) as this topic is covered on the Digital Twin page.</p>"},{"location":"user-guide/network-topology/#nodes","title":"Nodes","text":"<p>To define the nodes, create one or more templates and reference them in the <code>nodes</code> section. The values specified on the node level override the template values.</p> <pre><code>nodeTemplates:\n  - name: leaf #(1)!\n    nodeProfile: srlinux-ghcr-25.10.1 #(5)!\n    platform: 7220 IXR-D3L #(4)!\n    labels: #(2)!\n      eda.nokia.com/security-profile: managed #(6)!\n      eda.nokia.com/role: leaf\n\nnodes:\n  - name: leaf1 #(7)!\n    template: leaf #(3)!\n    labels:\n      new-node-level-label: new-value #(8)!\n</code></pre> <ol> <li>The free-form name of the node template resource.</li> <li>The labels to be applied to the node.</li> <li>The name of the node template that this node is based on.</li> <li>Platform name.     NPP and Bootstrap server validate the platform name they see upon connection.</li> <li>Node profile.     A reference to a <code>NodeProfile</code> resource that defines the profile of the node.</li> <li>A label that is used by the <code>NodeSecurityProfile</code> resource to determine the security profile of the node.</li> <li>The name of the node.</li> <li>Parameters specified on the node level override/merge with the template values. In this case, a new label is merged with the template-level labels.</li> </ol> <p>Based on the provided node definition, EDA will create the respective <code>TopoNode</code> resource representing the node in the topology.</p> leaf1 TopoNode<pre><code>apiVersion: core.eda.nokia.com/v1\nkind: TopoNode\nmetadata:\n  labels:\n    eda.nokia.com/role: leaf\n    eda.nokia.com/security-profile: managed\n    new-node-level-label: new-value\n  name: leaf1\n  namespace: eda\nspec:\n  nodeProfile: srlinux-ghcr-25.10.1\n  npp:\n    mode: normal\n  onBoarded: true\n  operatingSystem: srl\n  platform: 7220 IXR-D3L\n  productionAddress: {}\n  version: 25.10.1\nstatus:\n  node-details: 10.244.0.224:57400\n  node-state: Synced\n  npp-details: 10.244.0.75:50057\n  npp-pod: eda-npp-1\n  npp-state: Connected\n  operatingSystem: srl\n  platform: 7220 IXR-D3L\n  simulate: true\n  version: 25.10.1\n</code></pre>"},{"location":"user-guide/network-topology/#links","title":"Links","text":"<p>A link represents a connection between two nodes in the topology. In EDA, you will find two link types used in the context of a network topology:</p> <ol> <li>interSwitch - a link between two topology nodes, typically representing a connection between two network devices.</li> <li>edge - a link connecting a topology node to an edge device that is not part of the topology. Most often the access links from the leaf switches to the end devices (servers, workstations, etc.) are modelled as edge links.</li> </ol> <p>To define the links, create one or more link templates and reference them in the <code>links</code> section. The values specified on the link level override the template values.</p> <p>The following examples show common topology link definitions that you will find in the Network Topology workflow spec:</p> Inter switch linkEdge linkLocal LAGMultihome LAG <p>An inter switch link (ISL) is a point-to-point link that connects two network devices in the topology. In the example below, the ISL connects <code>leaf1</code> and <code>spine1</code> nodes using their <code>ethernet-1-1</code> interfaces.</p> <p>Diagram</p> <pre><code>linkTemplates:\n  - name: isl #(6)!\n    type: interSwitch #(5)!\n    speed: 25G #(7)!\n    encapType: \"null\"\n    labels: #(2)!\n      eda.nokia.com/role: interSwitch\n\nlinks:\n  - name: leaf1-spine1-1 #(1)!\n    template: isl #(9)!\n    endpoints: #(8)!\n      - local: #(3)!\n          node: leaf1\n          interface: ethernet-1-1\n        remote: #(4)!\n          node: spine1\n          interface: ethernet-1-1\n</code></pre> <ol> <li>The name of the <code>TopoLink</code> resource.</li> <li>The labels to be applied to the node.</li> <li>Definition of Local, or \"A\" endpoint of the link. Can contain the following fields: <code>interface</code> - Normalized name of the interface/port, e.g. <code>ethernet-1-1</code>. <code>node</code> - The reference to the <code>TopoNode</code> resource that this side of a link is connected to.</li> <li>Definition of Remote, or \"B\" endpoint of the link. Contains the same fields as the <code>local</code> definition.</li> <li>The type of link. One of <code>edge</code>, <code>interSwitch</code>, <code>loopback</code></li> <li>Name of the link template.</li> <li>Default link speed. Optional.</li> <li>Endpoints is a list of endpoint definitions, where each endpoint object contains the <code>local</code> and optionally the <code>remote</code> sides.     For a typical inter-switch link both <code>local</code> and <code>remote</code> sides are defined, where the <code>local</code> side refers to one topology node and the <code>remote</code> side refers to another.     You will see how edge links don't have a <code>remote</code> side defined in the next example.</li> <li>Reference to the link template that this link is based on.</li> </ol> <p>As a result of this link definition, EDA will create two resources - a <code>TopoLink</code> resource representing the link itself, and two <code>Interface</code> resources representing the interfaces on both ends of the link. The <code>Interface</code> resources will be responsible for configuring the respective interfaces on the devices.</p> TopoLinkInterface <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  labels:\n    eda.nokia.com/role: interSwitch\n    eda.nokia.com/source-link: leaf1-spine1-1\n  name: leaf1-spine1-1\n  namespace: eda\nspec:\n  links:\n    - local:\n        interface: ethernet-1-1\n        interfaceResource: leaf1-ethernet-1-1\n        node: leaf1\n      remote:\n        interface: ethernet-1-1\n        interfaceResource: spine1-ethernet-1-1\n        node: spine1\n      speed: 25G\n      type: interSwitch\nstatus:\n  members:\n    - interface: ethernet-1-1\n      node: leaf1\n      operationalState: up\n    - interface: ethernet-1-1\n      node: spine1\n      operationalState: up\n  operationalState: up\n</code></pre> Leaf1 ethernet-1-1Spine1 ethernet-1-1 <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    eda.nokia.com/role: interSwitch\n    eda.nokia.com/source-link: leaf1-spine1-1\n  name: leaf1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: 'null'\n  ethernet:\n    stormControl: {}\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      lacpPortPriority: 32768\n      node: leaf1\n  type: interface\nstatus:\n  enabled: true\n  lastChange: '2025-11-28T12:08:22.671Z'\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      lastChange: '2025-11-28T12:08:22.671Z'\n      neighbors:\n        - interface: ethernet-1/1\n          node: spine1\n      node: leaf1\n      nodeInterface: ethernet-1/1\n      operationalState: up\n      speed: 100G\n  operationalState: up\n  speed: 100G\n</code></pre> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    eda.nokia.com/role: interSwitch\n    eda.nokia.com/source-link: leaf1-spine1-1\n  name: spine1-ethernet-1-1\n  namespace: eda\nspec:\n  enabled: true\n  encapType: 'null'\n  ethernet:\n    stormControl: {}\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      lacpPortPriority: 32768\n      node: spine1\n  type: interface\nstatus:\n  enabled: true\n  lastChange: '2025-11-28T12:08:22.667Z'\n  members:\n    - enabled: true\n      interface: ethernet-1-1\n      lastChange: '2025-11-28T12:08:22.667Z'\n      neighbors:\n        - interface: ethernet-1/1\n          node: leaf1\n      node: spine1\n      nodeInterface: ethernet-1/1\n      operationalState: up\n      speed: 400G\n  operationalState: up\n  speed: 400G\n</code></pre> <p>The edge link is a link that connects a topology node (typically a leaf switch) to an edge device that is not part of the topology. The edge device may be a server, a GPU, or a generic device that is not managed by EDA. As this link has only one side connected to a topology node, only the <code>local</code> side is defined in the link definition:</p> <p>Diagram</p> <pre><code>linkTemplates:\n  - name: edge\n    type: edge #(1)!\n    encapType: dot1q\n    labels:\n      eda.nokia.com/role: edge #(2)!\n\nlinks:\n  - name: leaf1-ethernet-1-3\n    template: edge\n    endpoints:\n      - local:\n          node: leaf1\n          interface: ethernet-1-3\n</code></pre> <ol> <li>Edge links have their own special type - <code>edge</code>.</li> <li>The label is optional, but since the edge links are targeted by the overlay services like Virtual Network, it's a good practice to label them accordingly so that these applications can easily select the edge links.</li> </ol> <p>As a result of this link definition, EDA will create two resources - a <code>TopoLink</code> resource representing the link itself, and the <code>Interface</code> resource representing the interfaces on the leaf side. The <code>Interface</code> resources will be responsible for configuring the respective interface on the leaf device.</p> TopoLinkInterface <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  labels:\n    eda.nokia.com/role: edge\n    eda.nokia.com/source-link: leaf2-ethernet-1-3\n  name: leaf2-ethernet-1-3\n  namespace: eda\nspec:\n  links:\n    - local:\n        interface: ethernet-1-3\n        interfaceResource: leaf2-ethernet-1-3\n        node: leaf2\n      remote:\n        interfaceResource: ''\n        node: ''\n      type: edge\nstatus:\n  members:\n    - interface: ethernet-1-3\n      node: leaf2\n      operationalState: up\n  operationalState: up\n</code></pre> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    eda.nokia.com/role: edge\n    eda.nokia.com/source-link: leaf1-ethernet-1-3\n  name: leaf1-ethernet-1-3\n  namespace: eda\nspec:\n  enabled: true\n  encapType: dot1q\n  ethernet:\n    stormControl: {}\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-3\n      lacpPortPriority: 32768\n      node: leaf1\n  type: interface\nstatus:\n  enabled: true\n  lastChange: '2025-11-28T12:08:22.795Z'\n  members:\n    - enabled: true\n      interface: ethernet-1-3\n      lastChange: '2025-11-28T12:08:22.795Z'\n      neighbors: []\n      node: leaf1\n      nodeInterface: ethernet-1/3\n      operationalState: up\n      speed: 100G\n  operationalState: up\n  speed: 100G\n</code></pre> <p>The Link Aggregation Group (LAG) link combines multiple physical interfaces into a single logical link. In EDA, two types of LAG exist: local LAG and multihomed LAG.</p> <p>The \"local\" LAG aggregates ports between a single pair of nodes and is created by specifying multiple endpoints each having only local sides defined on the same node. In the example below, the LAG will consist of <code>ethernet-1-10</code> and <code>ethernet-1-11</code> interfaces on the <code>leaf1</code> node reaching out to an edge device that is expected to have a matching LAG configuration.</p> <p>Diagram</p> <pre><code>linkTemplates:\n  - name: edge\n    type: edge\n    encapType: dot1q\n    labels:\n      eda.nokia.com/role: edge\n\nlinks:\n  - name: leaf1-e1011\n    template: edge\n    endpoints:\n      - local:\n          node: leaf1 #(1)!\n          interface: ethernet-1-10\n      - local:\n          node: leaf1\n          interface: ethernet-1-11\n</code></pre> <ol> <li>Both endpoints in this example refer to the same node - <code>leaf1</code>, indicating that this is a local LAG link, where both interfaces are belonging to the same node.</li> </ol> <p>As a result of this link definition, EDA will create two resources - a <code>TopoLink</code> resource representing the link itself, and only one <code>Interface</code> resource with two members in it representing the local LAG.</p> <p>Also note, that the <code>Interface</code> resource also features LAG-specific configuration under the <code>lag</code> section in its spec.</p> TopoLinkInterface <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  labels:\n    eda.nokia.com/role: edge\n    eda.nokia.com/source-link: leaf1-e1011\n  name: leaf1-e1011\n  namespace: eda\nspec:\n  links:\n    - local:\n        interface: ethernet-1-10\n        interfaceResource: lag-leaf1-e1011-local\n        node: leaf1\n      remote:\n        interfaceResource: ''\n        node: ''\n      type: edge\n    - local:\n        interface: ethernet-1-11\n        interfaceResource: lag-leaf1-e1011-local\n        node: leaf1\n      remote:\n        interfaceResource: ''\n        node: ''\n      type: edge\nstatus:\n  members:\n    - interface: ethernet-1-10\n      node: leaf1\n      operationalState: up\n    - interface: ethernet-1-11\n      node: leaf1\n      operationalState: up\n  operationalState: up\n</code></pre> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    eda.nokia.com/role: edge\n    eda.nokia.com/source-link: leaf1-e1011\n  name: lag-leaf1-e1011-local\n  namespace: eda\nspec:\n  enabled: true\n  encapType: dot1q\n  ethernet:\n    stormControl: {}\n  lag:\n    lacp:\n      interval: fast\n      lacpFallback:\n        mode: static\n        timeout: 60\n      mode: active\n      systemPriority: 32768\n    minLinks: 1\n    multihoming:\n      esi: auto\n      mode: all-active\n      reloadDelayTimer: 100\n      revertive: false\n    type: lacp\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      lacpPortPriority: 32768\n      node: leaf1\n    - enabled: true\n      interface: ethernet-1-11\n      lacpPortPriority: 32768\n      node: leaf1\n  type: lag\nstatus:\n  enabled: true\n  lag:\n    adminKey: 2\n    systemIdMac: FE:2F:AA:00:00:02\n  lastChange: '2025-11-28T12:08:25.692Z'\n  members:\n    - enabled: true\n      interface: ethernet-1-10\n      lastChange: '2025-11-28T12:08:25.674Z'\n      neighbors: []\n      node: leaf1\n      nodeInterface: ethernet-1/10\n      operationalState: up\n      speed: 100G\n    - enabled: true\n      interface: ethernet-1-11\n      lastChange: '2025-11-28T12:08:25.692Z'\n      neighbors: []\n      node: leaf1\n      nodeInterface: ethernet-1/11\n      operationalState: up\n      speed: 100G\n    - enabled: true\n      interface: lag-2\n      lastChange: '2025-11-28T12:08:25.675Z'\n      neighbors: []\n      node: leaf1\n      nodeInterface: lag2\n      operationalState: up\n      speed: 200G\n  operationalState: up\n  speed: 200G\n</code></pre> <p>In contrast to the local LAG, the multihome LAG aggregates ports from a single node towards two and more nodes. A typical application of a multihome LAG is the ESI LAG in EVPN deployments where up to four switches connect to the same downstream device (e.g. server or a router) using a LAG.</p> <p>The multihome LAG is created by specifying multiple endpoints each having only local sides defined for different nodes. Like in the example below, the multihome LAG will consist of <code>ethernet-1-12</code> on the <code>leaf1</code> and same <code>ethernet-1-12</code> on the <code>leaf2</code> node.</p> <p>Diagram</p> <pre><code>linkTemplates:\n  - name: edge\n    type: edge\n    encapType: dot1q\n    labels:\n      eda.nokia.com/role: edge\n\nlinks:\n  - name: leaf1-2-e1212\n    template: edge\n    endpoints:\n      - local:\n          node: leaf1 #(1)!\n          interface: ethernet-1-12\n      - local:\n          node: leaf2\n          interface: ethernet-1-12\n</code></pre> <ol> <li>In contrast to the local LAG example, here the <code>local</code> sides of the endpoint object refer to different nodes - <code>leaf1</code> and <code>leaf2</code>. This denotes the \"multihome\" nature of this LAG link.</li> </ol> <p>As a result of this link definition, EDA will create two resources - a <code>TopoLink</code> resource representing the link itself, and only one <code>Interface</code> resource with two members where each member belongs to a different node.</p> <p>Also note, that the <code>Interface</code> resource also features LAG-specific configuration under the <code>lag</code> section in its spec.</p> TopoLinkInterface <pre><code>apiVersion: core.eda.nokia.com/v1\nkind: TopoLink\nmetadata:\n  labels:\n    eda.nokia.com/role: edge\n    eda.nokia.com/source-link: leaf1-2-e1212\n  name: leaf1-2-e1212\n  namespace: eda\nspec:\n  links:\n    - local:\n        interface: ethernet-1-12\n        interfaceResource: lag-leaf1-2-e1212-local\n        node: leaf1\n      remote:\n        interfaceResource: ''\n        node: ''\n      type: edge\n    - local:\n        interface: ethernet-1-12\n        interfaceResource: lag-leaf1-2-e1212-local\n        node: leaf2\n      remote:\n        interfaceResource: ''\n        node: ''\n      type: edge\nstatus:\n  members:\n    - interface: ethernet-1-12\n      node: leaf1\n      operationalState: up\n    - interface: ethernet-1-12\n      node: leaf2\n      operationalState: up\n  operationalState: up\n</code></pre> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Interface\nmetadata:\n  labels:\n    eda.nokia.com/role: edge\n    eda.nokia.com/source-link: leaf1-2-e1212\n  name: lag-leaf1-2-e1212-local\n  namespace: eda\nspec:\n  enabled: true\n  encapType: dot1q\n  ethernet:\n    stormControl: {}\n  lag:\n    lacp:\n      interval: fast\n      lacpFallback:\n        mode: static\n        timeout: 60\n      mode: active\n      systemPriority: 32768\n    minLinks: 1\n    multihoming:\n      esi: auto\n      mode: all-active\n      reloadDelayTimer: 100\n      revertive: false\n    type: lacp\n  lldp: true\n  members:\n    - enabled: true\n      interface: ethernet-1-12\n      lacpPortPriority: 32768\n      node: leaf1\n    - enabled: true\n      interface: ethernet-1-12\n      lacpPortPriority: 32768\n      node: leaf2\n  type: lag\nstatus:\n  enabled: true\n  lag:\n    adminKey: 3\n    systemIdMac: FE:2F:AA:00:00:03\n  lastChange: '2025-11-28T12:08:27.578Z'\n  members:\n    - enabled: true\n      interface: ethernet-1-12\n      lastChange: '2025-11-28T12:08:25.697Z'\n      neighbors: []\n      node: leaf1\n      nodeInterface: ethernet-1/12\n      operationalState: up\n      speed: 100G\n    - enabled: true\n      interface: lag-1\n      lastChange: '2025-11-28T12:08:25.697Z'\n      neighbors: []\n      node: leaf1\n      nodeInterface: lag1\n      operationalState: up\n      speed: 100G\n    - enabled: true\n      interface: ethernet-1-12\n      lastChange: '2025-11-28T12:08:27.577Z'\n      neighbors: []\n      node: leaf2\n      nodeInterface: ethernet-1/12\n      operationalState: up\n      speed: 100G\n    - enabled: true\n      interface: lag-2\n      lastChange: '2025-11-28T12:08:27.578Z'\n      neighbors: []\n      node: leaf2\n      nodeInterface: lag2\n      operationalState: up\n      speed: 100G\n  operationalState: up\n  speed: 100G\n</code></pre>"},{"location":"user-guide/network-topology/#breakouts","title":"Breakouts","text":"<p>Breakouts allow splitting a high-speed interface into multiple lower-speed channels, like a 400G port on Nokia SR Linux 7220 IXR-H4 can be broken out into multiple lower speed interfaces, e.g. 4 by 100G. To model port breakouts in EDA, the <code>TopoBreakout</code> resource is used. And to define the port breakouts, the familiar template-based approach is implemented in the Network Topology workflow.</p> <p>While the \"Try EDA 3-node topology\" does not feature breakout ports, the example below will take a similar topology with two leafs and one spine, where the <code>ethernet-1-1</code> interface on <code>spine1</code> is broken down to four 100G interfaces to which the leafs connect.</p> <p>The breakout template sets the number of channels and speed per channel, and the breakout definition references the template and specifies the nodes and interfaces where the breakout should be applied. In the example below only <code>spine1/ethernet-1-1</code> is broken out, but you can define nodes and interfaces on them as needed.</p> <pre><code>breakoutTemplates:\n  - name: 4x100\n    channels: 4\n    speed: 100G\nbreakouts:\n  - name: breakouts\n    template: 4x100\n    node:\n      - spine1\n    interface:\n      - ethernet-1-1\n\nlinks:\n  - name: leaf1-spine1-1\n    template: isl\n    endpoints:\n      - local:\n          node: leaf1\n          interface: ethernet-1-1\n        remote:\n          node: spine1\n          interface: ethernet-1-1-1 #(1)!\n  - name: leaf1-spine1-2\n    template: isl\n    endpoints:\n      - local:\n          node: leaf1\n          interface: ethernet-1-2\n        remote:\n          node: spine1\n          interface: ethernet-1-1-2\n  - name: leaf2-spine1-1\n    template: isl\n    endpoints:\n      - local:\n          node: leaf2\n          interface: ethernet-1-1\n        remote:\n          node: spine1\n          interface: ethernet-1-1-3\n  - name: leaf2-spine1-2\n    template: isl\n    endpoints:\n      - local:\n          node: leaf2\n          interface: ethernet-1-2\n        remote:\n          node: spine1\n          interface: ethernet-1-1-4\n</code></pre> <ol> <li>Note, how the interface name of a port that is broken out is represented in a normalized way with its channel suffix - <code>ethernet-1-1-1</code>, <code>ethernet-1-1-2</code>, etc.</li> </ol> <p>The above breakout definition will result in creation of the two identical resources - <code>TopoBreakout</code> and <code>Breakout</code>. The <code>TopoBreakout</code> won't be visible in the EDA UI while the <code>Breakout</code> resource can be seen in the Topology &gt; Breakouts section.</p> <pre><code>apiVersion: interfaces.eda.nokia.com/v1alpha1\nkind: Breakout\nmetadata:\n  name: breakouts\n  namespace: breakout-test\nspec:\n  channels: 4\n  interface:\n    - ethernet-1-1\n  node:\n    - spine1\n  speed: 100G\n</code></pre>"},{"location":"user-guide/network-topology/#topology-operations","title":"Topology operations","text":"<p>Now that you are familiar with how nodes, links, and breakouts are defined in the Network Topology workflow, let's see how to create, modify, and remove Network Topologies in EDA.</p> <p>Since Network Topology is a resource backed by the workflow it can be triggered via UI, REST API, CLIs and anything that can create a resource in EDA.</p> Network Topology Workflow in EDA UI <p>Regardless of the method used to create the Network Topology resource, a user would need to fill in the network topology resources as explained in the previous sections and select the desired operation - <code>create</code>, <code>replace</code>, or <code>delete</code>. Let's see what each operation does.</p> <p>To demonstrate the effects of each operation, let's create an empty namespace <code>net-topo-test</code> where we will deploy and modify the topology in the examples below.</p> <pre><code>edactl namespace bootstrap create --from-namespace eda net-topo-test #(1)!\n</code></pre> <ol> <li>Don't have <code>edactl</code> installed? It is one command away.</li> </ol> <p>Workflow names</p> <p>Workflow resources should have unique names within a namespace. When creating a new workflow in EDA UI the name is auto-generated, and when using <code>kubectl</code> users can leverage Kubernetes' <code>generateName</code> feature to create unique names. In the examples below we will use <code>generateName</code> field with <code>kubectl</code> snippets instead of providing a fixed name.</p>"},{"location":"user-guide/network-topology/#create","title":"Create","text":"<p>To create a Network Topology select the <code>create</code> operation in the Network Topology workflow spec. Create operation will error if any of the topology resources already exist in the target namespace, therefore it is suitable for either creating a new topology in an empty namespace, or adding new nodes and links to an existing topology without modifying the existing resources.</p> <p>Since our brand new <code>net-topo-test</code> namespace is empty, we can safely create the topology there, using the following workflow:</p> Topology<code>kubectl</code> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: create- #(1)!\n  namespace: net-topo-test\nspec:\n  operation: create\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n</code></pre> <ol> <li>The <code>generateName</code> field is used to let Kubernetes generate a unique name for the workflow resource and is only applicable for cases when the workflow resource is created with <code>kubectl</code>. If you were to paste this snippet in the EDA UI, you would need to replace this field with the <code>name: some-unique-name</code> field.</li> </ol> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: create- #(1)!\n  namespace: net-topo-test\nspec:\n  operation: create\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n\nEOF\n</code></pre> <p>You should expect the workflow created for this topology to complete and two nodes and one link to be created in the <code>net-topo-test</code> namespace.</p> <p>Because the <code>create</code> operation adds new topology resources without modifying the existing ones, it is possible to use it to incrementally add new nodes and links to an existing topology. For example, if we wanted to add a new node <code>node3</code> and connect it to <code>node1</code>, we could create a new workflow with the <code>create</code> operation and provide the new node and its links in the spec.</p> Topology<code>kubectl</code> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: add-\n  namespace: net-topo-test\nspec:\n  operation: create\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node3\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: node1-node3\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-2\n          remote:\n            node: node3\n            interface: ethernet-1-1\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: add-\n  namespace: net-topo-test\nspec:\n  operation: create\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node3\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: node1-node3\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-2\n          remote:\n            node: node3\n            interface: ethernet-1-1\n\nEOF\n</code></pre> <p>The result of running this workflow will be that <code>node3</code> is added to the existing topology along with its link to <code>node1</code>, while <code>node1</code> and <code>node2</code> remain unchanged.</p>"},{"location":"user-guide/network-topology/#replace","title":"Replace","text":"<p>Replace operation is used to replace the existing topology with a new one and it comes in two variants - <code>replace</code> and <code>replaceAll</code>.</p> <p>When using <code>replace</code> operation, the workflow will only replace the existing topology resources whose names match the ones defined in the workflow spec. Topology resources that exist in the target namespace but are not part of the new topology definition will be left unmodified. The example below demonstrates changing <code>node2</code> definition by adding the node-level platform value, overriding the template. The result of this replace operation will be that <code>node1</code> will remain unchanged, but <code>node2</code> will have its platform set to <code>7220 IXR-D2L</code>.</p> Topology<code>kubectl</code> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: replace-\n  namespace: net-topo-test\nspec:\n  operation: replace\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n      platform: 7220 IXR-D2L\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: replace-\n  namespace: net-topo-test\nspec:\n  operation: replace\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: node1\n      template: node\n    - name: node2\n      template: node\n      platform: 7220 IXR-D2L\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: node1-node2\n      template: isl\n      endpoints:\n        - local:\n            node: node1\n            interface: ethernet-1-1\n          remote:\n            node: node2\n            interface: ethernet-1-1\n\nEOF\n</code></pre> <p>Changing node-specific parameters like platform, operating system, version, etc. triggers re-onboarding of the node.</p> <p>When using <code>replaceAll</code> operation, the workflow will first remove all topology resources from the targeted namespace and then add the resources defined in the workflow spec. This operation is useful when you want to completely replace the existing topology with a new one.</p> <p>Danger</p> <p>Running the workflow with the <code>replaceAll</code> operation will effectively delete all topology resources in the target namespace and create the new node and link objects as defined in the workflow spec. Use with caution to avoid unintentional topology changes.</p> <p>The below example demonstrates how the previous topology with <code>node1</code> and <code>node2</code> is replaced with a new topology that consists of the three nodes - <code>switch1</code>, <code>switch2</code>, and <code>switch3</code>, and two links connecting them. As you can see, the names of the nodes are different, but this is not a problem, because the <code>replaceAll</code> operation removes all previous nodes and links and replaces them with the new ones.</p> Topology<code>kubectl</code> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: replace-all-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: switch1\n      template: node\n    - name: switch2\n      template: node\n    - name: switch3\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: switch1-switch2\n      template: isl\n      endpoints:\n        - local:\n            node: switch1\n            interface: ethernet-1-1\n          remote:\n            node: switch2\n            interface: ethernet-1-1\n    - name: switch1-switch3\n      template: isl\n      endpoints:\n        - local:\n            node: switch1\n            interface: ethernet-1-2\n          remote:\n            node: switch3\n            interface: ethernet-1-1\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: replace-all-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: switch1\n      template: node\n    - name: switch2\n      template: node\n    - name: switch3\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: switch1-switch2\n      template: isl\n      endpoints:\n        - local:\n            node: switch1\n            interface: ethernet-1-1\n          remote:\n            node: switch2\n            interface: ethernet-1-1\n    - name: switch1-switch3\n      template: isl\n      endpoints:\n        - local:\n            node: switch1\n            interface: ethernet-1-2\n          remote:\n            node: switch3\n            interface: ethernet-1-1\n\nEOF\n</code></pre>"},{"location":"user-guide/network-topology/#delete","title":"Delete","text":"<p>Use <code>delete</code> operation to remove named topology resources from the target namespace or <code>deleteAll</code> operation to remove all topology resources from the target namespace.</p> <p>Continuing from the previous step where we had three nodes - <code>switch1</code>, <code>switch2</code>, and <code>switch3</code> - we can delete the <code>switch3</code> node by providing a workflow with the <code>delete</code> operation and specifying the name of the node and its link to be deleted.</p> Topology<code>kubectl</code> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: delete-\n  namespace: net-topo-test\nspec:\n  operation: delete\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: switch3\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: switch1-switch3\n      template: isl\n      endpoints:\n        - local:\n            node: switch1\n            interface: ethernet-1-2\n          remote:\n            node: switch3\n            interface: ethernet-1-1\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: delete-\n  namespace: net-topo-test\nspec:\n  operation: delete\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: switch3\n      template: node\n\n  linkTemplates:\n    - name: isl\n      type: interSwitch\n  links:\n    - name: switch1-switch3\n      template: isl\n      endpoints:\n        - local:\n            node: switch1\n            interface: ethernet-1-2\n          remote:\n            node: switch3\n            interface: ethernet-1-1\n\nEOF\n</code></pre> <p>To remove all topology resources from the target namespace, use the <code>deleteAll</code> with an empty spec:</p> Topology<code>kubectl</code> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: delete-all-\n  namespace: net-topo-test\nspec:\n  operation: deleteAll\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: delete-all-\n  namespace: net-topo-test\nspec:\n  operation: deleteAll\n\nEOF\n</code></pre> <p>Running this workflow will remove all topology resources from the <code>net-topo-test</code> namespace. No nodes will remain.</p>"},{"location":"user-guide/network-topology/#topology-checks","title":"Topology checks","text":"<p>Performing operations on the topology is a high-touch activity as removing or changing the nodes and links accidentally clearly impacts the network services running on top of the network. To reduce the risk of making accidental changes to the topology, the Network Topology workflow allows a user to run it in the Dry Run mode by setting the <code>.spec.checks.dryRun: true</code> field in the workflow spec.</p> <p>With Dry Run enabled, the workflow will pause and ask for the user's confirmation before adding/removing or changing any of the topology resources.</p> <p>To demonstrate how Dry Run works, we will create a workflow that uses the <code>replaceAll</code> operation to remove any existing topology and create a new one with just one <code>node1</code> node. The workflow definition is as follows:</p> Topology<code>kubectl</code> <pre><code>apiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: replace-all-check-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: switch1\n      template: node\n  checks:\n    dryRun: true\n</code></pre> <pre><code>cat &lt;&lt; 'EOF' | kubectl create -f -\napiVersion: topologies.eda.nokia.com/v1alpha1\nkind: NetworkTopology\nmetadata:\n  generateName: replace-all-check-\n  namespace: net-topo-test\nspec:\n  operation: replaceAll\n\n  nodeTemplates:\n    - name: node\n      nodeProfile: srlinux-ghcr-25.10.1\n      platform: 7220 IXR-D3L\n      labels:\n        eda.nokia.com/security-profile: managed\n  nodes:\n    - name: switch1\n      template: node\n  checks:\n    dryRun: true\n\nEOF\n</code></pre> <p>Because the <code>replaceAll</code> operation translates to two actions:</p> <ol> <li>Deleting all existing topology resources</li> <li>Creating new topology resources</li> </ol> <p>The workflow will pause two times, first asking to confirm the transaction that removes all existing topology elements and resources that were created for the nodes by EDA. After confirming this action, the workflow will proceed to the second pause where it will ask to confirm the creation of the new topology resources as a second transaction. The topology checks are implemented as a transaction in the Dry Run mode, hence you will be able to inspect the transaction details like for any other transaction in EDA.</p> <p>The below video demonstrates how the Dry Run mode works in practice.</p> <ol> <li> <p>Edge devices are not shown in the diagram because they are not (currently) managed by EDA and hence are not part of the topology. However, the links from the nodes to the edge devices must be modelled with <code>TopoLink</code> resources of type <code>edge</code> to allow EDA to manage these interfaces.\u00a0\u21a9</p> </li> <li> <p>Interface breakouts are not shown in the diagram because there are no breakouts defined in the \"Try EDA\" three-node topology. However, if there were any port breakouts on the nodes, they would be modelled with the <code>TopoBreakout</code> resources.\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/queries/","title":"EQL - the EDA Query Language","text":"<p>A key philosophy of EDA is to make state streamable for further processing, where state can be sourced externally via gRPC, internally via core services, or locally via Kubernetes. Beyond being used as event triggers, state is incredibly useful for debugging, and so we required a means to allow humans to interact with it also. Enter the EDA Query Language, or EQL.</p> <p>Loosely based on Jira Query Language, EQL allows the full surface area of the EDA API, all state info in EDB, along with the full surface area of managed endpoints to be queried and parsed in real time. Queries can be made real time in the heat of troubleshooting, with instantaneous, streaming results. Queries can be sourced as data for visualizations, and streamed via the API or StateAggregator, allowing external applications to constrain event triggers.</p> <p>The easiest way to interact with queries is via the UI - simply click <code>Queries</code> in the navigation menu. You optionally can use the REST API, or <code>edactl</code>.</p> <p>A \"query\" consists of:</p> <ul> <li>A <code>Table</code>, being the only mandatory portion, e.g. <code>.namespace.node.srl.interface</code>.</li> <li>A <code>Selector</code> denoted by the <code>fields</code> keyword, defining an array of fields to return (along with any functions to run on said fields), e.g. <code>.namespace.node.srl.interface fields [oper-state, admin-state]</code>.</li> <li>A <code>Filter</code> denoted by the <code>where</code> keyword, defining an expression contained within parenthesis in which to include or exclude results, e.g. <code>.namespace.node.srl.interface where (admin-state = \"disable\" and .node.name = \"leaf1\")</code>.</li> <li>A <code>Sort</code>, denoted by the <code>order by</code> by keyword indicating the sorting that should be applied to the data before it is returned, e.g. <code>.namespace.node.srl.platform.control.process order by [memory-usage descending]</code>.</li> <li>A <code>Limit</code>, denoted by the <code>limit</code> keyword, limiting the number of results returned, e.g. <code>.namespace.node.srl.interface limit 10</code>.</li> <li>A <code>Frequency</code>, denoted by the <code>delta</code> or <code>sample</code> keywords, indicating the minimum update period for the query, e.g. <code>.namespace.node.srl.interface delta milliseconds 1000</code>, or the desire to receive data at a specified interval, irrespective of changes.</li> </ul>"},{"location":"user-guide/queries/#natural-language","title":"Natural language","text":"<p>Shipping in this release is an implementation of queries using natural language. After opening the query interface in the UI, select the drop down and select <code>Natural Language</code>.</p> <p>Tip</p> <p>Try <code>Show me my up interfaces</code></p> <p>Note</p> <p>You may need an API key configured in the <code>.spec.llm</code> context of your <code>EngineConfig</code>.</p>"},{"location":"user-guide/queries/#table","title":"Table","text":"<p>A <code>Table</code> is specified in jspath notation, with a boundary at all lists and containers within a endpoints schema, or within containers/lists provided by StateEngine scripts or external gRPC publishers via StateController.</p> <p>In simple terms each 'node' within the jspath is its own table - <code>.namespace.node</code> is a table, <code>.namespace.node.srl</code> is a table, and <code>.namespace.node.srl.interface</code> is a table. Tables cannot currently be qualified with keys - instead a <code>where</code> should be used.</p> <p>For example, to select all interfaces on a specific node:</p> <pre><code>.namespace.node.srl.interface where (.node.name = \"leaf1\")\n</code></pre> <p>Note</p> <p>Note that <code>.namespace.node.srl</code> is only relevant for SR Linux devices. SR OS devices publish to <code>.namespace.node.sros</code>, and StateEngine apps that normalize data should publish to <code>.namespace.node.normal</code>.</p>"},{"location":"user-guide/queries/#selector","title":"Selector","text":"<p>A <code>Selector</code> is denoted by the <code>fields</code> keyword, where the value is an array of fields to return, along with any functions to run. For example <code>.namespace.node.srl.interface FIELDS [admin-state, description] ORDER BY [oper-state ascending natural]</code>.</p> <p>No fields other than those defined are returned, if no fields are selected then all fields from the table are returned.</p> <p>The <code>fields</code> keyword must precede any <code>where</code> or <code>order by</code> keywords.</p> <p>A set of functions should be available to assist with evaluation and aggregation, for example: average() to evaluate the average of a field matching a Filter over time (the time window here is currently fixed to the current set of data). count() to return the count of unique combinations matching a Filter. sum() to sum the values for a given field matching a Filter.</p>"},{"location":"user-guide/queries/#filter","title":"Filter","text":"<p>A <code>Filter</code> is a string defining any filters to use, a <code>Filter</code> is defined with a <code>where</code> term.</p> <p>A <code>Filter</code> consists of an ordered set of fields, operators, values, and keywords. Keywords may be capitalized or may not, for example both <code>and</code> and <code>AND</code> are valid.</p> <p>Operators include <code>=</code>, <code>!=</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>&gt;</code>, <code>&lt;</code>, <code>in</code>, <code>not in</code>.</p> <ul> <li><code>in</code> is provided an array of values, for example <code>.node.srl.interface where (oper-state in [\"up\", \"down\"])</code>.</li> <li><code>in</code> may also take the values of another field if that field is a leaf-list (i.e. an array).</li> </ul> <p>A <code>Filter</code> may string together multiple criteria through the use of <code>()</code>, and the keywords <code>AND</code>, and <code>OR</code>. Note that even when using a single <code>where</code> statement it must be contained within <code>()</code>.</p> <p>For example <code>.table where ((oper-state = \"down\" and mtu = 1500) or oper-state = \"up\")</code>.</p> <p>A <code>Filter</code> may query ancestor keys and values by referencing their full jspath.</p> <p>For example, to add <code>Filter</code> criteria for a parent key <code>.namespace.node.srl.interface.subinterface where (.node.name = \"leaf1\")</code>.</p> <p>You may not currently filter on parent fields other than the key.</p>"},{"location":"user-guide/queries/#sort","title":"Sort","text":"<p>A <code>Sort</code> is similar to a <code>Filter</code>, but rather than describing how to select data, it describes how to return data. A <code>Sort</code> is denoted by the <code>ORDER BY</code> keywords which control the ordering (sorting) of data.</p> <p>A query may include a single <code>ORDER BY</code> keyword, where the value is an array of (fields, sorting algorithms, and directions) which are evaluated in the order they are presented.</p> <p>For example <code>.namespace.node.srl.interface ORDER by [oper-state ascending natural]</code>.</p> <p>The second value may be either <code>ascending</code> or <code>descending</code>. The third value is optional and indicates the algorithm to use. Only <code>natural</code> is currently supported.</p>"},{"location":"user-guide/queries/#limit","title":"Limit","text":"<p>A <code>Limit</code> is processed after any other operations (perhaps most relevant the <code>Sort</code> operation), denoted by the <code>limit</code> keyword, limiting the number of results that are returned.</p> <p><code>limit</code> accepts a single integer value. This can be combined with <code>Sort</code> to get the 'top' N results, or the 'bottom' N results, where N is the value provided to the <code>limit</code> keyword.</p> <p>The maximum value for <code>limit</code> is <code>1000</code>, and the minimum value is <code>1</code>.</p>"},{"location":"user-guide/queries/#frequency","title":"Frequency","text":"<p>A <code>Frequency</code> allows an end user to control the rate at which data is returned, and is denoted by the <code>delta</code> keyword.</p> <p>The <code>delta</code> keyword must be passed two values - one denoting the units used, and another the actual value. For example <code>.namespace.node.srl.interface.traffic-rate where (in-bps != 0) delta milliseconds 1000</code>. Meaning do not update the client more than once every 1 second.</p> <p>The value is the minimum period at which results will be updated for the query, or put another way it controls the maximum rate at which the client will be updated.</p>"},{"location":"user-guide/transactions/","title":"Transactions","text":""},{"location":"user-guide/transactions/#introduction","title":"Introduction","text":"<p>Transactions form the foundation of EDA's powerful revision control system and add sought-after reliability to infrastructure automation by applying the changes atomically, network-wide. Every action that leads to a config change in EDA - modifying a resource, installing an EDA application, upgrading a network operating system - is processed as a transaction.  </p> <p>At a very high-level, EDA transactions have three main steps:</p> <ol> <li>Generate config from abstractions</li> <li>Deploy config changes, network-wide</li> <li>Commit to Git for revision control</li> </ol> <p>In EDA, deploy and commit are inseparable. If the change is not deployable on any of the target node, the whole transaction is pronounced failed and the changes are reverted from all nodes. This means users can't commit changes that the network can't apply \u2014 every commit to Git is a point-in-time of the network's configuration history.<sup>1</sup> With a single command, you can roll back the entire network from the commit history. Your maintenance window back out just got a whole lot easier!</p> Details of the transaction steps <ol> <li>Generate config from abstractions<ul> <li>Run all configuration intent scripts which have a dependency on the resources in the transaction.<sup>2</sup></li> <li>Compile node configurations pieces from the intent scripts' outputs into full node configurations.</li> <li>Perform YANG schema validation on the full node configurations. If schema is invalid, transaction fails here.</li> </ul> </li> <li>Deploy config changes, network-wide<ul> <li>Push new configuration to all nodes with commit confirmation.</li> <li>If any node rejects the new config, transaction fails here and EDA performs a network-wide roll-back.</li> </ul> </li> <li>Commit to Git for revision control<ul> <li>Create a Git commit</li> <li>Push commit to remote Git server(s) for backup</li> </ul> </li> </ol>"},{"location":"user-guide/transactions/#whats-in-a-transaction-commit","title":"What's in a Transaction Commit?","text":"<p>Whenever you create/update/delete a resource in EDA, a number of scripts associated with this resource run. We call these scripts \"intents\".</p> <p>Intents have strict idempotency where every intent run with the same set of inputs will result in the same set of outputs. Always. Therefore EDA has no need to persistently store anything that can be derived or computed. EDA stores intent scripts, input resources, and pool allocations in Git - and that's it!<sup>3</sup></p> <p>Yes, that's right, EDA does not backup node configs - we simply don't need them for revision control and omitting those large repetitive files lets us scale the Git repo to very large networks.</p>"},{"location":"user-guide/transactions/#transaction-basket","title":"Transaction Basket","text":"<p>Multiple EDA resource changes can be applied together to fate-share a set of changes. The EDA UI uses a basket to represent this. When committing from the basket all resources are applied as a single transaction - if the transaction fails, none of the changes from the basket are committed.</p> <p>For REST API and Kubernetes users, the basket concept can be used via the Transaction API and the Transaction CRD, respectively.</p>"},{"location":"user-guide/transactions/#transaction-results","title":"Transaction Results","text":""},{"location":"user-guide/transactions/#summary","title":"Summary","text":"<p>EDA stores the result of a transaction for users to review. Here is some of the terminology you'll find in the results:</p> <ul> <li><code>Input Resources</code> - Resources created, updated or deleted by the user.</li> <li><code>Intents Run</code> - Configuration intent scripts executed during the transaction.</li> <li><code>Output Resources</code> - Resources derived from the intent run.</li> <li><code>Changed Resources</code> - Input and Output resources that are changed, compared to the previous committed transaction.</li> <li><code>Nodes Affected</code> - Nodes which are impacted by this transaction. This includes node configuration changes, node version changes, or changes to the associated TopoNode resource in EDA.</li> </ul> <p>Error Types:</p> <ul> <li><code>Intent Errors</code> - Errors returned by an intent script</li> <li><code>Node Config Errors</code> - Error in YANG schema validation or errors returned by the node when pushing configuration</li> <li><code>General Errors</code> - Errors related to the EDA environment</li> </ul>"},{"location":"user-guide/transactions/#diffs","title":"Diffs","text":"<p>Diff of all changed resources and changed node configurations in the transaction.</p>"},{"location":"user-guide/transactions/#transaction-topology","title":"Transaction Topology","text":"<p>Transaction Topology displays all input and output resources of a transaction and graphs the relationship between derived and parent resources.</p> <p>Changed resources are colored yellow in the topology, and if an intent error occurred during the transaction the related resource is colored red.</p> Transaction Topology Limitations <ol> <li> <p>Transaction Topology graphs the createUpdate relationships between resources. Read relationships are not graphed. For example: The Fabric intent reads from allocation pool resources. The link between the Fabric resource and the allocation pool resources is not displayed in the topology.</p> </li> <li> <p>Transaction Topology is not available for transaction results with more than 10,000 resources.</p> </li> </ol>"},{"location":"user-guide/transactions/#detail-level","title":"Detail Level","text":"<p>For all transactions committed to Git, EDA can always display the input resources and their diffs. Data not in Git (e.g. failed transaction, dry-run transactions, output resources, node configuration diffs, etc.) are stored in-memory for a limited time.</p> <p>There are three possible detail levels for transaction results:</p> <ul> <li><code>Detailed</code><ul> <li>Includes full transaction results</li> <li>All transactions created via EDA UI use this detail level</li> </ul> </li> <li><code>Standard</code><ul> <li>Does not include the changed resources list, changed resource diffs, and node configuration diffs</li> <li>This is the default detail level for transactions created via EDA API and Kubernetes. It is intended for optimized performance when processing frequent transactions from 'machine interfaces'.</li> </ul> </li> <li><code>Basic</code><ul> <li>Includes only data available in Git</li> </ul> </li> </ul> <p>EDA uses the following rules for removing detailed and standard transaction results:</p> <ul> <li>Keep details for a guaranteed 25 transactions per user<sup>4</sup></li> <li>Keep a maximum 10,000 resource diffs per user \u2014 details from the oldest transactions will be purged if this limit is exceeded</li> <li>Committed transactions are reduced to the basic detail level</li> <li>Failed and dry-run transactions are purged from the transaction log</li> </ul>"},{"location":"user-guide/transactions/#the-nodeconfig-resource","title":"The NodeConfig Resource","text":"<p>NodeConfig is a special resource in EDA that is not published to EDB or Kubernetes but you will often see in transaction results. These function as an internal configlet which intent scripts create to contribute specific sections of node configuration. EDA combines all the nodeConfig resources into a complete node configuration. This is why you'll see both 'NodeConfig' and 'Node Configuration' in the transaction diffs.</p>"},{"location":"user-guide/transactions/#advanced-filter","title":"Advanced Filter","text":"<p>The EDA UI offers an 'Advanced' toggle for transaction results. When toggled off, internal EDA resources are hidden from the results.</p>"},{"location":"user-guide/transactions/#dry-run","title":"Dry-Run","text":"<p>What if you want to review the configuration changes before pushing to the network? That's where dry-run comes in. Any transaction can be executed as a dry run. This performs all config generation and YANG schema validation, but does not push any changes to the network.</p>"},{"location":"user-guide/transactions/#revert-and-restore","title":"Revert and Restore","text":"<p>EDA exposes <code>Revert</code> and <code>Restore</code> actions for each committed transaction:</p> <ul> <li><code>Revert</code> sets all the input resources from a specific transaction back to the previous commit<sup>5</sup></li> <li><code>Restore</code> sets all EDA resources, apps, and allocations to exactly as they were at the specified commit</li> </ul> <p>Both actions are executed as a new transaction and committed with a new commit hash, i.e., the commit history always moves forward even if the transaction is a roll-back of changes.</p> <ol> <li> <p>\"But what if I change config outside EDA?\" Don't worry, EDA detects the deviation and commits it to the transaction log.\u00a0\u21a9</p> </li> <li> <p>Configuration intent scripts use the latest commit and the transaction input to derive resource and pieces of node configuration. The term 'declarative abstraction' is often used to describe this process.\u00a0\u21a9</p> </li> <li> <p>Additional data is stored in Git (User settings, user created dashboards, KeyCloak DBs, etc.) but these are not relevant to transactions.\u00a0\u21a9</p> </li> <li> <p>If there are outstanding in-progress transactions, a user can temporarily have more than 25 transactions\u00a0\u21a9</p> </li> <li> <p>If a more recent transaction made changes to any of the input resources, revert will fail. This prevents 'undoing' changes that are not part of the selected transaction.\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/using-the-clis/","title":"Using the CLIs","text":"<p>EDA exposes two north-bound APIs to its users - Kubernetes API and EDA API - and an in-cluster gRPC API. You used the Kubernetes API when you managed EDA resources using the <code>kubectl</code> CLI in the Getting Started guide. And you used the EDA's REST API when you, for example, opened the EDA UI in your browser.</p> <p>On top of the offered APIs we build CLI tools like <code>edactl</code> and <code>e9s</code> which come handy in certain scenarios where CLI access is preferred.</p> <p><code>edactl</code> provides a comprehensive suite of commands that allow users to create, query, update and delete resources within an EDA cluster, making it ideal for scripting and automation.</p> <p>On the other hand, <code>e9s</code> offers a dynamic, real-time terminal-based UI that simplifies the interaction with clusters by providing a high-level overview and quick navigation options for common tasks. While <code>edactl</code> demands precise command inputs, <code>e9s</code> excels in offering visual feedback and streamlined workflows, significantly reducing the complexity and time needed for cluster management tasks.</p> <p>In addition to EDA-specific CLIs, users get to benefit from the vast ecosystem of tools available in the Kubernetes ecosystem. We will cover some of such tools in this section as well.</p>"},{"location":"user-guide/using-the-clis/#edactl","title":"edactl","text":"<p><code>edactl</code> is your go-to tool for scripting, managing and automating pipelines with EDA. A swiss-knife for EDA users.</p> <p><code>edactl</code> is preinstalled in the <code>eda-toolbox</code> pod. You can either connect to the toolbox pod<sup>1</sup> and execute the utility directly from there, or you can setup a handy alias (for example in your <code>~/.zshenv</code>) to make it easily accessible.</p> Setting up <code>edactl</code> alias<pre><code>alias edactl='kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- edactl'\n</code></pre> <p>It offers a comprehensive suite of commands that enable users to interact seamlessly with an EDA cluster.</p> edactl commands<pre><code>Available Commands:\n  cluster      Show the cluster status\n  completion   Generate the autocompletion script for the specified shell\n  config       Interactions with EDACONFIG\n  edge-if-ping Ping from an edge interface\n  get          Displays one or many resources\n  git          Git related commands\n  help         Help about any command\n  intent       intent [config | state]\n  labels       Display the label key/values in use\n  namespace    Display active namespaces\n  node         Node related commands\n  platform     Platform related commands\n  query        Run an EQL query\n  sdk          Manipulate EDA sdk\n  sub          Subscribe to state updates\n  testman      testman related commands\n  transaction  List transaction results\n  workflow     Workflow related commands\n</code></pre> <p>For example, to query all interfaces with operational state <code>up</code> execute the following command while in the <code>eda-toolbox</code> pod:</p> <pre><code>edactl query '.namespace.node.srl.interface where (oper-state = \"up\")'\n</code></pre> <pre><code> Namespace Name    Node Name    Name           Admin State    Mtu    Loopback Mode    Ifindex     Oper State    Oper Down Reason    Last Change               Linecard    Forwarding Complex    Forwarding Mode    Vlan Tagging    Tpid         Description              Num Physical Channels\n eda               leaf1        ethernet-1/1   enable         9232   none             16382       up                                2024-12-13T10:11:38.554Z  1           0                     store-and-forward  false           TPID_0X8100\n eda               leaf1        ethernet-1/2   enable         9232   none             49150       up                                2024-12-13T10:11:38.606Z  1           0                     store-and-forward  false           TPID_0X8100\n eda               leaf1        ethernet-1/3   enable         9232   none             81918       up                                2024-12-13T10:11:38.674Z  1           0                     store-and-forward  true            TPID_0X8100\n</code></pre>"},{"location":"user-guide/using-the-clis/#e9s","title":"e9s","text":"<p><code>e9s</code> is the Terminal UI (TUI) for EDA and can help you interact with the platform similar to how you'd use the famous <code>k9s</code> for Kubernetes.</p> <p>It comes preinstalled in the <code>eda-toolbox</code> pod. You can either connect to the toolbox pod<sup>1</sup> and execute the utility directly from there, or you can setup a handy alias (for example in your <code>~/.zshenv</code>) to make it easily accessible.</p> e9s<pre><code>alias e9s='kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- sh -c \"TERM=xterm-256color e9s\"'\n</code></pre> <p>And behold the power of <code>e9s</code>!</p> <p></p> <p>Here is a quick demonstration on how to use the powerful EDA Query Language (EQL) to run queries in <code>e9s</code>:</p>"},{"location":"user-guide/using-the-clis/#kubectl","title":"kubectl","text":"<p><code>kubectl</code> is the CLI to reach for when interacting with Kubernetes. It is also downloaded as part of the playground setup and can be found in the <code>tools</code> directory of the playground repository. If you don't <code>kubectl</code> installed, you can copy the binary from the playground repo like so:</p> assuming your playground repo is in <code>~/nokia-eda/playground</code><pre><code>sudo cp $(realpath ~/nokia-eda/playground/tools/kubectl) /usr/local/bin/kubectl\n</code></pre>"},{"location":"user-guide/using-the-clis/#k9s","title":"k9s","text":"<p>k9s is a TUI for Kubernetes clusters that you can see in many of our demos. Once in a while you would want to inspect the state of your cluster in a more graphical way than just using <code>kubectl</code> - that is when <code>k9s</code> comes in handy.</p> <p>As with <code>kubectl</code> you can copy it from the playground repo:</p> assuming your playground repo is in <code>~/nokia-eda/playground</code><pre><code>sudo cp $(realpath ~/nokia-eda/playground/tools/k9s) /usr/local/bin/k9s\n</code></pre>"},{"location":"user-guide/using-the-clis/#lnav","title":"lnav","text":"<p>EDA is composed of many microservices, and it is often useful to have a log viewer to quickly inspect the logs distributed across the pods.</p> <p>The log aggregation that EDA uses is based on fluentbit/fluentd combination with the logs aggregated in the <code>eda-fluentd</code> deployment. To browse the logs you can use the lnav CLI you would find in this deployment.</p> <p>For convenience, you can set up an alias to quickly access the TUI logs viewer:</p> <pre><code>alias edalogs='kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=fluentd -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- sh -c \"TERM=xterm-256color lnav /var/log/eda/*/*/*.log\"'\n</code></pre>"},{"location":"user-guide/using-the-clis/#helm","title":"helm","text":"<p>Helm is one of the many package managers for Kubernetes. You might want to add it to your PATH to install additional apps and deployments on your cluster. For example, you may install the NetBox stack and test EDA&lt;-&gt;NetBox integration, all done in a single cluster.</p> <p>The <code>helm</code> CLI is downloaded by the playground installer, so you can fetch it and use it right away like so:</p> assuming your playground repo is in <code>~/nokia-eda/playground</code><pre><code>sudo cp $(realpath ~/nokia-eda/playground/tools/helm) /usr/local/bin/helm\n</code></pre> <ol> <li> <p>You can log in to the <code>eda-toolbox</code> pod using the following command executed from the playground repository:</p> <pre><code>make open-toolbox\n</code></pre> <p>Or using this command when running outside the playground repository:</p> <p><pre><code>kubectl -n eda-system exec -it $(kubectl -n eda-system get pods \\\n-l eda.nokia.com/app=eda-toolbox -o jsonpath=\"{.items[0].metadata.name}\") \\\n-- env \"TERM=xterm-256color\" bash -l\n</code></pre> \u21a9\u21a9</p> </li> </ol>"},{"location":"blog/author/rdodin/","title":"Roman Dodin","text":""},{"location":"blog/author/bwallis/","title":"Bruce Wallis","text":""}]}